{
  "combined_from": [
    "results/features/did3__image_classification_mnist__gpt-5-mini.json",
    "results/features/funsearch__image_classification_mnist__gpt-5-mini.json"
  ],
  "used_features": [
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity correlation (-1..1): correlation between radius and pixel intensity (negative => decays outward)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy).ravel()\n    vals = a.ravel().astype(float)\n    if vals.size == 0:\n        return 0.0\n    rx = r - r.mean()\n    vx = float((rx ** 2).sum())\n    vy = float(((vals - vals.mean()) ** 2).sum())\n    if vx <= 0.0 or vy <= 0.0:\n        return 0.0\n    cov = float((rx * (vals - vals.mean())).sum())\n    corr = cov / (np.sqrt(vx * vy) + eps)\n    result = float(np.clip(corr, -1.0, 1.0))\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate count of stroke endpoints (foreground pixels with <=1 8-neighbors)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.mean(gray)\n    fg = (gray > thr).astype(np.uint8)\n    if fg.sum() == 0:\n        return 0.0\n    p = np.pad(fg, pad_width=1, mode='constant', constant_values=0)\n    # sum of 8 neighbors\n    neigh = (\n        p[0:-2,0:-2] + p[0:-2,1:-1] + p[0:-2,2:] +\n        p[1:-1,0:-2] +               p[1:-1,2:] +\n        p[2:,0:-2]   + p[2:,1:-1]   + p[2:,2:]\n    )\n    neigh = neigh * fg  # align dims (neigh already same shape as fg)\n    endpoints = np.count_nonzero((fg == 1) & (neigh <= 1))\n    return float(endpoints)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of local intensity maxima (peaks) above adaptive threshold'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    # neighbors via roll but mask out wrap-around by setting wrapped rows/cols to -inf\n    neighbors = []\n    shifts = [(-1, 0), (1, 0), (0, -1), (0, 1), (-1, -1), (-1, 1), (1, -1), (1, 1)]\n    for dy, dx in shifts:\n        nb = np.roll(a, shift=dy, axis=0)\n        nb = np.roll(nb, shift=dx, axis=1)\n        # mask wrapped rows/cols\n        if dy == -1:\n            nb[-1, :] = -np.inf\n        if dy == 1:\n            nb[0, :] = -np.inf\n        if dx == -1:\n            nb[:, -1] = -np.inf\n        if dx == 1:\n            nb[:, 0] = -np.inf\n        neighbors.append(nb)\n    gt_all = np.ones_like(a, dtype=bool)\n    for nb in neighbors:\n        gt_all &= (a > nb)\n    peaks = gt_all & (a > thr)\n    count = float(np.sum(peaks))\n    result = count / (float(h * w) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of columns that contain a horizontal stroke across the middle third band (detects middle bar typical of 5)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.mean(gray)\n    ink = (gray < thr)\n    top = h // 3\n    bottom = min(h, 2 * (h // 3) + (h % 3 > 0))\n    mid_band = ink[top:bottom, :]\n    if mid_band.size == 0:\n        return 0.0\n    # a column is counted if there is continuous ink across at least half of the vertical span of mid_band\n    vertical_span = mid_band.shape[0]\n    if vertical_span == 0:\n        return 0.0\n    counts_per_col = np.sum(mid_band, axis=0)\n    strong_cols = counts_per_col >= (vertical_span * 0.4)  # threshold\n    frac = float(np.count_nonzero(strong_cols)) / float(w)\n    return frac\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score (1.0 = perfectly symmetric, 0.0 = very asymmetric)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 1.0\n    mid = w // 2\n    left = a[:, :mid]\n    if w % 2 == 0:\n        right = a[:, mid:]\n    else:\n        right = a[:, mid+1:]\n    # make same shape by cropping larger side\n    minw = min(left.shape[1], right.shape[1])\n    if minw == 0:\n        return 1.0\n    l = left[:, :minw]\n    r = right[:, :minw][:, ::-1]  # mirror right side\n    num = float(np.sum(np.abs(l - r)))\n    den = float(np.sum(np.abs(l) + np.abs(r)) + eps)\n    diff = num / den\n    sym = 1.0 - diff\n    return float(np.clip(sym, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of vertical gradient energy in the right third of the image (vertical_grad_energy_right / total_grad_energy)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # normalize\n    gmax = gray.max() if gray.size else 1.0\n    if gmax > 0:\n        gray = gray / float(gmax)\n    # gradients\n    try:\n        gy, gx = np.gradient(gray)\n    except Exception:\n        return 0.0\n    vert_energy = np.abs(gy)\n    total_energy = np.sum(np.abs(gy)) + np.sum(np.abs(gx)) + 1e-9\n    h, w = gray.shape[:2]\n    start = (2 * w) // 3\n    right_energy = np.sum(vert_energy[:, start:]) if start < w else 0.0\n    return float(right_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized preference between the two diagonal gradient directions: (sum|dx+dy|-sum|dx-dy|) / (sum total)'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float32)\n    else:\n        gray = image.astype(np.float32)\n    try:\n        dy, dx = np.gradient(gray)\n    except Exception:\n        dy = np.zeros_like(gray)\n        dx = np.zeros_like(gray)\n    diag1 = np.sum(np.abs(dx + dy))\n    diag2 = np.sum(np.abs(dx - dy))\n    return float((diag1 - diag2) / (diag1 + diag2 + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry: mean absolute difference between halves normalized by intensity range'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    if left.shape[1] != right.shape[1]:\n        # ensure same width by cropping the larger one\n        minw = min(left.shape[1], right.shape[1])\n        left = left[:, :minw]\n        right = right[:, :minw]\n    right_flipped = np.fliplr(right)\n    if left.size == 0 or right_flipped.size == 0:\n        return 0.0\n    mad = float(np.mean(np.abs(left - right_flipped)))\n    denom = float(a.max() - a.min()) + eps\n    result = mad / denom\n    result = float(np.clip(result, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical center-of-mass of intensity normalized to [-1..1] (negative => top)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0:\n        return 0.0\n    # make non-negative weights\n    weights = a - float(a.min())\n    total = float(weights.sum())\n    if total <= eps:\n        return 0.0\n    ys = np.arange(h)[:, None]\n    cog_y = float((weights * ys).sum() / total)\n    result = 2.0 * (cog_y / max(1.0, (h - 1))) - 1.0\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink mass in rightmost 25% strip to leftmost 25% strip (right_density / (left_density + eps))'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    mn, mx = gray.min(), gray.max()\n    if mx - mn > 1e-8:\n        gray = (gray - mn) / (mx - mn)\n    else:\n        gray = gray * 0.0\n    h, w = gray.shape[:2]\n    ink = gray < 0.5\n    if np.mean(ink) > 0.5:\n        ink = ~ink\n    quarter = max(1, w // 4)\n    left = ink[:, :quarter]\n    right = ink[:, -quarter:]\n    left_sum = float(np.count_nonzero(left))\n    right_sum = float(np.count_nonzero(right))\n    return float(right_sum / (left_sum + 1e-6))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Balance of bright vs dark pixels: (bright_count - dark_count) / total in [-1..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    vmin = float(flat.min())\n    vmax = float(flat.max())\n    if vmax - vmin <= 0:\n        return 0.0\n    bright_thresh = vmax - 0.1 * (vmax - vmin)\n    dark_thresh = vmin + 0.1 * (vmax - vmin)\n    bright = float((flat >= bright_thresh).sum())\n    dark = float((flat <= dark_thresh).sum())\n    result = (bright - dark) / (flat.size + eps)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of block-wise local contrast normalized by global std'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # choose block size relative to image\n    blk_h = max(1, h // 8)\n    blk_w = max(1, w // 8)\n    stds = []\n    for y in range(0, h, blk_h):\n        for x in range(0, w, blk_w):\n            block = a[y:y+blk_h, x:x+blk_w]\n            if block.size:\n                stds.append(float(block.std()))\n    if not stds:\n        return 0.0\n    stds = np.array(stds, dtype=float)\n    global_std = float(a.std()) + eps\n    result = float(stds.std()) / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of local bright peaks (3x3 maxima above mean+std)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    thr = float(img.mean() + img.std())\n    center = img\n    # compare to 8 neighbors using rolled versions (wrap-around is acceptable here)\n    neigh_ge = np.ones_like(img, dtype=bool)\n    shifts = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n    for dy, dx in shifts:\n        neigh = np.roll(np.roll(img, dy, axis=0), dx, axis=1)\n        neigh_ge &= (center >= neigh)\n    peaks = neigh_ge & (center > thr)\n    count = float(np.count_nonzero(peaks))\n    result = count / float(h * w + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of horizontal ink runs across the center row (how many separated ink segments), normalized by width'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    center_row = h // 2\n    thresh = np.percentile(gray, 50)\n    ink_dark = np.mean(gray.flatten()[:max(1, int(0.05*h*w))]) < np.mean(gray.flatten()[-max(1, int(0.05*h*w)):])\n    if ink_dark:\n        row = (gray[center_row, :] < thresh)\n    else:\n        row = (gray[center_row, :] > thresh)\n    # count runs of True in the row\n    runs = 0\n    inrun = False\n    for v in row:\n        if v and not inrun:\n            runs += 1\n            inrun = True\n        elif not v:\n            inrun = False\n    return float(runs / (w + 1e-8))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (>=1) of bounding box of bright region (pixels > mean+std); 0 if no bright region'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + a.std())\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    rows = np.any(mask, axis=1)\n    cols = np.any(mask, axis=0)\n    ymin = int(np.argmax(rows))\n    ymax = int(mask.shape[0] - 1 - np.argmax(rows[::-1]))\n    xmin = int(np.argmax(cols))\n    xmax = int(mask.shape[1] - 1 - np.argmax(cols[::-1]))\n    height = max(1, ymax - ymin + 1)\n    width = max(1, xmax - xmin + 1)\n    ratio = float(width) / float(height + eps)\n    # report ratio >=1 for scale-invariant measure\n    if ratio < 1.0:\n        ratio = 1.0 / (ratio + eps)\n    return float(np.clip(ratio, 0.0, 100.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Max of horizontal and vertical mirror similarity (1=perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    def sim(mat, flipped):\n        diff = np.abs(mat - flipped)\n        denom = np.mean(np.abs(mat - np.mean(mat))) + eps\n        score = 1.0 - (np.mean(diff) / denom)\n        return float(np.clip(score, 0.0, 1.0))\n    hor_sim = sim(a, a[:, ::-1])\n    ver_sim = sim(a, a[::-1, :])\n    result = max(hor_sim, ver_sim)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient direction bias: (mean|gx|-mean|gy|) / (mean|gx|+mean|gy|) in [-1..1]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    magx = float(np.mean(np.abs(gx))) + eps\n    magy = float(np.mean(np.abs(gy))) + eps\n    result = (magx - magy) / (magx + magy)\n    return float(np.clip(result, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency energy ratio from FFT (0..1), higher => smoother / large-scale structure'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute centered FFT power spectrum\n    F = np.fft.fft2(a - a.mean())\n    Fshift = np.fft.fftshift(F)\n    power = np.abs(Fshift) ** 2\n    # low-frequency square window around center: size = min(h,w)//4\n    cx = w // 2\n    cy = h // 2\n    r = max(1, min(h, w) // 8)\n    y0 = max(0, cy - r)\n    y1 = min(h, cy + r + 1)\n    x0 = max(0, cx - r)\n    x1 = min(w, cx + r + 1)\n    low = power[y0:y1, x0:x1].sum()\n    total = power.sum() + eps\n    result = float(low / total)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean dominant gradient orientation (circular mean) in the top-right quadrant, normalized to [-1,1] (captures slanted top-right strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 4 or w < 4:\n        return 0.0\n    r0, c0 = 0, w//2\n    r1, c1 = h//2, w\n    region = gray[r0:r1, c0:c1]\n    if region.size == 0:\n        return 0.0\n    gy, gx = np.gradient(region.astype(float))\n    mag = np.hypot(gx, gy)\n    mask = mag > (np.percentile(mag, 50) * 0.2 + 1e-9)\n    if not np.any(mask):\n        return 0.0\n    angles = np.arctan2(gy[mask], gx[mask])  # range -pi..pi\n    mean_sin = float(np.mean(np.sin(angles)))\n    mean_cos = float(np.mean(np.cos(angles)))\n    mean_angle = np.arctan2(mean_sin, mean_cos)\n    # normalize to [-1,1]\n    result = float(mean_angle / np.pi)\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean color saturation for RGB images normalized by image dynamic range (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim < 3 or arr.shape[2] < 3:\n        return 0.0\n    # use first three channels as RGB-like\n    rgb = np.nan_to_num(arr[..., :3].astype(float))\n    # per-pixel mean\n    m = rgb.mean(axis=2, keepdims=True)\n    diff = rgb - m\n    chroma = np.sqrt(((diff ** 2).sum(axis=2)) / 3.0)\n    rng = float(rgb.max() - rgb.min()) + eps\n    result = float(np.mean(chroma) / rng)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute Laplacian in center region to mean absolute Laplacian in outer region'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, gyx = np.gradient(gy)\n        gxy, gxx = np.gradient(gx)\n    except Exception:\n        return 0.0\n    lap = gxx + gyy\n    ch = max(1, h // 4)\n    cw = max(1, w // 4)\n    r0 = max(0, h//2 - ch//2)\n    r1 = min(h, r0 + ch)\n    c0 = max(0, w//2 - cw//2)\n    c1 = min(w, c0 + cw)\n    center = np.abs(lap[r0:r1, c0:c1])\n    border_mask = np.ones_like(lap, dtype=bool)\n    border_mask[r0:r1, c0:c1] = False\n    border = np.abs(lap[border_mask])\n    if center.size == 0 or border.size == 0:\n        return 0.0\n    mean_c = float(center.mean())\n    mean_b = float(border.mean())\n    result = mean_c / (mean_b + eps)\n    return float(np.clip(result, 0.0, 100.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Corner brightness contrast: (mean corners - mean center) normalized by global std'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = img.mean(axis=2).astype(float)\n    else:\n        a = img.astype(float)\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cs = max(1, min(h, w) // 8)\n    corners = []\n    corners.append(a[:cs, :cs])\n    corners.append(a[:cs, -cs:])\n    corners.append(a[-cs:, :cs])\n    corners.append(a[-cs:, -cs:])\n    corner_mean = float(np.mean([c.mean() if c.size else 0.0 for c in corners]))\n    cs2 = max(1, min(h, w) // 4)\n    cy = max(0, (h // 2) - (cs2 // 2))\n    cx = max(0, (w // 2) - (cs2 // 2))\n    center = a[cy:cy + cs2, cx:cx + cs2]\n    if center.size == 0:\n        return 0.0\n    center_mean = float(center.mean())\n    gstd = float(a.std()) + eps\n    result = (corner_mean - center_mean) / gstd\n    return float(np.clip(result, -5.0, 5.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge orientation coherence (0..1): how aligned edge orientations are'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= 0:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # orientation in [-pi,pi]\n    # orientation periodicity pi -> use 2*theta\n    vec = np.exp(1j * 2.0 * theta)\n    weighted = vec * mag\n    mean_vec = weighted.sum() / (mag.sum() + eps)\n    coherence = float(np.abs(mean_vec))\n    return float(np.clip(coherence, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score: 1 = perfectly symmetric left-right, 0 = very asymmetric'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    if w % 2 == 0:\n        left = a[:, :mid]\n        right = a[:, mid:]\n    else:\n        left = a[:, :mid]\n        right = a[:, mid+1:]\n    # mirror right\n    right_m = np.fliplr(right)\n    # align shapes\n    min_w = min(left.shape[1], right_m.shape[1])\n    if min_w == 0:\n        return 0.0\n    left_c = left[:, :min_w]\n    right_c = right_m[:, :min_w]\n    diff = np.abs(left_c - right_c)\n    denom = (np.mean(np.abs(a)) + eps)\n    score = 1.0 - float(np.mean(diff)) / denom\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute vertical neighbor difference normalized by intensity range'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.shape[0] < 2:\n        return 0.0\n    diff = np.abs(np.diff(a, axis=0))\n    mad = float(diff.mean())\n    rng = float(a.max() - a.min()) + eps\n    result = mad / rng\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average absolute Laplacian normalized by image std (sharpness proxy)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    gy, gx = np.gradient(a)\n    gxx = np.gradient(gx, axis=1)\n    gyy = np.gradient(gy, axis=0)\n    lap = gxx + gyy\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    overall_std = float(np.std(a)) + eps\n    result = mean_abs_lap / overall_std\n    # clamp to a reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio using discrete Laplacian (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # Laplacian via neighbors (4-connected)\n    up = a[:-2, 1:-1]\n    down = a[2:, 1:-1]\n    left = a[1:-1, :-2]\n    right = a[1:-1, 2:]\n    center = a[1:-1, 1:-1]\n    lap = (up + down + left + right) - 4.0 * center\n    hf = float(np.sum(np.abs(lap)))\n    total = float(np.sum(np.abs(center))) + eps\n    result = hf / (hf + total + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of horizontal transitions per row (higher for complex shapes, lower for single-stroke 1)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mx = gray.max()\n    weights = (mx - gray)\n    thr = np.percentile(weights, 60)\n    bin_fore = (weights >= thr).astype(np.uint8)\n    # transitions per row\n    if w < 2:\n        return 0.0\n    row_trans = np.abs(np.diff(bin_fore, axis=1)).sum(axis=1)\n    return float(np.mean(row_trans))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'FFT anisotropy: normalized difference between horizontal and vertical spectral energy (positive => horizontal textures)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # compute magnitude spectrum\n    F = np.fft.fftshift(np.fft.fft2(a))\n    mag = np.abs(F)\n    cy = h // 2\n    cx = w // 2\n    # energy concentrated along central row vs central column\n    row_energy = float(mag[cy, :].sum())\n    col_energy = float(mag[:, cx].sum())\n    total = float(mag.sum()) + eps\n    result = (row_energy - col_energy) / total\n    return float(np.clip(result, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity moment eccentricity (0..1): anisotropy of intensity distribution (1 = highly elongated)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices(a.shape)\n    # make non-negative weights\n    weights = a - a.min()\n    total = float(weights.sum())\n    if total == 0.0:\n        return 0.0\n    cx = float((weights * xs).sum()) / total\n    cy = float((weights * ys).sum()) / total\n    xcen = xs - cx\n    ycen = ys - cy\n    mxx = float((weights * (xcen**2)).sum()) / total\n    myy = float((weights * (ycen**2)).sum()) / total\n    mxy = float((weights * (xcen * ycen)).sum()) / total\n    trace = mxx + myy\n    det = mxx * myy - mxy * mxy\n    diff = np.sqrt(max(0.0, (trace * trace) / 4.0 - det))\n    lam1 = trace / 2.0 + diff\n    lam2 = trace / 2.0 - diff\n    ecc = (lam1 - lam2) / (lam1 + lam2 + eps)\n    return float(np.clip(ecc, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels contained in the bottom-left quadrant of the tight ink bounding box'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    ink = gray > 0\n    if not np.any(ink):\n        return 0.0\n    rows = np.nonzero(np.any(ink, axis=1))[0]\n    cols = np.nonzero(np.any(ink, axis=0))[0]\n    if rows.size == 0 or cols.size == 0:\n        return 0.0\n    r0, r1 = rows[0], rows[-1] + 1\n    c0, c1 = cols[0], cols[-1] + 1\n    sub = ink[r0:r1, c0:c1]\n    sh, sw = sub.shape\n    if sh == 0 or sw == 0:\n        return 0.0\n    bh = sh // 2\n    bw = sw // 2\n    bottom_left = sub[bh:, :bw]\n    total = float(np.count_nonzero(sub))\n    bl = float(np.count_nonzero(bottom_left))\n    return float(bl / (total + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative brightness of the top-center small box vs its immediate surround (positive => top-center is brighter/blank)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    top_h = max(1, h//6)\n    left = w//3\n    right = (2*w)//3\n    box = gray[0:top_h, left:right]\n    # surround ring: slightly below and flanking\n    ring = gray[top_h:top_h+max(1,top_h), max(0,left- max(1,w//10)):min(w,right+ max(1,w//10))]\n    box_mean = float(np.mean(box)) if box.size else 0.0\n    ring_mean = float(np.mean(ring)) if ring.size else box_mean\n    # if box is lighter (higher intensity) than ring -> likely open/top blank\n    denom = (ring_mean + box_mean) / 2.0 + 1e-9\n    return float((box_mean - ring_mean) / denom)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box fill ratio for pixels above a mild threshold (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean()) + 0.1 * float(a.std())\n    mask = a >= thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    rmin, rmax = int(ys.min()), int(ys.max())\n    cmin, cmax = int(xs.min()), int(xs.max())\n    bbox_area = float((rmax - rmin + 1) * (cmax - cmin + 1))\n    result = bbox_area / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of distinct ink connected components (separate islands), useful to spot digits with multiple disconnected loops'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.percentile(gray, 50.0)\n    ink = gray < thr\n    if np.mean(ink) > 0.6:\n        ink = gray > thr\n    if np.mean(ink) < 0.01:\n        thr = np.mean(gray)\n        ink = gray < thr\n    visited = np.zeros((h, w), dtype=bool)\n    from collections import deque\n    q = deque()\n    islands = 0\n    for i in range(h):\n        for j in range(w):\n            if ink[i, j] and not visited[i, j]:\n                islands += 1\n                visited[i, j] = True\n                q.append((i, j))\n                while q:\n                    x, y = q.popleft()\n                    for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n                        nx, ny = x + dx, y + dy\n                        if 0 <= nx < h and 0 <= ny < w and ink[nx, ny] and not visited[nx, ny]:\n                            visited[nx, ny] = True\n                            q.append((nx, ny))\n    return float(islands)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of gradient energy concentrated near the image border (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    # border width proportional to size\n    bw = max(1, min(h, w) // 8)\n    mask = np.zeros_like(a, dtype=bool)\n    mask[:bw, :] = True\n    mask[-bw:, :] = True\n    mask[:, :bw] = True\n    mask[:, -bw:] = True\n    total = float(mag.sum()) + eps\n    border = float(mag[mask].sum())\n    result = border / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'IQR contrast normalized by global std (interquartile range divided by std)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    vals = arr.ravel()\n    if vals.size == 0:\n        return 0.0\n    p75 = float(np.percentile(vals, 75))\n    p25 = float(np.percentile(vals, 25))\n    iqr = p75 - p25\n    std = float(vals.std()) + eps\n    result = iqr / std\n    return float(np.clip(result, 0.0, 100.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized x-coordinate of the ink centroid (0 = left, 1 = right); returns 0.5 if no ink'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.5\n    thresh = np.mean(gray)\n    dark_count = np.count_nonzero(gray < thresh)\n    bright_count = np.count_nonzero(gray > thresh)\n    ink = (gray < thresh) if dark_count < bright_count else (gray > thresh)\n    coords = np.argwhere(ink)\n    if coords.size == 0:\n        return 0.5\n    # coords are (row, col)\n    centroid_col = float(np.mean(coords[:, 1]))\n    return float(centroid_col / max(1, w - 1))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest contiguous horizontal foreground run length in the central horizontal band normalized by image width'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape\n        top = max(h//2 - max(1, h//10), 0)\n        bottom = min(h//2 + max(1, h//10), h)\n        band = gray[top:bottom, :]\n        thr = np.mean(band) if band.size else np.mean(gray)\n        fg = (band < thr) if np.mean(band) > 0.5 else (band > thr)\n        longest = 0\n        for row in fg:\n            # find longest run in this row\n            if row.size == 0:\n                continue\n            # convert to int and find runs\n            r = np.concatenate([[0], row.astype(int), [0]])\n            dif = np.diff(r)\n            starts = np.where(dif == 1)[0]\n            ends = np.where(dif == -1)[0]\n            if starts.size:\n                runs = ends - starts\n                longest = max(longest, runs.max())\n        return float(longest / max(w, 1))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground solidity: foreground area divided by its bounding-box area (thresholded)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    thr = float(img.mean() + 0.5 * img.std())\n    fg = (img > thr)\n    area = float(np.count_nonzero(fg))\n    if area == 0.0:\n        return 0.0\n    ys, xs = np.where(fg)\n    if ys.size == 0 or xs.size == 0:\n        return 0.0\n    ymin, ymax = ys.min(), ys.max()\n    xmin, xmax = xs.min(), xs.max()\n    bbox_area = float((ymax - ymin + 1) * (xmax - xmin + 1))\n    if bbox_area <= eps:\n        return 0.0\n    result = area / (bbox_area + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Peak density: proportion of pixels that are strict local maxima among 8-neighborhood'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    center = a\n    neighbors = []\n    neighbors.append(np.roll(center, 1, axis=0))\n    neighbors.append(np.roll(center, -1, axis=0))\n    neighbors.append(np.roll(center, 1, axis=1))\n    neighbors.append(np.roll(center, -1, axis=1))\n    neighbors.append(np.roll(np.roll(center, 1, axis=0), 1, axis=1))\n    neighbors.append(np.roll(np.roll(center, 1, axis=0), -1, axis=1))\n    neighbors.append(np.roll(np.roll(center, -1, axis=0), 1, axis=1))\n    neighbors.append(np.roll(np.roll(center, -1, axis=0), -1, axis=1))\n    comp = np.ones_like(center, dtype=bool)\n    for nb in neighbors:\n        comp &= (center > nb)\n    count = float(np.count_nonzero(comp))\n    area = float(center.size)\n    return float(np.clip(count / (area + 1e-12), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated fraction of enclosed hole pixels (background not connected to border) relative to image area'\n    import numpy as np\n    from collections import deque\n    eps = 1e-9\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gmin, gmax = gray.min(), gray.max()\n    denom = (gmax - gmin) + eps\n    norm = (gray - gmin) / denom\n    low_count = int(np.count_nonzero(norm < 0.5))\n    high_count = h * w - low_count\n    if low_count <= high_count:\n        ink = norm < 0.5\n    else:\n        ink = norm >= 0.5\n    background = ~ink\n    # flood fill background from borders to find reachable background\n    reachable = np.zeros_like(background, dtype=bool)\n    q = deque()\n    # push border background pixels\n    # top and bottom rows\n    top = np.where(background[0, :])[0]\n    for c in top:\n        q.append((0, int(c)))\n        reachable[0, int(c)] = True\n    bottom = np.where(background[h - 1, :])[0]\n    for c in bottom:\n        if not reachable[h - 1, int(c)]:\n            q.append((h - 1, int(c)))\n            reachable[h - 1, int(c)] = True\n    # left and right columns\n    left = np.where(background[:, 0])[0]\n    for r in left:\n        if not reachable[int(r), 0]:\n            q.append((int(r), 0))\n            reachable[int(r), 0] = True\n    right = np.where(background[:, w - 1])[0]\n    for r in right:\n        if not reachable[int(r), w - 1]:\n            q.append((int(r), w - 1))\n            reachable[int(r), w - 1] = True\n    # neighbors offsets 4-connected (sufficient)\n    while q:\n        r, c = q.popleft()\n        for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n            nr, nc = r + dr, c + dc\n            if 0 <= nr < h and 0 <= nc < w and not reachable[nr, nc] and background[nr, nc]:\n                reachable[nr, nc] = True\n                q.append((nr, nc))\n    # hole pixels are background but not reachable\n    hole_pixels = np.count_nonzero(background & (~reachable))\n    return float(hole_pixels / (h * w + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized RMS contrast: std / (mean + eps)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    mean = float(a.mean())\n    std = float(a.std())\n    result = std / (abs(mean) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-annulus contrast: difference between mean intensity in a small center disk and surrounding annulus (normalized)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = np.hypot(cy, cx) + eps\n    r_center = max(1.0, 0.12 * maxr)\n    r_outer = max(2.0, 0.3 * maxr)\n    center_mask = r <= r_center\n    ann_mask = (r > r_center) & (r <= r_outer)\n    if not np.any(center_mask) or not np.any(ann_mask):\n        return 0.0\n    mean_center = float(a[center_mask].mean())\n    mean_ann = float(a[ann_mask].mean())\n    overall_std = float(a.std()) + eps\n    result = (mean_center - mean_ann) / overall_std\n    # clip to sensible range\n    return float(np.clip(result, -10.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant edge orientation normalized to [-1..1] (-1=>-180deg, 1=>180deg)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = float(mag.sum())\n    if total <= eps:\n        return 0.0\n    angles = np.arctan2(gy, gx)  # radians in [-pi, pi]\n    ang_deg = np.degrees(angles).ravel()\n    weights = mag.ravel()\n    # histogram into 36 bins (~10 degrees)\n    nbins = 36\n    hist, edges = np.histogram(ang_deg, bins=nbins, range=(-180.0, 180.0), weights=weights)\n    idx = int(np.argmax(hist))\n    # bin center\n    center = 0.5 * (edges[idx] + edges[idx + 1])\n    # normalize to [-1..1]\n    result = float(center / 180.0)\n    # clip\n    result = max(-1.0, min(1.0, result))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical vs horizontal edge bias (-1..1), positive => vertical edges stronger'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    sv = float(np.abs(gx).sum())\n    sh = float(np.abs(gy).sum())\n    result = (sv - sh) / (sv + sh + eps)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity histogram entropy (8 bins), normalized to [0,1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(image.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(image.astype(float))\n    flat = arr.ravel()\n    if flat.size == 0:\n        return 0.0\n    # normalize to data range\n    mn, mx = float(flat.min()), float(flat.max())\n    if mx <= mn + eps:\n        return 0.0\n    bins = 8\n    hist, _ = np.histogram(flat, bins=bins, range=(mn, mx))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -np.sum(p_nonzero * np.log2(p_nonzero))\n    max_entropy = np.log2(bins)\n    result = float(entropy / (max_entropy + eps))\n    result = float(np.clip(result, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ink density in the left vertical third within the middle third of rows (detects left vertical strokes)'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    r0 = h // 3\n    r1 = min(h, 2 * h // 3)\n    c1 = max(1, w // 3)\n    thresh = np.mean(gray)\n    ink = (gray < thresh).astype(np.float32)\n    region = ink[r0:r1, 0:c1]\n    area = region.size if region.size > 0 else 1.0\n    return float(region.sum() / area)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity distribution entropy (normalized 0..1) using 16 bins'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    flat = arr.ravel()\n    if flat.size == 0:\n        return 0.0\n    bins = 16\n    hist, _ = np.histogram(flat, bins=bins, range=(flat.min(), flat.max()), density=False)\n    total = float(hist.sum())\n    if total <= 0:\n        return 0.0\n    p = hist.astype(float) / total\n    p = p[p > 0]\n    import math\n    entropy = -float((p * np.log(p)).sum())\n    norm = math.log(bins) if bins > 1 else 1.0\n    result = entropy / (norm + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with gradient magnitude above mean+std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    count = int(np.count_nonzero(mag > thr))\n    result = float(count) / float(mag.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Interquartile range (75th-25th percentile) normalized by median (robust contrast)'\n    import numpy as np\n    eps = 1e-12\n    vals = np.asarray(image)\n    if vals.size == 0:\n        return 0.0\n    if vals.ndim == 3:\n        vals = np.nan_to_num(vals.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(vals.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    p25 = float(np.percentile(vals, 25))\n    p75 = float(np.percentile(vals, 75))\n    med = float(np.median(vals))\n    denom = (abs(med) + eps)\n    result = (p75 - p25) / denom\n    return float(max(0.0, result))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of hole pixels located in the upper half of the image (0 if no holes)'\n    import numpy as np\n    from collections import deque\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray > thr\n    background = ~ink\n    # Flood-fill external background\n    ext = np.zeros_like(background, dtype=bool)\n    dq = deque()\n    for x in range(w):\n        if background[0, x]:\n            dq.append((0, x)); ext[0, x] = True\n        if background[h - 1, x]:\n            dq.append((h - 1, x)); ext[h - 1, x] = True\n    for y in range(h):\n        if background[y, 0] and not ext[y, 0]:\n            dq.append((y, 0)); ext[y, 0] = True\n        if background[y, w - 1] and not ext[y, w - 1]:\n            dq.append((y, w - 1)); ext[y, w - 1] = True\n    while dq:\n        y, x = dq.popleft()\n        if y > 0 and background[y - 1, x] and not ext[y - 1, x]:\n            ext[y - 1, x] = True; dq.append((y - 1, x))\n        if y < h - 1 and background[y + 1, x] and not ext[y + 1, x]:\n            ext[y + 1, x] = True; dq.append((y + 1, x))\n        if x > 0 and background[y, x - 1] and not ext[y, x - 1]:\n            ext[y, x - 1] = True; dq.append((y, x - 1))\n        if x < w - 1 and background[y, x + 1] and not ext[y, x + 1]:\n            ext[y, x + 1] = True; dq.append((y, x + 1))\n    holes = background & (~ext)\n    total_hole = np.count_nonzero(holes)\n    if total_hole == 0:\n        return 0.0\n    upper = holes[:h // 2, :]\n    upper_count = np.count_nonzero(upper)\n    return float(upper_count) / float(total_hole)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized index of the topmost foreground row (0 at top, 1 at bottom); smaller values indicate top-heavy marks like the bar of \"7\"'\n    import numpy as np\n    arr = np.array(image, dtype=float)\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    fg = gray < th\n    if np.count_nonzero(fg) > gray.size / 2:\n        fg = ~fg\n    rows = np.any(fg, axis=1)\n    idxs = np.where(rows)[0]\n    if idxs.size == 0:\n        return 1.0\n    top_idx = idxs[0]\n    return float(top_idx) / float(max(1, h - 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of connected ink components (1 for single blob), returns as float'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    bin_ink = (gray < thresh)\n    if np.count_nonzero(bin_ink) == 0:\n        bin_ink = (gray > thresh)\n    bin_ink = bin_ink.astype(bool)\n    visited = np.zeros((h, w), dtype=bool)\n    components = 0\n    for y in range(h):\n        for x in range(w):\n            if bin_ink[y, x] and not visited[y, x]:\n                components += 1\n                stack = [(y, x)]\n                visited[y, x] = True\n                while stack:\n                    cy, cx = stack.pop()\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1),(1,1),(1,-1),(-1,1),(-1,-1)):\n                        ny, nx = cy+dy, cx+dx\n                        if 0 <= ny < h and 0 <= nx < w and bin_ink[ny, nx] and not visited[ny, nx]:\n                            visited[ny, nx] = True\n                            stack.append((ny, nx))\n    return float(components)\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of ink runs in the vertical center column: counts separated vertical ink components along middle column'\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h < 3 or w < 1:\n        return 0.0\n    thresh = np.mean(gray)\n    bin_img = (gray < thresh).astype(np.uint8)\n    if np.sum(bin_img) < 1:\n        bin_img = (gray > thresh).astype(np.uint8)\n        if np.sum(bin_img) < 1:\n            return 0.0\n    col = bin_img[:, w // 2]\n    # count runs of ones\n    diff = np.diff(np.concatenate(([0], col, [0])))\n    starts = np.sum(diff == 1)\n    return float(starts)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of horizontal vs vertical edge energy (0..1 where >0.5 => more horizontal)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    # grayscale\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # compute simple gradients\n    gy, gx = np.gradient(a)\n    horiz_energy = float(np.sum(np.abs(gx)))\n    vert_energy = float(np.sum(np.abs(gy)))\n    # convert to normalized ratio 0..1: horiz/(horiz+vert)\n    denom = horiz_energy + vert_energy + eps\n    result = horiz_energy / denom\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical centroid offset normalized by image height (positive means centroid is lower than center)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.count_nonzero(ink) > 0.6 * h * w:\n        ink = ~ink\n    coords = np.argwhere(ink)\n    if coords.size == 0:\n        return 0.0\n    yc = float(np.mean(coords[:, 0]))\n    offset_norm = (yc - (h / 2.0)) / max(1.0, h)\n    return float(offset_norm)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energy favoring descending diagonal (sum|dx+dy| / (sum|dx-dy| + eps))'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    dy, dx = np.gradient(gray)\n    diag1 = dy + dx\n    diag2 = dy - dx\n    e1 = np.sum(np.abs(diag1))\n    e2 = np.sum(np.abs(diag2))\n    return float(e1 / (e2 + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of Laplacian divided by image variance (texture roughness), non-negative'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) +\n           np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    var_lap = float(np.var(lap))\n    var_img = float(np.var(a)) + eps\n    result = var_lap / var_img\n    return float(max(0.0, result))\n",
    "def feature(image: np.ndarray) -> float:\n    'Balance of gradient orientation energy (1.0 = equal vertical/horizontal energy)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    try:\n        gy, gx = np.gradient(img)\n    except Exception:\n        return 0.0\n    vert_energy = float(np.sum(np.abs(gx)))\n    horz_energy = float(np.sum(np.abs(gy)))\n    total = vert_energy + horz_energy + eps\n    balance = 1.0 - abs(vert_energy - horz_energy) / total\n    return float(np.clip(balance, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency energy ratio from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n        mag = np.abs(F)\n    except Exception:\n        return 0.0\n    total = float(mag.sum()) + eps\n    # central low-frequency square\n    half = max(1, min(h, w) // 8)\n    cy, cx = h // 2, w // 2\n    y0 = max(0, cy - half); y1 = min(h, cy + half + 1)\n    x0 = max(0, cx - half); x1 = min(w, cx + half + 1)\n    low = float(mag[y0:y1, x0:x1].sum())\n    result = low / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local-variance to global-variance ratio (texture contrast, >=0)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    global_var = float(a.var()) + eps\n    # block size proportional to image\n    bs = max(1, min(h, w) // 8)\n    # crop to multiple of bs\n    h0 = (h // bs) * bs\n    w0 = (w // bs) * bs\n    if h0 == 0 or w0 == 0:\n        # fallback to pixelwise local variance via 3x3 windows\n        pad = np.pad(a, 1, mode='reflect')\n        local_vars = []\n        for dy in range(3):\n            for dx in range(3):\n                patch = pad[dy:dy + h, dx:dx + w]\n                local_vars.append(patch)\n        stacked = np.stack(local_vars, axis=0)\n        lv = stacked.var(axis=0)\n        mean_lv = float(lv.mean())\n    else:\n        cropped = a[:h0, :w0]\n        reshaped = cropped.reshape(h0 // bs, bs, w0 // bs, bs)\n        # compute variance over each block\n        blocks = reshaped.swapaxes(1, 2).reshape(-1, bs, bs)\n        if blocks.size == 0:\n            return 0.0\n        var_blocks = blocks.reshape(blocks.shape[0], -1).var(axis=1)\n        mean_lv = float(np.mean(var_blocks))\n    ratio = mean_lv / global_var\n    return float(np.clip(ratio, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between top quartile mean and bottom quartile mean normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    flat = img.ravel()\n    if flat.size == 0:\n        return 0.0\n    q1 = np.percentile(flat, 25)\n    q3 = np.percentile(flat, 75)\n    low_mean = float(flat[flat <= q1].mean()) if np.any(flat <= q1) else float(flat.mean())\n    high_mean = float(flat[flat >= q3].mean()) if np.any(flat >= q3) else float(flat.mean())\n    gstd = float(flat.std()) + eps\n    result = (high_mean - low_mean) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Anti-diagonal asymmetry score: fraction of ink pixels that do not have a mirrored ink pixel across the anti-diagonal'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = image.mean(axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = (gray < thresh).astype(np.uint8)\n    ys, xs = np.nonzero(ink)\n    total = ys.size\n    if total == 0:\n        return 0.0\n    mismatches = 0\n    # anti-diagonal mapping: (r, c) -> (w-1-c, h-1-r)\n    for r, c in zip(ys, xs):\n        mr = w - 1 - c\n        mc = h - 1 - r\n        # check bounds (mapped indices are (row, col) = (mr, mc))\n        if 0 <= mr < h and 0 <= mc < w:\n            if ink[mr, mc] == 0:\n                mismatches += 1\n        else:\n            mismatches += 1\n    return float(mismatches / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of image classified as foreground by a simple Otsu threshold'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    flat = img.ravel()\n    if flat.size == 0:\n        return 0.0\n    mn = float(flat.min())\n    mx = float(flat.max())\n    if mx <= mn:\n        return 0.0\n    # scale to 0..255 for histogram stability\n    scaled = np.floor((flat - mn) / (mx - mn) * 255.0).astype(int)\n    hist = np.bincount(scaled, minlength=256).astype(float)\n    total = hist.sum()\n    if total <= 0:\n        return 0.0\n    cum = np.cumsum(hist)\n    cum_mean = np.cumsum(hist * np.arange(256))\n    global_mean = cum_mean[-1] / (total + 1e-12)\n    # between-class variance for each threshold\n    var_between = ((global_mean * cum - cum_mean) ** 2) / (cum * (total - cum) + 1e-12)\n    thresh_idx = int(np.nanargmax(var_between))\n    thresh_val = mn + (thresh_idx / 255.0) * (mx - mn)\n    mask = img > thresh_val\n    frac = float(np.count_nonzero(mask)) / float(img.size + 1e-12)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean horizontal gradient magnitude in the middle third of the image (detects a central horizontal bar)'\n    import numpy as np\n    # convert to single-channel float in [0,1]\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # normalize to [0,1] robustly\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx > mn:\n        norm = (gray - mn) / (mx - mn)\n    else:\n        norm = gray - mn\n    # compute gradients\n    gy, gx = np.gradient(norm)\n    horiz_mag = np.abs(gx)\n    # middle third rows\n    r0, r1 = h // 3, (2 * h) // 3\n    region = horiz_mag[r0:r1, :]\n    if region.size == 0:\n        return 0.0\n    return float(np.mean(region))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center vs outer mean contrast: (center_mean - outer_mean) / (overall_mean + eps)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 3 or w < 3:\n        return 0.0\n    ch0, ch1 = h // 4, 3 * h // 4\n    cw0, cw1 = w // 4, 3 * w // 4\n    center = arr[ch0:ch1, cw0:cw1]\n    if center.size == 0:\n        return 0.0\n    center_mean = float(center.mean())\n    outer_mask = np.ones_like(arr, dtype=bool)\n    outer_mask[ch0:ch1, cw0:cw1] = False\n    outer = arr[outer_mask]\n    outer_mean = float(outer.mean()) if outer.size else 0.0\n    overall_mean = float(arr.mean()) + eps\n    result = (center_mean - outer_mean) / overall_mean\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border vs inner variability: ratio of border standard deviation to inner standard deviation'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    t = max(1, min(h, w) // 8)\n    mask = np.ones_like(a, dtype=bool)\n    mask[t:-t, t:-t] = False\n    border = a[mask]\n    inner = a[~mask]\n    if border.size == 0 or inner.size == 0:\n        return 0.0\n    bstd = float(border.std())\n    istd = float(inner.std()) + 1e-12\n    result = bstd / istd\n    # reasonable clipping\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson-like brightness skewness (3*(mean-median)/std), clipped to [-1,1]'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size == 0:\n        return 0.0\n    mean = float(np.mean(arr))\n    med = float(np.median(arr))\n    std = float(np.std(arr))\n    if std <= 0:\n        return 0.0\n    skew = 3.0 * (mean - med) / std\n    return float(np.clip(skew, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial dispersion: std(distance to ink centroid) / mean(distance) for ink pixels; lower for round shapes'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(gray.min()), float(gray.max())\n    if mx <= mn:\n        return 0.0\n    thresh = mn + 0.1 * (mx - mn)\n    ink = gray > thresh\n    ys, xs = np.where(ink)\n    if xs.size <= 1:\n        return 0.0\n    cy, cx = float(ys.mean()), float(xs.mean())\n    d = np.sqrt((ys - cy) ** 2 + (xs - cx) ** 2)\n    mean_d = float(d.mean())\n    if mean_d == 0:\n        return 0.0\n    return float(d.std() / mean_d)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 32 histogram bins'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    mn, mx = float(flat.min()), float(flat.max())\n    if mx <= mn + eps:\n        return 0.0\n    bins = 32\n    hist, _ = np.histogram(flat, bins=bins, range=(mn, mx))\n    total = hist.sum()\n    if total <= 0:\n        return 0.0\n    p = hist.astype(float) / (total + eps)\n    p = p[p > 0]\n    ent = -np.sum(p * np.log(p))\n    # normalize by log(number of bins)\n    norm = np.log(bins)\n    result = ent / (norm + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of non-zero-pixel bounding box mapped to [0,1] (0.5=>square or empty)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.5\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    nz = np.nonzero(a)\n    if len(nz[0]) == 0:\n        return 0.5\n    rmin, rmax = nz[0].min(), nz[0].max()\n    cmin, cmax = nz[1].min(), nz[1].max()\n    h = float(max(1, rmax - rmin + 1))\n    w = float(max(1, cmax - cmin + 1))\n    ratio = w / h\n    # map ratio to [0,1] by using r' = ratio if ratio<=1 else 1/ratio, then scale to (0,1]\n    rprime = ratio if ratio <= 1.0 else 1.0 / ratio\n    # rprime in (0,1], map to [0,1] linearly (1 => 1, small => near 0)\n    result = float(np.clip(rprime, 0.0, 1.0))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative energy of main-diagonal (\\\\) gradients vs anti-diagonal (/) gradients (captures slanted strokes direction)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    # compute diagonal differences\n    if min(gray.shape) < 2:\n        return 0.0\n    dl = gray[:-1, :-1] - gray[1:, 1:]\n    dr = gray[:-1, 1:] - gray[1:, :-1]\n    edl = np.mean(np.abs(dl))\n    edr = np.mean(np.abs(dr))\n    denom = (edl + edr + 1e-9)\n    return float((edl - edr) / denom)  # range roughly [-1,1]\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal gradient energy (sum of abs differences along the two diagonal directions, normalized)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # compute diagonal differences\n    d1 = np.abs(gray[1:, 1:] - gray[:-1, :-1])  # NW-SE\n    d2 = np.abs(gray[1:, :-1] - gray[:-1, 1:])  # NE-SW\n    e1 = np.sum(d1)\n    e2 = np.sum(d2)\n    total = e1 + e2 + 1e-9\n    # return normalized difference (signed): positive means more NW-SE energy\n    return float((e1 - e2) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate average stroke thickness: ink pixel count divided by edge pixel count (higher = thicker strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn < 1e-8:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    thr = np.percentile(norm, 50)\n    bin_img = (norm >= thr).astype(float)\n    ink = bin_img.sum()\n    # edge estimation via gradient magnitude\n    gy, gx = np.gradient(norm)\n    grad = np.hypot(gx, gy)\n    # threshold edges relative to percentile\n    p75 = np.percentile(grad, 75)\n    edge_mask = grad >= (p75 * 0.25 if p75 > 0 else 1e-6)\n    edge_count = np.sum(edge_mask & (bin_img > 0.0))\n    if edge_count < 1.0:\n        return float(ink)  # fallback: return raw ink count as proxy\n    return float(ink / edge_count)\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference between upper-right and lower-right ink densities normalized by right-half ink (positive if top-right heavier)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.count_nonzero(ink) > 0.9 * h * w:\n        ink = gray > thr\n    right = ink[:, w//2:]\n    ur = np.count_nonzero(right[:h//2, :])\n    lr = np.count_nonzero(right[h//2:, :])\n    denom = float(ur + lr) if (ur + lr) > 0 else 1.0\n    return float((ur - lr) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of connected bright components (threshold mean) normalized by image area'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    thresh = np.nanmean(a)\n    mask = a > thresh\n    visited = np.zeros_like(mask, dtype=bool)\n    comps = 0\n    # simple stack-based 4-connectivity flood fill\n    coords = np.argwhere(mask)\n    if coords.size == 0:\n        return 0.0\n    for (rstart, cstart) in coords:\n        if visited[rstart, cstart]:\n            continue\n        if not mask[rstart, cstart]:\n            continue\n        comps += 1\n        stack = [(int(rstart), int(cstart))]\n        visited[rstart, cstart] = True\n        while stack:\n            r, c = stack.pop()\n            # neighbors\n            if r > 0 and mask[r-1, c] and not visited[r-1, c]:\n                visited[r-1, c] = True; stack.append((r-1, c))\n            if r+1 < h and mask[r+1, c] and not visited[r+1, c]:\n                visited[r+1, c] = True; stack.append((r+1, c))\n            if c > 0 and mask[r, c-1] and not visited[r, c-1]:\n                visited[r, c-1] = True; stack.append((r, c-1))\n            if c+1 < w and mask[r, c+1] and not visited[r, c+1]:\n                visited[r, c+1] = True; stack.append((r, c+1))\n    # normalize by area (components per 1000 pixels)\n    result = comps / (float(a.size) / 1000.0 + eps)\n    return float(np.clip(result, 0.0, float(max(0.0, result))))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels with strong gradient magnitude (edge density)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thresh = float(mag.mean() + 0.5 * mag.std())\n    count = float(np.count_nonzero(mag > thresh))\n    total = float(h * w) + eps\n    result = count / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between right-half and left-half ink density (right - left)'\n    import numpy as np\n    # Convert to grayscale float in [0,1]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    h, w = gray.shape[:2]\n    # Robust thresholding: median, determine if ink is darker than background by comparing border vs center\n    border = np.concatenate([gray[:3, :].ravel(), gray[-3:, :].ravel(), gray[:, :3].ravel(), gray[:, -3:].ravel()]) if h >=3 and w>=3 else gray.ravel()\n    center = gray[h//4:3*h//4, w//4:3*w//4] if h>=4 and w>=4 else gray\n    border_mean = float(border.mean()) if border.size else 0.0\n    center_mean = float(center.mean()) if center.size else 0.0\n    thresh = float(np.percentile(gray, 50)) if gray.size else 0.5\n    ink = (gray < thresh) if border_mean > center_mean else (gray > thresh)\n    ink = ink.astype(np.float64)\n    total = ink.sum()\n    if total <= 1e-6:\n        return 0.0\n    left = ink[:, :w//2].sum()\n    right = ink[:, w//2:].sum()\n    return float((right - left) / (total + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of pixel mass in the rightmost third of the image to total image mass (detects right-heavy \"3\" lobes)'\n    # handle grayscale vs RGB\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    total = np.sum(gray)\n    if total == 0:\n        return 0.0\n    c = max(1, w // 3)\n    right_mass = np.sum(gray[:, w - c:w])\n    return float(right_mass / (total + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global intensity entropy (normalized to [0,1])'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    # use 256 bins across data range\n    amin, amax = float(flat.min()), float(flat.max())\n    if amax <= amin:\n        return 0.0\n    hist, _ = np.histogram(flat, bins=256, range=(amin, amax))\n    probs = hist.astype(float) / (hist.sum() + eps)\n    probs = probs[probs > 0]\n    ent = -float(np.sum(probs * np.log2(probs + eps)))\n    # normalize by max entropy log2(256)=8\n    result = ent / 8.0\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean log(1+|Laplacian|) normalized by its max (texture sharpness)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 3 or w < 3:\n        return 0.0\n    C = img[1:-1, 1:-1]\n    up = img[:-2, 1:-1]\n    down = img[2:, 1:-1]\n    left = img[1:-1, :-2]\n    right = img[1:-1, 2:]\n    lap = np.abs(up + down + left + right - 4.0 * C)\n    if lap.size == 0:\n        return 0.0\n    loglap = np.log1p(lap)\n    meanlog = float(loglap.mean())\n    maxlog = float(loglap.max()) + eps\n    result = meanlog / maxlog\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity skewness (third standardized moment) of pixel values'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    mu = arr.mean()\n    sigma = arr.std()\n    if sigma <= 0:\n        return 0.0\n    skew = np.mean((arr - mu)**3) / (sigma**3 + eps)\n    return float(np.clip(skew, -1e6, 1e6))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright blobiness: normalized count of local maxima above 90th percentile (0..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    p90 = float(np.percentile(flat, 90))\n    mask = a > p90\n    if not np.any(mask):\n        return 0.0\n    # local maxima in 3x3: pixel > all 8 neighbors\n    center = a\n    neighbors = []\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            if dy == 0 and dx == 0:\n                continue\n            neighbors.append(np.roll(np.roll(a, dy, axis=0), dx, axis=1))\n    is_max = np.ones_like(a, dtype=bool)\n    for n in neighbors:\n        is_max &= (a > n)\n    peaks = is_max & mask\n    count = float(np.count_nonzero(peaks))\n    area = float(h * w)\n    result = count / (area + 1.0)  # avoid tiny division issues\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score (0..1): 1 means perfectly symmetric across vertical axis'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w < 2:\n        return 1.0\n    half = w // 2\n    left = arr[:, :half]\n    right = arr[:, w - half:]\n    # Flip right horizontally for comparison; if sizes differ, crop to min width\n    if left.shape[1] != right.shape[1]:\n        minw = min(left.shape[1], right.shape[1])\n        left = left[:, :minw]\n        right = right[:, -minw:]\n    right_flipped = np.fliplr(right)\n    diff = np.abs(left - right_flipped)\n    denom = np.mean(np.abs(arr)) + eps\n    norm_diff = float(diff.mean()) / denom\n    score = 1.0 - norm_diff\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from FFT (fraction of total energy in outer half of frequencies)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    img = img - img.mean()\n    try:\n        F = np.fft.fftshift(np.fft.fft2(img))\n    except Exception:\n        return 0.0\n    M = np.abs(F) ** 2\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = float(r.max()) + eps\n    # high frequency region: r > 0.5*maxr\n    mask = r > (0.5 * maxr)\n    total = float(M.sum()) + eps\n    high = float(M[mask].sum())\n    result = high / total\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Average length of horizontal ink runs divided by average length of vertical ink runs (>=1.0 indicates wider strokes).'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    ink = (gray < thresh).astype(np.uint8)\n    # horizontal runs: for each row, compute lengths of consecutive ones\n    horiz_lengths = []\n    for r in range(h):\n        row = ink[r]\n        if np.any(row):\n            # find run lengths\n            dif = np.diff(np.concatenate(([0], row, [0])))\n            starts = np.where(dif == 1)[0]\n            ends = np.where(dif == -1)[0]\n            lengths = ends - starts\n            horiz_lengths.extend(lengths.tolist())\n    vert_lengths = []\n    for c in range(w):\n        col = ink[:, c]\n        if np.any(col):\n            dif = np.diff(np.concatenate(([0], col, [0])))\n            starts = np.where(dif == 1)[0]\n            ends = np.where(dif == -1)[0]\n            lengths = ends - starts\n            vert_lengths.extend(lengths.tolist())\n    if len(horiz_lengths) == 0 and len(vert_lengths) == 0:\n        return 0.0\n    mean_h = float(np.mean(horiz_lengths)) if len(horiz_lengths) > 0 else 0.0\n    mean_v = float(np.mean(vert_lengths)) if len(vert_lengths) > 0 else 0.0\n    eps = 1e-6\n    return float(mean_h / (mean_v + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Compactness circularity: 4*pi*area / (perimeter^2) approximated from pixel neighbors (higher for round shapes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    fg = gray < thresh\n    if np.count_nonzero(fg) > 0.5 * h * w:\n        fg = ~fg\n    fg = fg.astype(np.uint8)\n    area = np.count_nonzero(fg)\n    if area == 0:\n        return 0.0\n    # perimeter approx: foreground pixels that have at least one background neighbor (4-neigh)\n    pad = np.pad(fg, pad_width=1, mode='constant', constant_values=0)\n    perim = 0\n    for r in range(1, h+1):\n        for c in range(1, w+1):\n            if pad[r, c]:\n                if not (pad[r-1, c] and pad[r+1, c] and pad[r, c-1] and pad[r, c+1]):\n                    perim += 1\n    perim = float(max(perim, 1))\n    compact = 4.0 * np.pi * float(area) / (perim * perim)\n    return float(compact)\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by mean absolute intensity'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image, dtype=float)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2))\n    else:\n        a = np.nan_to_num(arr)\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    up = np.roll(a, -1, axis=0)\n    down = np.roll(a, 1, axis=0)\n    left = np.roll(a, -1, axis=1)\n    right = np.roll(a, 1, axis=1)\n    lap = (4.0 * a) - up - down - left - right\n    mean_abs_lap = float(np.abs(lap).mean())\n    mean_abs = float(np.abs(a).mean()) + eps\n    result = mean_abs_lap / mean_abs\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of true cross-like pixels in the center box (pixel has up, down, left and right neighbors) \u2014 indicates a central crossing often present in \"4\")'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = float(np.percentile(gray.flatten(), 30))\n    mask = (gray < thr).astype(np.uint8)\n    if mask.sum() == 0:\n        thr = float(np.mean(gray))\n        mask = (gray < thr).astype(np.uint8)\n    # central box\n    r0, r1 = h // 3, max(h // 3 + 1, 2 * h // 3)\n    c0, c1 = w // 3, max(w // 3 + 1, 2 * w // 3)\n    box = mask[r0:r1, c0:c1]\n    if box.size == 0:\n        return 0.0\n    # pad to compute neighbors\n    pad = np.pad(mask, ((1, 1), (1, 1)), mode='constant', constant_values=0)\n    center = pad[1 + r0:1 + r1, 1 + c0:1 + c1]\n    up = pad[r0 + 0:r1 + 0, 1 + c0:1 + c1]\n    down = pad[r0 + 2:r1 + 2, 1 + c0:1 + c1]\n    left = pad[1 + r0:1 + r1, c0 + 0:c1 + 0]\n    right = pad[1 + r0:1 + r1, c0 + 2:c1 + 2]\n    crosses = np.logical_and.reduce((center == 1, up == 1, down == 1, left == 1, right == 1))\n    return float(np.count_nonzero(crosses) / max(1, box.size))\n",
    "def feature(image: np.ndarray) -> float:\n    'Border uniformity: fraction of border pixels within 5% of median border intensity (1 => uniform)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # collect border pixels (outer ring)\n    top = a[0, :]\n    bottom = a[-1, :]\n    left = a[1:-1, 0] if h > 2 else np.array([])\n    right = a[1:-1, -1] if h > 2 else np.array([])\n    border = np.concatenate([top.ravel(), bottom.ravel(), left.ravel(), right.ravel()]) if (top.size + bottom.size + left.size + right.size) > 0 else np.array([])\n    if border.size == 0:\n        return 0.0\n    med = float(np.median(border))\n    tol = max(1e-6, 0.05 * (np.abs(med) + eps))\n    close = np.abs(border - med) <= tol\n    frac = float(np.count_nonzero(close)) / float(border.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gini coefficient of intensity distribution (0..1), measures concentration'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    # shift to non-negative\n    vals = vals - vals.min()\n    if vals.sum() <= eps:\n        return 0.0\n    sorted_vals = np.sort(vals)\n    n = sorted_vals.size\n    idx = np.arange(1, n + 1, dtype=float)\n    gini = (2.0 * np.sum(idx * sorted_vals) / (n * sorted_vals.sum())) - (n + 1.0) / n\n    result = float(np.clip(gini, 0.0, 1.0))\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near intensity extremes (saturated/clipped proportion)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    vmin = float(arr.min())\n    vmax = float(arr.max())\n    if vmax == vmin:\n        return 0.0\n    rng = vmax - vmin\n    thr = max(1e-6, 0.01 * rng)  # within 1% of range\n    sat = np.logical_or(arr <= vmin + thr, arr >= vmax - thr)\n    result = float(np.count_nonzero(sat)) / float(arr.size)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 32 bins (0 = pure, 1 = max entropy)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return float(0.0)\n    bins = 32\n    counts, _ = np.histogram(vals, bins=bins)\n    total = counts.sum()\n    if total == 0:\n        return float(0.0)\n    p = counts.astype(float) / float(total)\n    p_nonzero = p[p > 0]\n    entropy = -float((p_nonzero * np.log2(p_nonzero)).sum())\n    max_ent = np.log2(bins)\n    result = entropy / (max_ent + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center gradient-energy fraction: fraction of gradient magnitude energy inside central region (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    ch = max(1, h // 4)\n    cw = max(1, w // 4)\n    r0 = h//2 - ch//2\n    r1 = r0 + ch\n    c0 = w//2 - cw//2\n    c1 = c0 + cw\n    r0 = max(0, r0); r1 = min(h, r1); c0 = max(0, c0); c1 = min(w, c1)\n    center_energy = float(np.sum(mag[r0:r1, c0:c1]))\n    total_energy = float(np.sum(mag)) + eps\n    result = center_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian-to-signal energy ratio (higher => more high-frequency second-derivative content)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        dxx = np.gradient(gx, axis=1)\n        dyy = np.gradient(gy, axis=0)\n    except Exception:\n        return 0.0\n    lap = dxx + dyy\n    energy_lap = float(np.sum(np.abs(lap)))\n    energy_img = float(np.sum(np.abs(a))) + eps\n    ratio = energy_lap / energy_img\n    # compress to (0..1)\n    result = ratio / (1.0 + ratio)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of foreground bounding box (width/height, >=0), 0 if no foreground'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    # simple foreground: pixels > mean\n    thr = float(a.mean())\n    mask = a > thr\n    if not mask.any():\n        return 0.0\n    rows = np.any(mask, axis=1)\n    cols = np.any(mask, axis=0)\n    r_idx = np.where(rows)[0]\n    c_idx = np.where(cols)[0]\n    if r_idx.size == 0 or c_idx.size == 0:\n        return 0.0\n    top, bot = int(r_idx[0]), int(r_idx[-1])\n    left, right = int(c_idx[0]), int(c_idx[-1])\n    bw = float(right - left + 1)\n    bh = float(bot - top + 1)\n    eps = 1e-8\n    result = bw / (bh + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized centroid offset of bright region from image center (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # foreground mask using mean threshold (robust and cheap)\n    thr = float(np.mean(a))\n    mask = a > thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    cy = ys.mean()\n    cx = xs.mean()\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    maxdist = np.hypot(center_y, center_x) + 1e-12\n    result = dist / maxdist\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of intensity centroid from geometric center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total = float(a.sum()) + eps\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    cy = float((a * ys).sum()) / total\n    cx = float((a * xs).sum()) / total\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    diag = np.hypot(h, w) / 2.0 + eps\n    return float(np.clip(dist / diag, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal symmetry correlation (main diagonal) for a centered square crop (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    s = min(h, w)\n    y0 = (h - s) // 2\n    x0 = (w - s) // 2\n    sq = a[y0:y0 + s, x0:x0 + s]\n    if sq.size == 0:\n        return 0.0\n    A = sq.ravel()\n    B = sq.T.ravel()\n    A_mean = A.mean()\n    B_mean = B.mean()\n    num = np.sum((A - A_mean) * (B - B_mean))\n    den = np.sqrt(np.sum((A - A_mean) ** 2) * np.sum((B - B_mean) ** 2)) + eps\n    corr = num / den\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong edges: proportion of pixels with gradient magnitude above local threshold'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + 0.5 * mag.std())\n    strong = (mag > thr)\n    # avoid counting border artifacts specially; just normalize by area\n    result = float(np.count_nonzero(strong)) / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dark-spot prominence: (global mean - mean around darkest pixel) / overall std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    min_idx = np.argmin(arr.ravel())\n    iy, ix = divmod(int(min_idx), w)\n    # neighborhood 7x7\n    r = max(1, min(h, w) // 10)\n    y0 = max(0, iy - r)\n    y1 = min(h, iy + r + 1)\n    x0 = max(0, ix - r)\n    x1 = min(w, ix + r + 1)\n    local = arr[y0:y1, x0:x1]\n    if local.size == 0:\n        return 0.0\n    global_mean = float(np.mean(arr))\n    local_mean = float(np.mean(local))\n    overall_std = float(np.std(arr)) + eps\n    result = (global_mean - local_mean) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Multiscale coarseness: ratio of variance of 2x2 pooled image to 8x8 pooled image (higher => finer texture)'\n    import numpy as np\n    eps = 1e-12\n    def block_mean(im, f):\n        h, w = im.shape\n        if f <= 1:\n            return im\n        # pad to multiple of f with edge values\n        ph = (f - (h % f)) % f\n        pw = (f - (w % f)) % f\n        if ph or pw:\n            im = np.pad(im, ((0, ph), (0, pw)), mode='edge')\n        nh, nw = im.shape\n        im2 = im.reshape(nh // f, f, nw // f, f)\n        return im2.mean(axis=(1, 3))\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    small = block_mean(a, 2)\n    large = block_mean(a, 8)\n    var_small = float(np.var(small))\n    var_large = float(np.var(large)) + eps\n    ratio = var_small / var_large\n    # map to [0,1] with a soft cap\n    result = float(1.0 - 1.0 / (1.0 + ratio))\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local maxima density: count of pixels greater than all 8 neighbors divided by image area'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center = a\n    # compare to 8 neighbors using shifts\n    neighbors = []\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            if dy == 0 and dx == 0:\n                continue\n            neighbors.append(np.roll(np.roll(a, dy, axis=0), dx, axis=1))\n    cmp_all = np.ones_like(a, dtype=bool)\n    for n in neighbors:\n        cmp_all &= (center > n)\n    # ignore wrap-around artifacts by zeroing borders that compared to wrapped values\n    cmp_all[0, :] = False\n    cmp_all[-1, :] = False\n    cmp_all[:, 0] = False\n    cmp_all[:, -1] = False\n    count = float(cmp_all.sum())\n    area = float(h * w)\n    result = count / (area + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel fraction using gradient magnitude (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = mag.mean() + 0.5 * mag.std()\n    edges = mag > thr\n    result = float(np.count_nonzero(edges)) / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of separated dark runs along the central vertical column (counts lobes along center line)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    fg = (gray < thr)\n    if fg.sum() == 0 or fg.sum() > 0.9 * fg.size:\n        fg = (gray > thr)\n    c = w // 2\n    col = fg[:, c].astype(int)\n    if col.sum() == 0:\n        return 0.0\n    padded = np.concatenate(([0], col, [0]))\n    changes = np.where(padded[1:] != padded[:-1])[0]\n    runs = changes.reshape(-1, 2)\n    num_runs = runs.shape[0]\n    return float(num_runs)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Centroid offset of bright region (threshold = mean+0.5*std) normalized by image diagonal'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    mu = float(arr.mean())\n    sd = float(arr.std())\n    thr = mu + 0.5 * sd\n    mask = arr > thr\n    if not np.any(mask):\n        return 0.0\n    weights = (arr - thr) * mask\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    total_w = float(weights.sum()) + eps\n    cy = float((weights * ys).sum()) / total_w\n    cx = float((weights * xs).sum()) / total_w\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    maxd = np.hypot(center_y, center_x) + eps\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of local intensity peaks per 1000 pixels (sparse local maxima count)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # pad and compare to 8 neighbors\n    p = np.pad(img, 1, mode='constant', constant_values=np.min(img))\n    center = p[1:-1, 1:-1]\n    neighs = [\n        p[0:-2, 0:-2], p[0:-2, 1:-1], p[0:-2, 2:],\n        p[1:-1, 0:-2],               p[1:-1, 2:],\n        p[2:,   0:-2], p[2:,   1:-1], p[2:,   2:]\n    ]\n    greater = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        greater &= (center > n)\n    # require peaks to be above mean+std to ignore noise\n    thresh = img.mean() + img.std()\n    peaks = greater & (center > thresh)\n    count = int(np.count_nonzero(peaks))\n    density = count / float(max(1, h * w)) * 1000.0\n    return float(density)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of transitions (ink <-> background) along the central column normalized by image height (high for multiple separated strokes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image)\n    if arr.size == 0:\n        return 0.0\n    h, w = arr.shape[:2]\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr.astype(float)\n    meanv = float(np.mean(gray))\n    mask = gray < meanv\n    if mask.sum() == 0:\n        mask = gray > meanv\n    col = mask[:, w//2].astype(int) if w > 0 else np.zeros((h,), dtype=int)\n    if col.size < 2:\n        return 0.0\n    transitions = np.sum(col[1:] != col[:-1])\n    return float(transitions / max(1, h))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of ink along the top-right to bottom-left main diagonal (samples a stripe along that diagonal, high for 7)'\n    import numpy as np\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    m = np.mean(gray)\n    mask_dark = gray < m\n    mask_light = gray > m\n    mask = mask_dark if np.count_nonzero(mask_dark) <= np.count_nonzero(mask_light) else mask_light\n    n = max(h, w, 1)\n    total_samples = 0\n    ink_hits = 0\n    half_width = max(1, int(min(h, w) * 0.03) )  # sample a small stripe width\n    for t in range(n):\n        row = int((t / (n - 1)) * (h - 1))\n        col = int(((n - 1 - t) / (n - 1)) * (w - 1))\n        # sample small neighborhood\n        r0 = max(0, row - half_width)\n        r1 = min(h, row + half_width + 1)\n        c0 = max(0, col - half_width)\n        c1 = min(w, col + half_width + 1)\n        total_samples += (r1 - r0) * (c1 - c0)\n        ink_hits += np.count_nonzero(mask[r0:r1, c0:c1])\n    if total_samples == 0:\n        return 0.0\n    return float(ink_hits / total_samples)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Color-channel mean imbalance (std of channel means normalized), 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim < 3 or arr.shape[2] < 2:\n        return 0.0\n    img = np.nan_to_num(arr.astype(float))\n    ch = img.reshape(-1, img.shape[2])\n    if ch.size == 0:\n        return 0.0\n    means = ch.mean(axis=0)\n    mmean = float(means.mean())\n    std_means = float(means.std())\n    result = std_means / (abs(mmean) + eps)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of edge orientations (0..1), weighted by edge magnitude'\n    import numpy as np\n    eps = 1e-12\n    bins = 16\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # [-pi, pi]\n    # orientation modulo pi (so direction and opposite are same)\n    theta_mod = np.mod(theta, np.pi)  # [0, pi)\n    # bin indices\n    bin_idx = np.floor((theta_mod / np.pi) * bins).astype(int)\n    bin_idx = np.clip(bin_idx, 0, bins - 1)\n    hist = np.zeros(bins, dtype=float)\n    # accumulate weighted by magnitude\n    for b in range(bins):\n        hist[b] = float(mag[bin_idx == b].sum())\n    total = hist.sum() + eps\n    p = hist / total\n    p_nonzero = p[p > 0]\n    ent = -float(np.sum(p_nonzero * np.log(p_nonzero + eps)))\n    norm = ent / (np.log(bins) + eps)\n    result = float(np.clip(norm, 0.0, 1.0))\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency (Laplacian) energy divided by total absolute energy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # discrete Laplacian via 4-neighbor stencil\n    lap = 4.0 * a\n    lap -= np.roll(a, 1, axis=0)\n    lap -= np.roll(a, -1, axis=0)\n    lap -= np.roll(a, 1, axis=1)\n    lap -= np.roll(a, -1, axis=1)\n    high_e = float(np.sum(np.abs(lap)))\n    total_e = float(np.sum(np.abs(a))) + eps\n    ratio = high_e / total_e\n    return float(np.clip(ratio, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right mirror symmetry (1 = perfectly symmetric left-right)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # mirror right to compare to left\n    right_mirror = np.fliplr(right)\n    # crop to same shape if odd width\n    min_w = min(left.shape[1], right_mirror.shape[1])\n    left_c = left[:, :min_w]\n    right_c = right_mirror[:, :min_w]\n    denom = np.mean(np.abs(a)) + eps\n    diff = np.mean(np.abs(left_c - right_c)) / denom\n    result = 1.0 - float(np.clip(diff, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border homogeneity: border std divided by global std (smaller => more homogeneous)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thickness = max(1, min(h, w) // 10)\n    mask = np.zeros_like(a, dtype=bool)\n    mask[:thickness, :] = True\n    mask[-thickness:, :] = True\n    mask[:, :thickness] = True\n    mask[:, -thickness:] = True\n    border = a[mask]\n    if border.size == 0:\n        return 0.0\n    border_std = float(border.std())\n    global_std = float(a.std()) + eps\n    result = border_std / global_std\n    return float(np.clip(result, 0.0, 50.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-minus-surround contrast: (center_mean - surround_mean) / image std'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    ch0 = h // 4\n    ch1 = 3 * h // 4\n    cw0 = w // 4\n    cw1 = 3 * w // 4\n    if ch1 <= ch0 or cw1 <= cw0:\n        return 0.0\n    center = arr[ch0:ch1, cw0:cw1]\n    if center.size == 0:\n        return 0.0\n    surround_mask = np.ones_like(arr, dtype=bool)\n    surround_mask[ch0:ch1, cw0:cw1] = False\n    if not np.any(surround_mask):\n        return 0.0\n    center_mean = float(np.mean(center))\n    surround_mean = float(np.mean(arr[surround_mask]))\n    overall_std = float(np.std(arr)) + eps\n    result = (center_mean - surround_mean) / overall_std\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-sparsity: fraction of pixels that are strong local bright outliers (sparse bright spots)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    m = float(flat.mean())\n    s = float(flat.std()) + eps\n    thr = m + 1.5 * s\n    count = float(np.count_nonzero(flat > thr))\n    frac = count / (flat.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local standard deviation over 3x3 neighborhoods (texture coarseness)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # local sums via rolling\n    def local_sum(X):\n        s = np.zeros_like(X, dtype=float)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s\n    s1 = local_sum(a) / 9.0\n    s2 = local_sum(a * a) / 9.0\n    var = s2 - (s1 * s1)\n    var = np.where(var >= 0, var, 0.0)\n    local_std = np.sqrt(var)\n    result = float(np.mean(local_std))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated number of holes (closed loops) in the foreground by counting background components not touching the border'\n    # Robust grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    # Simple adaptive binarization: foreground assumed darker than mean\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    # If too much ink, invert assumption\n    if np.count_nonzero(ink) > 0.6 * h * w:\n        ink = ~ink\n    bg = ~ink\n    visited = np.zeros(bg.shape, dtype=bool)\n    holes = 0\n    # flood fill background components; count those not touching border\n    for r in range(h):\n        for c in range(w):\n            if not bg[r, c] or visited[r, c]:\n                continue\n            # start flood fill\n            stack = [(r, c)]\n            visited[r, c] = True\n            touches_border = False\n            while stack:\n                y, x = stack.pop()\n                if y == 0 or x == 0 or y == h - 1 or x == w - 1:\n                    touches_border = True\n                # explore 8-neighbors\n                for dy in (-1, 0, 1):\n                    for dx in (-1, 0, 1):\n                        ny, nx = y + dy, x + dx\n                        if ny < 0 or ny >= h or nx < 0 or nx >= w:\n                            continue\n                        if not visited[ny, nx] and bg[ny, nx]:\n                            visited[ny, nx] = True\n                            stack.append((ny, nx))\n            if not touches_border:\n                holes += 1\n    return float(holes)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized centroid distance between bright and dark regions (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mean = float(a.mean())\n    std = float(a.std()) + eps\n    bright_thr = mean + 0.25 * std\n    dark_thr = mean - 0.25 * std\n    ys, xs = np.indices((h, w))\n    bright_mask = a > bright_thr\n    dark_mask = a < dark_thr\n    if not np.any(bright_mask) or not np.any(dark_mask):\n        return 0.0\n    bsum = float(a[bright_mask].sum()) + eps\n    dsum = float((mean - a[dark_mask]).sum()) + eps  # weight dark by depth below mean\n    bx = float((a * bright_mask * xs).sum()) / bsum\n    by = float((a * bright_mask * ys).sum()) / bsum\n    dx = float(((mean - a) * dark_mask * xs).sum()) / dsum\n    dy = float(((mean - a) * dark_mask * ys).sum()) / dsum\n    dist = np.hypot(bx - dx, by - dy)\n    norm = np.hypot(w, h) / 2.0 + eps\n    result = dist / norm\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels whose gradient magnitude exceeds mean+0.5*std (edge density)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + 0.5 * mag.std())\n    count = float(np.count_nonzero(mag > thr))\n    denom = float(mag.size) + eps\n    result = count / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of intensity centroid from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    y_idx, x_idx = np.indices((h, w))\n    total = float(a.sum()) + eps\n    cx = float((a * x_idx).sum()) / total\n    cy = float((a * y_idx).sum()) / total\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    diag = np.hypot(w, h) / 2.0 + eps\n    result = float(dist / diag)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative right-half horizontal edge strength: mean abs horizontal gradient in right half divided by global edge strength'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w <= 1:\n        return 0.0\n    gx = np.abs(np.diff(gray, axis=1))\n    total_mean = float(np.mean(gx)) + 1e-9\n    right_gx = gx[:, w // 2 - 1:] if (w // 2 - 1) >= 0 else gx\n    right_mean = float(np.mean(right_gx))\n    return float(right_mean / total_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate Harris corner density (fraction of pixels with strong corner response)'\n    import numpy as np\n    eps = 1e-12\n    k = 0.04\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    gy, gx = np.gradient(img)\n    Ixx = gx * gx\n    Iyy = gy * gy\n    Ixy = gx * gy\n    # local sum over 3x3 window via rolled sum (wrap-around)\n    Sxx = np.zeros_like(Ixx)\n    Syy = np.zeros_like(Iyy)\n    Sxy = np.zeros_like(Ixy)\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            Sxx += np.roll(np.roll(Ixx, dy, axis=0), dx, axis=1)\n            Syy += np.roll(np.roll(Iyy, dy, axis=0), dx, axis=1)\n            Sxy += np.roll(np.roll(Ixy, dy, axis=0), dx, axis=1)\n    # Harris response\n    det = Sxx * Syy - Sxy * Sxy\n    trace = Sxx + Syy\n    R = det - k * (trace ** 2)\n    # threshold: use mean + std of positive responses\n    pos = R[R > 0]\n    if pos.size == 0:\n        return 0.0\n    thr = float(pos.mean() + pos.std())\n    corners = (R > thr)\n    density = float(np.count_nonzero(corners)) / float(h * w + eps)\n    return float(density)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Harris-like corner density (fraction of strong corner responses, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    k = 0.04\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    A = gx * gx\n    B = gx * gy\n    C = gy * gy\n    # smooth with simple 3x3 average via convolution using cumsum for speed\n    padA = np.pad(A, 1, mode='reflect')\n    padB = np.pad(B, 1, mode='reflect')\n    padC = np.pad(C, 1, mode='reflect')\n    sA = padA.cumsum(axis=0).cumsum(axis=1)\n    sB = padB.cumsum(axis=0).cumsum(axis=1)\n    sC = padC.cumsum(axis=0).cumsum(axis=1)\n    ksize = 3\n    sumA = (sA[ksize:, ksize:] - sA[:-ksize, ksize:] - sA[ksize:, :-ksize] + sA[:-ksize, :-ksize]) / 9.0\n    sumB = (sB[ksize:, ksize:] - sB[:-ksize, ksize:] - sB[ksize:, :-ksize] + sB[:-ksize, :-ksize]) / 9.0\n    sumC = (sC[ksize:, ksize:] - sC[:-ksize, ksize:] - sC[ksize:, :-ksize] + sC[:-ksize, :-ksize]) / 9.0\n    # Harris response\n    R = (sumA * sumC - sumB * sumB) - k * (sumA + sumC) ** 2\n    Rmax = float(np.max(R))\n    if Rmax <= 0:\n        return 0.0\n    thr = max(1e-8, 0.01 * Rmax)\n    count = float((R > thr).sum())\n    result = count / float(h * w)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strict local intensity maxima (peaks) in 8-neighborhood'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    minval = a.min() - 1.0\n    p = np.pad(a, 1, mode='constant', constant_values=minval)\n    c = p[1:-1, 1:-1]\n    neighs = [\n        p[:-2, :-2], p[:-2, 1:-1], p[:-2, 2:],\n        p[1:-1, :-2],              p[1:-1, 2:],\n        p[2:, :-2],  p[2:, 1:-1],  p[2:, 2:]\n    ]\n    is_max = np.ones_like(c, dtype=bool)\n    for n in neighs:\n        is_max &= (c > n)\n    count = float(np.count_nonzero(is_max))\n    result = count / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by mean intensity (higher => more rapid intensity change)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    up = np.roll(a, 1, axis=0)\n    down = np.roll(a, -1, axis=0)\n    left = np.roll(a, 1, axis=1)\n    right = np.roll(a, -1, axis=1)\n    lap = (up + down + left + right) - 4.0 * a\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    mean_int = float(np.mean(np.abs(a))) + eps\n    result = mean_abs_lap / mean_int\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized variance of quadrant means (high => quadrants differ)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape if a.size else (0, 0)\n    if h == 0 or w == 0:\n        return 0.0\n    mh = h // 2\n    mw = w // 2\n    quads = []\n    quads.append(a[0:mh, 0:mw])\n    quads.append(a[0:mh, mw:w])\n    quads.append(a[mh:h, 0:mw])\n    quads.append(a[mh:h, mw:w])\n    means = np.array([float(q.mean()) if q.size else 0.0 for q in quads], dtype=float)\n    gstd = float(a.std()) + eps\n    var_means = float(means.var())\n    result = var_means / (gstd * gstd + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical stripe strength: std of column means normalized by image std (higher => vertical structure)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    col_means = np.mean(a, axis=0)\n    col_std = float(col_means.std())\n    gstd = float(a.std()) + eps\n    result = col_std / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Absolute top-bottom foreground mass difference normalized by total mass'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    minv = float(np.min(gray))\n    maxv = float(np.max(gray))\n    if maxv > minv:\n        gray = (gray - minv) / (maxv - minv)\n    else:\n        gray = gray * 0.0\n    thr = 0.5\n    mask_dark = gray < thr\n    mask_bright = gray > thr\n    mask = mask_dark if mask_dark.sum() <= mask_bright.sum() else mask_bright\n    h, w = mask.shape\n    top = mask[:h//2, :].sum()\n    bottom = mask[h//2:, :].sum()\n    total = top + bottom\n    if total == 0:\n        return 0.0\n    return float(abs(top - bottom) / float(total))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio in 2D FFT (0..1), higher = more fine detail'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # compute centered magnitude spectrum\n    F = np.fft.fftshift(np.fft.fft2(arr))\n    mag2 = np.abs(F) ** 2\n    ys = np.arange(h) - (h // 2)\n    xs = np.arange(w) - (w // 2)\n    Y, X = np.meshgrid(ys, xs, indexing='ij')\n    dist = np.hypot(Y, X)\n    maxd = dist.max() if dist.size else 1.0\n    cutoff = 0.5 * maxd\n    high_energy = mag2[dist >= cutoff].sum()\n    total = mag2.sum() + eps\n    ratio = float(high_energy / total)\n    return float(np.clip(ratio, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency energy ratio from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute power spectrum\n    F = np.fft.fftshift(np.fft.fft2(a))\n    power = (np.abs(F) ** 2)\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys, xs = np.indices((h, w))\n    r = np.hypot(xs - cx, ys - cy)\n    cutoff = max(1.0, min(h, w) / 8.0)\n    low_mask = r <= cutoff\n    total = float(power.sum()) + eps\n    low = float(power[low_mask].sum())\n    result = low / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Compactness estimate: (perimeter^2) / area for the foreground (higher means thinner/elongated strokes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image.astype(float), axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    p10, p90 = np.percentile(gray, (10, 90))\n    low_mean = float(np.mean(gray[gray <= p10])) if np.any(gray <= p10) else p10\n    high_mean = float(np.mean(gray[gray >= p90])) if np.any(gray >= p90) else p90\n    median = np.median(gray)\n    if low_mean < high_mean:\n        ink = (gray <= median).astype(np.uint8)\n    else:\n        ink = (gray >= median).astype(np.uint8)\n    area = float(np.count_nonzero(ink))\n    if area <= 0:\n        return 0.0\n    # approximate perimeter: foreground pixels that touch background\n    perimeter = 0\n    for i in range(h):\n        for j in range(w):\n            if ink[i, j]:\n                for di, dj in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n                    ni, nj = i + di, j + dj\n                    if not (0 <= ni < h and 0 <= nj < w and ink[ni, nj]):\n                        perimeter += 1\n    if perimeter <= 0:\n        return 0.0\n    compactness = (perimeter * perimeter) / (area + 1e-9)\n    return float(compactness)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal edge energy: mean absolute diagonal differences normalized by total gradient energy'\n    import numpy as np\n    img = np.array(image, dtype=float)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    gray = gray.astype(float)\n    # normalize to 0..1\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    rng = mx - mn if mx != mn else 1.0\n    grayn = (gray - mn) / rng\n    # diagonal difference along NW->SE and NE->SW\n    d1 = np.abs(grayn - np.roll(grayn, 1, axis=0).astype(float))\n    d1 = np.abs(d1 - np.roll(d1, 1, axis=1))\n    d2 = np.abs(grayn - np.roll(grayn, 1, axis=0))\n    d2 = np.abs(d2 - np.roll(d2, -1, axis=1))\n    diag_energy = np.mean(d1) + np.mean(d2)\n    # total (vertical+horizontal) energy\n    gy, gx = np.gradient(grayn)\n    total_energy = (np.mean(np.abs(gy)) + np.mean(np.abs(gx))) + 1e-8\n    return float(diag_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarseness proxy: preferred block scale among [1,2,4,8] normalized to [0..1] (higher => coarser)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    scales = [1, 2, 4, 8]\n    valid_scales = [s for s in scales if s <= max(1, min(h, w))]\n    if not valid_scales:\n        return 0.0\n    global_var = float(a.var()) + eps\n    avg_vars = []\n    for s in valid_scales:\n        # reshape into non-overlapping blocks approximate by cropping\n        H = (h // s) * s\n        W = (w // s) * s\n        if H == 0 or W == 0:\n            avg_vars.append(0.0)\n            continue\n        B = a[:H, :W].reshape((H//s, s, W//s, s)).swapaxes(1,2).reshape(-1, s*s)\n        # per-block variance\n        bv = B.var(axis=1)\n        avg_vars.append(float(np.mean(bv)))\n    avg_vars = np.array(avg_vars)\n    if avg_vars.sum() <= 0:\n        return 0.0\n    idx = int(np.argmax(avg_vars))\n    result = float(idx / max(1, (len(valid_scales) - 1)))\n    result = float(np.clip(result, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from 2D FFT (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        f = np.fft.fft2(a)\n        fshift = np.fft.fftshift(f)\n        mag = np.abs(fshift)\n    except Exception:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = r.max() + 1e-12\n    # high freq if radius > 0.5 * maxradius\n    mask = r > (0.5 * maxr)\n    total = float(mag.sum()) + 1e-12\n    high = float(mag[mask].sum())\n    result = high / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energy (NW-SE) to (NE-SW) using gx and gy (helps detect diagonal stroke orientations)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gx, gy = np.gradient(gray.astype(float))\n    d1 = gx + gy  # NW-SE\n    d2 = gx - gy  # NE-SW\n    e1 = np.sum(np.abs(d1))\n    e2 = np.sum(np.abs(d2))\n    eps = 1e-6\n    return float((e1 + eps) / (e2 + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Max horizontal run fraction: longest consecutive above-mean run in any row normalized by width'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if w == 0:\n        return 0.0\n    thr = float(np.mean(arr))\n    mask = arr > thr\n    max_run = 0\n    for i in range(h):\n        row = mask[i]\n        # compute run lengths in row\n        if row.any():\n            # differences trick\n            dif = np.diff(np.concatenate(([0], row.view(np.int8), [0])))\n            starts = np.where(dif == 1)[0]\n            ends = np.where(dif == -1)[0]\n            if starts.size and ends.size:\n                runs = ends - starts\n                max_run = max(int(runs.max()), max_run)\n    result = float(max_run) / float(w) if w else 0.0\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of intensity center-of-mass from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    vals = a - a.min()\n    total = float(vals.sum()) + eps\n    cy = float((vals * ys).sum()) / total\n    cx = float((vals * xs).sum()) / total\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    maxd = np.hypot(center_x, center_y) + eps\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute left-right mirror difference normalized by mean absolute intensity'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = img[:, :mid]\n    right = img[:, w-mid:]\n    right_flipped = np.fliplr(right)\n    # make shapes equal by cropping to min width\n    min_w = min(left.shape[1], right_flipped.shape[1])\n    left = left[:, :min_w]\n    right_flipped = right_flipped[:, :min_w]\n    if left.size == 0:\n        return 0.0\n    diff = np.abs(left - right_flipped)\n    mean_diff = float(diff.mean())\n    denom = float(np.mean(np.abs(img))) + eps\n    result = mean_diff / denom\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local entropy proxy: mean log(1 + local 3x3 std) (larger => more local complexity)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # local mean and mean of squares via 3x3 rolling sum (edge handled by roll)\n    def local_mean(X):\n        s = np.zeros_like(X, dtype=float)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    mean1 = local_mean(a)\n    mean2 = local_mean(a * a)\n    var = mean2 - (mean1 ** 2)\n    var = np.maximum(var, 0.0)\n    local_std = np.sqrt(var)\n    proxy = np.log1p(local_std)\n    result = float(np.mean(proxy))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect compactness score of non-zero content (1 = square-like, 0 = line-like or empty)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    mask = arr != 0\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    h_bbox = ys.max() - ys.min() + 1\n    w_bbox = xs.max() - xs.min() + 1\n    if h_bbox <= 0 or w_bbox <= 0:\n        return 0.0\n    ratio = float(min(h_bbox / (w_bbox + eps), w_bbox / (h_bbox + eps)))\n    # ratio in (0,1]; return as-is (1 => square, smaller => elongated)\n    result = float(np.clip(ratio, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of total ink pixels that lie in the central horizontal band (40%-60% height) to detect a mid crossbar'\n    import numpy as np\n    # grayscale conversion and normalization\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx > mn:\n        gray = (gray - mn) / (mx - mn)\n    else:\n        gray = gray * 0.0\n    h, w = gray.shape[:2]\n    # binarize assuming darker ink\n    thresh = 0.5\n    ink = gray < thresh\n    if np.count_nonzero(ink) == 0:\n        ink = gray > thresh\n    total_ink = float(np.count_nonzero(ink))\n    if total_ink == 0.0:\n        return 0.0\n    top = int(0.40 * h)\n    bottom = int(0.60 * h)\n    central_band = ink[top:bottom, :]\n    return float(np.count_nonzero(central_band) / total_ink)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the bottom third of the image (0..1)'\n    try:\n        if len(image.shape) == 3:\n            gray = image.mean(axis=2)\n        else:\n            gray = image.astype(float)\n        g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n        border = np.concatenate([g[0:1, :].ravel(), g[-1:, :].ravel(), g[:, 0:1].ravel(), g[:, -1:].ravel()])\n        border_mean = float(np.mean(border)) if border.size else 0.5\n        if border_mean > 0.5:\n            ink = g < max(0.0, border_mean - 0.15)\n        else:\n            ink = g > min(1.0, border_mean + 0.15)\n        h, w = ink.shape\n        total = np.count_nonzero(ink)\n        if total == 0:\n            return 0.0\n        bottom = np.count_nonzero(ink[(2*h)//3 : , :])\n        return float(bottom) / float(total)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of discrete Laplacian (sharpness measure), normalized by mean magnitude'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gy_y, gy_x = np.gradient(gy)\n        gx_y, gx_x = np.gradient(gx)\n    except Exception:\n        return 0.0\n    lap = gx_x + gy_y\n    var_lap = float(np.var(lap))\n    norm = float(np.mean(np.abs(a))) + eps\n    result = var_lap / norm\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right brightness bias normalized by image std (positive => left brighter)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return float(0.0)\n    mid = w // 2\n    left_mean = float(np.mean(a[:, :mid])) if a[:, :mid].size else 0.0\n    right_mean = float(np.mean(a[:, -mid:])) if a[:, -mid:].size else 0.0\n    overall_std = float(np.std(a)) + eps\n    result = (left_mean - right_mean) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near intensity extremes (within 5%% of min or max) (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    vmin = float(a.min())\n    vmax = float(a.max())\n    if vmax <= vmin + eps:\n        return 0.0\n    rng = vmax - vmin\n    low_th = vmin + 0.05 * rng\n    high_th = vmax - 0.05 * rng\n    mask = (a <= low_th) | (a >= high_th)\n    result = float(mask.sum()) / float(max(1, a.size))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top-bar strength: mean absolute horizontal gradient in the top quarter divided by overall mean horizontal gradient'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float32)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray.astype(np.float32))\n    abs_gx = np.abs(gx)\n    top_h = max(1, h // 4)\n    mean_top = float(np.mean(abs_gx[:top_h, :]))\n    mean_all = float(np.mean(abs_gx)) + 1e-9\n    return float(mean_top / mean_all)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Annular contrast: (mean annulus - mean center)/std overall'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = r.max() if r.size else 0.0\n    if maxr <= eps:\n        return 0.0\n    # center radius = 0.25 * max, annulus between 0.35 and 0.6 of max (adaptive)\n    r0 = 0.25 * maxr\n    r1 = 0.35 * maxr\n    r2 = 0.6 * maxr\n    center_mask = r <= r0\n    ann_mask = (r >= r1) & (r <= r2)\n    if not center_mask.any() or not ann_mask.any():\n        return 0.0\n    center_mean = float(a[center_mask].mean())\n    ann_mean = float(a[ann_mask].mean())\n    overall_std = float(a.std()) + eps\n    result = (ann_mean - center_mean) / overall_std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative high-frequency (Laplacian) energy compared to overall intensity'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    # Discrete Laplacian via 4-neighbor stencil\n    lap = 4.0 * a - np.roll(a, 1, axis=0) - np.roll(a, -1, axis=0) - np.roll(a, 1, axis=1) - np.roll(a, -1, axis=1)\n    lap_energy = float(np.sum(np.abs(lap)))\n    total_energy = float(np.sum(np.abs(a))) + eps\n    result = lap_energy / (total_energy + lap_energy + eps)  # fraction of high-frequency energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink mass in top half to bottom half (7 often has heavier top mass compared to 4)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    p50 = np.percentile(gray, 50)\n    if gray.mean() > p50:\n        thresh = np.percentile(gray, 70); binary = gray > thresh\n    else:\n        thresh = np.percentile(gray, 30); binary = gray < thresh\n    h = binary.shape[0]\n    top = binary[:h // 2, :].sum()\n    bottom = binary[h // 2:, :].sum()\n    if bottom == 0:\n        return float(top)\n    return float((top + 1e-9) / (bottom + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of vertical transitions per column (measures stroke complexity like loops vs single strokes)'\n    import numpy as np\n    arr = np.array(image, dtype=float)\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    if h <= 1 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    fg = gray < th\n    if np.count_nonzero(fg) > gray.size / 2:\n        fg = ~fg\n    # transitions per column: count changes along rows\n    diffs = np.abs(np.diff(fg.astype(int), axis=0))\n    transitions_per_col = np.sum(diffs, axis=0)  # number of changes per column\n    avg_trans = np.mean(transitions_per_col) / max(1.0, float(h))\n    return float(avg_trans)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal symmetry score comparing image to its transpose (1 = perfect)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    m = min(h, w)\n    if m == 0:\n        return 0.0\n    crop = a[:m, :m]\n    trans = crop.T\n    diff = np.abs(crop - trans)\n    norm = float(np.mean(np.abs(crop))) + eps\n    score = 1.0 - (float(np.mean(diff)) / norm)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientation histogram (orientation complexity 0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    angles = np.arctan2(gy, gx)  # [-pi,pi]\n    # map orientation modulo pi (so 0..pi)\n    orients = np.mod(angles, np.pi)\n    bins = 18\n    hist, _ = np.histogram(orients, bins=bins, range=(0.0, np.pi), density=False)\n    total = float(hist.sum()) + eps\n    p = hist / total\n    p_nonzero = p[p > 0]\n    ent = -float((p_nonzero * np.log(p_nonzero)).sum())\n    max_ent = float(np.log(bins) + eps)\n    return float(np.clip(ent / max_ent, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimate of number of enclosed background components (holes) inside the ink strokes'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    thr = 0.5 * (mn + mx)\n    foreground_is_dark = float(np.mean(gray)) < thr\n    if foreground_is_dark:\n        ink = (gray < thr)\n    else:\n        ink = (gray > thr)\n    bg = ~ink\n    # mark background reachable from borders\n    visited = np.zeros_like(bg, dtype=bool)\n    stack = []\n    # push border background pixels\n    for x in range(w):\n        if bg[0, x]:\n            stack.append((0, x))\n        if bg[h-1, x]:\n            stack.append((h-1, x))\n    for y in range(h):\n        if bg[y, 0]:\n            stack.append((y, 0))\n        if bg[y, w-1]:\n            stack.append((y, w-1))\n    while stack:\n        y, x = stack.pop()\n        if visited[y, x]:\n            continue\n        visited[y, x] = True\n        # 4-neighbors\n        if y > 0 and bg[y-1, x] and not visited[y-1, x]:\n            stack.append((y-1, x))\n        if y+1 < h and bg[y+1, x] and not visited[y+1, x]:\n            stack.append((y+1, x))\n        if x > 0 and bg[y, x-1] and not visited[y, x-1]:\n            stack.append((y, x-1))\n        if x+1 < w and bg[y, x+1] and not visited[y, x+1]:\n            stack.append((y, x+1))\n    # Remaining background pixels that are not visited are enclosed -> find their connected components\n    enclosed = (bg & (~visited))\n    holes = 0\n    seen = np.zeros_like(enclosed, dtype=bool)\n    for y in range(h):\n        for x in range(w):\n            if enclosed[y, x] and not seen[y, x]:\n                # flood fill this hole\n                holes += 1\n                stack = [(y, x)]\n                while stack:\n                    yy, xx = stack.pop()\n                    if seen[yy, xx]:\n                        continue\n                    seen[yy, xx] = True\n                    if yy > 0 and enclosed[yy-1, xx] and not seen[yy-1, xx]:\n                        stack.append((yy-1, xx))\n                    if yy+1 < h and enclosed[yy+1, xx] and not seen[yy+1, xx]:\n                        stack.append((yy+1, xx))\n                    if xx > 0 and enclosed[yy, xx-1] and not seen[yy, xx-1]:\n                        stack.append((yy, xx-1))\n                    if xx+1 < w and enclosed[yy, xx+1] and not seen[yy, xx+1]:\n                        stack.append((yy, xx+1))\n    return float(holes)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Rotation-180 similarity: normalized correlation with the image rotated 180 degrees (-1..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    try:\n        rot = np.rot90(a, 2)\n    except Exception:\n        return 0.0\n    if a.shape != rot.shape:\n        rot = np.resize(rot, a.shape)\n    a_mean = a - a.mean()\n    r_mean = rot - rot.mean()\n    num = float((a_mean * r_mean).sum())\n    denom = float(np.sqrt((a_mean ** 2).sum() * (r_mean ** 2).sum()) + 1e-12)\n    result = num / denom\n    # clamp to [-1,1]\n    return float(max(-1.0, min(1.0, result)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized cross-correlation between left half and mirrored right half (1 = perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = img[:, :mid]\n    right = img[:, -mid:] if mid > 0 else np.empty_like(left)\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    right_flipped = np.fliplr(right)\n    L = left.ravel().astype(float)\n    R = right_flipped.ravel().astype(float)\n    mL = L.mean()\n    mR = R.mean()\n    num = ((L - mL) * (R - mR)).sum()\n    den = (np.sqrt(((L - mL) ** 2).sum() * ((R - mR) ** 2).sum()) + eps)\n    corr = float(num) / float(den)\n    # map from [-1,1] to [0,1] so 1 = perfect symmetry, 0 = perfect anti-symmetry\n    result = (corr + 1.0) / 2.0\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Multi-scale Laplacian energy ratio (fine / coarse)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # discrete Laplacian\n    pad = np.pad(a, pad_width=1, mode='edge').astype(float)\n    center = pad[1:-1, 1:-1]\n    up = pad[0:-2, 1:-1]\n    down = pad[2:, 1:-1]\n    left = pad[1:-1, 0:-2]\n    right = pad[1:-1, 2:]\n    lap = (up + down + left + right) - 4.0 * center\n    fine_energy = float(np.mean(np.abs(lap))) + eps\n    # coarse: smooth by 3x3 average then laplacian\n    sm = (center + up + down + left + right +\n          np.roll(np.roll(center, 1, axis=0), 1, axis=1) +\n          np.roll(np.roll(center, 1, axis=0), -1, axis=1) +\n          np.roll(np.roll(center, -1, axis=0), 1, axis=1) +\n          np.roll(np.roll(center, -1, axis=0), -1, axis=1)) / 9.0\n    pad2 = np.pad(sm, pad_width=1, mode='edge')\n    c2 = pad2[1:-1, 1:-1]\n    u2 = pad2[0:-2, 1:-1]\n    d2 = pad2[2:, 1:-1]\n    l2 = pad2[1:-1, 0:-2]\n    r2 = pad2[1:-1, 2:]\n    lap2 = (u2 + d2 + l2 + r2) - 4.0 * c2\n    coarse_energy = float(np.mean(np.abs(lap2))) + eps\n    result = fine_energy / coarse_energy\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized displacement of foreground centroid (threshold=mean) from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = a.mean()\n    mask = a > thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    cy = ys.mean()\n    cx = xs.mean()\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    half_diag = np.hypot(h, w) / 2.0 + eps\n    return float(np.clip(dist / half_diag, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of foreground density in top half versus bottom half (top_density / (bottom_density + eps))'\n    import numpy as np\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    gray_n = (gray - mn) / (mx - mn) if mx - mn > 1e-8 else np.zeros_like(gray)\n    thr = np.mean(gray_n)\n    fg = gray_n < thr if np.mean(gray_n) > 0.5 else gray_n > thr\n    top = fg[:h // 2, :]\n    bottom = fg[h // 2:, :]\n    top_count = float(np.count_nonzero(top))\n    bottom_count = float(np.count_nonzero(bottom))\n    eps = 1e-6\n    return float(top_count / (bottom_count + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity center-of-mass offset magnitude (0..1) relative to image center'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    total = a.sum()\n    if total == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (ys * a).sum() / (total + eps)\n    cx = (xs * a).sum() / (total + eps)\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = float(np.hypot(cy - center_y, cx - center_x))\n    maxd = float(np.hypot(center_y, center_x)) + eps\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson correlation between intensity and distance from center (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    ys, xs = np.indices((h, w))\n    cx = (w - 1.0) / 2.0\n    cy = (h - 1.0) / 2.0\n    r = np.hypot(xs - cx, ys - cy).ravel()\n    v = a.ravel()\n    if r.size < 2 or v.size < 2:\n        return 0.0\n    r_mean = r.mean()\n    v_mean = v.mean()\n    r_std = r.std() + eps\n    v_std = v.std() + eps\n    cov = ((r - r_mean) * (v - v_mean)).mean()\n    corr = cov / (r_std * v_std)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean projection of the local gradient onto the top-right-to-bottom-left diagonal (alignment score)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray)\n    # unit vector for TR->BL direction in (x,y) coordinates: (-1,1)/sqrt(2)\n    ux, uy = -1.0 / np.sqrt(2.0), 1.0 / np.sqrt(2.0)\n    proj = gx * ux + gy * uy\n    mag = np.hypot(gx, gy)\n    # normalized projection magnitude per pixel\n    norm_proj = np.abs(proj) / (mag + 1e-9)\n    # mask out very small gradients\n    mask = mag > (np.percentile(mag, 30) * 0.2 + 1e-9)\n    if mask.sum() == 0:\n        return 0.0\n    result = float(np.mean(norm_proj[mask]))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute diagonal difference (shift (1,1)) to mean absolute vertical gradient (detects diagonal strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-12)\n    # diagonal difference (down-right)\n    diag = np.abs(g - np.roll(np.roll(g, -1, axis=0), -1, axis=1))\n    # avoid wrap-around influence by zeroing last row and column\n    diag[-1, :] = 0\n    diag[:, -1] = 0\n    gy = np.abs(np.gradient(g, axis=0))\n    diab = float(np.mean(np.abs(diag)))\n    vertb = float(np.mean(np.abs(gy))) + 1e-12\n    return float(diab / vertb)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right horizontal gradient asymmetry: (sum of positive grads on left half - right half) normalized (positive -> left-to-right transitions stronger on left)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    h, w = gray.shape[:2]\n    if w < 2:\n        return 0.0\n    hg = np.diff(gray, axis=1)  # shape (h, w-1)\n    pos = np.maximum(hg, 0.0)\n    mid = (w-1)//2\n    left_sum = pos[:, :mid].sum()\n    right_sum = pos[:, mid:].sum()\n    denom = (left_sum + right_sum + 1e-9)\n    return float((left_sum - right_sum) / denom)\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score (0..1): 1 = perfectly symmetric left-right'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    if w % 2 == 0:\n        right = a[:, mid:]\n    else:\n        right = a[:, mid+1:]\n    # flip right horizontally\n    right_flipped = np.fliplr(right)\n    # align sizes\n    min_w = min(left.shape[1], right_flipped.shape[1])\n    if min_w == 0:\n        return 0.0\n    left = left[:, :min_w]\n    right_flipped = right_flipped[:, :min_w]\n    diff = np.abs(left - right_flipped)\n    denom = np.mean(np.abs(a)) + eps\n    score = 1.0 - (diff.mean() / denom)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Compactness proxy: ink area divided by (perimeter + 1). Higher means thicker/compact ink regions.'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    thresh = np.mean(gray)\n    ink = (gray < thresh).astype(np.uint8)\n    if np.mean(ink) > 0.75:\n        ink = (~(ink.astype(bool))).astype(np.uint8)\n    area = float(np.sum(ink))\n    if area <= 0.0:\n        return 0.0\n    pad = np.pad(ink, ((1, 1), (1, 1)), mode='constant', constant_values=0)\n    neighbor_sum = (\n        pad[:-2, :-2] + pad[:-2, 1:-1] + pad[:-2, 2:] +\n        pad[1:-1, :-2] +               0  + pad[1:-1, 2:] +\n        pad[2:, :-2] + pad[2:, 1:-1] + pad[2:, 2:]\n    )\n    # a pixel is on perimeter if it has any background neighbor (neighbor_sum < 8)\n    perimeter_mask = np.logical_and(ink == 1, neighbor_sum < 8)\n    perimeter = float(np.sum(perimeter_mask))\n    compactness = area / (perimeter + 1.0)\n    return float(compactness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box fill ratio: foreground area divided by area of its tight bounding box (0..1)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.percentile(gray, 75))\n    mask = gray >= thr\n    if mask.sum() > 0.6 * (h * w):\n        mask = ~mask\n    mask = mask.astype(bool)\n    ys, xs = np.where(mask)\n    if ys.size == 0:\n        return 0.0\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    fg_area = float(mask.sum())\n    if bbox_area <= 0:\n        return 0.0\n    return float(fg_area / bbox_area)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score: normalized correlation between top half and mirrored bottom half (-1..1)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2:\n        return 0.0\n    mid = h // 2\n    top = img[:mid, :]\n    bot = img[-mid:, :]\n    if top.size == 0 or bot.size == 0:\n        return 0.0\n    bot_flip = np.flipud(bot)\n    A = top.ravel()\n    B = bot_flip.ravel()\n    if A.size == 0 or B.size == 0:\n        return 0.0\n    A_mean = A.mean()\n    B_mean = B.mean()\n    num = np.sum((A - A_mean) * (B - B_mean))\n    den = np.sqrt(np.sum((A - A_mean) ** 2) * np.sum((B - B_mean) ** 2)) + eps\n    result = num / den\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average horizontal gradient magnitude in the central horizontal band normalized by overall gradient (bridge strength)'\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3 or w < 3:\n        return 0.0\n    mn, mx = gray.min(), gray.max()\n    rng = mx - mn\n    if rng <= 0:\n        return 0.0\n    norm = (gray - mn) / (rng + 1e-9)\n    gy, gx = np.gradient(norm)\n    abs_gx = np.abs(gx)\n    ch0 = h // 3\n    ch1 = 2 * h // 3\n    center_band = abs_gx[ch0:ch1, :]\n    center_mean = float(np.mean(center_band))\n    overall_mean = float(np.mean(abs_gx)) + 1e-9\n    return center_mean / overall_mean\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of separate vertical ink runs in the right third (counts separated vertical components along right side)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    col_start = (2*w)//3\n    region = gray[:, col_start:w]\n    if region.size == 0:\n        return 0.0\n    thresh = float(np.mean(region))\n    low = int(np.count_nonzero(region < thresh))\n    high = int(np.count_nonzero(region > thresh))\n    if low < high:\n        ink = (region < thresh).astype(np.uint8)\n    else:\n        ink = (region > thresh).astype(np.uint8)\n    # collapse to a single column by OR-ing columns to find vertical runs\n    collapsed = np.any(ink, axis=1).astype(np.uint8)\n    runs = 0\n    prev = 0\n    for val in collapsed:\n        if val and not prev:\n            runs += 1\n        prev = val\n    return float(runs)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of bright-pixel centroid to image center (0=centered, ~1=corner)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    flat = a.ravel()\n    n = flat.size\n    k = max(1, int(0.01 * n))  # top 1% pixels\n    if k == 0:\n        k = 1\n    idx = np.argpartition(flat, -k)[-k:]\n    ys, xs = np.unravel_index(idx, (h, w))\n    cy = ys.mean()\n    cx = xs.mean()\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    max_dist = np.hypot(center_x, center_y) + 1e-12\n    result = dist / max_dist\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate stroke thickness: foreground area divided by foreground perimeter (higher = thicker)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    gray = (gray - mn) / (mx - mn)\n    thr = float(np.mean(gray))\n    foreground_dark = float(np.mean(gray)) > 0.5\n    mask = (gray < thr) if foreground_dark else (gray > thr)\n    area = float(mask.sum())\n    if area == 0.0:\n        return 0.0\n    # interior pixels have all 8 neighbors foreground\n    nbrs = np.zeros_like(mask, dtype=int)\n    shifts = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n    for dr, dc in shifts:\n        sr = slice(max(0, dr), h + min(0, dr))\n        sc = slice(max(0, dc), w + min(0, dc))\n        tr = slice(max(0, -dr), h + min(0, -dr))\n        tc = slice(max(0, -dc), w + min(0, -dc))\n        nbrs[sr, sc] += mask[tr, tc]\n    interior = (mask) & (nbrs == 8)\n    perimeter_pixels = mask & (~interior)\n    perimeter = float(perimeter_pixels.sum())\n    if perimeter <= 0.0:\n        return float(area)\n    return float(area) / float(perimeter)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation consistency: magnitude of mean gradient unit vector weighted by magnitude (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = float(mag.sum())\n    if total <= 0:\n        return 0.0\n    mean_x = float((gx * mag).sum() / (total + eps))\n    mean_y = float((gy * mag).sum() / (total + eps))\n    # normalize by magnitude scale: since gx*mag sum / total can exceed 1 in value scale,\n    # we convert to unit-vector measure by dividing by (mean magnitude) -> use total_mag_norm\n    mean_vec_mag = np.hypot(mean_x, mean_y)\n    # max possible is limited; clip to [0,1]\n    return float(np.clip(mean_vec_mag / (np.max(mag) + eps), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between ink counts in upper-left and upper-right quadrants ((UL-UR)/(UL+UR+eps))'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    fg = gray < thresh\n    if np.count_nonzero(fg) > 0.5 * h * w:\n        fg = ~fg\n    mid_r = h // 2\n    mid_c = w // 2\n    ul = np.count_nonzero(fg[0:mid_r, 0:mid_c])\n    ur = np.count_nonzero(fg[0:mid_r, mid_c:w])\n    return float((ul - ur) / (ul + ur + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram bimodality index (0..1): two peaks separated by a deep valley and distance'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size < 3:\n        return 0.0\n    bins = 16\n    try:\n        hist, edges = np.histogram(a, bins=bins, range=(a.min(), a.max()))\n    except Exception:\n        hist, edges = np.histogram(a, bins=bins)\n    if hist.sum() == 0:\n        return 0.0\n    # find two largest peaks\n    idxs = np.argsort(hist)\n    if idxs.size < 2:\n        return 0.0\n    p1, p2 = idxs[-1], idxs[-2]\n    lo = min(p1, p2)\n    hi = max(p1, p2)\n    valley = float(hist[lo:hi + 1].min()) if hi >= lo else float(hist[lo])\n    maxcount = float(hist.max()) if hist.max() > 0 else 1.0\n    peaksum = float(hist[p1] + hist[p2])\n    distance_norm = float(abs(p1 - p2)) / float(max(1, bins - 1))\n    bim = (peaksum - 2.0 * valley) / (2.0 * maxcount)\n    result = np.clip(bim * distance_norm, 0.0, 1.0)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of empty pixels in the central vertical band (center gap ratio)'\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    band_w = max(1, w // 8)\n    left = (w - band_w) // 2\n    right = left + band_w\n    if image.ndim == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gm = gray.max()\n    norm = gray / float(gm) if gm != 0 else gray\n    thresh = np.mean(norm)\n    ink = (norm < thresh).astype(np.uint8)\n    if ink.sum() == 0:\n        ink = 1 - ink\n    band = ink[:, left:right]\n    gap_ratio = 1.0 - (band.sum() / float(band.size) if band.size > 0 else 0.0)\n    return float(gap_ratio)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right vertical symmetry score: mean absolute column difference between left half and flipped right half (lower => more symmetric)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mid = w // 2\n    left = gray[:, :mid]\n    right = gray[:, w - mid:]\n    # flip right horizontally to compare\n    right_flipped = np.fliplr(right)\n    # If halves differ in width, crop to smallest\n    min_w = min(left.shape[1], right_flipped.shape[1])\n    if min_w == 0:\n        return 0.0\n    diff = np.abs(left[:, :min_w] - right_flipped[:, :min_w])\n    # normalize by intensity scale\n    denom = np.mean(np.abs(gray)) + 1e-6\n    return float(np.mean(diff) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean dominant edge angle in degrees (edges from left-top to right-bottom are ~45\u00b0; captures slanted 7)'\n    import numpy as np\n    import numpy as _np\n    if len(image.shape) == 3:\n        gray = _np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    gy, gx = _np.gradient(gray)\n    mag = _np.hypot(gx, gy)\n    if mag.sum() == 0:\n        return 0.0\n    # consider only sufficiently strong edges\n    thr = _np.percentile(mag.flatten(), 60)\n    mask = mag >= thr\n    angles = _np.arctan2(gy[mask], gx[mask])  # radians\n    if angles.size == 0:\n        return 0.0\n    mean_angle = _np.mean(angles)\n    # return degrees in range [-180,180]\n    deg = float(_np.degrees(mean_angle))\n    return deg\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with strong gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    thr = float(mag.mean()) + 0.5 * float(mag.std())\n    mask = mag > thr\n    result = float(np.count_nonzero(mask)) / float(mag.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Elongation of the main bright region estimated by PCA of pixel coordinates (0..1, 1 = very elongated)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    # threshold to select meaningful pixels\n    thresh = float(np.median(a)) + 0.5 * (float(a.std()) + eps)\n    ys, xs = np.nonzero(a > thresh)\n    if ys.size < 5:\n        return 0.0\n    vals = a[ys, xs].astype(float)\n    # weight coordinates by intensity\n    wsum = vals.sum() + eps\n    cx = (xs * vals).sum() / wsum\n    cy = (ys * vals).sum() / wsum\n    X = np.vstack(((xs - cx) * np.sqrt(vals), (ys - cy) * np.sqrt(vals)))\n    cov = np.cov(X)\n    # ensure positive semidef\n    try:\n        eig = np.linalg.eigvalsh(cov)\n    except Exception:\n        return 0.0\n    eig = np.sort(np.maximum(eig, 0.0))\n    if eig[-1] <= eps:\n        return 0.0\n    ratio = eig[-1] / (eig[0] + eps)\n    # elongation normalized to [0,1): map ratio -> 1 - (1/ratio) (0 for circle, closer to 1 for high elongation)\n    result = 1.0 - (1.0 / (ratio + 1.0))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Laplacian energy ratio: sum(|L|) / sum(|I|) (higher => more high-frequency content)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, gyx = np.gradient(gy)\n        gxy, gxx = np.gradient(gx)\n    except Exception:\n        return 0.0\n    lap = gxx + gyy\n    num = float(np.sum(np.abs(lap)))\n    den = float(np.sum(np.abs(a))) + eps\n    result = num / den\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference in ink density between the top-right and top-left quadrants (positive = more ink top-right)'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    mid_h = max(1, h // 2)\n    mid_w = max(1, w // 2)\n    top_left = gray[:mid_h, :mid_w]\n    top_right = gray[:mid_h, mid_w:]\n    # produce masks similarly in each quadrant\n    def quad_mask(q):\n        p40 = np.percentile(q, 40)\n        p60 = np.percentile(q, 60)\n        return (q <= p40) if np.count_nonzero(q <= p40) <= max(1, np.count_nonzero(q >= p60)) else (q >= p60)\n    ml = quad_mask(top_left)\n    mr = quad_mask(top_right)\n    ink_l = ml.sum()\n    ink_r = mr.sum()\n    denom = (ink_l + ink_r + 1e-9)\n    return float((ink_r - ink_l) / denom)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Perimeter-to-area proxy (circularity): (perimeter^2) / area -- higher for complex / loop-rich shapes'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    low_mean = np.mean(gray[gray <= p10]) if np.any(gray <= p10) else p10\n    high_mean = np.mean(gray[gray >= p90]) if np.any(gray >= p90) else p90\n    ink_dark = low_mean < high_mean\n    thr = np.percentile(gray, 50)\n    fg = ((gray <= thr) if ink_dark else (gray >= thr)).astype(np.float64)\n    area = fg.sum()\n    if area < 1e-6:\n        return 0.0\n    gy, gx = np.gradient(fg)\n    perimeter_est = np.sum(np.abs(gy)) + np.sum(np.abs(gx))\n    circ = (perimeter_est * perimeter_est) / (area + 1e-6)\n    return float(circ)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density via discrete Laplacian proportion (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # Laplacian via neighbor sums: lap = (4*center - up - down - left - right)\n    center = a\n    up = np.roll(a, 1, axis=0)\n    down = np.roll(a, -1, axis=0)\n    left = np.roll(a, 1, axis=1)\n    right = np.roll(a, -1, axis=1)\n    lap = (4.0 * center - up - down - left - right)\n    mag = np.abs(lap)\n    maxv = mag.max()\n    if maxv <= eps:\n        return 0.0\n    thresh = 0.25 * maxv\n    dense = float(np.count_nonzero(mag > thresh)) / float(mag.size)\n    return float(np.clip(dense, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Largest bright connected component area fraction (4-connected)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    area = h * w\n    if area == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = a > thr\n    visited = np.zeros(mask.shape, dtype=bool)\n    max_comp = 0\n    # neighbors (4-connected)\n    for yi in range(h):\n        for xi in range(w):\n            if mask[yi, xi] and not visited[yi, xi]:\n                # flood fill\n                cnt = 0\n                stack = [(yi, xi)]\n                visited[yi, xi] = True\n                while stack:\n                    y, x = stack.pop()\n                    cnt += 1\n                    # neighbors\n                    if y > 0 and mask[y-1, x] and not visited[y-1, x]:\n                        visited[y-1, x] = True\n                        stack.append((y-1, x))\n                    if y+1 < h and mask[y+1, x] and not visited[y+1, x]:\n                        visited[y+1, x] = True\n                        stack.append((y+1, x))\n                    if x > 0 and mask[y, x-1] and not visited[y, x-1]:\n                        visited[y, x-1] = True\n                        stack.append((y, x-1))\n                    if x+1 < w and mask[y, x+1] and not visited[y, x+1]:\n                        visited[y, x+1] = True\n                        stack.append((y, x+1))\n                if cnt > max_comp:\n                    max_comp = cnt\n    result = float(max_comp) / float(area + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Angle (radians) of the principal axis from PCA of ink coordinates (range approx -pi/2..pi/2)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    fg = gray < thresh\n    if np.count_nonzero(fg) > 0.5 * h * w:\n        fg = ~fg\n    ys, xs = np.nonzero(fg)\n    if ys.size < 2:\n        return 0.0\n    coords = np.vstack((xs.astype(float), ys.astype(float)))\n    cov = np.cov(coords)\n    # principal eigenvector\n    evals, evecs = np.linalg.eigh(cov + 1e-8 * np.eye(2))\n    principal = evecs[:, np.argmax(evals)]\n    angle = np.arctan2(principal[1], principal[0])\n    return float(angle)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum horizontal run length in the top third normalized by image width (detects long top bars like in 7)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    minv, maxv = float(np.min(gray)), float(np.max(gray))\n    scaled = (gray - minv) / (maxv - minv + 1e-8)\n    t = float(np.mean(scaled))\n    dark = scaled <= t\n    bright = scaled >= t\n    fore = dark if dark.sum() <= bright.sum() else bright\n    top_h = max(1, h // 3)\n    max_run = 0\n    for r in range(top_h):\n        row = fore[r, :].astype(int)\n        p = np.concatenate(([0], row, [0]))\n        idx = np.where(np.diff(p) != 0)[0]\n        for i in range(0, len(idx), 2):\n            start = idx[i]\n            end = idx[i+1]\n            max_run = max(max_run, end - start)\n    return float(max_run) / float(max(1, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (width / height) of the tight ink bounding box (returns 1.0 if no ink)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    top = gray[0:1, :]\n    bottom = gray[-1:, :]\n    left = gray[:, 0:1]\n    right = gray[:, -1:]\n    border_mean = float(np.mean(np.concatenate([top.flatten(), bottom.flatten(), left.flatten(), right.flatten()])))\n    rng = float(gray.max() - gray.min())\n    if rng <= 0:\n        return 1.0\n    if border_mean > np.mean(gray):\n        ink = (gray < (border_mean - 0.15 * rng)).astype(np.uint8)\n    else:\n        ink = (gray > (border_mean + 0.15 * rng)).astype(np.uint8)\n    ys, xs = np.where(ink)\n    if ys.size == 0:\n        return 1.0\n    miny, maxy = int(ys.min()), int(ys.max())\n    minx, maxx = int(xs.min()), int(xs.max())\n    bw = maxx - minx + 1\n    bh = maxy - miny + 1\n    if bh == 0:\n        return float(bw)\n    return float(bw / bh)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density per 1000 pixels using gradient magnitude thresholding'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(arr)\n    mag = np.hypot(gx, gy)\n    thr = mag.mean() + mag.std()\n    count = int(np.count_nonzero(mag > thr))\n    density = count / float(max(1, h * w)) * 1000.0\n    return float(density)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of image considered foreground by simple adaptive threshold (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    mean = float(a.mean())\n    std = float(a.std()) + eps\n    thresh = mean + 0.5 * std\n    mask = a > thresh\n    result = float(np.count_nonzero(mask)) / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels that match vertical mirror within tolerance (1.0 = perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = arr[:, :mid]\n    right = arr[:, -mid:]\n    right_mirror = np.fliplr(right)\n    # align shapes if odd width\n    if left.shape != right_mirror.shape:\n        min_c = min(left.shape[1], right_mirror.shape[1])\n        left = left[:, :min_c]\n        right_mirror = right_mirror[:, :min_c]\n    diff = np.abs(left - right_mirror)\n    tol = max(np.std(arr) * 0.2, 1e-6)\n    matched = np.count_nonzero(diff <= tol)\n    total = diff.size\n    if total == 0:\n        return 0.0\n    frac = matched / float(total)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative corner density via a lightweight Harris-like response (0..1)'\n    import numpy as np\n    eps = 1e-12\n    k = 0.04\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    gy, gx = np.gradient(a)\n    A = gx * gx\n    B = gy * gy\n    C = gx * gy\n    # local sums via 3x3 neighborhood using rolls\n    def local_sum(x):\n        s = np.zeros_like(x)\n        for dy in (-1, 0, 1):\n            for dx in (-1, 0, 1):\n                s += np.roll(np.roll(x, dy, axis=0), dx, axis=1)\n        return s\n    Sxx = local_sum(A)\n    Syy = local_sum(B)\n    Sxy = local_sum(C)\n    det = Sxx * Syy - Sxy * Sxy\n    trace = Sxx + Syy\n    R = det - k * (trace ** 2)\n    # robust threshold: count proportion above small fraction of max\n    rmax = float(np.max(R))\n    if rmax <= 0:\n        return 0.0\n    thresh = rmax * 1e-3\n    count = float(np.count_nonzero(R > thresh))\n    result = count / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bias toward diagonal vs axis-aligned gradients: (diag_fraction - axis_fraction), in [-1,1]'\n    import numpy as np\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image.astype(float), axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    # compute gradients\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray.astype(float))\n    mag = np.hypot(gx, gy)\n    total = np.sum(mag)\n    if total <= 0:\n        return 0.0\n    angle = np.arctan2(gy, gx)  # -pi..pi\n    # classify angles: axis-aligned near 0,pi/2; diagonal near pi/4, -pi/4\n    ang_deg = np.abs(np.degrees(angle)) % 180.0\n    # axis if within 22.5 deg of 0 or 90\n    axis_mask = ((ang_deg <= 22.5) | (np.abs(ang_deg - 90) <= 22.5))\n    diag_mask = ((np.abs(ang_deg - 45) <= 22.5) | (np.abs(ang_deg - 135) <= 22.5))\n    axis_sum = float(np.sum(mag[axis_mask]))\n    diag_sum = float(np.sum(mag[diag_mask]))\n    return float((diag_sum - axis_sum) / (total + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in bottom-left quarter to bottom-right quarter (left/right), normalized with eps'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    # binarize adaptively\n    thr = np.mean(gray) * 0.9 + np.min(gray) * 0.1\n    ink = (gray < thr).astype(float)  # assume darker ink has smaller values\n    bl = ink[(3*h)//4:h, 0:w//2].sum()\n    br = ink[(3*h)//4:h, w//2:w].sum()\n    eps = 1e-6\n    return float((bl + eps) / (br + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energy (|gx*gy|) concentrated in anti-diagonal (gx*gy < 0) to total diagonal energy'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gx, gy = np.gradient(gray)\n    diag_energy = np.abs(gx * gy)\n    if np.sum(diag_energy) == 0:\n        return 0.0\n    anti_diag_energy = np.sum(diag_energy[gx * gy < 0])\n    return float(anti_diag_energy / (np.sum(diag_energy) + 1e-12))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal stroke energy in the top-right quadrant: measures strength of 45-degree strokes (useful to detect 7-like diagonals)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    tr = gray[0:h//2, w//2:w]\n    if tr.size == 0:\n        return 0.0\n    gy, gx = np.gradient(tr.astype(float))\n    mag = np.hypot(gx, gy) + 1e-9\n    absgx = np.abs(gx)\n    absgy = np.abs(gy)\n    # diagonal indicator per pixel: 2*min(|gx|,|gy|)/( |gx|+|gy| )\n    diag_frac = 2.0 * np.minimum(absgx, absgy) / (absgx + absgy + 1e-9)\n    diag_weighted = (diag_frac * mag).sum()\n    # normalize by total gradient energy in the quadrant\n    total_energy = mag.sum() + 1e-9\n    return float(diag_weighted / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of FFT energy in high frequencies (outer quarter of radial freq)'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    mag = np.abs(F)\n    ys = np.arange(h)[:, None] - (h // 2)\n    xs = np.arange(w)[None, :] - (w // 2)\n    dist = np.hypot(ys, xs)\n    maxd = float(dist.max()) if dist.size else 1.0\n    mask_outer = dist >= (0.75 * maxd)\n    total = float(mag.sum()) + eps\n    outer = float(mag[mask_outer].sum())\n    result = outer / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean chromatic saturation estimate for color images (0..1), grayscale => 0'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    mx = np.maximum(np.maximum(R, G), B)\n    mn = np.minimum(np.minimum(R, G), B)\n    sat = (mx - mn) / (mx + eps)  # in [0,1]\n    result = float(np.mean(sat))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean edge magnitude computed from image gradients'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    try:\n        gy, gx = np.gradient(img)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    result = np.mean(mag) if mag.size else 0.0\n    return float(result + eps)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average block standard deviation (coarseness) normalized by overall std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    # choose block size proportional to image size\n    bs_y = max(1, h // 8)\n    bs_x = max(1, w // 8)\n    bs_y = min(bs_y, h)\n    bs_x = min(bs_x, w)\n    by = (h + bs_y - 1) // bs_y\n    bx = (w + bs_x - 1) // bs_x\n    block_stds = []\n    for i in range(by):\n        for j in range(bx):\n            y0 = i * bs_y\n            x0 = j * bs_x\n            y1 = min(h, y0 + bs_y)\n            x1 = min(w, x0 + bs_x)\n            block = arr[y0:y1, x0:x1]\n            if block.size:\n                block_stds.append(float(block.std()))\n    if len(block_stds) == 0:\n        return 0.0\n    mean_block_std = float(np.mean(block_stds))\n    overall_std = float(np.std(arr)) + eps\n    result = mean_block_std / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Simple intensity skewness: (mean - median) / std (robust, 0 if undefined)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(arr.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    mean = float(vals.mean())\n    median = float(np.median(vals))\n    std = float(vals.std())\n    if std <= 1e-12:\n        return 0.0\n    result = (mean - median) / std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized topmost ink row: fraction of image height to the first row containing ink (0=top,1=bottom)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0,:], gray[-1,:], gray[:,0], gray[:,-1]])\n    thresh = (np.mean(border) + np.mean(gray)) / 2.0\n    ink = (gray < thresh) if (np.mean(border) > np.mean(gray)) else (gray > thresh)\n    rows = np.any(ink, axis=1)\n    if not np.any(rows):\n        return 1.0\n    first = int(np.argmax(rows))\n    return float(first / max(1.0, h - 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of ink bounding box: height divided by width (robust to empty images)'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(gray.min()), float(gray.max())\n    rng = mx - mn + eps\n    norm = (gray - mn) / rng\n    ink = norm < 0.5 if np.mean(norm) > 0.5 else norm > 0.5\n    ys, xs = np.where(ink)\n    if ys.size == 0:\n        return 0.0\n    h_bbox = ys.max() - ys.min() + 1\n    w_bbox = xs.max() - xs.min() + 1\n    return float((h_bbox + eps) / (w_bbox + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between ink density in the top half and bottom half (top_density - bottom_density) / overall_density'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.count_nonzero(ink) > 0.6 * h * w:\n        ink = ~ink\n    top = ink[0:h//2, :]\n    bottom = ink[h//2:h, :]\n    top_count = float(np.count_nonzero(top))\n    bottom_count = float(np.count_nonzero(bottom))\n    total = top_count + bottom_count\n    if total <= 0.0:\n        return 0.0\n    return float((top_count - bottom_count) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shape eccentricity from second moments: 1 - (minor_axis / major_axis) (0=circle, ~1=elongated)'\n    import numpy as np\n    eps = 1e-9\n    if image is None:\n        return 0.0\n    arr = np.array(image)\n    if arr.size == 0:\n        return 0.0\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    norm = (gray - mn) / (mx - mn + eps)\n    ink = (norm < 0.5).astype(np.float64)\n    ys, xs = np.nonzero(ink)\n    if ys.size < 3:\n        return 0.0\n    cy, cx = float(np.mean(ys)), float(np.mean(xs))\n    yc = ys - cy\n    xc = xs - cx\n    # covariance matrix of coordinates (weighted equally)\n    cov_xx = float(np.mean(xc * xc))\n    cov_yy = float(np.mean(yc * yc))\n    cov_xy = float(np.mean(xc * yc))\n    trace = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    # eigenvalues of 2x2 covariance matrix\n    disc = max(trace * trace / 4.0 - det, 0.0)\n    l1 = trace / 2.0 + np.sqrt(disc)\n    l2 = trace / 2.0 - np.sqrt(disc)\n    # ensure ordering\n    major = max(l1, l2)\n    minor = min(l1, l2)\n    if major < eps:\n        return 0.0\n    ecc = 1.0 - (minor + eps) / (major + eps)\n    return float(np.clip(ecc, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of spectral energy concentrated in low-frequency band (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    # FFT power spectrum\n    F = np.fft.fftshift(np.fft.fft2(a))\n    P = np.abs(F) ** 2\n    # low-frequency central square (relative size 1/8)\n    r_h = max(1, h // 8)\n    r_w = max(1, w // 8)\n    cy, cx = h // 2, w // 2\n    mask = np.zeros_like(P, dtype=bool)\n    mask[cy - r_h:cy + r_h + 1, cx - r_w:cx + r_w + 1] = True\n    low_energy = float(P[mask].sum())\n    total_energy = float(P.sum()) + eps\n    result = low_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal orientation of ink strokes (angle normalized to [-1,1], positive for clockwise tilt)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[:3, :].ravel(), gray[-3:, :].ravel(), gray[:, :3].ravel(), gray[:, -3:].ravel()]) if h>=3 and w>=3 else gray.ravel()\n    center = gray[h//4:3*h//4, w//4:3*w//4] if h>=4 and w>=4 else gray\n    border_mean = float(border.mean()) if border.size else 0.0\n    thresh = float(np.percentile(gray, 50)) if gray.size else 0.5\n    ink = (gray < thresh) if border_mean > (center.mean() if center.size else 0.0) else (gray > thresh)\n    coords = np.argwhere(ink)\n    if coords.shape[0] < 3:\n        return 0.0\n    y = coords[:, 0].astype(np.float64)\n    x = coords[:, 1].astype(np.float64)\n    x = (x - x.mean())\n    y = (y - y.mean())\n    cov_xx = np.mean(x * x)\n    cov_xy = np.mean(x * y)\n    cov_yy = np.mean(y * y)\n    cov = np.array([[cov_xx, cov_xy], [cov_xy, cov_yy]])\n    # largest eigenvector\n    try:\n        vals, vecs = np.linalg.eigh(cov)\n        principal = vecs[:, np.argmax(vals)]\n        vx, vy = principal[0], principal[1]\n        # angle where 0 is horizontal, positive means tilt down-right\n        angle = np.arctan2(vy, vx)\n        # normalize by pi to [-1,1]\n        return float(angle / np.pi)\n    except Exception:\n        return 0.0\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local patch std (texture) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # choose patch size relative to image\n    ps = max(1, min(h, w) // 8)\n    stds = []\n    for i in range(0, h, ps):\n        for j in range(0, w, ps):\n            patch = a[i:i+ps, j:j+ps]\n            if patch.size:\n                stds.append(patch.std())\n    if len(stds) == 0:\n        return 0.0\n    mean_patch_std = float(np.mean(stds))\n    global_std = float(a.std()) + eps\n    result = mean_patch_std / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of strong local intensity peaks normalized by image area (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # threshold to avoid tiny fluctuations: mean + 0.5*std\n    mean = float(a.mean())\n    std = float(a.std())\n    thr = mean + 0.5 * std\n    # pad with -inf so border cannot be maxima by wrap\n    pad = np.pad(a, pad_width=1, mode='constant', constant_values=-np.inf)\n    center = pad[1:-1, 1:-1]\n    # compare to 8 neighbors\n    neighs = [\n        pad[0:-2, 0:-2], pad[0:-2, 1:-1], pad[0:-2, 2:],\n        pad[1:-1, 0:-2],                 pad[1:-1, 2:],\n        pad[2:, 0:-2],  pad[2:, 1:-1],  pad[2:, 2:]\n    ]\n    greater = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        greater &= (center > n)\n    strong = greater & (center > thr)\n    count = float(np.count_nonzero(strong))\n    frac = count / float(h * w + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ink density ratio: top third ink density divided by bottom third ink density (captures top-heavy strokes like in 7)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    if h < 3:\n        return 0.0\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    if p10 < p90:\n        thresh = 0.5 * (p10 + p90)\n        ink = gray < thresh\n    else:\n        thresh = np.mean(gray)\n        ink = gray > thresh\n    top_block = ink[:h//3, :]\n    bottom_block = ink[2*h//3:, :]\n    top_density = float(np.sum(top_block)) / max(1.0, top_block.size)\n    bottom_density = float(np.sum(bottom_block)) / max(1.0, bottom_block.size)\n    return float(top_density / (bottom_density + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink pixels in a horizontal mid-band (captures mid-bars as in 4 or 5)'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 0.0\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        h, w = gray.shape\n        corner = np.concatenate([\n            gray[:max(1, h//16), :max(1, w//16)].ravel(),\n            gray[-max(1, h//16):, :max(1, w//16)].ravel(),\n            gray[:max(1, h//16), -max(1, w//16):].ravel(),\n            gray[-max(1, h//16):, -max(1, w//16):].ravel()\n        ])\n        corner_mean = float(np.mean(corner)) if corner.size else 0.0\n        thresh = float(np.percentile(gray, 40))\n        if corner_mean > 0.5:\n            fg = gray < thresh\n        else:\n            fg = gray > thresh\n        mid_h = h // 2\n        band = max(1, h // 8)\n        mid_region = fg[mid_h-band:mid_h+band+1, :]\n        total_fg = float(np.count_nonzero(fg)) + 1e-8\n        return float(np.count_nonzero(mid_region) / total_fg)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute curvature of strong edges: average angular change of gradient direction (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    theta = np.arctan2(gy, gx)\n    # compute wrapped differences\n    def wrap(diff):\n        return (diff + np.pi) % (2 * np.pi) - np.pi\n    dtx = wrap(np.diff(theta, axis=1))\n    dty = wrap(np.diff(theta, axis=0))\n    magx = mag[:, :-1]\n    magy = mag[:-1, :]\n    # only consider locations with sufficient magnitude\n    thr = float(np.mean(mag))\n    maskx = magx > thr\n    masky = magy > thr\n    vals = []\n    if maskx.any():\n        vals.append(np.abs(dtx[maskx]).mean())\n    if masky.any():\n        vals.append(np.abs(dty[masky]).mean())\n    if not vals:\n        return 0.0\n    mean_abs = float(np.mean(vals))\n    result = mean_abs / np.pi  # normalize to ~[0,1]\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal symmetry score: normalized correlation between left half and mirrored right half (-1..1)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    mid = w // 2\n    if w < 2:\n        return 0.0\n    left = img[:, :mid]\n    right = img[:, -mid:]\n    right_mirror = np.fliplr(right)\n    A = left.ravel()\n    B = right_mirror.ravel()\n    if A.size == 0 or B.size == 0:\n        return 0.0\n    A_mean = A.mean()\n    B_mean = B.mean()\n    num = np.sum((A - A_mean) * (B - B_mean))\n    den = np.sqrt(np.sum((A - A_mean)**2) * np.sum((B - B_mean)**2)) + eps\n    result = num / den\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness index (0 for grayscale images)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # assume last dim is channels in RGB order if available\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    rg_mean, rg_std = float(rg.mean()), float(rg.std())\n    yb_mean, yb_std = float(yb.mean()), float(yb.std())\n    # Hasler & Suesstrunk metric\n    std_root = np.sqrt(rg_std ** 2 + yb_std ** 2)\n    mean_root = np.sqrt(rg_mean ** 2 + yb_mean ** 2)\n    result = std_root + 0.3 * mean_root\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink pixels in the left half to the right half (left/right), >1 means left-heavy'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # simple bimodal threshold\n    lo, hi = float(np.min(gray)), float(np.max(gray))\n    thresh = (lo + hi) / 2.0\n    ink = (gray < thresh)\n    left = np.sum(ink[:, :w//2])\n    right = np.sum(ink[:, w//2:])\n    eps = 1e-6\n    return float(left / (right + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation strength (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 36\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(image.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(image.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= 0:\n        return 0.0\n    # orientation in [0, pi)\n    ang = np.arctan2(gy, gx)\n    ang = np.abs(ang)  # map to [0, pi]\n    ang = ang % np.pi\n    flat_ang = ang.ravel()\n    flat_mag = mag.ravel()\n    # compute weighted histogram\n    bin_edges = np.linspace(0.0, np.pi, bins + 1)\n    hist, _ = np.histogram(flat_ang, bins=bin_edges, weights=flat_mag)\n    total = hist.sum() + eps\n    maxbin = float(hist.max())\n    result = maxbin / total\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect bias of non-empty bounding box (positive => wider, negative => taller) in [-1..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    tol = (np.nanmax(a) - np.nanmin(a)) * 0.05 + eps\n    mask = np.abs(a - np.nanmean(a)) > tol\n    if not mask.any():\n        return 0.0\n    rows = np.where(mask.any(axis=1))[0]\n    cols = np.where(mask.any(axis=0))[0]\n    if rows.size == 0 or cols.size == 0:\n        return 0.0\n    r0, r1 = rows[0], rows[-1]\n    c0, c1 = cols[0], cols[-1]\n    bbox_h = max(1, r1 - r0 + 1)\n    bbox_w = max(1, c1 - c0 + 1)\n    aspect = float(bbox_w) / float(bbox_h)\n    # map aspect to [-1,1]: (aspect-1)/(aspect+1) where >0 means wider\n    result = (aspect - 1.0) / (aspect + 1.0 + eps)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (Hasler-Suesstrunk) for RGB images, 0 for grayscale'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # Use first three channels as R,G,B\n    R = a[:, :, 0].ravel()\n    G = a[:, :, 1].ravel()\n    B = a[:, :, 2].ravel()\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    # Hasler & Suesstrunk colorfulness\n    color = np.sqrt(std_rg * std_rg + std_yb * std_yb) + 0.3 * np.sqrt(mean_rg * mean_rg + mean_yb * mean_yb)\n    return float(max(0.0, color))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels that are locally brighter than their 3x3 neighborhood mean'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # local mean via 3x3 box using rolls\n    s = np.zeros_like(arr)\n    s += arr\n    s += np.roll(arr, 1, axis=0)\n    s += np.roll(arr, -1, axis=0)\n    s += np.roll(arr, 1, axis=1)\n    s += np.roll(arr, -1, axis=1)\n    s += np.roll(np.roll(arr, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(arr, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(arr, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(arr, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    mask = arr > (local_mean + eps)\n    result = float(mask.sum()) / float(arr.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'L1 normalized horizontal symmetry score: average absolute row difference between top and flipped bottom'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = (gray - gray.min()) / max(1e-8, (gray.max() - gray.min()))\n    top = gray[:h // 2, :]\n    bottom = np.flipud(gray[(h + 1) // 2:, :]) if h % 2 else np.flipud(gray[h // 2:, :])\n    minh = min(top.shape[0], bottom.shape[0]) if top.size and bottom.size else 0\n    if minh == 0:\n        return 0.0\n    diff = np.abs(top[:minh, :] - bottom[:minh, :])\n    return float(np.mean(diff))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of horizontal edges in the upper third: mean horizontal gradient in top band divided by global gradient'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # horizontal gradient (differences along columns)\n    hg = np.abs(np.diff(gray, axis=1))\n    # average in upper third\n    top_rows = max(1, h // 3)\n    top_hg = hg[:top_rows, :]\n    mean_top = top_hg.mean() if top_hg.size else 0.0\n    mean_all = hg.mean() if hg.size else 0.0\n    denom = mean_all + 1e-8\n    return float(mean_top / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry: 1 - normalized mean absolute difference to rotated image (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 1.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 1.0\n    rot = np.flipud(np.fliplr(a)) if a.ndim == 2 else np.flip(a)\n    diff = np.abs(a - rot)\n    mean_diff = float(np.mean(diff))\n    mean_val = float(np.mean(np.abs(a))) + eps\n    score = 1.0 - (mean_diff / mean_val)\n    return float(np.clip(score, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of descending-diagonal gradient energy to ascending-diagonal gradient energy (detects \\\\ / strokes like in 2)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy()\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    # descending diagonal component ~ gx + gy, ascending ~ gx - gy\n    desc = np.abs(gx + gy)\n    asc = np.abs(gx - gy)\n    denom = np.sum(asc) + 1e-8\n    if denom == 0:\n        return 0.0\n    return float(np.sum(desc) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score (0..1) based on normalized correlation between halves'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2 or h == 0:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, w - mid:][:, ::-1]  # flip right to compare\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # crop to same shape if odd width\n    min_w = min(left.shape[1], right.shape[1])\n    left = left[:, :min_w].ravel()\n    right = right[:, :min_w].ravel()\n    if left.size == 0:\n        return 0.0\n    # correlation\n    left = left - left.mean()\n    right = right - right.mean()\n    num = float((left * right).sum())\n    den = (np.sqrt((left ** 2).sum() * (right ** 2).sum()) + eps)\n    corr = num / den\n    # map from [-1,1] to [0,1]\n    result = (corr + 1.0) / 2.0\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Structure tensor coherence: degree to which gradients align to a single orientation (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    Ix2 = (gx * gx)\n    Iy2 = (gy * gy)\n    Ixy = (gx * gy)\n    A = float(Ix2.sum())\n    C = float(Iy2.sum())\n    B = float(Ixy.sum())\n    trace = A + C\n    det = A * C - B * B\n    if trace <= eps:\n        return 0.0\n    # eigenvalues of 2x2 matrix: (trace +/- sqrt(trace^2 - 4det))/2\n    discr = max(trace * trace - 4.0 * det, 0.0)\n    l1 = 0.5 * (trace + np.sqrt(discr))\n    l2 = 0.5 * (trace - np.sqrt(discr))\n    if (l1 + l2) <= eps:\n        return 0.0\n    coherence = (l1 - l2) / (l1 + l2 + eps)\n    return float(np.clip(coherence, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Upper-left quadrant ink density normalized by overall ink density (captures presence of upper-left vertical stroke / mass)'\n    import numpy as np\n    try:\n        h, w = image.shape[:2]\n        if h == 0 or w == 0:\n            return 0.0\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        p40, p60 = np.percentile(gray, 40), np.percentile(gray, 60)\n        midpoint = (gray.max() + gray.min()) / 2.0\n        if np.mean(gray) > midpoint:\n            ink = gray < p40\n        else:\n            ink = gray > p60\n        ul = ink[:h // 2, :w // 2]\n        overall = ink\n        overall_count = float(np.count_nonzero(overall))\n        if overall_count == 0.0:\n            return 0.0\n        ul_count = float(np.count_nonzero(ul))\n        return (ul_count / float(ul.size + 1e-12)) / (overall_count / float(overall.size))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average corner-like response: mean of |gx|*|gy| (high for sharp corners common in 5)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = np.min(gray), np.max(gray)\n    denom = mx - mn if mx > mn else 1.0\n    gray_norm = (gray - mn) / denom\n    gy, gx = np.gradient(gray_norm)\n    cornerness = np.abs(gx) * np.abs(gy)\n    # normalize by average gradient magnitude to be scale invariant\n    avg_grad = (np.mean(np.abs(gx)) + np.mean(np.abs(gy))) / 2.0 + 1e-9\n    return float(np.mean(cornerness) / avg_grad)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of vertical edge energy concentrated in the left half (helps detect a left vertical stroke like in 4)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # gradients: np.gradient returns [d/drow (gy), d/dcol (gx)]\n    gy, gx = np.gradient(gray)\n    vertical_energy = np.abs(gx)\n    total = np.sum(vertical_energy) + 1e-9\n    left_energy = np.sum(vertical_energy[:, :max(1, w//2)])\n    return float(left_energy / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-centroid centeredness (1 = centroid at image center, 0 = far away)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    total = float(arr.sum()) + eps\n    # Use intensity-weighted centroid\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    cy = float((arr * ys).sum()) / total\n    cx = float((arr * xs).sum()) / total\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    max_dist = np.hypot(center_y, center_x) + eps\n    result = 1.0 - (dist / max_dist)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of runs (transitions) along the central column (how many separate vertical strokes cross the center area)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = gray.min(), gray.max()\n    if mx - mn > 1e-8:\n        gray_norm = (gray - mn) / (mx - mn)\n    else:\n        gray_norm = gray - mn\n    thr = gray_norm.mean()\n    fg = (gray_norm < thr) if thr > 0.5 else (gray_norm > thr)\n    h, w = fg.shape\n    c = w // 2\n    col = fg[:, c].astype(int)\n    runs = 0\n    in_run = False\n    for v in col:\n        if v and not in_run:\n            runs += 1\n            in_run = True\n        elif not v:\n            in_run = False\n    return float(runs)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Largest enclosed hole area divided by total ink area (detects closed loops like in 9 or 6)'\n    # Robust grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # Determine ink polarity by choosing the smaller side of mean threshold\n    m = gray.mean()\n    low_count = np.sum(gray < m)\n    if low_count <= (h * w / 2):\n        ink = (gray < m)\n    else:\n        ink = (gray > m)\n    ink = ink.astype(np.bool_)\n    ink_area = float(ink.sum())\n    if ink_area < 1:\n        return 0.0\n    # Find holes: connected components on inverted mask that do NOT touch the border\n    inv = (~ink)\n    visited = np.zeros_like(inv, dtype=np.bool_)\n    max_hole = 0\n    # iterate over pixels\n    for r in range(h):\n        for c in range(w):\n            if inv[r, c] and not visited[r, c]:\n                # BFS\n                stack = [(r, c)]\n                visited[r, c] = True\n                touches_border = False\n                comp_size = 0\n                while stack:\n                    y, x = stack.pop()\n                    comp_size += 1\n                    if y == 0 or x == 0 or y == h - 1 or x == w - 1:\n                        touches_border = True\n                    # 8-neighbors\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = y + dy, x + dx\n                            if 0 <= ny < h and 0 <= nx < w and not visited[ny, nx] and inv[ny, nx]:\n                                visited[ny, nx] = True\n                                stack.append((ny, nx))\n                if not touches_border:\n                    if comp_size > max_hole:\n                        max_hole = comp_size\n    return float(max_hole / (ink_area + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box fill of bright region (fraction of image area)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mean = float(a.mean())\n    std = float(a.std())\n    thr = mean + 0.25 * std\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    coords = np.argwhere(mask)\n    ys = coords[:, 0]\n    xs = coords[:, 1]\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    return float(np.clip(bbox_area / (h * w + eps), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized variance of distances of ink pixels to image center (low when ink concentrated centrally)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    ink = (gray < thresh)\n    ys, xs = np.nonzero(ink)\n    if ys.size == 0:\n        return 0.0\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    dy = ys.astype(float) - cy\n    dx = xs.astype(float) - cx\n    d2 = dx*dx + dy*dy\n    var = np.var(d2)\n    # normalize by maximum possible squared distance (corner)\n    maxd2 = ((cx)**2 + (cy)**2)\n    if maxd2 <= 0:\n        return float(var)\n    return float(var / maxd2)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant intensity-mode offset from mid-range (-1..1, negative=>darker mode)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(arr.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    nbins = 32\n    vmin, vmax = float(vals.min()), float(vals.max())\n    if vmax <= vmin + eps:\n        return 0.0\n    hist, edges = np.histogram(vals, bins=nbins, range=(vmin, vmax))\n    idx = int(np.argmax(hist))\n    bin_center = (edges[idx] + edges[idx + 1]) / 2.0\n    mid = (vmin + vmax) / 2.0\n    result = (bin_center - mid) / ((vmax - vmin) / 2.0 + eps)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Laplacian energy (high-frequency strength relative to overall intensity)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) +\n           np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    energy = float(np.sum(np.abs(lap)))\n    baseline = float(np.sum(np.abs(a))) + eps\n    return float(energy / baseline)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Color channel imbalance: normalized std of channel means (0..1), 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    img = np.nan_to_num(arr.astype(float))\n    ch = img[..., :3]\n    means = ch.reshape(-1, 3).mean(axis=0)\n    max_mean = float(np.max(np.abs(means)) + eps)\n    imbalance = float(np.std(means) / max_mean)\n    return float(np.clip(imbalance, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels in the top 5% intensity (bright-spot density)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    try:\n        thresh = float(np.percentile(flat, 95))\n    except Exception:\n        return 0.0\n    count = float((flat > thresh).sum())\n    result = count / float(flat.size)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near intensity extremes (within 5% of range)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = img.mean(axis=2).astype(float)\n    else:\n        arr = img.astype(float)\n    vmin = float(arr.min())\n    vmax = float(arr.max())\n    if vmax == vmin:\n        return 0.0\n    thr = 0.05 * (vmax - vmin)\n    high = np.count_nonzero(arr >= (vmax - thr))\n    low = np.count_nonzero(arr <= (vmin + thr))\n    count = int(high + low)\n    frac = float(count) / float(arr.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score: normalized correlation between top half and mirrored bottom half (-1..1)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    mid = h // 2\n    if h < 2:\n        return 0.0\n    top = img[:mid, :]\n    bottom = img[-mid:, :]\n    bottom_mirror = np.flipud(bottom)\n    A = top.ravel()\n    B = bottom_mirror.ravel()\n    if A.size == 0 or B.size == 0:\n        return 0.0\n    A_mean = A.mean()\n    B_mean = B.mean()\n    num = np.sum((A - A_mean) * (B - B_mean))\n    den = np.sqrt(np.sum((A - A_mean) ** 2) * np.sum((B - B_mean) ** 2)) + eps\n    result = num / den\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local peak density: count of strict local maxima (8-neighbour) normalized by image area'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # pad with very small value so edges can be maxima\n    pad = -1e12\n    A = np.pad(a, 1, mode='constant', constant_values=pad)\n    center = A[1:-1, 1:-1]\n    neighs = [\n        A[0:-2, 0:-2], A[0:-2, 1:-1], A[0:-2, 2:],\n        A[1:-1, 0:-2],               A[1:-1, 2:],\n        A[2:, 0:-2],   A[2:, 1:-1],   A[2:, 2:]\n    ]\n    mask = np.ones_like(center, dtype=bool)\n    for nbh in neighs:\n        mask &= (center > nbh)\n    peaks = int(mask.sum())\n    area = float(h * w)\n    result = peaks / (area + 1e-12)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientation histogram (0..1, 1 => maximal orientation disorder)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    total_mag = float(mag.sum())\n    if total_mag <= eps:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    # orientation ignoring sign -> map to [0, pi)\n    orient = np.mod(ang, np.pi)\n    bins = 12\n    hist, _ = np.histogram(orient, bins=bins, range=(0.0, np.pi), weights=mag)\n    p = hist.astype(float) / (hist.sum() + eps)\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -float((p_nonzero * np.log2(p_nonzero)).sum())\n    # normalize by max possible entropy log2(bins)\n    max_ent = float(np.log2(bins))\n    result = entropy / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean pairwise distance among top-5 brightest pixels normalized by image diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    flat = a.ravel()\n    if flat.size < 2:\n        return 0.0\n    k = min(5, flat.size)\n    idx = np.argpartition(-flat, k-1)[:k]\n    ys = (idx // w).astype(float)\n    xs = (idx % w).astype(float)\n    pts = np.stack([ys, xs], axis=1)\n    if pts.shape[0] < 2:\n        return 0.0\n    dsum = 0.0\n    pairs = 0\n    for i in range(pts.shape[0]):\n        for j in range(i+1, pts.shape[0]):\n            dsum += np.hypot(pts[i,0]-pts[j,0], pts[i,1]-pts[j,1])\n            pairs += 1\n    avgd = dsum / (pairs + eps)\n    maxd = np.hypot(h-1, w-1) + eps\n    result = float(np.clip(avgd / maxd, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative concentration of strong edges in the center region (ratio >1 means center more edge-dense)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    edges = mag > thr\n    total_edges = float(edges.sum())\n    total_area = float(arr.size)\n    # center region (middle half)\n    ch0, ch1 = h // 4, 3 * h // 4\n    cw0, cw1 = w // 4, 3 * w // 4\n    center_mask = np.zeros_like(edges, dtype=bool)\n    center_mask[ch0:ch1, cw0:cw1] = True\n    center_edges = float(np.logical_and(edges, center_mask).sum())\n    center_area = float(center_mask.sum()) + eps\n    overall_edge_density = (total_edges / (total_area + eps)) + eps\n    center_density = center_edges / center_area\n    result = center_density / overall_edge_density\n    # clip to a reasonable bound\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean pairwise correlation between RGB channels ([-1..1], 0 for non-RGB)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0 or img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    r = a[:, :, 0].ravel()\n    g = a[:, :, 1].ravel()\n    b = a[:, :, 2].ravel()\n    def corr(x, y):\n        xm = x.mean()\n        ym = y.mean()\n        sx = x.std()\n        sy = y.std()\n        if sx < eps or sy < eps:\n            return 0.0\n        return float(((x - xm) * (y - ym)).mean() / (sx * sy))\n    c1 = corr(r, g)\n    c2 = corr(r, b)\n    c3 = corr(g, b)\n    result = float((c1 + c2 + c3) / 3.0)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical to horizontal gradient energy (sum|dI/dy| / (sum|dI/dx| + eps))'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gx, gy = np.gradient(gray.astype(float))\n    vert_energy = np.sum(np.abs(gy))\n    horz_energy = np.sum(np.abs(gx))\n    return float(vert_energy / (horz_energy + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) computed from histogram of intensities'\n    import numpy as np\n    eps = 1e-12\n    nbins = 64\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.ravel(np.nan_to_num(img.mean(axis=2).astype(float)))\n    else:\n        arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    amin, amax = arr.min(), arr.max()\n    if amax <= amin:\n        return 0.0\n    hist, _ = np.histogram(arr, bins=nbins, range=(amin, amax))\n    probs = hist.astype(float) / (hist.sum() + eps)\n    probs = probs[probs > 0]\n    ent = -np.sum(probs * np.log2(probs + eps))\n    max_ent = np.log2(nbins)\n    result = ent / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    # compute histogram\n    mn, mx = float(a.min()), float(a.max())\n    if mn == mx:\n        return 0.0\n    hist, _ = np.histogram(a, bins=bins, range=(mn, mx))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0]\n    entropy = -np.sum(p * np.log2(p + eps))\n    max_entropy = np.log2(bins)\n    result = entropy / (max_entropy + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of the intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 64\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    mn = float(a.min()); mx = float(a.max())\n    if mx <= mn + eps:\n        return 0.0\n    hist, _ = np.histogram(a.flatten(), bins=bins, range=(mn, mx))\n    total = hist.sum()\n    if total == 0:\n        return 0.0\n    p = hist.astype(float) / float(total)\n    p_nonzero = p[p > 0.0]\n    entropy = -np.sum(p_nonzero * np.log2(p_nonzero))\n    max_entropy = np.log2(bins) + eps\n    result = float(entropy / max_entropy)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels considered foreground (intensity > mean + 0.5*std)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m + 0.5 * s\n    mask = a > thr\n    frac = float(np.count_nonzero(mask)) / (a.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal offset of the largest hole centroid from image center normalized by width (positive -> hole to the right)'\n    import numpy as np\n    from collections import deque\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray > thr  # True = ink, False = background\n    background = ~ink\n    # Flood fill external background starting from borders\n    seen = np.zeros_like(background, dtype=bool)\n    dq = deque()\n    # push all border background pixels\n    for x in range(w):\n        if background[0, x]:\n            dq.append((0, x)); seen[0, x] = True\n        if background[h - 1, x]:\n            dq.append((h - 1, x)); seen[h - 1, x] = True\n    for y in range(h):\n        if background[y, 0] and not seen[y, 0]:\n            dq.append((y, 0)); seen[y, 0] = True\n        if background[y, w - 1] and not seen[y, w - 1]:\n            dq.append((y, w - 1)); seen[y, w - 1] = True\n    while dq:\n        y, x = dq.popleft()\n        # 4-neighbors\n        if y > 0 and background[y - 1, x] and not seen[y - 1, x]:\n            seen[y - 1, x] = True; dq.append((y - 1, x))\n        if y < h - 1 and background[y + 1, x] and not seen[y + 1, x]:\n            seen[y + 1, x] = True; dq.append((y + 1, x))\n        if x > 0 and background[y, x - 1] and not seen[y, x - 1]:\n            seen[y, x - 1] = True; dq.append((y, x - 1))\n        if x < w - 1 and background[y, x + 1] and not seen[y, x + 1]:\n            seen[y, x + 1] = True; dq.append((y, x + 1))\n    # Holes are background pixels not reached by external fill\n    holes = background & (~seen)\n    hole_count = np.count_nonzero(holes)\n    if hole_count == 0:\n        return 0.0\n    ys, xs = np.where(holes)\n    cx = np.mean(xs)\n    center_x = (w - 1) / 2.0\n    return float((cx - center_x) / (w + 1e-8))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal edge strength difference between left and right in the top third (detects whether the top bar is centered or biased)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    top_h = max(1, h // 3)\n    Gx, Gy = np.gradient(gray)\n    horiz_edge = np.abs(Gx)  # horizontal edges respond to horizontal intensity changes\n    left_energy = np.sum(horiz_edge[0:top_h, :w//2])\n    right_energy = np.sum(horiz_edge[0:top_h, w//2:])\n    denom = left_energy + right_energy + 1e-8\n    return float(right_energy - left_energy) / float(denom)\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of vertical transitions per column (variation across columns); higher => more vertical complexity'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    mask = gray < np.mean(gray)\n    if mask.sum() > mask.size * 0.6:\n        mask = ~mask\n    h, w = mask.shape\n    if mask.sum() == 0:\n        return 0.0\n    transitions = []\n    for c in range(w):\n        col = mask[:, c].astype(np.uint8)\n        t = np.sum(col[:-1] != col[1:])\n        transitions.append(t)\n    return float(np.std(np.array(transitions)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with strong gradient magnitude (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    count = float(np.count_nonzero(mag > thr))\n    result = count / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Peakiness of gradient orientation histogram (max bin fraction, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    theta = np.arctan2(gy, gx).ravel()\n    bins = 36\n    hist, _ = np.histogram(theta, bins=bins, range=(-np.pi, np.pi))\n    total = float(hist.sum()) + eps\n    peak = float(hist.max()) if hist.size else 0.0\n    result = peak / total\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Average patch entropy (4x4 blocks) normalized to [0..1] (8 bins)'\n    import numpy as np\n    eps = 1e-12\n    bins = 8\n    ph, pw = 4, 4\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < ph or w < pw:\n        return 0.0\n    ch = (h // ph) * ph\n    cw = (w // pw) * pw\n    sub = arr[:ch, :cw]\n    if sub.size == 0:\n        return 0.0\n    blocks = sub.reshape(ch // ph, ph, cw // pw, pw).swapaxes(1,2).reshape(-1, ph*pw)\n    max_ent = np.log2(bins)\n    ent_sum = 0.0\n    for blk in blocks:\n        vmin = float(blk.min())\n        vmax = float(blk.max())\n        if vmax <= vmin:\n            continue\n        hist, _ = np.histogram(blk, bins=bins, range=(vmin, vmax))\n        p = hist.astype(float) / (hist.sum() + eps)\n        pnz = p[p > 0.0]\n        if pnz.size == 0:\n            continue\n        ent = -np.sum(pnz * np.log2(pnz))\n        ent_sum += ent / (max_ent + eps)\n    avg = ent_sum / float(blocks.shape[0] + eps)\n    return float(np.clip(avg, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of vertical gradient energy that lies in the right half (captures vertical components concentrated on the right as in 3)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gx, gy = np.gradient(gray)\n    vert_energy = np.abs(gy)\n    total_energy = np.sum(vert_energy) + 1e-8\n    right_energy = np.sum(vert_energy[:, w//2:])\n    return float(right_energy) / float(total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Upper-to-lower stroke density ratio (higher if more strokes in upper half)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    rng = mx - mn + 1e-8\n    norm = (gray - mn) / rng\n    stroke_darker = np.mean(norm) < 0.5\n    mask = (norm < 0.5) if stroke_darker else (norm > 0.5)\n    mid = h // 2\n    upper = mask[:mid, :]\n    lower = mask[mid:, :]\n    upper_mean = float(np.sum(upper) / (upper.size + 1e-8))\n    lower_mean = float(np.sum(lower) / (lower.size + 1e-8))\n    return float((upper_mean - lower_mean))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical gradient energy in left half to right half (left_vs_right_vertical_grad)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if w < 2:\n        return 0.0\n    dy, dx = np.gradient(gray)\n    vert = np.abs(dy)\n    left = vert[:, :w//2]\n    right = vert[:, w//2:]\n    left_energy = np.sum(left)\n    right_energy = np.sum(right)\n    if right_energy <= 1e-8:\n        return float(left_energy)\n    return float(left_energy / right_energy)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean log-variance of non-overlapping blocks (texture coarseness)'\n    import numpy as np\n    eps = 1e-12\n    BLOCK = 8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    bh = max(1, min(BLOCK, h))\n    bw = max(1, min(BLOCK, w))\n    # number of full blocks\n    nh = h // bh\n    nw = w // bw\n    if nh == 0 or nw == 0:\n        # fallback to global variance\n        v = float(np.var(a))\n        return float(np.log(v + eps))\n    vals = []\n    for i in range(nh):\n        for j in range(nw):\n            block = a[i*bh:(i+1)*bh, j*bw:(j+1)*bw]\n            vals.append(float(np.var(block)))\n    vals = np.array(vals, dtype=float)\n    mean_log_var = float(np.mean(np.log(vals + eps)))\n    # scale to a reasonable numeric range\n    return float(mean_log_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong edges that lie within the outer 20% border (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    thr = float(np.mean(mag)) + float(np.std(mag)) * 0.5\n    edges = mag > thr\n    if not np.any(edges):\n        return 0.0\n    ys, xs = np.indices((h, w))\n    br = int(max(1, np.floor(0.2 * min(h, w))))\n    border_mask = (xs < br) | (xs >= (w - br)) | (ys < br) | (ys >= (h - br))\n    num_border_edges = int(np.count_nonzero(edges & border_mask))\n    num_edges = int(np.count_nonzero(edges))\n    frac = float(num_border_edges) / float(num_edges + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local variance (3x3) normalized by global standard deviation'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute local mean and local mean of squares using rolling sums\n    def local_mean(X):\n        s = np.zeros_like(X)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    mean_loc = local_mean(a)\n    mean_sq_loc = local_mean(a * a)\n    var_loc = mean_sq_loc - (mean_loc * mean_loc)\n    mean_local_variance = float(np.mean(var_loc))\n    gstd = float(a.std()) + eps\n    result = mean_local_variance / gstd\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Row-wise high-pixel fraction variability: std/mean of per-row hot-pixel fractions'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # per-row threshold: row mean + 0.5 * row std\n    row_means = a.mean(axis=1)\n    row_stds = a.std(axis=1)\n    thr = row_means + 0.5 * row_stds\n    # broadcast threshold to compare\n    mask = a > thr[:, None]\n    row_fracs = mask.sum(axis=1) / (w + eps)\n    mean_frac = float(row_fracs.mean())\n    std_frac = float(row_fracs.std())\n    result = std_frac / (mean_frac + eps)\n    # clip to a reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean binary ink presence in a narrow horizontal band around the image midline (detects middle crossbar like in \"4\")'\n    import numpy as np\n    h, w = image.shape[:2]\n    # convert to grayscale\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # robust binarization (assume ink differs from median)\n    thr = np.mean(gray)\n    mask = gray < thr\n    prop = mask.mean()\n    if prop > 0.9 or prop < 0.01:\n        mask = gray > thr\n    # choose a narrow band around middle (10% of height)\n    band_h = max(1, h // 10)\n    start = max(0, h // 2 - band_h // 2)\n    band = mask[start:start + band_h, :]\n    return float(band.mean())\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box aspect ratio of foreground (0..1) using median threshold'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    thr = float(np.median(a))\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    ymin, ymax = ys.min(), ys.max()\n    xmin, xmax = xs.min(), xs.max()\n    bh = float(ymax - ymin + 1)\n    bw = float(xmax - xmin + 1)\n    if bh <= 0.0 or bw <= 0.0:\n        return 0.0\n    ratio = min(bh / bw, bw / bh)\n    result = float(np.clip(ratio, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean color saturation for RGB images (0..1), 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    mx = np.max(a[..., :3], axis=2)\n    mn = np.min(a[..., :3], axis=2)\n    sat = (mx - mn) / (mx + eps)\n    result = float(np.mean(sat))\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Linear slope of mean intensity vs normalized radius from center (negative => center bright)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h) - cy\n    xs = np.arange(w) - cx\n    Y, X = np.meshgrid(ys, xs, indexing='ij')\n    R = np.hypot(Y, X)\n    Rn = R / (R.max() + 1e-12)\n    # bin radii into 12 rings\n    bins = 12\n    inds = (Rn * (bins - 1)).astype(int).ravel()\n    vals = a.ravel()\n    ring_means = []\n    ring_centers = []\n    for i in range(bins):\n        mask = inds == i\n        if not np.any(mask):\n            # skip empty rings\n            continue\n        ring_means.append(float(vals[mask].mean()))\n        ring_centers.append((i / float(bins - 1)))\n    if len(ring_means) < 2:\n        return 0.0\n    xs = np.array(ring_centers)\n    ys = np.array(ring_means)\n    # simple robust slope via covariance\n    xm = xs.mean(); ym = ys.mean()\n    denom = np.sum((xs - xm) ** 2) + 1e-12\n    slope = np.sum((xs - xm) * (ys - ym)) / denom\n    # normalize slope by image std so comparable across ranges\n    norm = np.std(a) + 1e-12\n    result = -slope / norm  # negative slope => intensity decreases with radius => center bright -> positive result\n    # compress to reasonable range\n    return float(np.tanh(result))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of diagonal strokes: (45\u00b0 + -45\u00b0 energy) / (vertical + horizontal + diag) \u2014 higher for slanted strokes like 7'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 0.0\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        # compute gradients\n        gy, gx = np.gradient(gray)\n        # energies\n        vert_energy = np.sum(np.abs(gy))\n        horz_energy = np.sum(np.abs(gx))\n        diag1 = (gx + gy) / np.sqrt(2.0)\n        diag2 = (gx - gy) / np.sqrt(2.0)\n        diag_energy = np.sum(np.abs(diag1)) + np.sum(np.abs(diag2))\n        denom = vert_energy + horz_energy + diag_energy + 1e-8\n        return float(diag_energy / denom)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local contrast: average absolute difference from 3x3 local mean normalized by mean intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # sum over 3x3 neighborhood using rolls (wrap-around, efficient)\n    s = np.zeros_like(a, dtype=float)\n    shifts = [(0,0),(1,0),(-1,0),(0,1),(0,-1),(1,1),(1,-1),(-1,1),(-1,-1)]\n    for dy, dx in shifts:\n        s += np.roll(np.roll(a, dy, axis=0), dx, axis=1)\n    local_mean = s / 9.0\n    local_contrast = np.mean(np.abs(a - local_mean))\n    denom = float(np.mean(np.abs(a))) + eps\n    result = local_contrast / denom\n    return float(np.clip(result, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative top-left vs top-right horizontal edge strength: mean |horizontal gradient| in top-left divided by top-right'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    med = np.median(gray)\n    # compute gradients on gray\n    try:\n        gy, gx = np.gradient(gray)\n    except Exception:\n        gy = np.zeros_like(gray)\n        gx = np.zeros_like(gray)\n    horiz = np.abs(gx)\n    midx = w // 2\n    top = slice(0, max(1, h // 4))  # top quarter\n    left_strength = np.mean(horiz[top, :midx]) if np.any(~np.isnan(horiz[top, :midx])) else 0.0\n    right_strength = np.mean(horiz[top, midx:w]) if np.any(~np.isnan(horiz[top, midx:w])) else 0.0\n    if right_strength < 1e-9:\n        return float(left_strength)\n    return float(left_strength / right_strength)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean gradient magnitude normalized by mean intensity'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    mean_mag = float(mag.mean())\n    mean_int = float(np.mean(a))\n    result = mean_mag / (abs(mean_int) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of gradient energy attributable to horizontal edges (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    abs_gx = np.abs(gx)\n    abs_gy = np.abs(gy)\n    hor_energy = float(abs_gy.sum())\n    total = float(abs_gx.sum() + abs_gy.sum() + eps)\n    result = hor_energy / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance from top to the first ink row (top gap / image height)'\n    import numpy as np\n    img = image.astype(float)\n    h, w = img.shape[:2]\n    if img.max() > 1.0:\n        img = img / 255.0\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    thr = gray.mean()\n    cand1 = gray < thr\n    cand2 = gray > thr\n    mask = cand1 if cand1.sum() <= cand2.sum() else cand2\n    rows = np.where(mask.any(axis=1))[0]\n    if rows.size == 0:\n        return 1.0\n    top_row = rows.min()\n    return float(top_row / max(1.0, h - 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1), higher = more diverse intensities'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    # use fixed number of bins for stability\n    bins = 32\n    try:\n        hist, _ = np.histogram(arr.ravel(), bins=bins, density=True)\n    except Exception:\n        return 0.0\n    prob = hist.clip(min=0.0)\n    prob_sum = prob.sum()\n    if prob_sum <= 0:\n        return 0.0\n    prob = prob / (prob_sum + eps)\n    entropy = -np.sum(np.where(prob > 0, prob * np.log(prob), 0.0))\n    max_entropy = np.log(bins) + eps\n    result = float(entropy / max_entropy)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0 = single value, 1 = maximal entropy for bins)'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(image.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(image.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    hist, _ = np.histogram(flat, bins=bins, range=(flat.min(), flat.max()))\n    total = hist.sum()\n    if total == 0:\n        return 0.0\n    p = hist.astype(float) / float(total)\n    p_nonzero = p[p > 0.0]\n    entropy = -np.sum(p_nonzero * np.log(p_nonzero + eps))\n    # normalize by log(bins)\n    max_ent = np.log(float(bins) + eps)\n    result = float(entropy / (max_ent + eps))\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of image pixels above an adaptive mean+std threshold (foreground density)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thresh = m + 0.5 * s\n    mask = a > thresh\n    result = float(np.count_nonzero(mask)) / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of center-region pixels above global mean (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    ch = h // 4\n    cw = w // 4\n    center = a[ch:3*ch if 3*ch > ch else h, cw:3*cw if 3*cw > cw else w]\n    if center.size == 0:\n        return 0.0\n    global_mean = float(a.mean())\n    count = float(np.count_nonzero(center > global_mean))\n    result = count / float(center.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Laplacian energy: sum(|Laplacian|)/sum(|pixel|)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    # discrete 4-neighbor Laplacian\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) + np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    num = float(np.sum(np.abs(lap)))\n    den = float(np.sum(np.abs(a))) + eps\n    result = num / den\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels within one standard deviation of the mean (0..1), low => high contrast'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    if s == 0.0:\n        return 1.0\n    low = m - s\n    high = m + s\n    mask = (a >= low) & (a <= high)\n    result = float(np.count_nonzero(mask)) / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of local peaks (8-neighbor maxima) above mean+std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compare to 8 neighbors using rolls\n    center = a\n    neighbors = [\n        np.roll(np.roll(a, dy, axis=0), dx, axis=1)\n        for dy in (-1, 0, 1) for dx in (-1, 0, 1) if not (dy == 0 and dx == 0)\n    ]\n    is_peak = np.ones_like(a, dtype=bool)\n    for n in neighbors:\n        is_peak &= (center > n)\n    thr = float(a.mean() + a.std())\n    mask = is_peak & (center > thr)\n    count = float(np.count_nonzero(mask))\n    result = count / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energies: (|gx+gy| energy) / (|gx-gy| energy)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray.astype(float))\n    diag1 = gx + gy\n    diag2 = gx - gy\n    e1 = np.sum(np.abs(diag1))\n    e2 = np.sum(np.abs(diag2))\n    eps = 1e-9\n    return float((e1 + eps) / (e2 + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientations weighted by magnitude (0..1)'\n    import numpy as np\n    eps = 1e-12\n    nbins = 16\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total_mag = float(mag.sum())\n    if total_mag <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # map to [0, 2*pi)\n    theta = (theta + 2 * np.pi) % (2 * np.pi)\n    bins = np.linspace(0.0, 2 * np.pi, nbins + 1)\n    hist = np.zeros(nbins, dtype=float)\n    # bin weighted by magnitude\n    inds = np.minimum(np.searchsorted(bins, theta, side='right') - 1, nbins - 1)\n    # accumulate\n    for i in range(nbins):\n        hist[i] = float(mag[inds == i].sum())\n    probs = hist / (hist.sum() + eps)\n    probs = probs[probs > 0]\n    ent = -np.sum(probs * np.log2(probs + eps))\n    max_ent = np.log2(nbins)\n    result = float(ent / (max_ent + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in right third to ink in left third (detects right-heavy digits like 3/7)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    if np.max(gray) > 1.5:\n        gray = gray / 255.0\n    mid = float(np.percentile(gray, 50))\n    ink = (gray < mid) if (np.mean(gray) > 0.5) else (gray > mid)\n    ink = ink.astype(np.uint8)\n    h, w = gray.shape\n    third = max(1, w // 3)\n    left = float(np.sum(ink[:, :third]))\n    right = float(np.sum(ink[:, -third:]))\n    # return ratio right/left (higher means more ink on right)\n    return float(right / (left + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast of the brightest quadrant vs others normalized by image std'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    hm = h // 2\n    wm = w // 2\n    q1 = arr[:hm, :wm]\n    q2 = arr[:hm, wm:]\n    q3 = arr[hm:, :wm]\n    q4 = arr[hm:, wm:]\n    means = [float(np.mean(q)) if q.size else 0.0 for q in (q1, q2, q3, q4)]\n    overall_std = float(np.std(arr)) + eps\n    sorted_means = sorted(means, reverse=True)\n    top = sorted_means[0]\n    second = sorted_means[1] if len(sorted_means) > 1 else 0.0\n    result = (top - second) / overall_std\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gini coefficient of intensity magnitudes (0..1, higher => more sparse/concentrated)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    vals = np.abs(vals)\n    if vals.size == 0:\n        return 0.0\n    vals = vals + 0.0  # ensure float\n    total = vals.sum()\n    if total <= eps:\n        return 0.0\n    # sort ascending\n    sorted_vals = np.sort(vals)\n    n = sorted_vals.size\n    idx = np.arange(1, n + 1, dtype=float)\n    gini = (2.0 * (idx * sorted_vals).sum()) / ((n * total) + eps) - (n + 1.0) / n\n    result = float(np.clip(gini, 0.0, 1.0))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Skewness of intensity distribution (tanh-compressed, -1..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    n = a.size\n    if n < 3:\n        return 0.0\n    mu = float(a.mean())\n    sd = float(a.std())\n    if sd <= 0:\n        return 0.0\n    skew = float(((a - mu) ** 3).mean()) / (sd ** 3)\n    return float(np.tanh(skew / 3.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels with high gradient magnitude (>90th percentile)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy).ravel()\n    if mag.size == 0:\n        return 0.0\n    thresh = np.percentile(mag, 90)\n    high_count = float(np.count_nonzero(mag > thresh))\n    frac = high_count / (mag.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity slope: normalized change of mean intensity with radius (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    maxr = float(r.max()) + eps\n    # bin into 10 radial bins\n    nbins = 10\n    bins = np.linspace(0.0, maxr, nbins + 1)\n    bin_idx = np.digitize(r.ravel(), bins) - 1\n    bin_means = []\n    bin_centers = []\n    vals = a.ravel()\n    for b in range(nbins):\n        sel = bin_idx == b\n        if np.any(sel):\n            bin_means.append(float(vals[sel].mean()))\n            # use center radius value\n            bin_centers.append(float((bins[b] + bins[b+1]) / 2.0))\n    if len(bin_means) < 2:\n        return 0.0\n    y = np.array(bin_means)\n    x = np.array(bin_centers)\n    xm = x.mean()\n    ym = y.mean()\n    denom = (np.sum((x - xm) ** 2) + eps)\n    slope = float(np.sum((x - xm) * (y - ym)) / denom)\n    # normalize slope by mean intensity and max radius to keep scale\n    norm = (y.mean() + eps)\n    slope_norm = slope * maxr / norm\n    # clip to -1..1\n    result = float(np.clip(slope_norm, -1.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian energy: mean absolute Laplacian normalized by mean absolute intensity (0..1+)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(img)\n    gyy, gyx = np.gradient(gy)\n    gxy, gxx = np.gradient(gx)\n    lap = gxx + gyy\n    num = float(np.mean(np.abs(lap)))\n    denom = float(np.mean(np.abs(img))) + 1e-12\n    result = num / denom\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Stddev of per-row stroke-thickness estimates (higher = more variation in thickness vertically)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    thr = np.mean(gray)\n    ink = (gray < thr)\n    if ink.sum() == 0:\n        return 0.0\n    h, w = ink.shape[:2]\n    thicknesses = []\n    for r in range(h):\n        row = ink[r, :].astype(int)\n        ink_pixels = row.sum()\n        # count transitions (changes between 0 and 1). Each stroke segment contributes 2 transitions.\n        trans = np.sum(row[:-1] != row[1:])\n        segments = max(1, trans // 2)\n        thickness = ink_pixels / segments if segments > 0 else float(ink_pixels)\n        thicknesses.append(thickness)\n    if len(thicknesses) <= 1:\n        return 0.0\n    return float(np.std(thicknesses) / (np.mean(thicknesses) + 1e-6))\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of intensity histogram (0..1 normalized)'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        arr = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr_in.astype(float))\n    # use 16-bin histogram\n    try:\n        hist, _ = np.histogram(arr.ravel(), bins=16, range=(float(arr.min()), float(arr.max()+eps)))\n    except Exception:\n        return 0.0\n    total = hist.sum()\n    if total <= 0:\n        return 0.0\n    p = hist.astype(float) / float(total)\n    ent = -np.sum(np.where(p > 0, p * np.log(p + eps), 0.0))\n    # normalize by log(bins)\n    result = ent / (np.log(16.0) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Prominent peak count per 1000 pixels: local maxima above mean+0.5*std'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    mu = float(a.mean())\n    sd = float(a.std())\n    thr = mu + 0.5 * sd\n    # pad with very small values so edges are not treated as neighbors due to wrap\n    pad = np.full((h + 2, w + 2), -np.inf, dtype=float)\n    pad[1:-1, 1:-1] = a\n    center = pad[1:-1, 1:-1]\n    neighbors = [\n        pad[0:-2, 0:-2], pad[0:-2, 1:-1], pad[0:-2, 2:],\n        pad[1:-1, 0:-2],                 pad[1:-1, 2:],\n        pad[2:, 0:-2],   pad[2:, 1:-1],  pad[2:, 2:]\n    ]\n    greater = np.ones_like(center, dtype=bool)\n    for n in neighbors:\n        greater &= (center > n)\n    mask = greater & (center > thr)\n    count = int(np.count_nonzero(mask))\n    norm = (h * w) / 1000.0\n    result = float(count / (norm + 1e-12))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram peakiness: how much the largest intensity bin dominates (0..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    vals = a.ravel()\n    if vals.size == 0:\n        return 0.0\n    # choose bins but not too many\n    nb = min(128, max(8, int(np.sqrt(vals.size))))\n    hist, _ = np.histogram(vals, bins=nb, range=(vals.min(), vals.max()))\n    mean_bin = float(hist.mean()) + 1e-12\n    peak = float(hist.max())\n    # peakiness ratio then map to 0..1 via peak/(peak+mean)\n    score = peak / (peak + mean_bin)\n    return float(np.clip(score, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground pixel fraction above (mean + 0.5*std), measures sparsity/density (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thresh = m + 0.5 * s\n    fg = np.count_nonzero(a > thresh)\n    result = fg / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal axis angle of bright region normalized to [0..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = a > thr\n    if not np.any(mask):\n        return 0.5  # undefined orientation -> neutral\n    ys, xs = np.nonzero(mask)\n    weights = a[mask].astype(float)\n    total_w = weights.sum() + eps\n    cy = (weights * ys).sum() / total_w\n    cx = (weights * xs).sum() / total_w\n    dy = ys.astype(float) - cy\n    dx = xs.astype(float) - cx\n    cov_xx = (weights * (dx * dx)).sum() / total_w\n    cov_yy = (weights * (dy * dy)).sum() / total_w\n    cov_xy = (weights * (dx * dy)).sum() / total_w\n    # orientation of principal eigenvector\n    angle = 0.5 * np.arctan2(2.0 * cov_xy, (cov_xx - cov_yy))  # -pi/2..pi/2\n    # map to 0..1\n    result = (angle + (np.pi / 2.0)) / np.pi\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bimodality score of intensity histogram (0..1, higher => clearer two peaks)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    bins = 64\n    hist, edges = np.histogram(a.ravel(), bins=bins)\n    hist = hist.astype(float)\n    if hist.sum() == 0:\n        return 0.0\n    # find two highest peaks\n    inds = np.argsort(hist)[-2:]\n    p1, p2 = min(inds), max(inds)\n    p1v = hist[p1]\n    p2v = hist[p2]\n    if p1 == p2:\n        return 0.0\n    between = hist[p1:p2+1]\n    min_between = float(np.min(between)) if between.size > 0 else 0.0\n    denom = min(p1v, p2v) + eps\n    score = 1.0 - (min_between / denom)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance (0..1) between intensity-weighted centroid and image center'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    total = float(a.sum()) + eps\n    cx = float((xs * a).sum()) / total\n    cy = float((ys * a).sum()) / total\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = float(np.hypot(cx - center_x, cy - center_y))\n    maxdist = float(np.hypot(center_x, center_y)) + eps\n    return float(np.clip(dist / maxdist, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry measured by normalized cross-correlation (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # flip right for comparison\n    right_flipped = np.fliplr(right)\n    # if shapes differ (odd width), crop to smallest\n    min_w = min(left.shape[1], right_flipped.shape[1])\n    left = left[:, :min_w].ravel()\n    right_flipped = right_flipped[:, :min_w].ravel()\n    if left.size == 0:\n        return 0.0\n    left = left - left.mean()\n    right_flipped = right_flipped - right_flipped.mean()\n    denom = (np.sqrt((left**2).sum()) * np.sqrt((right_flipped**2).sum())) + eps\n    corr = float((left * right_flipped).sum() / denom)\n    result = float(np.clip(abs(corr), 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean vertical edge strength in the left half (useful to detect left-side vertical strokes)'\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    # scale to 0..1\n    vmin, vmax = float(np.min(gray)), float(np.max(gray))\n    if vmax == vmin:\n        return 0.0\n    norm = (gray - vmin) / (vmax - vmin)\n    gy, gx = np.gradient(norm)\n    vert = np.abs(gy)\n    left = vert[:, :w//2]\n    return float(np.mean(left))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative density of foreground in lower-right quadrant vs lower-left quadrant (detects 7\\'s diagonal)'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        if image.ndim == 3:\n            gray = np.mean(image.astype(float), axis=2)\n        else:\n            gray = image.astype(float)\n        mn, mx = gray.min(), gray.max()\n        rng = mx - mn + 1e-9\n        norm = (gray - mn) / rng\n        dark_count = np.count_nonzero(norm < 0.5)\n        light_count = np.count_nonzero(norm > 0.5)\n        if dark_count == 0 and light_count == 0:\n            return 0.0\n        fg = (norm < 0.5) if dark_count <= light_count else (norm > 0.5)\n        mid_r = h // 2\n        mid_c = w // 2\n        br = fg[mid_r:h, mid_c:w]\n        bl = fg[mid_r:h, 0:mid_c]\n        br_sum = float(np.count_nonzero(br))\n        bl_sum = float(np.count_nonzero(bl)) + 1e-9\n        return br_sum / bl_sum\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Corner-like density via high Laplacian magnitude fraction (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, _ = np.gradient(gy)\n        _, gxx = np.gradient(gx)\n        lap = gxx + gyy\n    except Exception:\n        return 0.0\n    mag = np.abs(lap).ravel()\n    if mag.size == 0:\n        return 0.0\n    thr = float(np.percentile(mag, 90))\n    high = mag > thr\n    result = float(high.sum()) / float(mag.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of a horizontal stroke around the vertical center (center band density / overall ink density)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    med = np.median(gray)\n    b1 = gray < med\n    b2 = gray > med\n    ink = b1 if np.count_nonzero(b1) <= np.count_nonzero(b2) else b2\n    if np.count_nonzero(ink) == 0:\n        ink = gray < np.mean(gray)\n    band_half = max(1, h // 10)\n    mid = h // 2\n    top = max(0, mid - band_half)\n    bottom = min(h, mid + band_half + 1)\n    band = ink[top:bottom, :]\n    overall = np.count_nonzero(ink)\n    band_count = np.count_nonzero(band)\n    if overall == 0:\n        return 0.0\n    return float((band_count / (bottom - top) / w) / (overall / (h * w)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of foreground mass in the top half to total foreground mass (top/both)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy().astype(float)\n    h, w = gray.shape[:2]\n    if h == 0:\n        return 0.0\n    thr = np.mean(gray)\n    fg_dark = gray < thr\n    fg_bright = gray > thr\n    fg = fg_dark if np.count_nonzero(fg_dark) <= np.count_nonzero(fg_bright) else fg_bright\n    total = np.count_nonzero(fg)\n    if total == 0:\n        return 0.0\n    top = fg[:h//2, :]\n    top_count = np.count_nonzero(top)\n    return float(top_count / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of bright-pixel centroid from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = a > thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    cy = ys.mean()\n    cx = xs.mean()\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    maxdist = np.hypot(center_y, center_x) + eps\n    result = float(dist / maxdist)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-region compactness: fraction of image occupied by bright pixels concentrated within their bounding box (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = float(a.mean() + a.std())\n    bright = a > thresh\n    bp = int(bright.sum())\n    if bp == 0:\n        return 0.0\n    ys, xs = np.where(bright)\n    miny, maxy = ys.min(), ys.max()\n    minx, maxx = xs.min(), xs.max()\n    bbox_area = float((maxy - miny + 1) * (maxx - minx + 1)) + eps\n    img_area = float(h * w) + eps\n    fill_ratio = float(bp) / bbox_area\n    occupancy = bbox_area / img_area\n    result = float(np.clip(fill_ratio * occupancy, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Lacunarity-like measure: average variance-to-mean of nonzero block counts across scales'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # binary map using mean threshold\n    thr = float(a.mean())\n    b = (a > thr).astype(np.int32)\n    scales = []\n    max_scale = min(h, w)\n    if max_scale < 2:\n        return 0.0\n    # choose a few block sizes\n    sizes = []\n    s = 2\n    while s <= max_scale and len(sizes) < 5:\n        sizes.append(s)\n        s *= 2\n    if not sizes:\n        sizes = [max(1, max_scale)]\n    ratios = []\n    for size in sizes:\n        bh = int(np.ceil(h / size))\n        bw = int(np.ceil(w / size))\n        counts = []\n        for i in range(bh):\n            for j in range(bw):\n                ys = slice(i * size, min((i + 1) * size, h))\n                xs = slice(j * size, min((j + 1) * size, w))\n                block = b[ys, xs]\n                counts.append(int(block.sum()))\n        counts = np.array(counts, dtype=float)\n        if counts.size == 0:\n            continue\n        mean_c = counts.mean()\n        var_c = counts.var()\n        # avoid division by zero\n        ratio = float(var_c / (mean_c + eps))\n        ratios.append(ratio)\n    if not ratios:\n        return 0.0\n    return float(np.mean(ratios))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average of left-right and top-bottom symmetry measured by Pearson correlation (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # left-right\n    midx = w // 2\n    left = arr[:, :midx]\n    right = arr[:, -midx:] if midx > 0 else np.empty_like(left)\n    if left.size == 0 or right.size == 0:\n        lr_corr = 0.0\n    else:\n        right_flipped = np.fliplr(right)\n        L = left.ravel()\n        R = right_flipped.ravel()\n        Lm = L.mean()\n        Rm = R.mean()\n        num = ((L - Lm) * (R - Rm)).mean()\n        den = (L.std() * R.std()) + eps\n        lr_corr = float(np.clip(num / den, -1.0, 1.0))\n    # top-bottom\n    midy = h // 2\n    top = arr[:midy, :]\n    bot = arr[-midy:, :] if midy > 0 else np.empty_like(top)\n    if top.size == 0 or bot.size == 0:\n        tb_corr = 0.0\n    else:\n        bot_flipped = np.flipud(bot)\n        T = top.ravel()\n        B = bot_flipped.ravel()\n        Tm = T.mean()\n        Bm = B.mean()\n        num = ((T - Tm) * (B - Bm)).mean()\n        den = (T.std() * B.std()) + eps\n        tb_corr = float(np.clip(num / den, -1.0, 1.0))\n    result = (lr_corr + tb_corr) / 2.0\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local intensity peak density: fraction of pixels that are strict 3x3 local maxima above mean+0.5*std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thresh = m + 0.5 * s\n    pad_val = float(a.min()) - 1.0\n    b = np.pad(a, 1, mode='constant', constant_values=pad_val)\n    center = b[1:-1, 1:-1]\n    neighs = [\n        b[0:-2, 0:-2], b[0:-2, 1:-1], b[0:-2, 2:],\n        b[1:-1, 0:-2],               b[1:-1, 2:],\n        b[2:,   0:-2], b[2:,   1:-1], b[2:,   2:]\n    ]\n    greater = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        greater &= (center > n)\n    peaks = (center > thresh) & greater\n    count = float(np.count_nonzero(peaks))\n    result = count / float(h * w)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels that are strict local maxima in a 3x3 neighborhood (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    pad_val = float(a.min()) - 1.0\n    p = np.pad(a, pad_width=1, mode='constant', constant_values=pad_val)\n    center = p[1:-1, 1:-1]\n    neighbors = [\n        p[0:-2, 0:-2], p[0:-2, 1:-1], p[0:-2, 2:],\n        p[1:-1, 0:-2],               p[1:-1, 2:],\n        p[2:  , 0:-2], p[2:  , 1:-1], p[2:  , 2:],\n    ]\n    mask = np.ones_like(center, dtype=bool)\n    for n in neighbors:\n        mask &= (center > n)\n    count = float(np.count_nonzero(mask))\n    result = count / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink pixels in the top 20% of rows to total ink pixels (top-edge density)'\n    import numpy as np\n    eps = 1e-8\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # normalize to 0..1\n    mn, mx = float(gray.min()), float(gray.max())\n    rng = mx - mn + eps\n    norm = (gray - mn) / rng\n    # decide ink polarity: assume ink is the minority intensity side\n    if np.mean(norm) > 0.5:\n        ink = norm < 0.5\n    else:\n        ink = norm > 0.5\n    total_ink = np.count_nonzero(ink)\n    if total_ink == 0:\n        return 0.0\n    top_rows = max(1, h // 5)\n    top_region = ink[:top_rows, :]\n    return float(np.count_nonzero(top_region) / (total_ink + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'If multiple holes detected, return normalized vertical separation between the two largest hole centroids; otherwise 0'\n    if len(image.shape) == 3:\n        gray = image.mean(axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    bg = np.median(border) if border.size > 0 else np.median(gray)\n    rng = float(gray.max() - gray.min()) if gray.size else 0.0\n    tol = max(rng * 0.10, 1e-6)\n    if bg > gray.mean():\n        fg = gray < (bg - tol)\n    else:\n        fg = gray > (bg + tol)\n    fg = fg.astype(bool)\n    if not fg.any():\n        return 0.0\n    rows = np.any(fg, axis=1); cols = np.any(fg, axis=0)\n    if not rows.any() or not cols.any():\n        return 0.0\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    sub = fg[rmin:rmax + 1, cmin:cmax + 1]\n    bh, bw = sub.shape\n    back = (~sub).astype(np.uint8)\n    visited = np.zeros_like(back, dtype=np.uint8)\n    holes = []\n    for i in range(bh):\n        for j in range(bw):\n            if back[i, j] and not visited[i, j]:\n                stack = [(i, j)]\n                visited[i, j] = 1\n                touches_border = False\n                comp = []\n                while stack:\n                    y, x = stack.pop()\n                    comp.append((y, x))\n                    if y == 0 or x == 0 or y == bh - 1 or x == bw - 1:\n                        touches_border = True\n                    for dy, dx in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n                        ny, nx = y + dy, x + dx\n                        if 0 <= ny < bh and 0 <= nx < bw and back[ny, nx] and not visited[ny, nx]:\n                            visited[ny, nx] = 1\n                            stack.append((ny, nx))\n                if not touches_border:\n                    ys = [p[0] for p in comp]\n                    xs = [p[1] for p in comp]\n                    holes.append({'area': len(comp), 'cy': float(np.mean(ys)), 'cx': float(np.mean(xs))})\n    if len(holes) < 2:\n        return 0.0\n    holes_sorted = sorted(holes, key=lambda x: x['area'], reverse=True)\n    h1, h2 = holes_sorted[0], holes_sorted[1]\n    vert_sep = abs(h1['cy'] - h2['cy'])\n    norm = float(max(1.0, bh - 1))\n    return float(vert_sep / norm)\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score based on mean absolute difference (1 => symmetric)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0 or w == 0:\n        return 0.0\n    left = a[:, :w//2]\n    right = a[:, - (w//2):] if w//2 > 0 else np.empty((h, 0))\n    if left.size == 0 or right.size == 0:\n        # trivial symmetry when one side is empty\n        return 1.0\n    # flip right to align with left\n    right_flipped = np.fliplr(right)\n    # If widths mismatch (odd center column), compare up to min width\n    minw = min(left.shape[1], right_flipped.shape[1])\n    if minw == 0:\n        return 1.0\n    left_c = left[:, :minw]\n    right_c = right_flipped[:, :minw]\n    diff_mean = float(np.mean(np.abs(left_c - right_c)))\n    denom = float(np.mean(np.abs(a))) + eps\n    normalized_error = diff_mean / denom\n    # convert to similarity: 1 - scaled error (use tanh for robustness)\n    score = 1.0 - float(np.tanh(normalized_error))\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical stroke ratio: fraction of columns with column-std above mean+0.5*std of column stds'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w == 0 or h == 0:\n        return 0.0\n    col_std = a.std(axis=0)\n    mean_cs = float(col_std.mean())\n    std_cs = float(col_std.std())\n    thr = mean_cs + 0.5 * std_cs\n    count = float(np.count_nonzero(col_std > thr))\n    result = count / float(w + eps)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of local maxima above mean+std (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std()) + eps\n    threshold = m + s\n    padmin = float(a.min()) - 1.0\n    pad = np.pad(a, 1, mode='constant', constant_values=padmin)\n    center = pad[1:1 + h, 1:1 + w]\n    neighs = []\n    for dy in (0, 1, 2):\n        for dx in (0, 1, 2):\n            if dy == 1 and dx == 1:\n                continue\n            neighs.append(pad[dy:dy + h, dx:dx + w])\n    mask = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        mask &= (center > n)\n    mask &= (center > threshold)\n    count = float(np.count_nonzero(mask))\n    result = count / (float(h * w) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of maximum foreground projection in top half to maximum in bottom half (top_peak / bottom_peak)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    fg = gray < thr\n    if np.count_nonzero(fg) > 0.6 * fg.size:\n        fg = ~fg\n    proj = np.sum(fg.astype(np.int32), axis=1)  # per-row foreground count\n    mid = h // 2\n    top_peak = float(np.max(proj[:max(1, mid)])) if mid > 0 else float(np.max(proj))\n    bottom_peak = float(np.max(proj[mid:])) if mid < h else float(np.max(proj))\n    return float(top_peak / (bottom_peak + 1e-6))\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (width/height) of bounding box of thresholded bright region (clip 0..10)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    mean = arr.mean()\n    std = arr.std()\n    thr = mean + 0.5 * std\n    mask = arr > thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    miny, maxy = ys.min(), ys.max()\n    minx, maxx = xs.min(), xs.max()\n    bw = float(maxx - minx + 1)\n    bh = float(maxy - miny + 1) + eps\n    ratio = bw / bh\n    ratio = float(np.clip(ratio, 0.0, 10.0))\n    return float(ratio)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Absolute log aspect ratio compressed to [0,1] (0 => square)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    try:\n        h, w = arr.shape[:2]\n    except Exception:\n        return 0.0\n    if h <= 0 or w <= 0:\n        return 0.0\n    val = abs(np.log(float(h) / float(w)))\n    # compress via tanh and scale to [0,1]\n    return float(np.tanh(val))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation strength (0..1): fraction of gradient energy in the peak angle bin'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    bins = 36\n    # shift angles to 0..2pi\n    ang2 = (ang + np.pi) % (2 * np.pi)\n    hist, _ = np.histogram(ang2.ravel(), bins=bins, range=(0.0, 2 * np.pi), weights=mag.ravel())\n    total = hist.sum() + eps\n    peak = float(hist.max())\n    result = float(peak / total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio relative to total image variance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # local mean via 3x3 average using rolls\n    local = np.zeros_like(a)\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            local += np.roll(np.roll(a, dy, axis=0), dx, axis=1)\n    local = local / 9.0\n    high = a - local\n    energy_high = float((high ** 2).sum())\n    energy_total = float(((a - a.mean()) ** 2).sum()) + eps\n    result = energy_high / energy_total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of mean intensity versus radius from center (normalized)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    y = np.arange(h)[:, None]\n    x = np.arange(w)[None, :]\n    r = np.hypot(y - cy, x - cx)\n    maxr = max(1.0, r.max())\n    # radial bins\n    nbins = int(min(64, max(2, int(maxr))))\n    bins = np.linspace(0.0, maxr, nbins + 1)\n    radial_means = []\n    for i in range(nbins):\n        mask = (r >= bins[i]) & (r < bins[i+1])\n        if np.any(mask):\n            radial_means.append(float(a[mask].mean()))\n    if len(radial_means) < 2:\n        return 0.0\n    rad_means = np.array(radial_means)\n    result = float(rad_means.var() / (a.std() + eps))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness (higher => more colorful). Returns 0 for grayscale inputs'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # assume channels in order R,G,B\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    # normalize by typical intensity scale to keep values reasonable\n    scale = (np.mean(a) + 1e-12)\n    result = colorfulness / scale\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of prominent histogram modes (smoothed 64-bin histogram), clipped to 10'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size == 0:\n        return 0.0\n    bins = 64\n    mn, mx = float(arr.min()), float(arr.max())\n    if mx <= mn:\n        return 0.0\n    hist, _ = np.histogram(arr, bins=bins, range=(mn, mx))\n    # smooth with 3-point moving average\n    k = np.array([1.0, 1.0, 1.0]) / 3.0\n    padded = np.pad(hist.astype(float), (1, 1), mode='edge')\n    smooth = np.convolve(padded, k, mode='valid')\n    avg = float(smooth.mean()) + eps\n    # count local maxima above average\n    peaks = 0\n    for i in range(1, smooth.size - 1):\n        if smooth[i] > smooth[i - 1] and smooth[i] > smooth[i + 1] and smooth[i] > avg:\n            peaks += 1\n    result = float(min(peaks, 10))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fill ratio: bright-region pixel count divided by its bounding-box area (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mu = float(arr.mean())\n    sigma = float(arr.std())\n    thresh = mu + 0.5 * sigma\n    mask = arr > thresh\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    if bbox_area <= 0:\n        return 0.0\n    fill = float(mask.sum()) / (bbox_area + eps)\n    return float(np.clip(fill, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of sign changes (zero crossings) in the vertical gradient per column in the right half (captures alternating bulges)'\n    import numpy as np\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2).astype(float)\n    else:\n        gray = img.astype(float)\n    gy, gx = np.gradient(gray.astype(float))\n    right = gx[:, max(w//2, 0):]  # horizontal derivative across right half\n    if right.size == 0:\n        return 0.0\n    # count sign changes along each column\n    sign = np.sign(right)\n    # replace zeros with previous nonzero to avoid noisy zero rows\n    sign[sign == 0] = 1\n    changes = np.abs(np.diff(sign, axis=0)) > 0\n    col_changes = changes.sum(axis=0)\n    return float(np.mean(col_changes) / max(1.0, h - 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Interdecile contrast: (90th - 10th percentile) normalized by median (robust contrast)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    p90 = float(np.percentile(flat, 90))\n    p10 = float(np.percentile(flat, 10))\n    med = float(np.median(flat))\n    denom = abs(med) + 1e-8\n    result = (p90 - p10) / denom\n    return float(max(0.0, result))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score based on correlation (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:] if mid > 0 else np.array([], dtype=float).reshape(h, 0)\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # mirror right to align\n    right_mir = np.fliplr(right)\n    # crop to common shape\n    min_cols = min(left.shape[1], right_mir.shape[1])\n    left_c = left[:, :min_cols].ravel()\n    right_c = right_mir[:, :min_cols].ravel()\n    if left_c.size == 0 or right_c.size == 0:\n        return 0.0\n    # zero-mean correlation\n    left_c -= left_c.mean()\n    right_c -= right_c.mean()\n    denom = np.sqrt((left_c ** 2).sum() * (right_c ** 2).sum()) + eps\n    corr = float((left_c * right_c).sum()) / denom\n    result = max(0.0, corr)  # negative correlation considered no symmetry\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in top-left quadrant to top-right quadrant (helps detect slanted/top-left hooks)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float32)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.5\n    mn, mx = gray.min(), gray.max()\n    if mx - mn < 1e-6:\n        return 0.5\n    scaled = ((gray - mn) / (mx - mn) * 255.0).astype(np.uint8)\n    hist, _ = np.histogram(scaled, bins=256, range=(0, 255))\n    prob = hist.astype(np.float64) / scaled.size\n    cum_prob = np.cumsum(prob)\n    cum_mean = np.cumsum(prob * np.arange(256))\n    total_mean = cum_mean[-1]\n    denom = cum_prob * (1.0 - cum_prob) + 1e-12\n    between = (total_mean * cum_prob - cum_mean) ** 2 / denom\n    thr_idx = int(np.nanargmax(between))\n    thr = thr_idx\n    mask = (scaled <= thr)\n    mid_w = w // 2\n    mid_h = h // 2\n    top_left = mask[:mid_h, :mid_w].sum()\n    top_right = mask[:mid_h, mid_w:].sum()\n    if top_right == 0:\n        return float(top_left)\n    return float(top_left / top_right)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized vertical center of mass offset: (y_centroid / height) - 0.5 (negative = top-biased, positive = bottom-biased)'\n    import numpy as _np\n    if len(image.shape) == 3:\n        gray = _np.mean(image, axis=2)\n    else:\n        gray = image.astype(_np.float32)\n    h, w = gray.shape\n    m = _np.mean(gray)\n    ink_mask = (gray < m).astype(_np.float32)\n    total = float(ink_mask.sum())\n    if total <= 0.0:\n        return 0.0\n    ys = _np.arange(h).astype(_np.float32)\n    ysum = float((ink_mask * ys[:, None]).sum())\n    y_centroid = ysum / total\n    offset = float((y_centroid / float(h)) - 0.5)\n    return offset\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels in the top 1% intensity band (saturation/clipping indicator)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    amin = a.min()\n    amax = a.max()\n    rng = amax - amin\n    if rng <= 0:\n        return 0.0\n    thresh = amax - 0.01 * rng\n    frac = float(np.count_nonzero(a >= thresh)) / (a.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average local entropy over non-overlapping blocks (higher => textured)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    block = max(4, min(h, w) // 8)\n    bh = block; bw = block\n    n_h = h // bh\n    n_w = w // bw\n    if n_h == 0 or n_w == 0:\n        # fallback single-block entropy\n        vals = a.ravel()\n        if vals.size == 0:\n            return 0.0\n        hist, _ = np.histogram(vals, bins=16)\n        p = hist.astype(float) / (hist.sum() + eps)\n        p = p[p > 0]\n        ent = -np.sum(p * np.log2(p + eps))\n        return float(ent)\n    ents = []\n    for i in range(n_h):\n        for j in range(n_w):\n            block_vals = a[i * bh:(i + 1) * bh, j * bw:(j + 1) * bw].ravel()\n            if block_vals.size == 0:\n                continue\n            hist, _ = np.histogram(block_vals, bins=16)\n            p = hist.astype(float) / (hist.sum() + eps)\n            p = p[p > 0]\n            ent = -np.sum(p * np.log2(p + eps))\n            ents.append(ent)\n    if not ents:\n        return 0.0\n    return float(np.mean(ents))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized contrast between center region and periphery (center mean minus periphery mean, divided by overall std)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape[:2]\n    ch, cw = max(1, h // 4), max(1, w // 4)\n    center = img[ch:3*ch, cw:3*cw]\n    # periphery = everything except center region\n    mask = np.ones_like(img, dtype=bool)\n    mask[ch:3*ch, cw:3*cw] = False\n    periphery = img[mask]\n    center_mean = float(np.mean(center)) if center.size else 0.0\n    periphery_mean = float(np.mean(periphery)) if periphery.size else 0.0\n    overall_std = float(np.std(img)) + eps\n    result = (center_mean - periphery_mean) / overall_std\n    return float(np.nan_to_num(result))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial spread: standard deviation of distances of ink pixels to their centroid normalized by image diagonal (0..1)'\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink_mask = (gray < thr)\n    ys, xs = np.where(ink_mask)\n    if ys.size == 0:\n        return 0.0\n    cy = np.mean(ys)\n    cx = np.mean(xs)\n    dists = np.hypot(ys - cy, xs - cx)\n    std = float(np.std(dists))\n    diag = np.hypot(h, w) + 1e-8\n    return float(std / diag)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized inter-percentile range (90th-10th) divided by dynamic range (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    p90 = float(np.percentile(a, 90))\n    p10 = float(np.percentile(a, 10))\n    mn = float(a.min())\n    mx = float(a.max())\n    denom = (mx - mn) + 1e-12\n    result = (p90 - p10) / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal gradient energy in the top third (indicates strong top horizontal stroke)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gx = np.abs(np.gradient(gray, axis=1))\n    total_energy = gx.sum() + 1e-9\n    top_energy = gx[0:max(1,h//3), :].sum()\n    return float(top_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels in the center region that are nonzero relative to whole image nonzero fraction (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total_nz = int(np.count_nonzero(a))\n    if total_nz == 0:\n        return 0.0\n    ch0 = h // 4\n    ch1 = 3 * h // 4\n    cw0 = w // 4\n    cw1 = 3 * w // 4\n    center = a[ch0:ch1, cw0:cw1]\n    if center.size == 0:\n        return 0.0\n    center_nz = int(np.count_nonzero(center))\n    return float(np.clip(center_nz / float(total_nz), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal gradient energy: (negative-slope minus positive-slope) normalized to [-1,1]'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = gray.min(), gray.max()\n    norm = (gray - mn) / (mx - mn + 1e-9)\n    gy, gx = np.gradient(norm)\n    # energy for negative slope edges (~top-right to bottom-left) and positive slope\n    energy_neg = np.sum(np.abs(gx - gy))\n    energy_pos = np.sum(np.abs(gx + gy))\n    denom = energy_neg + energy_pos + 1e-9\n    return float((energy_neg - energy_pos) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global structure-tensor anisotropy (0..1): orientation dominance measure from gradients'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    A = float(np.sum(gx * gx))\n    B = float(np.sum(gy * gy))\n    C = float(np.sum(gx * gy))\n    lam_diff = np.sqrt((A - B) ** 2 + 4.0 * (C ** 2))\n    anis = lam_diff / (A + B + eps)\n    return float(np.clip(anis, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal centroid (0..1) of hole pixels (0 if no hole); 0=left, 1=right'\n    import numpy as np\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    p20, p80 = np.percentile(gray, 20), np.percentile(gray, 80)\n    mid = 0.5 * (p20 + p80)\n    ink_darker = np.mean(gray) < mid\n    ink = (gray <= mid) if ink_darker else (gray >= mid)\n    bg = ~ink\n    visited = np.zeros((h, w), dtype=bool)\n    stack = []\n    for x in range(w):\n        if bg[0, x]:\n            stack.append((0, x)); visited[0, x] = True\n        if bg[h-1, x]:\n            stack.append((h-1, x)); visited[h-1, x] = True\n    for y in range(h):\n        if bg[y, 0] and not visited[y, 0]:\n            stack.append((y, 0)); visited[y, 0] = True\n        if bg[y, w-1] and not visited[y, w-1]:\n            stack.append((y, w-1)); visited[y, w-1] = True\n    while stack:\n        r, c = stack.pop()\n        for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n            rr, cc = r+dr, c+dc\n            if 0 <= rr < h and 0 <= cc < w and bg[rr, cc] and not visited[rr, cc]:\n                visited[rr, cc] = True\n                stack.append((rr, cc))\n    holes = bg & (~visited)\n    if not holes.any():\n        return 0.0\n    ys, xs = np.nonzero(holes)\n    cx = xs.mean() / max(1, w-1)\n    return float(cx)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of top-quarter rows that contain multiple separate horizontal ink runs'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    mn, mx = float(gray.min()), float(gray.max())\n    norm = (gray - mn) / (mx - mn + 1e-8)\n    mask = (norm < 0.5).astype(np.uint8)\n    h, w = mask.shape\n    top_rows = max(1, h // 4)\n    sub = mask[:top_rows, :]\n    rows_with_multi = 0\n    for row in sub:\n        if row.sum() == 0:\n            continue\n        diffs = np.diff(np.concatenate(([0], row, [0])))\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        runs = ends - starts\n        if runs.size >= 2 and runs.max() > 0:\n            rows_with_multi += 1\n    return float(rows_with_multi) / float(top_rows)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal stroke orientation (angle in radians normalized to [-pi,pi]) estimated from ink pixel PCA'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    thr = float(np.percentile(gray, 50))\n    mask_dark = gray < thr\n    ink_ratio = float(mask_dark.mean())\n    if ink_ratio > 0.6 or ink_ratio < 0.01:\n        thr = float(np.mean(gray))\n        mask_dark = gray < thr\n    mask = mask_dark if float(mask_dark.mean()) <= 0.6 else (~mask_dark)\n    coords = np.column_stack(np.nonzero(mask))\n    if coords.shape[0] < 3:\n        return 0.0\n    coords = coords.astype(float)\n    coords -= coords.mean(axis=0)\n    U, S, Vt = np.linalg.svd(coords, full_matrices=False)\n    # principal axis is Vt[0]; compute angle of vector (dy, dx)\n    vy, vx = Vt[0,0], Vt[0,1]\n    angle = float(np.arctan2(vy, vx))\n    # normalize to a bounded float between -pi and pi\n    return float(angle)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energy to (vertical + horizontal) gradient energy'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray)  # gy = d/drow (vertical), gx = d/dcol (horizontal)\n    vert = np.abs(gy)\n    hor = np.abs(gx)\n    diag1 = np.abs(gx + gy)\n    diag2 = np.abs(gx - gy)\n    diag_energy = diag1.sum() + diag2.sum()\n    base_energy = vert.sum() + hor.sum()\n    eps = 1e-8\n    return float(diag_energy / (base_energy + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of horizontal ink/background transitions per central row (center 3 rows)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink_mask_candidate = gray < thresh\n    if np.count_nonzero(ink_mask_candidate) > (h * w / 2):\n        ink = (~ink_mask_candidate).astype(int)\n    else:\n        ink = ink_mask_candidate.astype(int)\n    center = h // 2\n    rows = [max(0, center - 1), center, min(h - 1, center + 1)]\n    transitions = []\n    for r in rows:\n        row = ink[r, :]\n        # transitions count: number of times adjacent pixels differ\n        trans = int(np.sum(np.abs(row[1:] - row[:-1])))\n        transitions.append(trans)\n    return float(np.mean(transitions))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local variance (3x3) normalized by global variance (higher = coarser texture)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # compute local mean and mean of squares using 3x3 neighborhood via roll trick\n    S = np.zeros_like(a)\n    S2 = np.zeros_like(a)\n    shifts = [(0,0),(1,0),(-1,0),(0,1),(0,-1),(1,1),(1,-1),(-1,1),(-1,-1)]\n    for dy, dx in shifts:\n        S += np.roll(np.roll(a, dy, axis=0), dx, axis=1)\n        S2 += np.roll(np.roll(a*a, dy, axis=0), dx, axis=1)\n    S /= 9.0\n    S2 /= 9.0\n    local_var = S2 - S*S\n    # avoid negative numerical artifacts\n    local_var = np.maximum(local_var, 0.0)\n    mean_local_var = float(local_var.mean())\n    global_var = float(a.var()) + 1e-12\n    result = mean_local_var / global_var\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized diagonal gradient energy ratio: |dx - dy| energy / (|dx|+|dy| energy + eps) measures diagonal strokes'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # gradients\n    gy, gx = np.gradient(gray)\n    # energy aligned with one diagonal vs the other\n    energy_diag = np.sum(np.abs(gx - gy))\n    energy_antidiag = np.sum(np.abs(gx + gy))\n    denom = energy_diag + energy_antidiag + 1e-8\n    return float(energy_diag / denom)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean horizontal gradient magnitude to mean vertical gradient magnitude in the center region (stroke orientation cue)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn < 1e-8:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    h, w = norm.shape\n    ch0 = max(0, h // 4)\n    ch1 = min(h, 3 * h // 4)\n    cw0 = max(0, w // 4)\n    cw1 = min(w, 3 * w // 4)\n    center = norm[ch0:ch1, cw0:cw1]\n    if center.size == 0:\n        return 0.0\n    gy, gx = np.gradient(center)\n    mean_horiz = float(np.mean(np.abs(gx)))\n    mean_vert = float(np.mean(np.abs(gy)))\n    if mean_vert < 1e-8:\n        return float(mean_horiz / (mean_vert + 1e-8))\n    return float(mean_horiz / mean_vert)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized variance of radial distances of ink pixels from their centroid (lower = more circular/central symmetry).'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    ink = (gray < thresh)\n    ys, xs = np.nonzero(ink)\n    if ys.size == 0:\n        return 0.0\n    cy = np.mean(ys)\n    cx = np.mean(xs)\n    d2 = (ys - cy)**2 + (xs - cx)**2\n    var = float(np.var(np.sqrt(d2)))\n    # normalize by maximum possible radius (~ diagonal)\n    maxr = np.sqrt((h-1)**2 + (w-1)**2)\n    return float(var / (maxr + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Compactness of top-intensity region: area(top P%) / bounding-box-area (0..1)'\n    import numpy as np\n    eps = 1e-12\n    P = 5.0  # top percent\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    cutoff = float(np.percentile(flat, 100.0 - P))\n    mask = a >= cutoff\n    if not mask.any():\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    miny, maxy = ys.min(), ys.max()\n    minx, maxx = xs.min(), xs.max()\n    area = float(mask.sum())\n    bbox_area = float(max(1, maxy - miny + 1)) * float(max(1, maxx - minx + 1))\n    result = area / (bbox_area + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference of vertical gradient energy between left third and right third ((L-R)/(L+R))'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray.astype(float))\n    venergy = np.abs(gy)\n    left = venergy[:, :max(1, w // 3)].sum()\n    right = venergy[:, max(1, 2 * w // 3):].sum()\n    return float((left - right) / (left + right + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal symmetry correlation between left and right halves (-1..1, + means symmetric)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    half = w // 2\n    left = a[:, :half]\n    right = a[:, -half:]\n    # flip right to align with left\n    right_f = np.fliplr(right)\n    # ensure same shape\n    if left.shape != right_f.shape:\n        minc = min(left.shape[1], right_f.shape[1])\n        left = left[:, :minc]\n        right_f = right_f[:, :minc]\n    L = left.ravel()\n    Rv = right_f.ravel()\n    if L.size == 0:\n        return 0.0\n    Lm = float(L.mean())\n    Rm = float(Rv.mean())\n    Lc = L - Lm\n    Rc = Rv - Rm\n    denom = (np.sqrt((Lc ** 2).sum() * (Rc ** 2).sum()) + eps)\n    corr = float((Lc * Rc).sum() / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of ink pixels located in the lower-right quadrant (captures right-bottom weight like in 3)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # simple threshold: midpoint between min and max\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    thresh = 0.5 * (mn + mx)\n    ink = gray < thresh\n    total_ink = float(np.count_nonzero(ink))\n    if total_ink < 1e-6:\n        return 0.0\n    lr_ink = np.count_nonzero(ink[h//2:, w//2:])\n    return float(lr_ink / total_ink)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink in the upper-right quadrant (high values indicate right-side top ink concentration typical of 3)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = (gray < thr)\n    total = np.count_nonzero(ink)\n    if total == 0:\n        return 0.0\n    ur = np.count_nonzero(ink[0:h//2, w//2:w])\n    return float(ur) / float(total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Corner gradient energy fraction (how much gradient energy is in corners)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    corner_size = max(1, int(min(h, w) * 0.15))\n    # four corners\n    c1 = mag[0:corner_size, 0:corner_size]\n    c2 = mag[0:corner_size, -corner_size:]\n    c3 = mag[-corner_size:, 0:corner_size]\n    c4 = mag[-corner_size:, -corner_size:]\n    corner_energy = float(c1.sum() + c2.sum() + c3.sum() + c4.sum())\n    total_energy = float(mag.sum()) + eps\n    result = corner_energy / total_energy\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimate of number of enclosed holes (connected white regions fully surrounded by ink)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    mn, mx = gray.min(), gray.max()\n    thresh = (mn + mx) / 2.0\n    ink = (gray < thresh) if gray.mean() > thresh else (gray > thresh)\n    h, w = ink.shape\n    # background mask: True for background pixels (not ink)\n    background = ~ink\n    # flood fill from borders to find exterior background\n    visited = np.zeros_like(background, dtype=bool)\n    stack = []\n    # push border background pixels\n    ys = [0, h-1]\n    xs = [0, w-1]\n    for x in range(w):\n        if background[0, x] and not visited[0, x]:\n            stack.append((0, x))\n            visited[0, x] = True\n        if background[h-1, x] and not visited[h-1, x]:\n            stack.append((h-1, x))\n            visited[h-1, x] = True\n    for y in range(h):\n        if background[y, 0] and not visited[y, 0]:\n            stack.append((y, 0))\n            visited[y, 0] = True\n        if background[y, w-1] and not visited[y, w-1]:\n            stack.append((y, w-1))\n            visited[y, w-1] = True\n    while stack:\n        y, x = stack.pop()\n        for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n            ny, nx = y+dy, x+dx\n            if 0 <= ny < h and 0 <= nx < w and background[ny, nx] and not visited[ny, nx]:\n                visited[ny, nx] = True\n                stack.append((ny, nx))\n    # any background pixel not visited is an enclosed hole; count connected components of those\n    holes_mask = background & (~visited)\n    seen = np.zeros_like(holes_mask, dtype=bool)\n    hole_count = 0\n    for y in range(h):\n        for x in range(w):\n            if holes_mask[y, x] and not seen[y, x]:\n                # flood fill this hole\n                hole_count += 1\n                stack = [(y, x)]\n                seen[y, x] = True\n                while stack:\n                    cy, cx = stack.pop()\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ny, nx = cy+dy, cx+dx\n                        if 0 <= ny < h and 0 <= nx < w and holes_mask[ny, nx] and not seen[ny, nx]:\n                            seen[ny, nx] = True\n                            stack.append((ny, nx))\n    return float(hole_count)\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Harris-corner density: fraction of strong corner responses (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    gy, gx = np.gradient(a)\n    Ixx = gx * gx\n    Iyy = gy * gy\n    Ixy = gx * gy\n    # simple 3x3 box filter using rolls\n    def boxmean(X):\n        s = np.zeros_like(X)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    Sxx = boxmean(Ixx)\n    Syy = boxmean(Iyy)\n    Sxy = boxmean(Ixy)\n    det = Sxx * Syy - Sxy * Sxy\n    trace = Sxx + Syy\n    k = 0.04\n    R = det - k * (trace ** 2)\n    Rmax = float(np.max(R)) if R.size else 0.0\n    if Rmax <= 0:\n        return 0.0\n    thresh = Rmax * 0.01\n    count = float((R > thresh).sum())\n    result = float(np.clip(count / (h * w + eps), 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong local maxima (peaks) relative to image area'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # threshold: median + 0.5*std\n    med = float(np.median(a))\n    std = float(a.std())\n    thresh = med + 0.5 * std\n    # pad with very low value so edges are not compared to wrapped neighbors\n    pad_val = float(a.min()) - 1.0\n    p = np.pad(a, pad_width=1, mode='constant', constant_values=pad_val)\n    center = p[1:-1, 1:-1]\n    neighs = [\n        p[0:-2, 0:-2], p[0:-2, 1:-1], p[0:-2, 2:],\n        p[1:-1, 0:-2],                p[1:-1, 2:],\n        p[2:, 0:-2],   p[2:, 1:-1],   p[2:, 2:]\n    ]\n    # strict greater than all neighbors and above threshold\n    mask = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        mask &= (center > n)\n    mask &= (center > thresh)\n    count = float(np.count_nonzero(mask))\n    area = float(center.size) + eps\n    result = count / area\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Color channel variation proxy: mean per-pixel inter-channel range (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3 and img.shape[2] >= 2:\n        # compute per-pixel range across channels\n        arr = np.nan_to_num(img.astype(float))\n        per_pixel_range = arr.max(axis=2) - arr.min(axis=2)\n        # normalize by dynamic range of image channels\n        max_possible = float(per_pixel_range.max()) + eps\n        # if all channels identical, this will be zero\n        mean_range = float(per_pixel_range.mean())\n        # if values likely in 0..255 or 0..1, scale by observed max to produce 0..1\n        denom = max_possible if max_possible > eps else (mean_range + eps)\n        result = mean_range / (denom + eps)\n        return float(np.clip(result, 0.0, 1.0))\n    else:\n        # grayscale has no channel variation\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal orientation of intensity (0..1) as normalized angle of major axis (0..180 deg)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total = float(a.sum())\n    if total == 0.0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (a * xs).sum() / total\n    cy = (a * ys).sum() / total\n    xcen = xs.ravel().astype(float) - cx\n    ycen = ys.ravel().astype(float) - cy\n    wts = a.ravel().astype(float)\n    if wts.sum() == 0.0:\n        return 0.0\n    xx = (wts * (xcen * xcen)).sum() / (wts.sum() + eps)\n    yy = (wts * (ycen * ycen)).sum() / (wts.sum() + eps)\n    xy = (wts * (xcen * ycen)).sum() / (wts.sum() + eps)\n    cov = np.array([[xx, xy], [xy, yy]])\n    try:\n        vals, vecs = np.linalg.eigh(cov)\n    except Exception:\n        return 0.0\n    # principal eigenvector corresponds to largest eigenvalue\n    idx = int(np.argmax(vals))\n    vx, vy = vecs[0, idx], vecs[1, idx]\n    angle = np.arctan2(vy, vx)  # radians between -pi..pi\n    angle_deg = np.degrees(angle)\n    # normalize to 0..180\n    angle_deg = abs((angle_deg + 180.0) % 180.0)\n    result = float(np.clip(angle_deg / 180.0, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry (absolute Pearson correlation between left half and mirrored right half)'\n    import numpy as np\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    # if shapes differ, crop larger to match\n    if left.shape[1] != right.shape[1]:\n        minw = min(left.shape[1], right.shape[1])\n        left = left[:, :minw]\n        right = right[:, -minw:]\n    right_flipped = np.fliplr(right)\n    L = left.ravel()\n    R = right_flipped.ravel()\n    if L.size == 0:\n        return 0.0\n    Lm = L.mean()\n    Rm = R.mean()\n    denom = (np.std(L) * np.std(R))\n    if denom == 0:\n        return 0.0\n    corr = float(((L - Lm) * (R - Rm)).mean() / (denom + 1e-12))\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized diagonal (45\u00b0) edge energy: diagonal magnitude / total edge energy (captures slanted strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(gray.astype(float))\n    # diagonal projection (45\u00b0)\n    diag = (gx + gy) / np.sqrt(2.0)\n    diag_energy = np.sum(np.abs(diag))\n    total_energy = np.sum(np.abs(gx)) + np.sum(np.abs(gy))\n    return float(diag_energy / (total_energy + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Strong-edge density: fraction of pixels with gradient magnitude > mean+std'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    m = float(mag.mean())\n    s = float(mag.std())\n    thresh = m + s\n    strong = float((mag > thresh).sum())\n    total = float(mag.size)\n    result = strong / (total + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average fraction of nearly-uniform rows and columns (rows/cols with very small std relative to image)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    img_std = float(a.std()) + eps\n    row_stds = a.std(axis=1)\n    col_stds = a.std(axis=0)\n    thr = max(1e-6, 0.08 * img_std)\n    row_frac = float((row_stds < thr).sum()) / float(max(1, h))\n    col_frac = float((col_stds < thr).sum()) / float(max(1, w))\n    result = 0.5 * (row_frac + col_frac)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of pixels above the 90th intensity percentile (bright-pixel ratio)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    # collapse color to intensity\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(img.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    p90 = float(np.percentile(a, 90))\n    count = float(np.count_nonzero(a > p90))\n    result = count / (a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized horizontal distance from the right edge to the rightmost ink pixel (0 means ink touches right border)'\n    import numpy as np\n    if image is None:\n        return 1.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 1.0\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    bg_med = float(np.median(border))\n    img_med = float(np.median(gray))\n    thresh = (bg_med + img_med) / 2.0\n    if bg_med > img_med:\n        ink = gray < thresh\n    else:\n        ink = gray > thresh\n    ink = ink.astype(bool)\n    if not np.any(ink):\n        return 1.0\n    # find rightmost ink column index\n    cols = np.where(np.any(ink, axis=0))[0]\n    if cols.size == 0:\n        return 1.0\n    rightmost = float(cols.max())\n    dist = (w - 1.0 - rightmost) / float(w)\n    return float(dist)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Corner vs center contrast: mean(corners) - mean(center) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    bw = max(1, min(h, w) // 6)\n    # four corners\n    tl = a[:bw, :bw]\n    tr = a[:bw, -bw:]\n    bl = a[-bw:, :bw]\n    br = a[-bw:, -bw:]\n    corners = np.concatenate([tl.ravel(), tr.ravel(), bl.ravel(), br.ravel()]) if a.size else np.array([])\n    ch = h // 4\n    cw = w // 4\n    center = a[ch:ch+max(1,h//2), cw:cw+max(1,w//2)]\n    if corners.size == 0 or center.size == 0:\n        return 0.0\n    corner_mean = float(corners.mean())\n    center_mean = float(center.mean())\n    global_std = float(a.std()) + eps\n    result = (corner_mean - center_mean) / global_std\n    # normalize into roughly -3..3, then scale to -1..1 via tanh-like clamp\n    result = float(np.tanh(result))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness for RGB images (0..1); returns 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    arr = np.nan_to_num(img[..., :3].astype(float))\n    R = arr[..., 0]\n    G = arr[..., 1]\n    B = arr[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    metric = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    # compress to 0..1\n    val = float(metric / (1.0 + metric + eps))\n    return float(np.clip(val, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Area of the largest background cavity inside the ink bounding box normalized by bbox area'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = (np.max(gray) + np.min(gray)) / 2.0\n    ink = (gray > thresh).astype(np.uint8)\n    if np.count_nonzero(ink) == 0:\n        return 0.0\n    rows = np.any(ink, axis=1)\n    cols = np.any(ink, axis=0)\n    rmin = int(np.argmax(rows))\n    rmax = int(h - 1 - np.argmax(rows[::-1]))\n    cmin = int(np.argmax(cols))\n    cmax = int(w - 1 - np.argmax(cols[::-1]))\n    if rmax < rmin or cmax < cmin:\n        return 0.0\n    sub = 1 - ink[rmin:rmax+1, cmin:cmax+1]  # background inside bbox\n    sh, sw = sub.shape\n    visited = np.zeros_like(sub, dtype=bool)\n    largest = 0\n    for i in range(sh):\n        for j in range(sw):\n            if sub[i, j] and not visited[i, j]:\n                stack = [(i, j)]\n                visited[i, j] = True\n                area = 0\n                touches_border = False\n                while stack:\n                    y, x = stack.pop()\n                    area += 1\n                    if y == 0 or x == 0 or y == sh-1 or x == sw-1:\n                        touches_border = True\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ny, nx = y+dy, x+dx\n                        if 0 <= ny < sh and 0 <= nx < sw and sub[ny, nx] and not visited[ny, nx]:\n                            visited[ny, nx] = True\n                            stack.append((ny, nx))\n                if not touches_border and area > largest:\n                    largest = area\n    bbox_area = max(1, sh * sw)\n    return float(largest / bbox_area)\n",
    "def feature(image: np.ndarray) -> float:\n    'Average ink density in a narrow vertical band between hole centroids (3-pixel wide). If no holes, use center column.'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gmax = gray.max()\n    if gmax > 1.5:\n        gray = gray / gmax\n    thresh = float(np.mean(gray))\n    dark_frac = float(np.mean(gray < thresh))\n    if 0.01 < dark_frac < 0.99:\n        ink = (gray < thresh) if dark_frac < 0.5 else (gray > thresh)\n    else:\n        ink = gray < thresh\n    bg = ~ink\n    h, w = gray.shape\n    visited = np.zeros_like(bg, dtype=bool)\n    neighbors = [(-1,-1),(-1,0),(-1,1),(0,-1),(0,1),(1,-1),(1,0),(1,1)]\n    holes = []\n    for r in range(h):\n        for c in range(w):\n            if visited[r, c] or not bg[r, c]:\n                continue\n            stack = [(r, c)]\n            visited[r, c] = True\n            touches_border = False\n            area = 0\n            sum_c = 0.0\n            while stack:\n                rr, cc = stack.pop()\n                area += 1\n                sum_c += cc\n                if rr == 0 or rr == h-1 or cc == 0 or cc == w-1:\n                    touches_border = True\n                for dr, dc in neighbors:\n                    nr, nc = rr + dr, cc + dc\n                    if 0 <= nr < h and 0 <= nc < w and (not visited[nr, nc]) and bg[nr, nc]:\n                        visited[nr, nc] = True\n                        stack.append((nr, nc))\n            if not touches_border and area > 0:\n                holes.append((area, sum_c/area))\n    if len(holes) >= 2:\n        # choose mid-column between two largest holes\n        holes.sort(reverse=True, key=lambda x: x[0])\n        x1 = holes[0][1]\n        x2 = holes[1][1]\n        center_col = int(round((x1 + x2) / 2.0))\n    elif len(holes) == 1:\n        center_col = int(round(holes[0][1]))\n    else:\n        center_col = w // 2\n    half_width = max(1, w // 100, 1)  # small band\n    c0 = max(0, center_col - half_width)\n    c1 = min(w, center_col + half_width + 1)\n    band = ink[:, c0:c1]\n    density = float(np.count_nonzero(band)) / float(band.size) if band.size > 0 else 0.0\n    return float(density)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of gradient vectors whose angle is near +45 degrees (diagonal orientation), useful for detecting diagonal strokes like in 7'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gx, gy = np.gradient(gray)\n    ang = np.arctan2(gy, gx)  # range (-pi, pi)\n    # target +45 degrees = pi/4\n    target = np.pi / 4.0\n    diff = np.abs(((ang - target + np.pi) % (2*np.pi)) - np.pi)\n    mask = diff <= (np.pi / 12.0)  # +/-15 degrees\n    total = ang.size\n    return float(np.count_nonzero(mask)) / float(total + 1e-8)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border uniformity: 1 = very uniform border, 0 = highly variable'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    bw = max(1, min(h, w) // 10)\n    top = a[0:bw, :].ravel()\n    bottom = a[-bw:, :].ravel() if bw <= h else np.array([], dtype=float)\n    left = a[:, 0:bw].ravel()\n    right = a[:, -bw:].ravel() if bw <= w else np.array([], dtype=float)\n    # combine but avoid double-counting corners by using masks\n    border_vals = np.concatenate([top, bottom, left, right])\n    if border_vals.size == 0:\n        return 0.0\n    std_border = float(np.std(border_vals))\n    mean_border = float(np.mean(border_vals))\n    rel = std_border / (abs(mean_border) + eps)\n    # map to [0,1] with diminishing returns\n    result = 1.0 / (1.0 + rel)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink density in the upper-left quadrant to the upper-right quadrant (helps detect left-leaning top strokes)'\n    import numpy as np\n    # convert to grayscale\n    if image is None:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    # robust binarization: choose ink as the minority side of mean threshold\n    thresh = np.mean(gray)\n    mask = gray < thresh\n    if np.count_nonzero(mask) > mask.size / 2:\n        mask = ~mask\n    ul = mask[:h//2, :w//2].sum()\n    ur = mask[:h//2, w//2:].sum()\n    eps = 1e-6\n    return float((ul + eps) / (ur + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal edge energy (diagonal gradients compared to total gradient energy)'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    diag1 = gx + gy\n    diag2 = gx - gy\n    diag_energy = np.sum(np.abs(diag1)) + np.sum(np.abs(diag2))\n    total_energy = np.sum(np.abs(gx)) + np.sum(np.abs(gy))\n    if total_energy == 0:\n        return 0.0\n    return float(diag_energy / (total_energy + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean hole boundary complexity: average of (perimeter / sqrt(area)) across holes (0 if no holes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink_candidate = gray < thresh\n    if np.count_nonzero(ink_candidate) > 0.9 * h * w:\n        ink = ~ink_candidate\n    else:\n        ink = ink_candidate\n    ink = ink.astype(bool)\n    background = ~ink\n    visited = np.zeros_like(background, dtype=bool)\n    stack = []\n    for i in range(h):\n        if background[i, 0]: stack.append((i, 0)); visited[i, 0] = True\n        if background[i, w - 1] and not visited[i, w - 1]: stack.append((i, w - 1)); visited[i, w - 1] = True\n    for j in range(w):\n        if background[0, j] and not visited[0, j]: stack.append((0, j)); visited[0, j] = True\n        if background[h - 1, j] and not visited[h - 1, j]: stack.append((h - 1, j)); visited[h - 1, j] = True\n    while stack:\n        i, j = stack.pop()\n        for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n            ni, nj = i + di, j + dj\n            if 0 <= ni < h and 0 <= nj < w and background[ni, nj] and not visited[ni, nj]:\n                visited[ni, nj] = True\n                stack.append((ni, nj))\n    holes_mask = background & (~visited)\n    comp_visited = np.zeros_like(holes_mask, dtype=bool)\n    complexities = []\n    for i in range(h):\n        for j in range(w):\n            if holes_mask[i, j] and not comp_visited[i, j]:\n                s = [(i, j)]\n                comp_visited[i, j] = True\n                coords = []\n                while s:\n                    ci, cj = s.pop()\n                    coords.append((ci, cj))\n                    for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ni, nj = ci + di, cj + dj\n                        if 0 <= ni < h and 0 <= nj < w and holes_mask[ni, nj] and not comp_visited[ni, nj]:\n                            comp_visited[ni, nj] = True\n                            s.append((ni, nj))\n                coords = np.array(coords)\n                area = coords.shape[0]\n                # perimeter approximated as hole pixels having any neighbor that is ink\n                perim = 0\n                for (ci, cj) in coords:\n                    for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ni, nj = ci + di, cj + dj\n                        if 0 <= ni < h and 0 <= nj < w and ink[ni, nj]:\n                            perim += 1\n                complexities.append(perim / np.sqrt(area + 1e-6))\n    if len(complexities) == 0:\n        return 0.0\n    return float(np.mean(complexities))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right L1 normalized symmetry score: average absolute column difference between left and flipped right (lower = more symmetric)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # Compare left half and mirrored right half\n    mid = w // 2\n    left = gray[:, :mid]\n    right = np.fliplr(gray[:, w - mid: w]) if mid > 0 else np.zeros_like(left)\n    # If sizes mismatch, trim\n    min_cols = min(left.shape[1], right.shape[1]) if left.size and right.size else 0\n    if min_cols == 0:\n        return 0.0\n    left = left[:, :min_cols]\n    right = right[:, :min_cols]\n    diff = np.abs(left - right)\n    denom = np.mean(np.abs(gray)) + 1e-9\n    score = np.mean(diff) / denom\n    return float(score)\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between top-right and top-left ink counts (positive when top-right dominates, negative if top-left dominates)'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image.astype(float), axis=2)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 0.0\n        gmin, gmax = float(np.min(gray)), float(np.max(gray))\n        grayn = (gray - gmin) / (gmax - gmin + 1e-9)\n        mask = grayn < np.mean(grayn)\n        h, w = mask.shape\n        top = slice(0, max(1, h//3))\n        mid = w//2\n        tr = np.count_nonzero(mask[top, mid:w])\n        tl = np.count_nonzero(mask[top, 0:mid])\n        denom = tr + tl + 1e-9\n        return float((tr - tl) / denom)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the bottom-right quadrant (useful to detect tails like 9)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    rng = np.max(gray) - np.min(gray)\n    thr = np.mean(gray) - 0.15 * (rng if rng > 0 else 1.0)\n    ink = gray < thr\n    if np.count_nonzero(ink) < 1:\n        ink = gray > thr\n    H, W = ink.shape\n    br = ink[H//2:, W//2:]\n    total = float(np.count_nonzero(ink))\n    if total == 0.0:\n        return 0.0\n    return float(np.count_nonzero(br)) / total\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Directional edge density (0..1): fraction of pixels with gradient magnitude above mean'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    mean_mag = float(mag.mean())\n    mask = mag > (mean_mag + eps)\n    result = float(mask.sum()) / float(max(1, mag.size))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry correlation of intensities (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = arr[:, :mid]\n    right = arr[:, -mid:] if mid > 0 else np.empty((h, 0))\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    right_flipped = np.fliplr(right)\n    # match shapes if widths differ by 1\n    min_w = min(left.shape[1], right_flipped.shape[1])\n    left_crop = left[:, :min_w].ravel()\n    right_crop = right_flipped[:, :min_w].ravel()\n    if left_crop.size == 0:\n        return 0.0\n    Lc = left_crop - left_crop.mean()\n    Rc = right_crop - right_crop.mean()\n    denom = (np.linalg.norm(Lc) * np.linalg.norm(Rc) + eps)\n    corr = float(np.dot(Lc, Rc) / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimate vertical separation between two prominent background peaks inside a central vertical strip (returns normalized row-distance, 0 if <2 peaks)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    fg = gray < thr\n    if np.count_nonzero(fg) > 0.6 * fg.size:\n        fg = ~fg\n    # central vertical strip\n    half = max(1, w // 10)\n    c = w // 2\n    c0 = max(0, c - half)\n    c1 = min(w, c + half + 1)\n    strip_bg_fraction = np.mean((~fg)[:, c0:c1], axis=1)\n    peak_mask = strip_bg_fraction > 0.5\n    padded = np.concatenate(([0], peak_mask.view(np.int8), [0]))\n    diffs = np.diff(padded)\n    starts = np.where(diffs == 1)[0]\n    ends = np.where(diffs == -1)[0] - 1\n    centers = []\n    for s, e in zip(starts, ends):\n        centers.append((s + e) / 2.0)\n    if len(centers) < 2:\n        return 0.0\n    # take two largest separated centers by distance\n    centers = np.array(centers)\n    # choose the two peaks with largest separation\n    i, j = np.unravel_index(np.argmax(np.abs(centers[:, None] - centers[None, :])), centers.shape*2)\n    sep = abs(centers[i] - centers[j])\n    return float(sep / max(1.0, h - 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram peakiness: how concentrated intensity mass is in a single histogram bin (0..1)'\n    import numpy as np\n    NB = 64\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        flat = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(arr.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    vmin = float(flat.min())\n    vmax = float(flat.max())\n    if vmax <= vmin:\n        return 0.0\n    hist, _ = np.histogram(flat, bins=NB, range=(vmin, vmax))\n    total = float(hist.sum()) + eps\n    max_count = float(hist.max())\n    mean_count = total / float(NB)\n    peak_ratio = max_count / (mean_count + eps)\n    result = (peak_ratio - 1.0) / (float(NB) - 1.0)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian (second-derivative) magnitude as texture measure'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, gyx = np.gradient(gy)\n        gxy, gxx = np.gradient(gx)\n    except Exception:\n        return 0.0\n    lap = gyy + gxx\n    result = float(np.mean(np.abs(lap)))\n    # normalize by mean absolute intensity to keep scale stable\n    denom = float(np.mean(np.abs(a)) + eps)\n    return float(result / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Inter-percentile contrast: (90th - 10th percentile) normalized by median'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    p90 = float(np.percentile(flat, 90))\n    p10 = float(np.percentile(flat, 10))\n    p50 = float(np.percentile(flat, 50)) + eps\n    result = (p90 - p10) / p50\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of strong vertical edges (gx) relative to image size'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag_v = np.abs(gx)\n    # threshold relative to typical vertical gradient strength\n    thr = float(np.mean(mag_v) + 0.5 * np.std(mag_v))\n    count = float(np.count_nonzero(mag_v > thr))\n    denom = float(a.size)\n    result = count / (denom + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels that are strong edges (edge density)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    med = float(np.median(mag))\n    std = float(mag.std())\n    thresh = med + 0.5 * std\n    count = float(np.count_nonzero(mag > thresh))\n    result = count / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted centroid offset from image center normalized by diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    weights = a - a.min()\n    wsum = float(weights.sum())\n    if wsum <= 0:\n        # fallback to binary centroid using above-median mask\n        mask = a > np.median(a)\n        if not np.any(mask):\n            return 0.0\n        ys_m, xs_m = np.nonzero(mask)\n        cy = float(ys_m.mean())\n        cx = float(xs_m.mean())\n    else:\n        cx = float((weights * xs).sum()) / (wsum + eps)\n        cy = float((weights * ys).sum()) / (wsum + eps)\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    diag = np.hypot(w, h) + eps\n    result = dist / diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Skewness of row mean intensities (positive => heavier tail at bottom rows)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    row_means = a.mean(axis=1)\n    m = float(row_means.mean())\n    std = float(row_means.std()) + eps\n    skew = float(np.mean((row_means - m) ** 3)) / (std ** 3 + eps)\n    return float(np.clip(skew, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal edge density: fraction of pixels with strong diagonal gradients'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    # diagonal responses for the two diagonal directions\n    d1 = np.abs(gx + gy)\n    d2 = np.abs(gx - gy)\n    diag = np.maximum(d1, d2)\n    thr = float(np.median(diag) + diag.std())\n    strong = diag > thr\n    frac = float(np.count_nonzero(strong)) / float(diag.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal edge bias: (NW-SE - NE-SW) / total diagonal energy (range -1..1)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    # NW-SE differences\n    a = gray[:-1, :-1] - gray[1:, 1:]\n    b = gray[:-1, 1:] - gray[1:, :-1]  # NE-SW\n    en_a = np.sum(np.abs(a))\n    en_b = np.sum(np.abs(b))\n    denom = en_a + en_b + 1e-9\n    return float((en_a - en_b) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized horizontal centroid of ink (0=left, 1=right)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    if h == 0 or w == 0:\n        return 0.5\n    m = float(np.mean(gray))\n    lower = gray <= m\n    upper = gray > m\n    mean_lower = float(np.mean(gray[lower])) if np.any(lower) else m\n    mean_upper = float(np.mean(gray[upper])) if np.any(upper) else m\n    ink = lower if mean_lower < mean_upper else upper\n    ys, xs = np.nonzero(ink)\n    if xs.size == 0:\n        return 0.5\n    cx = float(np.mean(xs)) / max(1.0, w - 1)\n    return float(cx)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of center-region pixels that are strict local maxima compared to 8 neighbors (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    ch = max(1, h // 4)\n    cw = max(1, w // 4)\n    r0 = max(1, h//2 - ch//2)\n    r1 = min(h-1, r0 + ch)\n    c0 = max(1, w//2 - cw//2)\n    c1 = min(w-1, c0 + cw)\n    region = a[r0:r1, c0:c1]\n    if region.size == 0:\n        return 0.0\n    # compare to 8 neighbors using shifted slices on the original array\n    center = a[r0:r1, c0:c1]\n    n0 = a[r0-1:r1-1, c0-1:c1-1]  # up-left\n    n1 = a[r0-1:r1-1, c0:c1]    # up\n    n2 = a[r0-1:r1-1, c0+1:c1+1]  # up-right\n    n3 = a[r0:r1, c0-1:c1-1]     # left\n    n4 = a[r0:r1, c0+1:c1+1]     # right\n    n5 = a[r0+1:r1+1, c0-1:c1-1]  # down-left\n    n6 = a[r0+1:r1+1, c0:c1]    # down\n    n7 = a[r0+1:r1+1, c0+1:c1+1]  # down-right\n    is_peak = (center > n0) & (center > n1) & (center > n2) & (center > n3) & (center > n4) & (center > n5) & (center > n6) & (center > n7)\n    frac = float(np.count_nonzero(is_peak)) / (float(center.size) + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong gradient pixels (edge density) using mean+std threshold'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thresh = float(np.mean(mag) + np.std(mag))\n    strong = np.count_nonzero(mag > thresh)\n    result = strong / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of ink in the bottom-left quadrant (normalized by quadrant area) - distinguishes bottom-left empty 7 from looped 3'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    meanv = gray.mean()\n    stdv = gray.std() if gray.std() > 1e-9 else 1.0\n    fg = (np.abs(gray - meanv) > 0.5 * stdv)\n    bl = fg[h//2:, :w//2]\n    denom = bl.size if bl.size else 1\n    return float(bl.sum() / float(denom))\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of radial mean intensities normalized by global variance'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    r = np.hypot(ys - cy, xs - cx)\n    # number of radial bins\n    nbins = max(4, int(min(h, w) / 2))\n    if nbins <= 1:\n        return 0.0\n    rmax = r.max()\n    if rmax <= 0:\n        return 0.0\n    bins = np.linspace(0.0, rmax, nbins + 1)\n    inds = np.digitize(r.ravel(), bins) - 1\n    means = []\n    flat = a.ravel()\n    for i in range(nbins):\n        sel = flat[inds == i]\n        if sel.size:\n            means.append(float(sel.mean()))\n    if len(means) <= 1:\n        return 0.0\n    rad_var = float(np.var(np.array(means)))\n    global_var = float(np.var(a)) + eps\n    result = rad_var / global_var\n    # keep in reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson correlation between radial distance from center and intensity (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy).ravel()\n    vals = a.ravel()\n    if vals.size < 2:\n        return 0.0\n    rv = r - r.mean()\n    vv = vals - vals.mean()\n    denom = (np.sqrt(np.sum(rv * rv) * np.sum(vv * vv)) + eps)\n    corr = float(np.sum(rv * vv) / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry: normalized negative mean absolute difference between left and mirrored right (positive => symmetric)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, w - mid:]\n    # flip right horizontally to compare\n    right_flipped = np.fliplr(right)\n    # crop to same width if mismatch\n    minw = min(left.shape[1], right_flipped.shape[1])\n    left_c = left[:, :minw]\n    right_c = right_flipped[:, :minw]\n    if left_c.size == 0:\n        return 0.0\n    diff = np.abs(left_c - right_c).mean()\n    norm = a.std() + eps\n    result = 1.0 - (diff / norm)  # closer to 1 means more symmetric\n    return float(np.clip(result, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (height / width) of the tight ink bounding box (1.0 ~ square); distinguishes tall strokes from round loops'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    if border_mean > np.median(gray):\n        thr = (border_mean + float(np.min(gray))) / 2.0\n        ink = gray < thr\n    else:\n        thr = (border_mean + float(np.max(gray))) / 2.0\n        ink = gray > thr\n    coords = np.argwhere(ink)\n    if coords.size == 0:\n        return 0.0\n    min_r, min_c = coords.min(axis=0)\n    max_r, max_c = coords.max(axis=0)\n    bbox_h = max_r - min_r + 1\n    bbox_w = max_c - min_c + 1\n    if bbox_w <= 0:\n        return float(bbox_h)\n    return float(bbox_h) / float(bbox_w)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation fraction (peak bin energy / total) using 16 bins'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = float(mag.sum()) + 1e-12\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # orientation modulo pi (undirected)\n    theta_mod = np.mod(theta, np.pi)\n    bins = 16\n    bin_edges = np.linspace(0.0, np.pi, bins + 1)\n    hist = np.zeros(bins, dtype=float)\n    # compute weighted histogram\n    inds = np.minimum(np.searchsorted(bin_edges, theta_mod, side='right') - 1, bins - 1)\n    inds = np.clip(inds, 0, bins - 1)\n    flat_inds = inds.ravel()\n    flat_weights = mag.ravel()\n    for idx, wgt in zip(flat_inds, flat_weights):\n        hist[int(idx)] += float(wgt)\n    peak = float(hist.max())\n    result = peak / total\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average gradient magnitude in the bottom third of the image normalized by overall average gradient (edgeiness at bottom)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    if image.ndim == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx > mn:\n        g = (gray - mn) / (mx - mn)\n    else:\n        g = np.zeros_like(gray, dtype=float)\n    gx, gy = np.gradient(g)\n    mag = np.sqrt(gx * gx + gy * gy)\n    r0 = (2 * h) // 3\n    bottom_mag = mag[r0:h, :]\n    overall_mean = float(np.mean(mag)) + 1e-9\n    return float(np.mean(bottom_mag) / overall_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local checkerboard score: fraction of 2x2 blocks that alternate above/below global mean'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gm = float(img.mean())\n    binm = img > gm\n    # examine all 2x2 blocks\n    blocks_h = h - 1\n    blocks_w = w - 1\n    # extract corners\n    tl = binm[0:blocks_h, 0:blocks_w]\n    tr = binm[0:blocks_h, 1:blocks_w+1]\n    bl = binm[1:blocks_h+1, 0:blocks_w]\n    br = binm[1:blocks_h+1, 1:blocks_w+1]\n    # checkerboard patterns: diagonal pairs equal and opposite to the other diagonal\n    diag_equal = (tl == br) & (tr == bl)\n    diagonals_diff = (tl != tr)\n    checker = diag_equal & diagonals_diff\n    total_blocks = float(blocks_h * blocks_w)\n    score = float(checker.sum()) / (total_blocks + 1e-12)\n    return float(np.clip(score, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference in ink fraction between the upper-right and upper-left quadrants (UR - UL) normalized by total ink'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    thresh = (float(np.min(gray)) + float(np.max(gray))) / 2.0\n    ink = (gray < thresh)\n    mid_h = h // 2\n    mid_w = w // 2\n    UR = np.sum(ink[:mid_h, mid_w:])\n    UL = np.sum(ink[:mid_h, :mid_w])\n    total = np.sum(ink)\n    if total == 0:\n        return 0.0\n    return float((UR - UL) / float(total))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted centroid offset normalized by max radius (0=centered, 1=at edge)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    total = float(arr.sum())\n    if total == 0:\n        return 0.0\n    cy = float(((ys * arr).sum()) / (total + eps))\n    cx = float(((xs * arr).sum()) / (total + eps))\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    maxr = np.hypot(center_y, center_x) + eps\n    offset = dist / maxr\n    return float(np.clip(offset, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from FFT (fraction of power outside central low-pass disk, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        F = np.fft.fft2(a)\n        Fshift = np.fft.fftshift(F)\n        power = np.abs(Fshift) ** 2\n    except Exception:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    radius = max(1.0, min(h, w) / 8.0)\n    low_mask = r <= radius\n    low_energy = float(power[low_mask].sum())\n    total_energy = float(power.sum()) + eps\n    high_energy = float(total_energy - low_energy)\n    result = float(np.clip(high_energy / total_energy, 0.0, 1.0))\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial brightness slope from center (negative => darker toward corners), normalized by std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    r = np.sqrt((ys - cy) ** 2 + (xs - cx) ** 2)\n    rmax = float(r.max()) + eps\n    rnorm = (r / rmax).ravel()\n    vals = a.ravel()\n    # bin radial values into 10 rings and compute mean intensity per ring\n    bins = 10\n    inds = np.floor(rnorm * bins).astype(int)\n    inds = np.clip(inds, 0, bins - 1)\n    means = []\n    radii = []\n    for b in range(bins):\n        mask = inds == b\n        if mask.sum() == 0:\n            continue\n        means.append(float(vals[mask].mean()))\n        radii.append(float((b + 0.5) / bins)\n                     )\n    if len(means) < 2:\n        return 0.0\n    radii = np.array(radii)\n    means = np.array(means)\n    # simple linear slope\n    denom = (np.sum((radii - radii.mean()) ** 2) + eps)\n    slope = float(np.sum((radii - radii.mean()) * (means - means.mean())) / denom)\n    result = slope / (float(a.std()) + eps)\n    return float(np.clip(result, -10.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian (average second-derivative magnitude) indicating edge/texture strength'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # discrete Laplacian via neighbor rolls (handles edges via wrap which is cheap)\n    lap = -4.0 * a\n    lap += np.roll(a, 1, axis=0)\n    lap += np.roll(a, -1, axis=0)\n    lap += np.roll(a, 1, axis=1)\n    lap += np.roll(a, -1, axis=1)\n    result = float(np.mean(np.abs(lap)))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of enclosed background connected components (holes) detected by border flood-fill'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.sum(ink) == 0 or np.sum(ink) > 0.6 * h * w:\n        ink = gray > thr\n    bg = ~ink\n    # Flood-fill external background starting from borders\n    external = np.zeros_like(bg, dtype=bool)\n    stack = []\n    # push border background pixels\n    top_row = np.where(bg[0, :])[0]\n    for c in top_row:\n        stack.append((0, c))\n        external[0, c] = True\n    bottom_row = np.where(bg[-1, :])[0]\n    for c in bottom_row:\n        if not external[h-1, c]:\n            stack.append((h-1, c)); external[h-1, c] = True\n    left_col = np.where(bg[:, 0])[0]\n    for r in left_col:\n        if not external[r, 0]:\n            stack.append((r, 0)); external[r, 0] = True\n    right_col = np.where(bg[:, -1])[0]\n    for r in right_col:\n        if not external[r, w-1]:\n            stack.append((r, w-1)); external[r, w-1] = True\n    # 4-neighborhood flood fill\n    while stack:\n        r, c = stack.pop()\n        for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n            nr, nc = r + dr, c + dc\n            if 0 <= nr < h and 0 <= nc < w and bg[nr, nc] and not external[nr, nc]:\n                external[nr, nc] = True\n                stack.append((nr, nc))\n    holes_mask = bg & (~external)\n    # Count hole connected components (4-connectivity)\n    visited = np.zeros_like(holes_mask, dtype=bool)\n    hole_count = 0\n    for r in range(h):\n        for c in range(w):\n            if holes_mask[r, c] and not visited[r, c]:\n                hole_count += 1\n                # BFS\n                q = [(r, c)]\n                visited[r, c] = True\n                while q:\n                    rr, cc = q.pop()\n                    for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n                        nr, nc = rr+dr, cc+dc\n                        if 0 <= nr < h and 0 <= nc < w and holes_mask[nr, nc] and not visited[nr, nc]:\n                            visited[nr, nc] = True\n                            q.append((nr, nc))\n    return float(hole_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of border pixels within one std of border median (1 = very uniform border)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    t = max(1, min(h, w) // 10)\n    masks = []\n    masks.append(arr[0:t, :])\n    masks.append(arr[h-t:h, :])\n    masks.append(arr[:, 0:t])\n    masks.append(arr[:, w-t:w])\n    border_vals = np.concatenate([m.ravel() for m in masks if m.size], axis=0) if any(m.size for m in masks) else np.array([])\n    if border_vals.size == 0:\n        return 0.0\n    med = float(np.median(border_vals))\n    std = float(np.std(border_vals)) + eps\n    within = np.count_nonzero(np.abs(border_vals - med) <= std)\n    result = float(within) / float(border_vals.size)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute horizontal gradient to mean absolute vertical gradient: detects prevalence of horizontal bars vs round edges'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 1.0\n    if gray.size == 0:\n        return 1.0\n    try:\n        gy, gx = np.gradient(gray)  # gy: d/drow (vertical), gx: d/dcol (horizontal)\n    except Exception:\n        return 1.0\n    mean_abs_gx = float(np.mean(np.abs(gx)))\n    mean_abs_gy = float(np.mean(np.abs(gy)))\n    return float(mean_abs_gx / (mean_abs_gy + 1e-8))\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson correlation between radius and mean ring intensity (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    r_int = np.floor(r).astype(int)\n    max_r = int(r_int.max())\n    if max_r <= 0:\n        return 0.0\n    flat_r = r_int.ravel()\n    flat_i = img.ravel()\n    counts = np.bincount(flat_r)\n    sums = np.bincount(flat_r, weights=flat_i)\n    valid = counts > 0\n    if valid.sum() < 2:\n        return 0.0\n    means = sums[valid] / (counts[valid] + eps)\n    radii = np.arange(0, max_r + 1)[valid].astype(float)\n    # compute Pearson correlation\n    mr = means.mean()\n    rr = radii.mean()\n    num = float(((means - mr) * (radii - rr)).sum())\n    den = float(np.sqrt(((means - mr) ** 2).sum() * ((radii - rr) ** 2).sum()) + eps)\n    corr = num / den if den > 0 else 0.0\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum continuous horizontal ink run length normalized by image width'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    mask_lo = gray < th\n    mask_hi = gray > th\n    mask = mask_lo if np.count_nonzero(mask_lo) <= np.count_nonzero(mask_hi) else mask_hi\n    max_run = 0\n    for r in range(h):\n        row = mask[r]\n        # fast run length scan\n        run = 0\n        # iterate over booleans\n        for val in row:\n            if val:\n                run += 1\n            else:\n                if run > max_run:\n                    max_run = run\n                run = 0\n        if run > max_run:\n            max_run = run\n    return float(max_run / max(1, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of image energy in high-frequency bands of the 2D FFT (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n        P = np.abs(F) ** 2\n    except Exception:\n        return 0.0\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h) - cy\n    xs = np.arange(w) - cx\n    Y, X = np.meshgrid(ys, xs, indexing='ij')\n    R = np.hypot(Y, X)\n    maxr = R.max() if R.size else 1.0\n    if maxr <= 0:\n        return 0.0\n    # define high freq as outer 40% of radius\n    hf_mask = R >= (0.6 * maxr)\n    total = float(P.sum()) + 1e-12\n    hf = float(P[hf_mask].sum())\n    return float(np.clip(hf / total, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of gradient energy to total intensity variance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    grad_energy = float((gx * gx + gy * gy).sum())\n    var_energy = float(((a - a.mean()) ** 2).sum())\n    result = grad_energy / (var_energy + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score (0..1) comparing left and mirrored right halves'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, w - mid:]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    right_flipped = np.fliplr(right)\n    # align shapes (if odd width)\n    minw = min(left.shape[1], right_flipped.shape[1])\n    left = left[:, :minw]\n    right_flipped = right_flipped[:, :minw]\n    diff = np.abs(left - right_flipped)\n    denom = np.mean(np.abs(a)) + eps\n    score = 1.0 - float(diff.mean()) / float(denom)\n    result = float(np.clip(score, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for grayscale); normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    arr = np.nan_to_num(img.astype(float))\n    R = arr[..., 0]\n    G = arr[..., 1]\n    B = arr[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(np.abs(rg)))\n    mean_yb = float(np.mean(np.abs(yb)))\n    colorfulness = np.sqrt(std_rg * std_rg + std_yb * std_yb) + 0.3 * np.sqrt(mean_rg * mean_rg + mean_yb * mean_yb)\n    gstd = float(arr.mean(axis=2).std()) + eps\n    result = colorfulness / gstd\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram peakiness: proportion of pixels in the largest intensity bin (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return float(0.0)\n    bins = 64\n    counts, _ = np.histogram(vals, bins=bins)\n    total = float(counts.sum())\n    if total <= 0.0:\n        return float(0.0)\n    peak = float(counts.max())\n    result = peak / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of corner-like pixels normalized by image area'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    ang = np.arctan2(gy, gx)\n    # pad for neighbor comparisons\n    pad_ang = np.pad(ang, ((1, 1), (1, 1)), mode='edge')\n    pad_mag = np.pad(mag, ((1, 1), (1, 1)), mode='constant', constant_values=0.0)\n    center_ang = pad_ang[1:-1, 1:-1]\n    center_mag = pad_mag[1:-1, 1:-1]\n    # compare with 8 neighbors: if several neighbors have very different angle and center is strong edge -> corner\n    diffs = 0\n    count = np.zeros_like(center_ang, dtype=int)\n    neighbors = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n    for dy, dx in neighbors:\n        nbr_ang = pad_ang[1+dy:h+1+dy, 1+dx:w+1+dx]\n        # angular difference wrapped\n        d = np.abs(np.angle(np.exp(1j*(center_ang - nbr_ang))))\n        count += (d > (np.pi / 4)).astype(int)\n    mag_thresh = np.median(mag) + 0.5 * mag.std()\n    corners = ((count >= 3) & (center_mag > mag_thresh))\n    result = float(np.count_nonzero(corners)) / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with strong gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    strong = (mag >= thr).sum()\n    result = float(strong) / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of neighbor relationships that are diagonal vs total (captures diagonal tails)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy().astype(float)\n    gray = gray.astype(float)\n    t = np.mean(gray)\n    mask1 = gray < t\n    mask2 = gray > t\n    mask = mask1 if mask1.sum() <= mask2.sum() else mask2\n    mask = mask.astype(np.uint8)\n    if mask.sum() == 0:\n        return 0.0\n    pad = np.pad(mask, ((1, 1), (1, 1)), mode='constant', constant_values=0)\n    # diagonal neighbors\n    nw = pad[:-2, :-2]\n    ne = pad[:-2, 2:]\n    sw = pad[2:, :-2]\n    se = pad[2:, 2:]\n    diag_count = (nw + ne + sw + se).astype(np.int64)\n    # orthogonal neighbors\n    up = pad[:-2, 1:-1]\n    down = pad[2:, 1:-1]\n    left = pad[1:-1, :-2]\n    right = pad[1:-1, 2:]\n    ortho_count = (up + down + left + right).astype(np.int64)\n    # Only count neighbor links for foreground pixels\n    diag_sum = np.sum(diag_count[mask == 1])\n    ortho_sum = np.sum(ortho_count[mask == 1])\n    total_links = diag_sum + ortho_sum\n    if total_links == 0:\n        return 0.0\n    return float(diag_sum) / float(total_links)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum horizontal run of foreground (threshold=median) normalized by width'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w == 0:\n        return 0.0\n    med = np.median(arr) if arr.size else 0.0\n    mask = arr > med\n    max_run = 0\n    for r in range(h):\n        row = mask[r]\n        if not np.any(row):\n            continue\n        idx = np.nonzero(row)[0]\n        if idx.size == 0:\n            continue\n        # split indices into contiguous runs\n        diffs = np.diff(idx)\n        if diffs.size == 0:\n            lengths = [1]\n        else:\n            splits = np.where(diffs > 1)[0] + 1\n            runs = np.split(idx, splits)\n            lengths = [len(run) for run in runs]\n        row_max = max(lengths) if lengths else 0\n        if row_max > max_run:\n            max_run = row_max\n    result = max_run / float(w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in the left third of the image (left mass / total ink mass)'\n    import numpy as np\n    # Normalize to grayscale\n    img = image.astype(float)\n    h, w = img.shape[:2]\n    if img.max() > 1.0:\n        img = img / 255.0\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    # Determine ink as minority of pixels relative to mean\n    thr = gray.mean()\n    cand1 = gray < thr\n    cand2 = gray > thr\n    mask = cand1 if cand1.sum() <= cand2.sum() else cand2\n    total = float(mask.sum())\n    if total == 0.0:\n        return 0.0\n    left = float(mask[:, :max(1, w // 3)].sum())\n    return float(left / (total + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical gradient energy to horizontal gradient energy (vertical_vs_horizontal_stroke_strength)'\n    img = image.astype(float)\n    if len(img.shape) == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    # gradients: gy along rows (vertical), gx along cols (horizontal)\n    gy, gx = np.gradient(gray)\n    vert_energy = np.sum(np.abs(gy))\n    horiz_energy = np.sum(np.abs(gx))\n    # avoid division by zero\n    if horiz_energy <= 1e-8:\n        return float(vert_energy)\n    return float(vert_energy / horiz_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of horizontal gradient in the top third vs overall (high value indicates a prominent top bar)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    # horizontal gradient\n    gy, gx = np.gradient(gray)\n    abs_gx = np.abs(gx)\n    top_region = abs_gx[0:max(1, h//3), :]\n    top_mean = float(np.mean(top_region)) if top_region.size > 0 else 0.0\n    overall_mean = float(np.mean(abs_gx)) + 1e-9\n    return float(top_mean / overall_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of gradient energy concentrated in the central region (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = float(mag.sum()) + eps\n    ch, cw = max(1, h // 4), max(1, w // 4)\n    cy0, cy1 = h//2 - ch//2, h//2 + (ch - ch//2)\n    cx0, cx1 = w//2 - cw//2, w//2 + (cw - cw//2)\n    center_sum = float(mag[cy0:cy1, cx0:cx1].sum())\n    return float(np.clip(center_sum / total, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels brighter than mean+0.1*std (simple foreground ratio)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m + 0.1 * s\n    fg = float(np.count_nonzero(a > thr))\n    result = fg / (float(a.size) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local variance (3x3) normalized by global variance (0..10)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute local mean (3x3) using rolls\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    local_var = np.mean((a - local_mean) ** 2)\n    global_var = float(a.var()) + eps\n    result = local_var / global_var\n    # clip to avoid extreme values from tiny denominators\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local peak density: fraction of strict local maxima above local threshold'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center = a\n    # compare to 8 neighbors using roll (wraps, so we'll zero edges afterwards)\n    n1 = np.roll(center, 1, axis=0)\n    n2 = np.roll(center, -1, axis=0)\n    n3 = np.roll(center, 1, axis=1)\n    n4 = np.roll(center, -1, axis=1)\n    n5 = np.roll(n1, 1, axis=1)\n    n6 = np.roll(n1, -1, axis=1)\n    n7 = np.roll(n2, 1, axis=1)\n    n8 = np.roll(n2, -1, axis=1)\n    peak_mask = (center > n1) & (center > n2) & (center > n3) & (center > n4) & (center > n5) & (center > n6) & (center > n7) & (center > n8)\n    # remove wrapped borders (first/last row/col)\n    peak_mask[0, :] = False\n    peak_mask[-1, :] = False\n    peak_mask[:, 0] = False\n    peak_mask[:, -1] = False\n    thr = float(center.mean()) + 0.5 * float(center.std())\n    peak_mask = peak_mask & (center > thr)\n    count = float(np.count_nonzero(peak_mask))\n    area = float(h * w) + eps\n    result = count / area\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average peak sharpness: mean (peak - neighbor mean) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    k = min(20, flat.size)\n    top_idx = np.argpartition(-flat, k-1)[:k]\n    ys, xs = np.unravel_index(top_idx, (h, w))\n    diffs = []\n    for y, x in zip(ys, xs):\n        y0 = max(0, y-1); y1 = min(h, y+2)\n        x0 = max(0, x-1); x1 = min(w, x+2)\n        neigh = a[y0:y1, x0:x1].astype(float)\n        if neigh.size <= 1:\n            continue\n        neigh_mean = (neigh.sum() - a[y, x]) / (neigh.size - 1)\n        diffs.append(max(0.0, float(a[y, x]) - neigh_mean))\n    if len(diffs) == 0:\n        return 0.0\n    global_std = float(a.std()) + eps\n    result = float(np.mean(diffs)) / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal stroke orientation (degrees) computed from ink pixel PCA; positive ~ down-right diagonal (useful for distinguishing 7)'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    if gray.size == 0:\n        return 0.0\n    thr = (np.nanmin(gray) + np.nanmax(gray)) / 2.0\n    dark_count = np.count_nonzero(gray < thr)\n    ink = (gray < thr) if dark_count < gray.size / 2 else (gray > thr)\n    coords = np.column_stack(np.nonzero(ink))\n    if coords.shape[0] < 2:\n        return 0.0\n    # coords: rows, cols -> convert to x,y coordinates where x=col, y=row\n    pts = np.column_stack((coords[:, 1].astype(float), coords[:, 0].astype(float)))\n    mean = pts.mean(axis=0)\n    ptsc = pts - mean\n    cov = np.cov(ptsc.T)\n    # eigen decomposition\n    try:\n        eigvals, eigvecs = np.linalg.eigh(cov)\n    except Exception:\n        return 0.0\n    principal = eigvecs[:, np.argmax(eigvals)]\n    angle_rad = np.arctan2(principal[1], principal[0])\n    angle_deg = float(np.degrees(angle_rad))\n    return angle_deg\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical gradient energy concentrated in the left third of the image (left vertical energy / total energy)'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float32)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    # compute gradients (dy, dx)\n    try:\n        dy, dx = np.gradient(gray)\n    except Exception:\n        dy = np.zeros_like(gray)\n        dx = np.zeros_like(gray)\n    total_energy = np.sum(np.abs(dy)) + eps\n    left_w = max(1, w // 3)\n    left_energy = np.sum(np.abs(dy[:, :left_w]))\n    return float(left_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of columns with strong horizontal transitions (texture/striping indicator)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w == 0 or h < 2:\n        return 0.0\n    col_diff_means = np.mean(np.abs(np.diff(a, axis=0)), axis=0)\n    overall_mean = float(col_diff_means.mean()) + eps\n    high = col_diff_means > (1.5 * overall_mean)\n    result = float(np.count_nonzero(high)) / float(w)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance between intensity-weighted centroid and image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    ys, xs = np.indices((h, w))\n    total = float(a.sum())\n    if total <= eps:\n        return 0.0\n    cx = (xs * a).sum() / (total + eps)\n    cy = (ys * a).sum() / (total + eps)\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    max_dist = np.hypot(center_x, center_y) + eps\n    result = dist / max_dist\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Annular contrast: brightness of a ring around center normalized by global std (-5..5)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = r.max() + eps\n    radius = 0.5 * maxr\n    width = max(1.0, 0.12 * maxr)\n    ann_mask = (np.abs(r - radius) <= width)\n    center_mask = (r <= max(1.0, radius * 0.5))\n    outer_mask = (r >= min(maxr, radius * 1.5))\n    if not np.any(ann_mask):\n        return 0.0\n    ann_mean = float(a[ann_mask].mean())\n    cen_mean = float(a[center_mask].mean()) if np.any(center_mask) else ann_mean\n    out_mean = float(a[outer_mask].mean()) if np.any(outer_mask) else ann_mean\n    denom = float(a.std()) + eps\n    result = (ann_mean - 0.5 * (cen_mean + out_mean)) / denom\n    return float(np.clip(result, -5.0, 5.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute 45-degree diagonal gradient to mean absolute -45-degree diagonal gradient (skewed stroke indicator)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    # compute diagonal differences\n    d1 = np.abs(gray[1:, 1:] - gray[:-1, :-1])\n    d2 = np.abs(gray[1:, :-1] - gray[:-1, 1:])\n    m1 = float(np.mean(d1)) + 1e-9\n    m2 = float(np.mean(d2)) + 1e-9\n    return float(m1 / m2)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of hole area that lies in the upper half of the image (holes detected as background components not connected to the image border)'\n    import numpy as np\n    from collections import deque\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(np.float32), axis=2)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    bg = np.median(border) if border.size > 0 else 0.0\n    diff = np.abs(gray - bg)\n    thr = max(0.05 * (gray.max() - gray.min()), 0.5 * np.std(gray), 1e-6)\n    binar = (diff > thr).astype(np.uint8)  # foreground=1, background=0\n    if h == 0 or w == 0:\n        return 0.0\n    # Mark outside background via flood fill from border for pixels that are background (0)\n    outside = np.zeros((h, w), dtype=bool)\n    q = deque()\n    for x in range(w):\n        if binar[0, x] == 0:\n            q.append((0, x)); outside[0, x] = True\n        if binar[h-1, x] == 0:\n            q.append((h-1, x)); outside[h-1, x] = True\n    for y in range(h):\n        if binar[y, 0] == 0:\n            q.append((y, 0)); outside[y, 0] = True\n        if binar[y, w-1] == 0:\n            q.append((y, w-1)); outside[y, w-1] = True\n    while q:\n        y, x = q.popleft()\n        for ny, nx in ((y-1,x),(y+1,x),(y,x-1),(y,x+1)):\n            if 0 <= ny < h and 0 <= nx < w and not outside[ny, nx] and binar[ny, nx] == 0:\n                outside[ny, nx] = True\n                q.append((ny, nx))\n    holes_mask = (~outside) & (binar == 0)\n    total_hole = int(np.count_nonzero(holes_mask))\n    if total_hole == 0:\n        return 0.0\n    upper_half = holes_mask[:h//2, :]\n    upper_area = int(np.count_nonzero(upper_half))\n    return float(upper_area / total_hole)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of a bottom horizontal bar: mean abs horizontal gradient in bottom quarter divided by overall mean'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    try:\n        gy, gx = np.gradient(gray)\n    except Exception:\n        gy = np.zeros_like(gray); gx = np.zeros_like(gray)\n    overall = float(np.mean(np.abs(gx))) + 1e-9\n    bottom_slice = slice(max(0, 3*h//4), h)\n    bottom_strength = float(np.mean(np.abs(gx[bottom_slice, :])))\n    return float(bottom_strength / overall)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum horizontal coverage fraction within the top third (max row ink count in top third divided by width)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    top = gray[: max(1, h // 3), :]\n    thresh = np.mean(gray)\n    dark_count = np.count_nonzero(gray < thresh)\n    bright_count = np.count_nonzero(gray > thresh)\n    ink_top = (top < thresh) if dark_count < bright_count else (top > thresh)\n    if ink_top.size == 0:\n        return 0.0\n    row_counts = np.sum(ink_top, axis=1)\n    max_row = float(np.max(row_counts)) if row_counts.size > 0 else 0.0\n    return float(max_row / w)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink in a central vertical band (width = ~1/6 of image width) capturing vertical strokes'\n    import numpy as np\n    if image is None:\n        return 0.0\n    gray = np.array(image, dtype=float)\n    if gray.ndim == 3:\n        gray = np.mean(gray, axis=2)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    rng = mx - mn + 1e-9\n    gray = (gray - mn) / rng\n    h, w = gray.shape\n    bw = max(1, w // 6)\n    start = max(0, (w - bw) // 2)\n    end = start + bw\n    thresh = np.mean(gray)\n    fg1 = gray < thresh\n    fg2 = gray > thresh\n    fg = fg1 if np.count_nonzero(fg1) <= np.count_nonzero(fg2) else fg2\n    total = np.count_nonzero(fg)\n    if total == 0:\n        return 0.0\n    center_band = fg[:, start:end]\n    return float(np.count_nonzero(center_band) / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge orientation concentration (circular concentration of gradient orientations, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    # orientation symmetry: use double-angle to make opposite directions equivalent\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    cos2 = np.cos(2.0 * theta)\n    sin2 = np.sin(2.0 * theta)\n    # weight by magnitude\n    W = mag.ravel()\n    S_cos = float((W * cos2.ravel()).sum())\n    S_sin = float((W * sin2.ravel()).sum())\n    Wsum = float(W.sum()) + eps\n    R = np.hypot(S_cos, S_sin) / Wsum\n    return float(np.clip(R, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average radial alignment of gradients (1=pointing outward from center)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 1 or w < 1:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    yy, xx = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    vx = xx - cx\n    vy = yy - cy\n    vr = np.hypot(vx, vy)\n    gm = np.hypot(gx, gy)\n    valid = (gm > eps) & (vr > 0)\n    if not np.any(valid):\n        return 0.0\n    dot = gx[valid] * vx[valid] + gy[valid] * vy[valid]\n    denom = (gm[valid] * vr[valid]) + eps\n    cosval = dot / denom\n    # map from [-1,1] to [0,1] where 1 = outward, 0 = inward\n    mapped = (cosval + 1.0) / 2.0\n    result = float(np.mean(mapped))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated number of enclosed holes in the ink (counts connected background components that do not touch the image border)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-8)\n    bw = max(1, min(h, w) // 10)\n    border = np.concatenate([g[:bw, :].ravel(), g[-bw:, :].ravel(), g[:, :bw].ravel(), g[:, -bw:].ravel()])\n    thresh = (float(np.mean(border)) + float(np.mean(g))) / 2.0 if border.size else 0.5\n    ink = g < thresh if np.mean(border) > np.mean(g) else g > thresh\n    bg = ~ink\n    visited = np.zeros_like(bg, dtype=bool)\n    holes = 0\n    # BFS to find connected components in bg\n    for r in range(h):\n        for c in range(w):\n            if not bg[r, c] or visited[r, c]:\n                continue\n            # new component\n            stack = [(r, c)]\n            visited[r, c] = True\n            touches_border = (r == 0 or c == 0 or r == h - 1 or c == w - 1)\n            while stack:\n                rr, cc = stack.pop()\n                for dr in (-1, 0, 1):\n                    for dc in (-1, 0, 1):\n                        if dr == 0 and dc == 0:\n                            continue\n                        nr, nc = rr + dr, cc + dc\n                        if nr < 0 or nc < 0 or nr >= h or nc >= w:\n                            continue\n                        if not bg[nr, nc] or visited[nr, nc]:\n                            continue\n                        visited[nr, nc] = True\n                        if nr == 0 or nc == 0 or nr == h - 1 or nc == w - 1:\n                            touches_border = True\n                        stack.append((nr, nc))\n            if not touches_border:\n                holes += 1\n    return float(holes)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bias of ink between upper-right and lower-left quadrants normalized by ink area (positive -> more upper-right ink)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    minv, maxv = float(np.min(gray)), float(np.max(gray))\n    scaled = (gray - minv) / (maxv - minv + 1e-8)\n    t = float(np.mean(scaled))\n    dark = scaled <= t\n    bright = scaled >= t\n    fore = dark if dark.sum() <= bright.sum() else bright\n    if fore.sum() == 0:\n        return 0.0\n    r_mid = h // 2\n    c_mid = w // 2\n    upper_right = fore[:r_mid, c_mid:].sum()\n    lower_left = fore[r_mid:, :c_mid].sum()\n    return float((upper_right - lower_left) / (fore.sum() + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels effectively zero (sparsity) relative to max intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    maxv = float(np.nanmax(arr)) if arr.size else 0.0\n    if maxv <= eps:\n        # image completely zero -> maximally sparse\n        return 1.0\n    tol = maxv * 0.01  # consider near-zero as <1% of max\n    count_zero_like = float(np.count_nonzero(np.abs(arr) <= tol))\n    result = count_zero_like / float(arr.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of positive-slope diagonal strokes vs negative-slope diagonals (range approximately [-1,1])'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = gray.min(), gray.max()\n    if mx - mn < 1e-8:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    bw = (norm > 0.5).astype(float)\n    h, w = bw.shape\n    # compute max summed intensity along diagonals (positive slope = diag of fliplr)\n    pos_sums = []\n    neg_sums = []\n    for k in range(-w + 1, h):\n        neg_diag = np.diagonal(bw, offset=k)\n        pos_diag = np.diagonal(np.fliplr(bw), offset=k)\n        neg_sums.append(float(np.sum(np.abs(neg_diag))))\n        pos_sums.append(float(np.sum(np.abs(pos_diag))))\n    max_neg = max(neg_sums) if neg_sums else 0.0\n    max_pos = max(pos_sums) if pos_sums else 0.0\n    eps = 1e-8\n    return float((max_pos - max_neg) / (max_pos + max_neg + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by image dynamic range (texture measure)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # compute discrete Laplacian with padding to avoid wrap\n    pad_val = 0.0\n    p = np.pad(a, pad_width=1, mode='edge').astype(float)\n    center = p[1:-1, 1:-1]\n    up = p[0:-2, 1:-1]\n    down = p[2:, 1:-1]\n    left = p[1:-1, 0:-2]\n    right = p[1:-1, 2:]\n    lap = (up + down + left + right - 4.0 * center)\n    mean_abs = float(np.mean(np.abs(lap)))\n    dynamic = float(a.max() - a.min()) + eps\n    result = mean_abs / dynamic\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry: correlation between top and mirrored bottom halves (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 2:\n        return 1.0\n    half = h // 2\n    top = arr[:half, :]\n    if h % 2 == 0:\n        bottom = arr[half:, :]\n    else:\n        bottom = arr[half+1:, :]\n    # make same shape\n    minh = min(top.shape[0], bottom.shape[0])\n    top = top[:minh, :].ravel()\n    bottom = bottom[:minh, :][::-1, :].ravel()\n    if top.size == 0:\n        return 1.0\n    ta = top - top.mean()\n    ba = bottom - bottom.mean()\n    num = np.sum(ta * ba)\n    den = np.sqrt((ta*ta).sum() * (ba*ba).sum()) + eps\n    corr = float(num / den)\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of bright local maxima (3x3 neighborhood), higher => more spots'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    center = a\n    # neighbors via rolls (wrap-around, fast)\n    n1 = np.roll(center, 1, axis=0)\n    n2 = np.roll(center, -1, axis=0)\n    n3 = np.roll(center, 1, axis=1)\n    n4 = np.roll(center, -1, axis=1)\n    n5 = np.roll(n1, 1, axis=1)\n    n6 = np.roll(n1, -1, axis=1)\n    n7 = np.roll(n2, 1, axis=1)\n    n8 = np.roll(n2, -1, axis=1)\n    greater = (center > n1) & (center > n2) & (center > n3) & (center > n4) & (center > n5) & (center > n6) & (center > n7) & (center > n8)\n    thresh = float(center.mean() + center.std())\n    peaks = greater & (center > thresh)\n    count = float(np.count_nonzero(peaks))\n    result = count / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized horizontal position of the rightmost ink pixel (0.0 left .. 1.0 right)'\n    import numpy as np\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    bin_img = (gray < thr).astype(np.uint8)\n    # If more than half are foreground, invert to make ink the minority\n    if bin_img.sum() > (h * w) / 2:\n        bin_img = 1 - bin_img\n    ys, xs = np.where(bin_img)\n    if xs.size == 0:\n        return 0.0\n    rightmost = float(xs.max()) / float(max(w - 1, 1))\n    return float(rightmost)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center block mean minus corner means divided by global std (contrast, can be negative)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ch = max(1, h // 3)\n    cw = max(1, w // 3)\n    r0 = h // 2 - ch // 2\n    c0 = w // 2 - cw // 2\n    center = a[r0:r0 + ch, c0:c0 + cw]\n    qh = ch\n    qw = cw\n    corners = []\n    corners.append(a[0:qh, 0:qw])\n    corners.append(a[0:qh, -qw:])\n    corners.append(a[-qh:, 0:qw])\n    corners.append(a[-qh:, -qw:])\n    center_mean = float(center.mean()) if center.size else 0.0\n    corner_means = [float(x.mean()) if x.size else 0.0 for x in corners]\n    corner_mean = float(np.mean(corner_means)) if len(corner_means) else 0.0\n    gstd = float(a.std()) + eps\n    result = (center_mean - corner_mean) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy based on 32-bin histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    bins = 32\n    hist, _ = np.histogram(a, bins=bins)\n    total = hist.sum()\n    if total == 0:\n        return 0.0\n    p = hist.astype(float) / float(total)\n    ent = -np.sum(np.where(p > 0, p * np.log2(p + eps), 0.0))\n    max_ent = np.log2(bins) + eps\n    result = ent / max_ent\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute diagonal-projected edge strength in the upper-right quadrant (captures diagonal strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mx = gray.max() if gray.max() != 0 else 1.0\n    gray = gray / mx\n    gy, gx = np.gradient(gray)\n    h, w = gray.shape[:2]\n    r_end = max(1, h//3)\n    c0 = w//2\n    gx_sub = gx[:r_end, c0:]\n    gy_sub = gy[:r_end, c0:]\n    if gx_sub.size == 0:\n        return 0.0\n    # project gradient onto the diagonal direction (1,-1)/sqrt(2) to detect strokes slanted down-right\n    proj = (gx_sub - gy_sub) / np.sqrt(2)\n    return float(np.mean(np.abs(proj)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average nearest-neighbor distance among top-brightness pixels normalized by image diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # select top 5% brightest pixels\n    flat = a.ravel()\n    k = max(1, int(0.05 * flat.size))\n    if flat.size <= k:\n        thresh = flat.min() - 1.0\n    else:\n        # partition to get threshold efficiently\n        idx = np.argpartition(flat, -k)[-k:]\n        thresh = flat[idx].min()\n    ys, xs = np.where(a >= thresh)\n    n = ys.size\n    if n <= 1:\n        return 0.0\n    # sample if too many\n    max_pts = 300\n    if n > max_pts:\n        sel = np.random.choice(n, size=max_pts, replace=False)\n        ys = ys[sel]; xs = xs[sel]; n = max_pts\n    pts = np.stack([ys.astype(float), xs.astype(float)], axis=1)\n    # compute nearest neighbor distances\n    diffs = pts[:, None, :] - pts[None, :, :]  # n x n x 2\n    d2 = np.sum(diffs * diffs, axis=2)\n    np.fill_diagonal(d2, np.inf)\n    nn = np.sqrt(np.min(d2, axis=1))\n    avg_nn = float(np.mean(nn))\n    diag = np.hypot(h, w) + eps\n    result = float(avg_nn / diag)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (Hasler-S\u00fcsstrunk); 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim < 3 or img.shape[2] < 3:\n        return 0.0\n    arr = np.nan_to_num(img.astype(float))\n    R = arr[..., 0]\n    G = arr[..., 1]\n    B = arr[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    return float(colorfulness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Slope of foreground point cloud (linear regression slope of y vs x), positive indicates down-right dominant strokes'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    maxv = float(np.max(gray)) if np.max(gray) != 0 else 1.0\n    gray = gray / maxv\n    p_low = np.percentile(gray, 40)\n    p_high = np.percentile(gray, 60)\n    fg = ((gray < p_low) if np.mean(gray) <= np.median(gray) else (gray > p_high)).astype(np.uint8)\n    ys, xs = np.nonzero(fg)\n    if xs.size < 2:\n        return 0.0\n    xs = xs.astype(float)\n    ys = ys.astype(float)\n    xm = xs.mean()\n    ym = ys.mean()\n    varx = np.sum((xs - xm) ** 2)\n    if varx == 0:\n        return 0.0\n    cov = np.sum((xs - xm) * (ys - ym))\n    slope = cov / varx\n    # normalize roughly by aspect ratio (height/width) to keep values comparable\n    h, w = gray.shape\n    norm = (h / (w + 1e-9))\n    return float(slope * norm)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Centroid offset of top 5% brightest pixels normalized by diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    flat = img.ravel()\n    if flat.size == 0:\n        return 0.0\n    k = max(1, int(0.05 * flat.size))\n    thr = np.partition(flat, -k)[-k]\n    mask = img >= thr\n    if not mask.any():\n        return 0.0\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    total = float(mask.sum()) + eps\n    mean_y = float((mask * ys).sum() / total)\n    mean_x = float((mask * xs).sum() / total)\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    dist = np.hypot(mean_y - cy, mean_x - cx)\n    diag = np.hypot(h, w) / 2.0 + eps\n    result = dist / diag\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Harris-like corner strength ratio: sum of positive corner response normalized by total gradient energy'\n    import numpy as np\n    eps = 1e-12\n    k = 0.04\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    A = gx * gx\n    B = gy * gy\n    C = gx * gy\n    # local sums using simple 3x3 box via convolution-like sum using slicing\n    def local_sum(X):\n        s = np.zeros_like(X)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    S_A = local_sum(A)\n    S_B = local_sum(B)\n    S_C = local_sum(C)\n    det = S_A * S_B - (S_C ** 2)\n    trace = S_A + S_B\n    R = det - k * (trace ** 2)\n    pos = R[R > 0].sum()\n    grad_energy = np.hypot(gx, gy).sum() + eps\n    result = pos / grad_energy\n    return float(max(0.0, result))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of edges located in the center region (center-edge density ratio)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    thresh = float(np.median(mag))\n    edges = mag > thresh\n    ch0 = h // 4\n    ch1 = 3 * h // 4\n    cw0 = w // 4\n    cw1 = 3 * w // 4\n    center_mask = np.zeros_like(edges, dtype=bool)\n    center_mask[ch0:ch1, cw0:cw1] = True\n    total_edges = float(edges.sum()) + eps\n    center_edges = float((edges & center_mask).sum())\n    result = center_edges / total_edges\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of transitions (background<->ink) along the central horizontal row; open shapes produce different counts than closed loops'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    center_row = h // 2\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    if border_mean > np.median(gray):\n        thr = (border_mean + float(np.min(gray))) / 2.0\n        ink_row = (gray[center_row, :] < thr).astype(int)\n    else:\n        thr = (border_mean + float(np.max(gray))) / 2.0\n        ink_row = (gray[center_row, :] > thr).astype(int)\n    if w <= 1:\n        return 0.0\n    transitions = int(np.sum(np.abs(np.diff(ink_row))))\n    # transitions is the number of boundaries; return transitions/2 as number of segments, but keep raw as float\n    return float(transitions)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute horizontal gradient to mean absolute vertical gradient (vertical strokes produce higher horizontal gradient)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    mean_abs_gx = float(np.mean(np.abs(gx)))\n    mean_abs_gy = float(np.mean(np.abs(gy)))\n    return float((mean_abs_gx + 1e-9) / (mean_abs_gy + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between mean intensity in a small central disk and an outer ring (high when a light hole is surrounded by dark ink)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image, dtype=float)\n    h, w = arr.shape[:2]\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    Y, X = np.ogrid[:h, :w]\n    dist = np.sqrt((Y - cy) ** 2 + (X - cx) ** 2)\n    r = max(1.0, min(h, w) / 8.0)\n    inner_mask = dist <= r\n    outer_mask = (dist > r) & (dist <= 2.0 * r)\n    if inner_mask.sum() == 0 or outer_mask.sum() == 0:\n        return 0.0\n    inner_mean = float(np.mean(gray[inner_mask]))\n    outer_mean = float(np.mean(gray[outer_mask]))\n    # contrast where hole is lighter than surrounding ink -> positive\n    return float((inner_mean - outer_mean) / (np.abs(outer_mean) + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal stroke energy: ratio of main-diagonal difference energy to anti-diagonal (helps detect diagonally-slanted strokes like in 4 or 7)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    L = max(1, min(h, w))\n    # sample main diagonal and anti-diagonal\n    idx = np.arange(L)\n    main_diag = gray[idx, idx]\n    anti_diag = gray[idx, w - 1 - idx]\n    e_main = np.sum(np.abs(np.diff(main_diag)))\n    e_anti = np.sum(np.abs(np.diff(anti_diag)))\n    # return normalized ratio (main over anti) with eps\n    eps = 1e-6\n    return float((e_main + eps) / (e_anti + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Absolute horizontal symmetry (0.0 asymmetric, 1.0 perfectly symmetric)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w < 2:\n        return 1.0\n    half = w // 2\n    left = arr[:, :half]\n    if w % 2 == 0:\n        right = arr[:, half:]\n    else:\n        right = arr[:, half+1:]\n    # make same shape by trimming larger side\n    minw = min(left.shape[1], right.shape[1])\n    left = left[:, :minw].ravel()\n    right = right[:, :minw][:, ::-1].ravel()  # mirror right\n    if left.size == 0:\n        return 1.0\n    la = left - left.mean()\n    ra = right - right.mean()\n    num = np.sum(la * ra)\n    den = np.sqrt((la*la).sum() * (ra*ra).sum()) + eps\n    corr = float(num / den)\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity variance: variance of mean intensities across concentric rings (10 bins)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    dist = np.hypot(ys - cy, xs - cx)\n    maxd = float(dist.max()) if dist.size else 1.0\n    if maxd <= 0:\n        return 0.0\n    nbins = 10\n    bins = np.linspace(0, maxd, nbins + 1)\n    means = []\n    for i in range(nbins):\n        mask = (dist >= bins[i]) & (dist < bins[i+1])\n        if np.any(mask):\n            means.append(np.mean(img[mask]))\n    if len(means) <= 1:\n        return 0.0\n    result = float(np.var(means) / (np.mean(means)**2 + eps))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of FFT energy in high frequencies (outer third of radial freq)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    mag = np.abs(F)\n    ys = np.arange(h)[:, None] - (h // 2)\n    xs = np.arange(w)[None, :] - (w // 2)\n    dist = np.hypot(ys, xs)\n    maxd = float(dist.max()) if dist.size else 1.0\n    mask_high = dist >= (0.66 * maxd)\n    total = float(mag.sum()) + eps\n    high = float(mag[mask_high].sum())\n    result = high / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of FFT energy in low frequencies (central quarter of radial freq)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    mag = np.abs(F)\n    ys = np.arange(h)[:, None] - (h // 2)\n    xs = np.arange(w)[None, :] - (w // 2)\n    dist = np.hypot(ys, xs)\n    maxd = float(dist.max()) if dist.size else 1.0\n    mask_center = dist <= (0.25 * maxd)\n    total = float(mag.sum()) + eps\n    center = float(mag[mask_center].sum())\n    result = center / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness (Hasler-Susstrunk) metric normalized by 100 (0..~1+ for vivid images); 0 for pure grayscale'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim < 3 or arr.shape[2] < 3:\n        return 0.0\n    img = np.nan_to_num(arr.astype(float))\n    # use first three channels as R,G,B\n    R = img[:, :, 0]\n    G = img[:, :, 1]\n    B = img[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    # normalize to a reasonable scale\n    result = colorfulness / (100.0 + 1e-12)\n    return float(max(0.0, result))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Compactness of bright region: perimeter^2 / area for pixels above mean+std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    thr = float(img.mean() + img.std())\n    mask = img > thr\n    area = float(np.count_nonzero(mask))\n    if area < 1:\n        return 0.0\n    # perimeter: count mask pixels that have at least one 4-neighbor outside mask (using rolls)\n    outside = np.zeros_like(mask, dtype=bool)\n    outside |= ~np.roll(mask, 1, axis=0)\n    outside |= ~np.roll(mask, -1, axis=0)\n    outside |= ~np.roll(mask, 1, axis=1)\n    outside |= ~np.roll(mask, -1, axis=1)\n    border = mask & outside\n    perim = float(np.count_nonzero(border))\n    result = (perim * perim) / (area + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels within 1% range of median intensity (flatness indicator)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    mn, mx = arr.min(), arr.max()\n    span = max(eps, mx - mn)\n    med = float(np.median(arr))\n    tol = 0.01 * span\n    frac = float(np.count_nonzero(np.abs(arr - med) <= tol)) / float(arr.size)\n    return float(frac)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Angle (radians) of the first principal component of ink pixel coordinates (0 = horizontal, positive = down-right slope)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    thr = (p10 + p90) / 2.0\n    mask = (gray < thr) if (p10 < p90) else (gray > thr)\n    rows, cols = np.where(mask)\n    if rows.size < 2:\n        return 0.0\n    coords = np.vstack((cols.astype(float), rows.astype(float)))\n    cov = np.cov(coords)\n    eigvals, eigvecs = np.linalg.eig(cov + 1e-12 * np.eye(2))\n    principal = eigvecs[:, np.argmax(eigvals)]\n    angle = np.arctan2(principal[1], principal[0])\n    return float(angle)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of detected ink pixels located in the right half of the image (0..1)'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    ink = gray < th\n    total = np.count_nonzero(ink)\n    if total == 0:\n        return 0.0\n    right = np.count_nonzero(ink[:, w//2:])\n    return float(right / (total + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density: fraction of pixels with gradient magnitude > mean+std (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    count = int(np.count_nonzero(mag > thr))\n    result = float(count) / (mag.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute diagonal (top-right to bottom-left) gradient energy inside the top-right quadrant'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    gray = gray.astype(float)\n    h, w = gray.shape[:2]\n    # quadrant bounds (top-right)\n    r0, r1 = 0, max(1, h // 2)\n    c0, c1 = max(0, w // 2), w\n    sub = gray[r0:r1, c0:c1]\n    if sub.size == 0:\n        return 0.0\n    gy, gx = np.gradient(sub)\n    # projection onto diagonal vector (1,-1) normalized\n    proj = (gx - gy) / np.sqrt(2.0)\n    return float(np.mean(np.abs(proj)))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Per-image color channel spread (std of channel means) normalized by mean brightness (colorfulness proxy)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # mean per channel\n    means = a.mean(axis=(0, 1))\n    spread = float(np.std(means))\n    avg = float(means.mean()) + eps\n    result = spread / avg\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Absolute horizontal offset of the largest hole centroid from image center (0..0.5 normalized)'\n    try:\n        if len(image.shape) == 3:\n            gray = image.mean(axis=2)\n        else:\n            gray = image.astype(float)\n        g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n        border = np.concatenate([g[0:1, :].ravel(), g[-1:, :].ravel(), g[:, 0:1].ravel(), g[:, -1:].ravel()])\n        border_mean = float(np.mean(border)) if border.size else 0.5\n        if border_mean > 0.5:\n            ink = g < max(0.0, border_mean - 0.15)\n        else:\n            ink = g > min(1.0, border_mean + 0.15)\n        h, w = ink.shape\n        bg = ~ink\n        ext = np.zeros_like(bg, dtype=bool)\n        stack = []\n        for i in range(h):\n            for j in (0, w-1):\n                if bg[i, j] and not ext[i, j]:\n                    stack.append((i, j)); ext[i, j] = True\n        for j in range(w):\n            for i in (0, h-1):\n                if bg[i, j] and not ext[i, j]:\n                    stack.append((i, j)); ext[i, j] = True\n        while stack:\n            y, x = stack.pop()\n            for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                ny, nx = y+dy, x+dx\n                if 0 <= ny < h and 0 <= nx < w and bg[ny, nx] and not ext[ny, nx]:\n                    ext[ny, nx] = True\n                    stack.append((ny, nx))\n        enclosed = bg & (~ext)\n        visited = np.zeros_like(enclosed, dtype=bool)\n        best_area = 0\n        best_cx = None\n        for i in range(h):\n            for j in range(w):\n                if enclosed[i, j] and not visited[i, j]:\n                    area = 0\n                    sumx = 0.0\n                    q = [(i, j)]\n                    visited[i, j] = True\n                    while q:\n                        y, x = q.pop()\n                        area += 1\n                        sumx += x\n                        for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                            ny, nx = y+dy, x+dx\n                            if 0 <= ny < h and 0 <= nx < w and enclosed[ny, nx] and not visited[ny, nx]:\n                                visited[ny, nx] = True\n                                q.append((ny, nx))\n                    if area > best_area:\n                        best_area = area\n                        best_cx = (sumx / area)\n        if best_cx is None:\n            return 0.0\n        center = (w - 1) / 2.0\n        return float(abs(best_cx - center) / max(1.0, w))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels above a simple foreground threshold (mean+std)'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    if a.size == 0:\n        return 0.0\n    thr = float(a.mean() + a.std())\n    mask = a > thr\n    result = float(np.count_nonzero(mask)) / float(a.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of edge/gradient pixels with diagonal angles between ~20 and ~70 degrees (captures diagonal stroke prevalence)'\n    import numpy as np\n    import numpy as _np\n    if image is None:\n        return 0.0\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = _np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if h < 2 or w < 2:\n        return 0.0\n    gx, gy = _np.gradient(gray)\n    mag = _np.hypot(gx, gy)\n    if _np.all(mag == 0):\n        return 0.0\n    # consider only strong gradients (>70th percentile)\n    thr = _np.percentile(mag, 70)\n    mask = mag > thr\n    if _np.count_nonzero(mask) == 0:\n        return 0.0\n    angles = _np.abs(_np.arctan2(gy[mask], gx[mask]))  # 0..pi\n    # diagonal angles roughly between 20deg (0.35) and 70deg (1.22)\n    diag_mask = (angles >= 0.35) & (angles <= 1.22)\n    return float(_np.count_nonzero(diag_mask)) / float(_np.count_nonzero(mask))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical centroid (mean row index of ink) normalized to [0,1] where 0 is top and 1 is bottom'\n    import numpy as np\n    if image is None:\n        return 0.5\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    thresh = (float(np.min(gray)) + float(np.max(gray))) / 2.0\n    ink = (gray < thresh)\n    coords = np.argwhere(ink)\n    if coords.size == 0:\n        return 0.5\n    mean_row = coords[:, 0].mean()\n    return float(mean_row / max(1.0, h - 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized imbalance between brightest and darkest quadrant means (0..inf, clipped)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    hy, wx = h // 2, w // 2\n    if hy < 1 or wx < 1:\n        return 0.0\n    q1 = arr[:hy, :wx].mean() if arr[:hy, :wx].size else 0.0\n    q2 = arr[:hy, wx:].mean() if arr[:hy, wx:].size else 0.0\n    q3 = arr[hy:, :wx].mean() if arr[hy:, :wx].size else 0.0\n    q4 = arr[hy:, wx:].mean() if arr[hy:, wx:].size else 0.0\n    means = np.array([q1, q2, q3, q4], dtype=float)\n    overall_std = float(np.std(arr)) + eps\n    imbalance = (means.max() - means.min()) / overall_std\n    result = float(max(0.0, imbalance))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute vertical gradient (detects horizontal bars) in the top 15% of image rows'\n    import numpy as _np\n    if image is None:\n        return 0.0\n    try:\n        h, w = image.shape[:2]\n        if h == 0 or w == 0:\n            return 0.0\n        if image.ndim == 3:\n            gray = _np.mean(image, axis=2).astype(_np.float64)\n        else:\n            gray = image.astype(_np.float64)\n        mn, mx = gray.min(), gray.max()\n        denom = (mx - mn) if (mx - mn) != 0 else 1.0\n        gray = (gray - mn) / denom\n        top_h = max(1, int(max(1, 0.15 * h)))\n        region = gray[:top_h, :]\n        # vertical gradient (change along rows) highlights horizontal edges\n        gy, _ = _np.gradient(region, axis=0), _np.gradient(region, axis=1)\n        mag = _np.abs(gy)\n        # normalize by global mean gradient to be robust\n        global_gy, _ = _np.gradient(gray, axis=0), _np.gradient(gray, axis=1)\n        global_mean = _np.mean(_np.abs(global_gy)) + 1e-9\n        return float(_np.mean(mag) / global_mean)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Absolute top vs bottom ink imbalance (fractional difference between top and bottom halves)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.mean(gray) - 0.05 * np.std(gray)\n    mask = gray < thr\n    top = np.sum(mask[:h//2, :])\n    bottom = np.sum(mask[h//2:, :])\n    denom = max(1.0, top + bottom)\n    return float(abs(top - bottom) / denom)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Median stroke thickness estimated as median length of contiguous foreground runs in rows, normalized by image width'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    rng = float(gray.max() - gray.min())\n    if rng == 0:\n        return 0.0\n    med = float(np.median(gray)); mean = float(np.mean(gray)); delta = rng * 0.05\n    if mean < med:\n        fg = (gray < (med - delta)).astype(int)\n    else:\n        fg = (gray > (med + delta)).astype(int)\n    run_lengths = []\n    for r in range(h):\n        row = fg[r, :]\n        if row.sum() == 0:\n            continue\n        # find contiguous runs\n        diff = np.diff(np.concatenate(([0], row, [0])))\n        starts = np.where(diff == 1)[0]\n        ends = np.where(diff == -1)[0]\n        lengths = (ends - starts).astype(float)\n        if lengths.size > 0:\n            run_lengths.extend(lengths.tolist())\n    if len(run_lengths) == 0:\n        return 0.0\n    median_len = float(np.median(np.array(run_lengths)))\n    return float(median_len / max(1.0, w))\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio: fraction of FFT magnitude in outer half of radial frequencies'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    # compute centered FFT magnitude\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    mag = np.abs(F)\n    ys = np.arange(h)[:, None] - (h // 2)\n    xs = np.arange(w)[None, :] - (w // 2)\n    dist = np.hypot(ys, xs)\n    maxd = float(dist.max()) if dist.size else 1.0\n    if maxd <= 0:\n        return 0.0\n    # outer half frequencies\n    mask_outer = dist >= (0.5 * maxd)\n    total = float(mag.sum()) + 1e-12\n    outer = float(mag[mask_outer].sum())\n    result = outer / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global contrast via (P95 - P5) normalized by (|P95|+|P5|) to be robust to sign'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        flat = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(img.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    p95 = float(np.percentile(flat, 95))\n    p5 = float(np.percentile(flat, 5))\n    num = p95 - p5\n    denom = abs(p95) + abs(p5) + eps\n    result = num / denom\n    # map to [0,1] by taking absolute fraction of spread relative to magnitude sum\n    result = abs(result)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of binary edge crossings per row (texture frequency)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w < 3 or h < 1:\n        return 0.0\n    # detect strong column-wise differences\n    col_diff = np.abs(np.diff(arr, axis=1))\n    thr = float(np.std(col_diff)) * 0.5 + eps\n    edges = col_diff > thr  # shape (h, w-1)\n    # crossings per row are transitions in this binary edge map\n    transitions = np.count_nonzero(np.diff(edges.astype(np.int8), axis=1), axis=1)  # length h\n    avg_trans = float(np.mean(transitions)) if transitions.size else 0.0\n    # normalize by possible transitions (w-2) to keep scale comparable\n    denom = max(1.0, float(max(1, w - 2)))\n    result = avg_trans / denom\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical gradient energy on right half vs left half (captures vertical strokes primarily on one side)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray)\n    right_energy = np.sum(np.abs(gy[:, w//2:]))\n    left_energy = np.sum(np.abs(gy[:, :w//2]))\n    eps = 1e-6\n    return float((right_energy + eps) / (left_energy + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute diagonal gradient magnitude inside a band around the main diagonal (measures diagonal stroke strength)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    # grayscale\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    # gradients\n    try:\n        gy, gx = np.gradient(gray.astype(float))\n    except Exception:\n        return 0.0\n    # diagonal component approximately (gx + gy) / sqrt(2)\n    diag = (gx + gy) / np.sqrt(2.0)\n    # build band mask around main diagonal\n    yy, xx = np.mgrid[0:h, 0:w]\n    # distance from main diagonal normalized\n    diag_dist = np.abs((yy / max(1.0, h - 1)) - (xx / max(1.0, w - 1)))\n    band_width = 0.12  # proportion of image; adjustable\n    mask = diag_dist <= band_width\n    vals = np.abs(diag[mask])\n    if vals.size == 0:\n        return 0.0\n    return float(vals.mean())\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant color/pixel value fraction (largest unique-value cluster) (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    # For color, quantize slightly to reduce unique counts\n    if arr.ndim == 3 and arr.shape[2] >= 3:\n        img = np.nan_to_num(arr.astype(float))\n        # reduce precision to 6 bits per channel to cluster similar colors\n        q = np.right_shift(img.astype(np.int64), 2)\n        flat = q.reshape(-1, q.shape[-1])\n        try:\n            # view rows as structured for unique\n            dtype = np.dtype(('i8', flat.shape[1]))\n            view = flat.view(dtype)\n            vals, counts = np.unique(view, return_counts=True)\n            maxc = counts.max() if counts.size else 0\n            total = flat.shape[0]\n            return float(np.clip(maxc / float(total + 1e-12), 0.0, 1.0))\n        except Exception:\n            flat1 = flat.reshape(-1, flat.shape[-1])\n            total = flat1.shape[0]\n            return float(1.0 if total > 0 and np.all(flat1[0] == flat1).all() else 0.0)\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n        if a.size == 0:\n            return 0.0\n        # quantize to 64 levels\n        mn, mx = a.min(), a.max()\n        if mx == mn:\n            return 1.0\n        bins = np.linspace(mn, mx, num=65)\n        inds = np.digitize(a, bins)\n        vals, counts = np.unique(inds, return_counts=True)\n        maxc = counts.max() if counts.size else 0\n        total = a.size\n        return float(np.clip(maxc / float(total + 1e-12), 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Average local contrast: mean of patch stds normalized by global std'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # choose patch size around 8x8 relative to image\n    ph = max(1, min(8, h))\n    pw = max(1, min(8, w))\n    stds = []\n    for i in range(0, h, ph):\n        for j in range(0, w, pw):\n            patch = a[i:min(i+ph, h), j:min(j+pw, w)]\n            if patch.size:\n                stds.append(patch.std())\n    if len(stds) == 0:\n        return 0.0\n    local_mean_std = float(np.mean(stds))\n    global_std = float(a.std()) + 1e-12\n    result = local_mean_std / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean horizontal edge (absolute y-gradient) strength in the bottom third normalized by total gradient energy (detects strong bottom bars vs top bars)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h < 3:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gy, gx = np.gradient(gray)\n    mag = np.abs(gy)\n    bottom = mag[max(0, 2*h//3):, :]\n    bottom_energy = float(np.mean(bottom)) if bottom.size else 0.0\n    total_energy = float(np.mean(np.sqrt(gx*gx + gy*gy))) + 1e-12\n    return float(bottom_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Elongation of bright region based on weighted covariance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    thr = float(np.median(flat))\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    weights = a[mask] - thr\n    weights = np.maximum(weights, 0.0)\n    if weights.sum() <= 0:\n        weights = np.ones_like(weights)\n    wsum = float(weights.sum()) + eps\n    cx = float((xs * weights).sum()) / wsum\n    cy = float((ys * weights).sum()) / wsum\n    dx = xs - cx\n    dy = ys - cy\n    Sxx = float((weights * (dx * dx)).sum()) / wsum + eps\n    Syy = float((weights * (dy * dy)).sum()) / wsum + eps\n    Sxy = float((weights * (dx * dy)).sum()) / wsum\n    trace = Sxx + Syy\n    det = Sxx * Syy - Sxy * Sxy\n    # eigenvalues of 2x2 covariance\n    temp = np.sqrt(max(trace * trace / 4.0 - det, 0.0))\n    lam1 = trace / 2.0 + temp\n    lam2 = trace / 2.0 - temp\n    if lam1 <= 0:\n        result = 0.0\n    else:\n        result = float(np.clip(1.0 - (lam2 / (lam1 + eps)), 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient strength to orthogonal gradient strength (diagonal prominence indicates slanted strokes like 4)'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        # compute gradients\n        gy, gx = np.gradient(gray.astype(float))\n        abs_gx = np.abs(gx)\n        abs_gy = np.abs(gy)\n        diag1 = (gx + gy) / np.sqrt(2.0)\n        diag2 = (gx - gy) / np.sqrt(2.0)\n        mean_diag = (np.abs(diag1).mean() + np.abs(diag2).mean()) / 2.0\n        mean_hv = (abs_gx.mean() + abs_gy.mean()) / 2.0\n        return float(mean_diag / (mean_hv + 1e-12))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of strict local maxima (pixels greater than 8 neighbors)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 3 or w < 3:\n        return 0.0\n    C = img[1:-1, 1:-1]\n    up = img[:-2, 1:-1]\n    down = img[2:, 1:-1]\n    left = img[1:-1, :-2]\n    right = img[1:-1, 2:]\n    ul = img[:-2, :-2]\n    ur = img[:-2, 2:]\n    dl = img[2:, :-2]\n    dr = img[2:, 2:]\n    mask = (C > up) & (C > down) & (C > left) & (C > right) & (C > ul) & (C > ur) & (C > dl) & (C > dr)\n    count = float(np.count_nonzero(mask))\n    result = count / float(h * w)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal symmetry: normalized correlation between left and right halves (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:] if mid > 0 else np.empty((h, 0))\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # flip right to compare mirror\n    right_flipped = right[:, ::-1]\n    # crop to identical shape if needed\n    mh = min(left.shape[0], right_flipped.shape[0])\n    mw = min(left.shape[1], right_flipped.shape[1])\n    L = left[:mh, :mw].ravel()\n    R = right_flipped[:mh, :mw].ravel()\n    if L.size == 0:\n        return 0.0\n    Lc = L - L.mean()\n    Rc = R - R.mean()\n    denom = (np.sqrt((Lc ** 2).sum() * (Rc ** 2).sum()) + eps)\n    corr = float((Lc * Rc).sum() / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of horizontal ink runs per row (transitions 0->1) normalized by image width'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    mid = (p10 + p90) / 2.0\n    mask_hi = gray > mid\n    mask_lo = gray < mid\n    ink = (mask_hi if np.count_nonzero(mask_hi) < np.count_nonzero(mask_lo) else mask_lo).astype(np.uint8)\n    if w == 0:\n        return 0.0\n    # count 0->1 transitions across each row\n    padded = np.pad(ink, ((0, 0), (1, 0)), mode='constant', constant_values=0)\n    transitions = (padded[:, 1:] > padded[:, :-1]) & (padded[:, 1:] == 1)\n    runs_per_row = np.sum(transitions, axis=1)\n    mean_runs = np.mean(runs_per_row) if runs_per_row.size else 0.0\n    return float(mean_runs / max(1.0, w))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right mirror symmetry: 1 - normalized mean absolute difference between image and its horizontal flip (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 1.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 1.0\n    flip = np.fliplr(a)\n    diff = np.abs(a - flip)\n    mean_diff = float(np.mean(diff))\n    mean_val = float(np.mean(np.abs(a))) + eps\n    score = 1.0 - (mean_diff / mean_val)\n    return float(np.clip(score, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of peaks in the intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    vmin = float(a.min()); vmax = float(a.max())\n    if vmax <= vmin + eps:\n        return 0.0\n    bins = 32\n    hist, _ = np.histogram(a.ravel(), bins=bins, range=(vmin, vmax))\n    if hist.sum() == 0:\n        return 0.0\n    # simple smoothing\n    s = np.convolve(hist.astype(float), np.array([1.0, 1.0, 1.0]) / 3.0, mode='same')\n    peaks = 0\n    mean_s = s.mean()\n    for i in range(1, len(s) - 1):\n        if s[i] > s[i - 1] and s[i] > s[i + 1] and s[i] > mean_s:\n            peaks += 1\n    result = float(peaks) / float(bins)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy fraction from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    # subtract mean\n    a = a - float(a.mean())\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute magnitude spectrum\n    F = np.fft.fftshift(np.fft.fft2(a))\n    mag = np.abs(F)\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = float(r.max()) + eps\n    cutoff = 0.25 * maxr\n    high = mag[r > cutoff].sum()\n    total = mag.sum() + eps\n    result = float(high) / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of the rightmost ink column index per row (normalized by width) - boundary variation of right side'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    meanv = gray.mean()\n    stdv = gray.std() if gray.std() > 1e-9 else 1.0\n    fg = (np.abs(gray - meanv) > 0.5 * stdv)\n    rightmost = []\n    for r in range(h):\n        cols = np.nonzero(fg[r, :])[0]\n        if cols.size:\n            rightmost.append(float(cols.max()))\n    if len(rightmost) < 2:\n        return 0.0\n    s = float(np.std(np.array(rightmost)))\n    return float(s / float(max(1.0, w)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of radial variance of ink pixels in the lower half to the upper half with respect to the ink centroid'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mx = float(np.max(gray)) if np.max(gray) != 0 else 1.0\n    gray = gray / mx\n    thresh = np.mean(gray)\n    ink_mask = (gray < thresh).astype(np.uint8)\n    coords = np.argwhere(ink_mask)\n    if coords.shape[0] == 0:\n        return 0.0\n    ys = coords[:, 0].astype(float)\n    xs = coords[:, 1].astype(float)\n    centroid_y = ys.mean()\n    centroid_x = xs.mean()\n    # distances for lower and upper ink pixels\n    lower_idx = ys >= centroid_y\n    upper_idx = ys < centroid_y\n    if lower_idx.sum() == 0 or upper_idx.sum() == 0:\n        return 0.0\n    lower_d2 = ((ys[lower_idx] - centroid_y) ** 2 + (xs[lower_idx] - centroid_x) ** 2)\n    upper_d2 = ((ys[upper_idx] - centroid_y) ** 2 + (xs[upper_idx] - centroid_x) ** 2)\n    lower_var = lower_d2.var() if lower_d2.size > 1 else 0.0\n    upper_var = upper_d2.var() if upper_d2.size > 1 else 0.0\n    return float(lower_var / (upper_var + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of center-region pixels that are significantly brighter than image median'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    ch, cw = max(1, h // 4), max(1, w // 4)\n    center = arr[ch:3*ch, cw:3*cw]\n    if center.size == 0:\n        return 0.0\n    med = float(np.median(arr))\n    std = float(np.std(arr))\n    thr = med + 0.5 * std\n    frac = float(np.count_nonzero(center > thr)) / float(center.size)\n    return float(frac)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean normalized distance of top 0.5% brightest pixels to image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    pct = 0.005\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        vals = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        vals = np.nan_to_num(img.astype(float))\n    h, w = vals.shape\n    if vals.size == 0:\n        return 0.0\n    flat = vals.ravel()\n    n = flat.size\n    k = max(1, int(np.ceil(pct * n)))\n    idx = np.argpartition(flat, -k)[-k:]\n    ys, xs = np.unravel_index(idx, (h, w))\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dists = np.hypot(ys - center_y, xs - center_x)\n    mean_dist = float(dists.mean()) if dists.size else 0.0\n    half_diag = np.hypot(h, w) / 2.0 + eps\n    result = mean_dist / half_diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Annular contrast: normalized difference between center and surrounding ring'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    maxr = min(cx, cy)\n    if maxr <= 0:\n        return 0.0\n    r1 = maxr * 0.1\n    r2 = maxr * 0.3\n    center_mask = r <= r1\n    ring_mask = (r > r1) & (r <= r2)\n    if not np.any(center_mask) or not np.any(ring_mask):\n        return 0.0\n    center_mean = float(np.mean(a[center_mask]))\n    ring_mean = float(np.mean(a[ring_mask]))\n    denom = (abs(center_mean) + abs(ring_mean) + eps)\n    result = abs(center_mean - ring_mean) / denom\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong gradient pixels whose orientation lies between -70 and -20 degrees (targeting downward-left diagonals common in 7)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    mag = np.hypot(gx, gy)\n    maxmag = float(np.max(mag)) + 1e-12\n    # consider only reasonably strong gradients\n    strong = mag > (0.2 * maxmag)\n    # angle: arctan2(y, x), but we want negative gy to be \"down\" consistent with image coords\n    angles = np.arctan2(-gy, gx) * (180.0 / np.pi)  # degrees\n    mask = strong & (angles >= -70.0) & (angles <= -20.0)\n    denom = float(np.count_nonzero(strong)) + 1e-12\n    return float(np.count_nonzero(mask) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top-left vs top-right ink fraction in the top quarter: top_right / (top_left + top_right) (higher => top-right heavy)'\n    import numpy as np\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    mn, mx = float(gray.min()), float(gray.max())\n    if mx == mn:\n        return 0.0\n    mid = 0.5 * (mn + mx)\n    if np.mean(gray) < mid:\n        ink = (gray < mid).astype(np.uint8)\n    else:\n        ink = (gray > mid).astype(np.uint8)\n    top_h = max(1, h // 4)\n    left_w = w // 2\n    tl = float(ink[:top_h, :left_w].sum())\n    tr = float(ink[:top_h, left_w:].sum())\n    tot = tl + tr\n    if tot < 1e-6:\n        return 0.0\n    return float(tr / tot)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean per-pixel color saturation (0..1), 0 for grayscale; measures channel spread'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    mx = np.max(a, axis=2)\n    mn = np.min(a, axis=2)\n    sat = (mx - mn) / (mx + eps)\n    result = float(np.mean(sat))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Central symmetry: similarity to 180-degree rotated image (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    a_rot = np.rot90(a, 2)\n    diff_mean = float(np.mean(np.abs(a - a_rot)))\n    norm = float(np.mean(np.abs(a))) + eps\n    sim = 1.0 - (diff_mean / norm)\n    return float(np.clip(sim, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Row-wise centroid variation (std of column centroid across rows) normalized by image width (higher for curved digits like 6 or 0)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.count_nonzero(ink) > 0.6 * h * w:\n        ink = ~ink\n    centroids = []\n    for r in range(h):\n        row = ink[r, :]\n        if np.any(row):\n            cols = np.nonzero(row)[0]\n            centroids.append(float(np.mean(cols)))\n    if len(centroids) < 2:\n        return 0.0\n    std_centroid = float(np.std(centroids))\n    return float(std_centroid / max(1.0, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial symmetry similarity: how similar the image is to its flips/180-rotation (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    if arr.size == 0:\n        return 0.0\n    rng = float(arr.max() - arr.min()) + 1e-12\n    def sim(a, b):\n        return 1.0 - (np.mean(np.abs(a - b)) / rng)\n    try:\n        sim_h = sim(arr, np.flipud(arr))\n        sim_v = sim(arr, np.fliplr(arr))\n        sim_rot = sim(arr, np.rot90(arr, 2))\n    except Exception:\n        return 0.0\n    result = max(sim_h, sim_v, sim_rot)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (0 for grayscale, higher => more colorful)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    return float(np.clip(colorfulness, 0.0, 1e6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Std of mean intensities across 4 concentric rings normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = r.max() + eps\n    bins = 4\n    ring_ids = np.floor((r / maxr) * bins).astype(int)\n    ring_ids = np.clip(ring_ids, 0, bins - 1)\n    means = []\n    for k in range(bins):\n        sel = (ring_ids == k)\n        if sel.any():\n            means.append(float(a[sel].mean()))\n    if len(means) <= 1:\n        return 0.0\n    global_std = float(a.std()) + eps\n    result = float(np.std(np.array(means))) / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Circular variance of gradient orientations weighted by magnitude (0..1, 0 = strongly aligned)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    total = float(mag.sum()) + eps\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    c = float((np.cos(theta) * mag).sum()) / total\n    s = float((np.sin(theta) * mag).sum()) / total\n    R = np.hypot(c, s)  # resultant length in [0,1]\n    circ_var = 1.0 - float(np.clip(R, 0.0, 1.0))\n    return float(circ_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of radial ring means normalized by overall variance (0..inf)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    if img.size == 0:\n        return 0.0\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    dist = np.hypot(ys - cy, xs - cx)\n    maxd = float(dist.max()) if dist.size else 1.0\n    if maxd <= eps:\n        return 0.0\n    nbins = min(30, max(4, int(round(maxd))))\n    bins = np.linspace(0, maxd, nbins + 1)\n    ring_means = []\n    for i in range(nbins):\n        mask = (dist >= bins[i]) & (dist < bins[i + 1])\n        if np.any(mask):\n            ring_means.append(np.mean(img[mask]))\n    if len(ring_means) <= 1:\n        return 0.0\n    rm = np.array(ring_means)\n    var_rm = float(rm.var())\n    overall_var = float(img.var()) + eps\n    result = var_rm / overall_var\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average positive Harris-like corner response normalized by image energy'\n    import numpy as np\n    eps = 1e-12\n    k = 0.04\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    Ixx = gx * gx\n    Iyy = gy * gy\n    Ixy = gx * gy\n    def local_mean(X):\n        s = np.zeros_like(X)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    Sxx = local_mean(Ixx)\n    Syy = local_mean(Iyy)\n    Sxy = local_mean(Ixy)\n    det = Sxx * Syy - Sxy * Sxy\n    trace = Sxx + Syy\n    R = det - k * (trace ** 2)\n    Rpos = R[R > 0]\n    if Rpos.size == 0:\n        return 0.0\n    norm = float(np.sum(np.abs(a))) + eps\n    result = float(np.mean(Rpos)) / (norm + eps)\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (>=1) of bounding box of very bright pixels (90th percentile); 0 if none'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    flat = arr.ravel()\n    if flat.size == 0:\n        return 0.0\n    thresh = float(np.percentile(flat, 90))\n    mask = arr > thresh\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    h, w = arr.shape\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bh = float(y1 - y0 + 1)\n    bw = float(x1 - x0 + 1)\n    if bh <= 0 or bw <= 0:\n        return 0.0\n    ar = max(bw / bh, bh / bw)\n    # clip to avoid extreme values\n    return float(min(ar, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average run-lengths per row (binary runs of foreground) normalized by width'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w == 0:\n        return 0.0\n    thr = float(np.mean(a))\n    mask = a > thr\n    # count runs per row: True where current is True and previous is False\n    prev = np.zeros_like(mask, dtype=bool)\n    prev[:, 1:] = mask[:, :-1]\n    runs_start = mask & (~prev)\n    runs_per_row = runs_start.sum(axis=1).astype(float)\n    avg_runs = float(np.mean(runs_per_row)) if runs_per_row.size else 0.0\n    result = avg_runs / float(max(1, w))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted eccentricity of content (0 = round/uniform, 1 = linear)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    weights = a - float(a.min())\n    S = float(weights.sum())\n    if S <= eps:\n        return 0.0\n    ys = np.arange(h, dtype=float)[:, None]\n    xs = np.arange(w, dtype=float)[None, :]\n    cy = float((weights * ys).sum()) / S\n    cx = float((weights * xs).sum()) / S\n    yc = (ys - cy)\n    xc = (xs - cx)\n    var_y = float((weights * (yc ** 2)).sum()) / S\n    var_x = float((weights * (xc ** 2)).sum()) / S\n    cov_xy = float((weights * xc * yc).sum()) / S\n    # covariance matrix eigenvalues\n    trace = var_x + var_y\n    det = var_x * var_y - cov_xy * cov_xy\n    # numerical stability\n    disc = max(trace * trace / 4.0 - det, 0.0)\n    sqrt_disc = np.sqrt(disc)\n    lam1 = trace / 2.0 + sqrt_disc\n    lam2 = trace / 2.0 - sqrt_disc\n    if lam1 <= eps:\n        return 0.0\n    ratio = lam2 / (lam1 + eps)\n    ecc = 1.0 - float(np.clip(ratio, 0.0, 1.0))\n    return float(np.clip(ecc, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative mid-bar strength: mean horizontal gradient magnitude in the middle third rows divided by overall horizontal gradient'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # Compute horizontal gradient (dx)\n    dy, dx = np.gradient(gray)\n    abs_dx = np.abs(dx)\n    mid_start = h // 3\n    mid_end = (2 * h) // 3\n    mid_mean = np.mean(abs_dx[mid_start:mid_end, :])\n    overall_mean = np.mean(abs_dx) + 1e-6\n    return float(mid_mean / overall_mean)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of horizontal-edge strength to vertical-edge strength (mean abs vertical gradient / mean abs horizontal gradient)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    # compute gradients\n    try:\n        gy, gx = np.gradient(gray)\n    except Exception:\n        gy = np.zeros_like(gray)\n        gx = np.zeros_like(gray)\n    h_edge = np.mean(np.abs(gy)) if gy.size else 0.0\n    v_edge = np.mean(np.abs(gx)) if gx.size else 0.0\n    return float((h_edge + 1e-9) / (v_edge + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation concentration (resultant vector length 0..1 indicates dominant orientation)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    sum_mag = float(mag.sum()) + eps\n    vx = float(gx.sum()) / sum_mag\n    vy = float(gy.sum()) / sum_mag\n    R = float(np.hypot(vx, vy))\n    return float(np.clip(R, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted spatial elongation (0=round/square, 1=highly elongated)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    weight = arr\n    total = float(weight.sum())\n    if total <= eps:\n        return 0.0\n    mean_y = float((weight * ys).sum() / (total + eps))\n    mean_x = float((weight * xs).sum() / (total + eps))\n    dy = ys - mean_y\n    dx = xs - mean_x\n    cov_yy = float((weight * (dy ** 2)).sum() / (total + eps))\n    cov_xx = float((weight * (dx ** 2)).sum() / (total + eps))\n    cov_xy = float((weight * (dx * dy)).sum() / (total + eps))\n    cov = np.array([[cov_xx, cov_xy], [cov_xy, cov_yy]])\n    try:\n        eig = np.linalg.eigvals(cov)\n    except Exception:\n        return 0.0\n    eig = np.real(eig)\n    if eig.size < 2:\n        return 0.0\n    max_e = float(np.max(eig))\n    min_e = float(np.min(eig))\n    if max_e <= eps:\n        return 0.0\n    ratio = min_e / (max_e + eps)\n    elongation = 1.0 - ratio\n    return float(np.clip(elongation, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels significantly brighter than image mean (sparse bright regions)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    mean = float(np.mean(arr))\n    std = float(np.std(arr)) + eps\n    thr = mean + 0.75 * std\n    cnt = float(np.count_nonzero(arr > thr))\n    total = float(arr.size) + eps\n    result = cnt / total\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global slant estimate: arctangent of best-fit line slope to edge pixels, normalized to [-1,1]'\n    import numpy as np\n    gray = np.mean(image, axis=2) if len(image.shape) == 3 else image.astype(np.float64)\n    h, w = gray.shape[:2]\n    med = np.percentile(gray, 50)\n    if gray.max() == gray.min():\n        return 0.0\n    low_mean = np.mean(gray[gray <= med]) if np.any(gray <= med) else med\n    high_mean = np.mean(gray[gray > med]) if np.any(gray > med) else med\n    ink = (gray <= med).astype(np.uint8) if low_mean < high_mean else (gray >= med).astype(np.uint8)\n    # find edge pixels by neighbor variance: ink pixels that have at least one non-ink neighbor\n    pad = np.pad(ink, 1, mode='constant', constant_values=0)\n    neigh_sum = (pad[0:-2,0:-2] + pad[0:-2,1:-1] + pad[0:-2,2:] +\n                 pad[1:-1,0:-2] +                 0 + pad[1:-1,2:] +\n                 pad[2:,0:-2]   + pad[2:,1:-1]   + pad[2:,2:])\n    center = pad[1:-1,1:-1]\n    edge = np.logical_and(center == 1, neigh_sum < 8)\n    ys, xs = np.nonzero(edge)\n    if xs.size < 2:\n        return 0.0\n    # fit line x = a*y + b (so slope sign corresponds to slant of strokes)\n    a, b = np.polyfit(ys.astype(np.float64), xs.astype(np.float64), 1)\n    ang = np.arctan(a)  # between -pi/2..pi/2\n    return float(ang / (np.pi / 2))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of pixels within 1% of image min or max (saturation ratio)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    mn = float(flat.min())\n    mx = float(flat.max())\n    rng = mx - mn\n    if rng <= 0:\n        return 0.0\n    thr = rng * 0.01\n    sat = ((flat <= mn + thr) | (flat >= mx - thr)).sum()\n    result = float(sat) / float(flat.size)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    hist, _ = np.histogram(a, bins=bins, range=(a.min(), a.max() if a.max() > a.min() else a.min()+1.0))\n    total = float(hist.sum()) + eps\n    p = hist.astype(float) / total\n    p_nonzero = p[p > 0.0]\n    ent = -float((p_nonzero * np.log(p_nonzero)).sum())\n    # normalize by max possible entropy = log(bins)\n    max_ent = float(np.log(bins) + eps)\n    result = ent / max_ent\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio via discrete Laplacian (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    gyy, _ = np.gradient(gy)\n    _, gxx = np.gradient(gx)\n    lap = np.abs(gxx + gyy)\n    high = float(lap.sum())\n    total = float(np.abs(a - a.mean()).sum())\n    result = high / (high + total + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientations (0..1), weighted by gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy).ravel()\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx).ravel()  # [-pi, pi]\n    nbins = 16\n    hist, _ = np.histogram(theta, bins=nbins, range=(-np.pi, np.pi), weights=mag)\n    total = float(hist.sum()) + eps\n    p = hist.astype(float) / total\n    p = p[p > 0]\n    ent = -float(np.sum(p * np.log(p + eps)))\n    max_ent = float(np.log(nbins))\n    result = ent / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative bias of ink between upper-right and upper-left quadrants: (UR - UL) / (UR + UL + eps) in upper half'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(np.float32), axis=2)\n    else:\n        gray = image.astype(np.float32)\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    thresh = np.mean(gray)\n    ink = (gray < thresh)\n    h, w = ink.shape\n    mid_r = h // 2\n    mid_c = w // 2\n    upper = ink[0:mid_r, :]\n    ul = np.count_nonzero(upper[:, 0:mid_c])\n    ur = np.count_nonzero(upper[:, mid_c:w])\n    val = (float(ur) - float(ul)) / (float(ur) + float(ul) + 1e-9)\n    return float(val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink pixels in the top third vs bottom third (top_third / (bottom_third+eps)); 5s often have heavier bottom third'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 1.0\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    if border_mean > np.median(gray):\n        thr = (border_mean + float(np.min(gray))) / 2.0\n        ink = (gray < thr).astype(int)\n    else:\n        thr = (border_mean + float(np.max(gray))) / 2.0\n        ink = (gray > thr).astype(int)\n    t = max(1, h // 3)\n    top = np.sum(ink[:t, :])\n    bottom = np.sum(ink[-t:, :])\n    return float(top) / (float(bottom) + 1e-6)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energy (around \u00b145\u00b0) to total gradient energy - detects strong diagonal strokes like in 7'\n    # Robust grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gy, gx = np.gradient(gray)\n    mag = np.hypot(gx, gy)\n    theta = np.arctan2(gy, gx)  # [-pi, pi]\n    # Mask for orientations near +45deg or -45deg (\u00b122.5\u00b0)\n    band = np.pi / 8.0\n    mask = (np.abs(theta - (np.pi/4)) <= band) | (np.abs(theta + (np.pi/4)) <= band)\n    diag_energy = np.sum(mag * mask)\n    total_energy = np.sum(mag)\n    eps = 1e-8\n    return float(diag_energy / (total_energy + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of zero pixels (sparsity) in the image [0..1]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    a = np.nan_to_num(arr)\n    if a.ndim == 3:\n        h, w = a.shape[0], a.shape[1]\n    else:\n        h, w = a.shape\n    total = float(h) * float(w) + eps\n    zeros = float((a[..., :1] if a.ndim == 3 else a) .ravel().__array__().size)  # placeholder to ensure shape handling\n    # simpler count_nonzero on per-pixel intensity: collapse channels first\n    if a.ndim == 3:\n        inten = a.mean(axis=2)\n    else:\n        inten = a\n    zeros = float((inten == 0).sum())\n    result = zeros / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized vertical centroid offset of ink: distance between ink centroid and image center (y-axis) / height'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0:\n        return 0.0\n    thr = float(np.mean(gray))\n    cand = gray < thr\n    if np.sum(cand) > gray.size / 2:\n        ink = ~cand\n    else:\n        ink = cand\n    coords = np.argwhere(ink)\n    if coords.size == 0:\n        return 0.0\n    cy = float(np.mean(coords[:, 0]))\n    center_y = (h - 1) / 2.0\n    return float(abs(cy - center_y) / max(1.0, h))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical edge strength to horizontal edge strength (vertical/horizontal)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    gx, gy = np.gradient(gray)\n    # gx = d/dy (vertical), gy = d/dx (horizontal) depending on numpy's ordering\n    vert = float(np.abs(gx).sum())\n    hor = float(np.abs(gy).sum())\n    return float(vert / (hor + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal edge dominance: sum of main-diagonal absolute diffs divided by total orthogonal edge strength'\n    import numpy as np\n    if image is None:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    a = np.abs(gray[:-1, :-1] - gray[1:, 1:]).sum()\n    b = np.abs(gray[:-1, 1:] - gray[1:, :-1]).sum()\n    diag = float(a + b)\n    hor = float(np.abs(np.diff(gray, axis=1)).sum())\n    ver = float(np.abs(np.diff(gray, axis=0)).sum())\n    return float(diag / (hor + ver + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean vertical gradient magnitude in the right third to the left third (captures right-side curvature)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h <= 1:\n        return 0.0\n    vgrad = np.abs(np.diff(gray, axis=0))\n    left = vgrad[:, : max(1, w//3)]\n    right = vgrad[:, (2*w)//3 : ] if (2*w)//3 < w else vgrad[:, -1:]\n    left_mean = float(np.mean(left)) if left.size else 0.0\n    right_mean = float(np.mean(right)) if right.size else 0.0\n    if left_mean == 0.0:\n        return float(right_mean)\n    return float(right_mean / (left_mean + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of strong edge energy aligned with diagonal orientations (~\u00b145\u00b0) compared to all strong edges'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        if h < 2 or w < 2:\n            return 0.0\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        gy, gx = np.gradient(gray)\n        mag = np.hypot(gx, gy)\n        if np.all(mag == 0):\n            return 0.0\n        # consider only relatively strong edges\n        thr = np.percentile(mag, 60)\n        strong = mag > thr\n        if not np.any(strong):\n            return 0.0\n        angle = np.abs(np.arctan2(gy, gx))  # absolute angle [0, pi]\n        # diagonal proximity to 45deg (pi/4) or 135deg (3pi/4)\n        diag_dist = np.minimum(np.abs(angle - (np.pi/4)), np.abs(angle - (3*np.pi/4)))\n        diag_mask = (diag_dist <= (np.pi/8)) & strong\n        return float(np.sum(mag[diag_mask]) / (np.sum(mag[strong]) + 1e-12))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant orientation strength from weighted coordinate covariance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    ys, xs = np.indices((h, w))\n    weights = a - a.min()\n    W = float(weights.sum())\n    if W <= 0.0:\n        return 0.0\n    mx = float((weights * xs).sum()) / W\n    my = float((weights * ys).sum()) / W\n    dx = xs - mx\n    dy = ys - my\n    cxx = float((weights * (dx * dx)).sum()) / W\n    cyy = float((weights * (dy * dy)).sum()) / W\n    cxy = float((weights * (dx * dy)).sum()) / W\n    cov = np.array([[cxx, cxy], [cxy, cyy]], dtype=float)\n    try:\n        vals = np.linalg.eigvalsh(cov)\n    except Exception:\n        return 0.0\n    vals = np.sort(vals)[::-1]  # descending\n    lam1 = float(vals[0])\n    lam2 = float(vals[1])\n    strength = (lam1 - lam2) / (lam1 + lam2 + eps)\n    result = float(np.clip(strength, 0.0, 1.0))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean horizontal edge strength in the top third of the image (detects prominent top bars like in 7 or 9)'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 0.0\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        h, w = gray.shape\n        top = gray[:max(1, h//3), :]\n        gy, gx = np.gradient(top)\n        horiz_edges = np.abs(gx)\n        return float(np.mean(horiz_edges))\n    except Exception:\n        return 0.0\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted eccentricity (elongation) of the pixel distribution in [0..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    weights = a.ravel()\n    total = weights.sum()\n    if total <= eps:\n        return 0.0\n    x = xs.ravel().astype(float)\n    y = ys.ravel().astype(float)\n    x_mean = (weights * x).sum() / (total + eps)\n    y_mean = (weights * y).sum() / (total + eps)\n    dx = x - x_mean\n    dy = y - y_mean\n    cov_xx = (weights * (dx * dx)).sum() / (total + eps)\n    cov_yy = (weights * (dy * dy)).sum() / (total + eps)\n    cov_xy = (weights * (dx * dy)).sum() / (total + eps)\n    trace = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    # eigenvalues of 2x2 covariance\n    tmp = np.sqrt(max(0.0, (trace * trace) / 4.0 - det))\n    l1 = trace / 2.0 + tmp\n    l2 = trace / 2.0 - tmp\n    denom = (l1 + l2) + eps\n    if denom <= eps:\n        return 0.0\n    ecc = (l1 - l2) / denom\n    return float(np.clip(ecc, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink intensity (binary) in the central horizontal band to total ink (higher = strong middle stroke)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = gray.mean()\n    ink = (gray < thr).astype(np.uint8)\n    a = h // 3\n    b = (2 * h) // 3\n    center_band = ink[a:b, :]\n    total_ink = float(np.count_nonzero(ink))\n    if total_ink == 0.0:\n        return 0.0\n    center_ink = float(np.count_nonzero(center_band))\n    return center_ink / total_ink\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry: normalized correlation with horizontally flipped image (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    flipped = np.fliplr(a)\n    num = float(np.sum(a * flipped))\n    denom = np.sqrt(float(np.sum(a * a)) * float(np.sum(flipped * flipped))) + 1e-12\n    corr = num / denom\n    # map from [-1,1] to [0,1]\n    result = (corr + 1.0) / 2.0\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows that contain no ink (indicates stroke breaks or disjoint strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[:3, :].ravel(), gray[-3:, :].ravel(), gray[:, :3].ravel(), gray[:, -3:].ravel()]) if h>=3 and w>=3 else gray.ravel()\n    center = gray[h//4:3*h//4, w//4:3*w//4] if h>=4 and w>=4 else gray\n    border_mean = float(border.mean()) if border.size else 0.0\n    thresh = float(np.percentile(gray, 50)) if gray.size else 0.5\n    ink = (gray < thresh) if border_mean > (center.mean() if center.size else 0.0) else (gray > thresh)\n    ink = ink.astype(np.uint8)\n    if h == 0:\n        return 0.0\n    empty_rows = np.sum(np.all(ink == 0, axis=1))\n    return float(empty_rows / (h + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum normalized contiguous horizontal ink run length within the top quarter of the image'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    top_h = max(1, h // 4)\n    region = gray[:top_h, :]\n    # binary threshold similar adaptive rule\n    t = region.mean()\n    ink_dark_fraction = (region < t).sum() / float(region.size) if region.size else 0.0\n    if ink_dark_fraction < 0.5:\n        bin_region = (region < t).astype(np.uint8)\n    else:\n        bin_region = (region > t).astype(np.uint8)\n    max_run = 0\n    # compute run lengths per row\n    for row in bin_region:\n        run = 0\n        row_max = 0\n        for val in row:\n            if val:\n                run += 1\n            else:\n                if run > row_max:\n                    row_max = run\n                run = 0\n        if run > row_max:\n            row_max = run\n        if row_max > max_run:\n            max_run = int(row_max)\n    # normalize\n    if w == 0:\n        return 0.0\n    return float(max_run) / float(w)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of intensity in the central vertical third to total intensity (captures a centered vertical stroke)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    # convert to gray\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    left = w // 3\n    right = w - left\n    center_region = gray[:, left:right]\n    total = np.sum(gray)\n    center_sum = np.sum(center_region)\n    if total == 0:\n        return 0.0\n    return float(center_sum / (total + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    # choose number of bins relative to image dynamic range but cap\n    nbins = 64\n    try:\n        hist, _ = np.histogram(a.ravel(), bins=nbins, range=(float(a.min()), float(a.max()) + eps))\n    except Exception:\n        return 0.0\n    total = float(hist.sum()) + eps\n    p = hist.astype(float) / total\n    # remove zeros\n    p = p[p > 0]\n    if p.size == 0:\n        return 0.0\n    entropy = -float((p * np.log2(p)).sum())\n    max_ent = np.log2(nbins)\n    result = float(entropy / (max_ent + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Central intensity fraction (0..1): mean intensity in central box vs whole image'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ch0 = h // 4\n    cw0 = w // 4\n    ch1 = 3 * h // 4\n    cw1 = 3 * w // 4\n    center = a[ch0:ch1, cw0:cw1]\n    if center.size == 0:\n        return 0.0\n    center_sum = float(center.sum())\n    total = float(a.sum()) + eps\n    result = center_sum / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram bimodality index: difference between two largest peaks scaled by their separation (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    bins = 16\n    try:\n        hist, edges = np.histogram(a, bins=bins, range=(a.min(), a.max()))\n    except Exception:\n        hist, edges = np.histogram(a, bins=bins)\n    if hist.sum() == 0:\n        return 0.0\n    idx = np.argsort(hist)[::-1]\n    p1_idx = int(idx[0])\n    p1 = float(hist[p1_idx])\n    p2 = float(hist[idx[1]]) if hist.size > 1 else 0.0\n    separation = abs(p1_idx - int(idx[1])) if hist.size > 1 else 0\n    sep_norm = separation / max(1, bins - 1)\n    score = (p1 - p2) / (p1 + p2 + 1e-12)\n    result = float(np.clip(score * sep_norm, 0.0, 1.0))\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box aspect-deviation of bright foreground (0=centered square..1=very elongated)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mean = float(a.mean())\n    std = float(a.std())\n    thr = mean + 0.5 * std\n    fg = a > thr\n    if not np.any(fg):\n        return 0.0\n    ys, xs = np.where(fg)\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bh = max(1, (y1 - y0 + 1))\n    bw = max(1, (x1 - x0 + 1))\n    aspect = float(bw) / float(bh)\n    # deviation metric: 0 when aspect==1, approaching 1 when very elongated\n    result = abs(aspect - 1.0) / (aspect + 1.0)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local 3x3 standard deviation normalized by global std (low = smooth texture)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute local mean and mean of squares via neighbor summation\n    s = np.zeros_like(a, dtype=float)\n    s_sq = np.zeros_like(a, dtype=float)\n    for X, S in ((a, s), (a*a, s_sq)):\n        S += X\n        S += np.roll(X, 1, axis=0)\n        S += np.roll(X, -1, axis=0)\n        S += np.roll(X, 1, axis=1)\n        S += np.roll(X, -1, axis=1)\n        S += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        S += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        S += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        S += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    local_mean_sq = s_sq / 9.0\n    local_var = np.maximum(local_mean_sq - (local_mean**2), 0.0)\n    local_std = np.sqrt(local_var)\n    mean_local_std = float(np.mean(local_std))\n    global_std = float(a.std()) + eps\n    result = mean_local_std / global_std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of bounding box of bright region (>=1.0), 0.0 if no bright region'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mu = float(arr.mean())\n    sigma = float(arr.std())\n    thresh = mu + 0.5 * sigma\n    mask = arr > thresh\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bh = float(y1 - y0 + 1)\n    bw = float(x1 - x0 + 1)\n    if bh <= 0 or bw <= 0:\n        return 0.0\n    aspect = bw / (bh + eps)\n    if aspect < 1.0:\n        aspect = 1.0 / (aspect + eps)\n    # cap to a reasonable range\n    result = float(np.clip(aspect, 1.0, 50.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with gradient magnitude above a robust threshold'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    med = float(np.median(mag))\n    std = float(mag.std())\n    thresh = med + 0.5 * std\n    frac = float(np.count_nonzero(mag > thresh)) / (mag.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal stroke orientation (absolute angle normalized to [0,1]; 0=horizontal, 1=vertical)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    if np.max(gray) > 1.5:\n        gray = gray / 255.0\n    mid = float(np.percentile(gray, 50))\n    ink = (gray < mid) if (np.mean(gray) > 0.5) else (gray > mid)\n    coords = np.argwhere(ink)\n    if coords.shape[0] < 3:\n        return 0.0\n    # center data\n    pts = coords.astype(float)\n    pts -= pts.mean(axis=0, keepdims=True)\n    # SVD to get principal direction\n    try:\n        _, s, vt = np.linalg.svd(pts, full_matrices=False)\n        vx, vy = vt[0, 1], vt[0, 0]  # vt rows are principal components; careful with axis order\n        # compute orientation of principal axis: arctan2(dy, dx) but our coords are (row, col)\n        dx = vt[0, 1]\n        dy = vt[0, 0]\n        angle = float(abs(np.arctan2(dy, dx)))  # 0..pi\n        return float(angle / np.pi)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of the foreground bounding box (width / height), 0.0 if no foreground found'\n    import numpy as np\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    gray_n = (gray - mn) / (mx - mn) if mx - mn > 1e-8 else np.zeros_like(gray)\n    thr = np.mean(gray_n)\n    fg = gray_n < thr if np.mean(gray_n) > 0.5 else gray_n > thr\n    ys, xs = np.where(fg)\n    if ys.size == 0:\n        return 0.0\n    y0, y1 = int(np.min(ys)), int(np.max(ys))\n    x0, x1 = int(np.min(xs)), int(np.max(xs))\n    bw = max(1, x1 - x0 + 1)\n    bh = max(1, y1 - y0 + 1)\n    return float(bw / bh)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of strict local maxima (8-neighbor) that exceed mean+std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(image.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(image.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    center = a\n    neighs = []\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            if dy == 0 and dx == 0:\n                continue\n            neighs.append(np.roll(np.roll(a, dy, axis=0), dx, axis=1))\n    # strict greater than all neighbors\n    greater = np.ones_like(a, dtype=bool)\n    for n in neighs:\n        greater &= (center > n)\n    thr = center.mean() + center.std()\n    peaks = np.count_nonzero(greater & (center > thr))\n    total = float(a.size) + eps\n    return float(np.clip(peaks / total, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of image that is locally smooth (low gradient magnitude)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    mean_mag = float(mag.mean())\n    if mean_mag <= 0:\n        return 1.0\n    # smooth pixels where magnitude is small relative to mean\n    mask = mag <= (0.5 * mean_mag)\n    frac = float(np.count_nonzero(mask)) / float(max(1, mag.size))\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Solidity approximation of the largest bright component (area / bounding-box-area)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    thr = arr.mean() + 0.5 * arr.std()\n    mask = arr > thr\n    if not mask.any():\n        return 0.0\n    visited = np.zeros(mask.shape, dtype=bool)\n    best_area = 0\n    best_bbox_area = 1\n    # 4-neighbor flood fill for each component\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                stack = [(y, x)]\n                visited[y, x] = True\n                ys_min = y; ys_max = y; xs_min = x; xs_max = x\n                area = 0\n                while stack:\n                    cy, cx = stack.pop()\n                    area += 1\n                    if cy < ys_min: ys_min = cy\n                    if cy > ys_max: ys_max = cy\n                    if cx < xs_min: xs_min = cx\n                    if cx > xs_max: xs_max = cx\n                    # neighbors\n                    if cy > 0 and mask[cy-1, cx] and not visited[cy-1, cx]:\n                        visited[cy-1, cx] = True; stack.append((cy-1, cx))\n                    if cy+1 < h and mask[cy+1, cx] and not visited[cy+1, cx]:\n                        visited[cy+1, cx] = True; stack.append((cy+1, cx))\n                    if cx > 0 and mask[cy, cx-1] and not visited[cy, cx-1]:\n                        visited[cy, cx-1] = True; stack.append((cy, cx-1))\n                    if cx+1 < w and mask[cy, cx+1] and not visited[cy, cx+1]:\n                        visited[cy, cx+1] = True; stack.append((cy, cx+1))\n                bbox_h = max(1, ys_max - ys_min + 1)\n                bbox_w = max(1, xs_max - xs_min + 1)\n                bbox_area = bbox_h * bbox_w\n                if area > best_area:\n                    best_area = area\n                    best_bbox_area = bbox_area\n    solidity = float(best_area) / float(best_bbox_area + eps)\n    return float(np.clip(solidity, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels belonging to the dominant intensity bin (background uniformity)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    # use 64 bins between min and max\n    mn = float(flat.min())\n    mx = float(flat.max())\n    if mx <= mn:\n        return 1.0\n    bins = 64\n    hist, edges = np.histogram(flat, bins=bins, range=(mn, mx))\n    idx = int(np.argmax(hist))\n    low = edges[idx]\n    high = edges[idx + 1]\n    count = int(np.count_nonzero((a >= low) & (a < high)))\n    frac = float(count) / float(flat.size)\n    return float(frac)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-spot prominence: (max - local mean) normalized by image std (0..10 clipped)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    mx = float(a.max())\n    coords = np.argwhere(a == mx)\n    if coords.size == 0:\n        return 0.0\n    y, x = coords[0]\n    r = max(1, min(h, w) // 20)\n    y0 = max(0, y - r)\n    y1 = min(h, y + r + 1)\n    x0 = max(0, x - r)\n    x1 = min(w, x + r + 1)\n    local = a[y0:y1, x0:x1]\n    local_mean = float(local.mean()) if local.size else 0.0\n    gstd = float(a.std()) + eps\n    prominence = (mx - local_mean) / gstd\n    result = max(0.0, prominence)\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground fraction using simple mean+std threshold (fraction of pixels above threshold)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    total = arr.size\n    if total == 0:\n        return 0.0\n    mu = float(arr.mean())\n    sd = float(arr.std())\n    thr = mu + sd\n    count = int(np.count_nonzero(arr > thr))\n    frac = float(count) / float(total)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized image entropy (0..1) computed from a 32-bin intensity histogram'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(arr.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    nbins = 32\n    vmin, vmax = float(vals.min()), float(vals.max())\n    if vmax <= vmin + eps:\n        return 0.0\n    hist, _ = np.histogram(vals, bins=nbins, range=(vmin, vmax))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0.0]\n    if p.size == 0:\n        return 0.0\n    entropy = -float((p * np.log(p + eps)).sum())\n    norm = float(np.log(nbins) + eps)\n    result = float(np.clip(entropy / norm, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows that contain at least one foreground pixel in the leftmost third (measures left vertical stroke continuity typical of \"5\")'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    # simple adaptive binarization\n    rng = gray.max() - gray.min()\n    if rng <= 0:\n        return 0.0\n    thresh = gray.min() + 0.2 * rng\n    binm = gray > thresh\n    c = max(1, w // 3)\n    left_block = binm[:, :c]\n    row_has_left = np.any(left_block, axis=1)\n    return float(np.sum(row_has_left) / h)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram entropy of image intensities (bits), normalized by log2(bins)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    # use fixed number of bins for stability\n    bins = 32\n    vmin = float(a.min())\n    vmax = float(a.max())\n    if vmax <= vmin:\n        return 0.0\n    hist, _ = np.histogram(a.ravel(), bins=bins, range=(vmin, vmax), density=True)\n    # avoid log(0)\n    hist = hist + eps\n    ent = -np.sum(hist * np.log2(hist))\n    # normalize by max entropy log2(bins)\n    result = ent / (np.log2(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of columns in the top half that have two or more separated ink runs (detects stacked lobes)'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        if h < 2 or w < 1:\n            return 0.0\n        lo, hi = float(np.min(gray)), float(np.max(gray))\n        if hi == lo:\n            return 0.0\n        th = lo + 0.5 * (hi - lo)\n        ink = (gray < th)\n        top_h = max(1, h // 2)\n        region = ink[:top_h, :]\n        cols_with_multi = 0\n        for c in range(w):\n            col = region[:, c].astype(np.uint8)\n            if col.sum() == 0:\n                continue\n            # count runs\n            diffs = np.diff(np.concatenate(([0], col, [0])))\n            runs = np.sum(diffs == 1)\n            if runs >= 2:\n                cols_with_multi += 1\n        return float(cols_with_multi) / float(w)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink mass above the main diagonal to ink mass below it (main diagonal from top-left to bottom-right)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    gray = np.mean(image, axis=2) if len(image.shape) == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    ink = (gray < thresh).astype(np.float32)\n    # Compute normalized coordinates and compare c_norm > r_norm -> above diagonal (toward upper-right)\n    rows = np.arange(h).reshape(h, 1).astype(np.float32) / (h - 1 if h > 1 else 1)\n    cols = np.arange(w).reshape(1, w).astype(np.float32) / (w - 1 if w > 1 else 1)\n    mask_above = cols > rows\n    mass_above = np.sum(ink[mask_above])\n    mass_below = np.sum(ink[~mask_above])\n    return float(mass_above / (mass_below + 1e-6))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels much brighter than average (above mean + 1*std)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thresh = m + s\n    count = float((a > thresh).sum())\n    result = count / (float(a.size) + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry (1=perfect symmetry, 0=none)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    rot = np.rot90(a, 2)\n    diff = np.abs(a - rot)\n    denom = float(a.max() - a.min()) + eps\n    norm_diff = float(diff.mean()) / denom\n    result = 1.0 - np.clip(norm_diff, 0.0, 1.0)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal bias: (sum along / diagonal - sum anti-diagonal) normalized by total, captures slanted strokes'\n    eps = 1e-9\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn < eps:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    ink = (norm < 0.5).astype(float)\n    # project coordinates onto diagonal vectors\n    ys, xs = np.nonzero(ink)\n    if xs.size == 0:\n        return 0.0\n    proj_diag = xs + ys  # projection onto (1,1)\n    proj_antidiag = xs - ys  # projection onto (1,-1)\n    # compute weighted sums\n    sd = float(np.sum(proj_diag))\n    sa = float(np.sum(np.abs(proj_antidiag)))\n    total = float(np.sum(ink))\n    return float((sd - sa) / (total + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in lower-right half to ink in lower-left half (captures right-leaning bottoms vs left loops)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    maxv = float(np.max(gray)) if np.max(gray) != 0 else 1.0\n    gray = gray / maxv\n    p_low = np.percentile(gray, 40)\n    p_high = np.percentile(gray, 60)\n    fg = (gray < p_low) if np.mean(gray) <= np.median(gray) else (gray > p_high)\n    h, w = gray.shape\n    lower = slice(h // 2, h)\n    left = slice(0, w // 2)\n    right = slice(w // 2, w)\n    ink_lr = np.count_nonzero(fg[lower, right])\n    ink_ll = np.count_nonzero(fg[lower, left])\n    eps = 1e-6\n    return float((ink_lr + eps) / (ink_ll + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between upper-right and upper-left ink mass: (UR-UL)/(UR+UL+eps)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(np.float32), axis=2)\n    else:\n        gray = image.astype(np.float32)\n    if gray.size == 0:\n        return 0.0\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    thr = np.mean(gray) - 0.25 * (np.std(gray) + 1e-9)\n    ink = (gray < thr).astype(np.float32)\n    h, w = ink.shape\n    mid_h = max(1, h // 2)\n    mid_w = max(1, w // 2)\n    upper = ink[:mid_h, :]\n    UL = np.sum(upper[:, :mid_w])\n    UR = np.sum(upper[:, mid_w:])\n    eps = 1e-9\n    return float((UR - UL) / (UR + UL + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast of brightest 5% pixels vs rest normalized by image std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    arr = a.ravel()\n    if arr.size == 0:\n        return 0.0\n    p95 = float(np.percentile(arr, 95))\n    top = arr[arr >= p95]\n    rest = arr[arr < p95]\n    if top.size == 0:\n        return 0.0\n    top_mean = float(top.mean())\n    rest_mean = float(rest.mean()) if rest.size else float(top_mean)\n    overall_std = float(arr.std()) + eps\n    result = (top_mean - rest_mean) / overall_std\n    if result < 0.0:\n        result = 0.0\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimate of number of holes (background components inside bounding box) using 4-connectivity; returns integer as float'\n    import numpy as np\n    from collections import deque\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    gray_n = (gray - mn) / (mx - mn) if mx - mn > 1e-8 else np.zeros_like(gray)\n    thr = np.mean(gray_n)\n    fg = (gray_n < thr) if np.mean(gray_n) > 0.5 else (gray_n > thr)\n    ys, xs = np.where(fg)\n    if ys.size == 0:\n        return 0.0\n    y0, y1 = int(np.min(ys)), int(np.max(ys))\n    x0, x1 = int(np.min(xs)), int(np.max(xs))\n    sub = fg[y0:y1+1, x0:x1+1]\n    # background mask inside bounding box\n    bg = (~sub).astype(np.uint8)\n    H, W = bg.shape\n    visited = np.zeros_like(bg, dtype=bool)\n    holes = 0\n    for i in range(H):\n        for j in range(W):\n            if bg[i, j] == 1 and not visited[i, j]:\n                # BFS\n                q = deque([(i, j)])\n                visited[i, j] = True\n                touches_border = False\n                while q:\n                    y, x = q.popleft()\n                    if y == 0 or x == 0 or y == H-1 or x == W-1:\n                        touches_border = True\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ny, nx = y+dy, x+dx\n                        if 0 <= ny < H and 0 <= nx < W and not visited[ny, nx] and bg[ny, nx] == 1:\n                            visited[ny, nx] = True\n                            q.append((ny, nx))\n                if not touches_border:\n                    holes += 1\n    return float(holes)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global gradient orientation coherence: normalized magnitude of vector sum of gradients (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    sum_gx = float(gx.sum())\n    sum_gy = float(gy.sum())\n    denom = float(mag.sum()) + eps\n    coherence = np.hypot(sum_gx, sum_gy) / denom\n    return float(np.clip(coherence, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink located in the bottom-right quadrant (captures right-side tails like in 9)'\n    import numpy as np\n    if len(image.shape) == 3:\n        g = image.mean(axis=2).astype(np.float32)\n    else:\n        g = image.astype(np.float32)\n    mx = g.max() if g.size else 1.0\n    if mx > 1.0:\n        g = g / mx\n    med = np.median(g) if g.size else 0.0\n    ink = (g < 0.5) if med > 0.5 else (g > 0.5)\n    h, w = g.shape\n    br = np.zeros_like(ink)\n    br[h//2:, w//2:] = True\n    total = np.count_nonzero(ink)\n    if total == 0:\n        return 0.0\n    br_count = np.count_nonzero(ink & br)\n    return float(br_count / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between brightest and darkest corner means normalized by image std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    patch = max(1, min(h, w) // 8)\n    corners = []\n    corners.append(arr[0:patch, 0:patch])\n    corners.append(arr[0:patch, w-patch:w])\n    corners.append(arr[h-patch:h, 0:patch])\n    corners.append(arr[h-patch:h, w-patch:w])\n    means = [float(np.mean(c)) if c.size else 0.0 for c in corners]\n    if not means:\n        return 0.0\n    diff = float(max(means) - min(means))\n    std = float(np.std(arr)) + eps\n    result = diff / std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized gap between 90th and 50th percentiles of intensities'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        flat = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(arr.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    p50 = float(np.percentile(flat, 50.0))\n    p90 = float(np.percentile(flat, 90.0))\n    rng = float(flat.max() - flat.min()) + eps\n    result = (p90 - p50) / rng\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance of intensity-weighted centroid of bright region from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # pick bright pixels relative to median\n    med = float(np.median(a))\n    std = float(a.std()) + eps\n    mask = a > (med + 0.25 * std)\n    if np.count_nonzero(mask) == 0:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    weights = a[ys, xs].astype(float)\n    if weights.sum() <= 0:\n        return 0.0\n    cx = float((xs * weights).sum()) / float(weights.sum())\n    cy = float((ys * weights).sum()) / float(weights.sum())\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    maxd = np.hypot(center_x, center_y) + eps\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian variance as a simple focus/sharpness measure (higher => more texture)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # discrete Laplacian via 4-neighbor stencil using rolls\n    lap = 4.0 * a - (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) + np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1))\n    # ignore wrap artifacts by zeroing borders\n    lap[0, :] = 0.0\n    lap[-1, :] = 0.0\n    lap[:, 0] = 0.0\n    lap[:, -1] = 0.0\n    var = float(np.var(lap))\n    # normalize by overall intensity scale\n    norm = float(np.mean(np.abs(a))) + eps\n    result = var / norm\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient direction as a normalized angle in [-1..1] (signed)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    s = float(mag.sum())\n    if s <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    mean_sin = float((mag * np.sin(theta)).sum()) / s\n    mean_cos = float((mag * np.cos(theta)).sum()) / s\n    angle = np.arctan2(mean_sin, mean_cos)  # -pi..pi\n    # normalize to [-1,1]\n    return float(angle / np.pi)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of local intensity maxima normalized by image area (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    padval = float(a.min() - 1.0)\n    p = np.pad(a, pad_width=1, mode='constant', constant_values=padval)\n    center = p[1:-1, 1:-1]\n    neighbors = [\n        p[0:-2, 0:-2], p[0:-2, 1:-1], p[0:-2, 2:],\n        p[1:-1, 0:-2],               p[1:-1, 2:],\n        p[2:,   0:-2], p[2:,   1:-1], p[2:,   2:]\n    ]\n    is_max = np.ones_like(center, dtype=bool)\n    for n in neighbors:\n        is_max &= (center > n)\n    # suppress tiny noise: require peak above mean + 0.5*std\n    thr = float(a.mean() + 0.5 * a.std())\n    is_max &= (center > thr)\n    count = int(is_max.sum())\n    result = float(count) / float(max(1, a.size))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized dynamic range contrast: (max - min) / (std + eps)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.ravel(np.nan_to_num(img.mean(axis=2).astype(float)))\n    else:\n        arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    rng = float(arr.max() - arr.min())\n    s = float(arr.std())\n    result = rng / (s + eps)\n    # keep value bounded to avoid extreme outliers\n    return float(np.clip(result, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of intensity histogram (bits)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    mn = float(a.min())\n    mx = float(a.max())\n    if mx <= mn:\n        return 0.0\n    # use 256 bins or fewer if tiny array\n    bins = 256 if a.size >= 256 else max(2, a.size)\n    hist, _ = np.histogram(a, bins=bins, range=(mn, mx))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -float((p_nonzero * np.log2(p_nonzero)).sum())\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of a top horizontal stroke: proportion of ink in the top 20% rows'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    thr = 0.5 * (mn + mx)\n    foreground_is_dark = float(np.mean(gray)) < thr\n    if foreground_is_dark:\n        ink = gray < thr\n    else:\n        ink = gray > thr\n    total = float(np.count_nonzero(ink))\n    if total == 0.0:\n        return 0.0\n    top_rows = max(1, h // 5)\n    top_count = float(np.count_nonzero(ink[:top_rows, :]))\n    return float(top_count / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-region spread: mean distance of pixels above median to their centroid normalized by image diagonal'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        vals = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        vals = np.nan_to_num(img.astype(float))\n    h, w = vals.shape\n    if vals.size == 0:\n        return 0.0\n    thr = float(np.median(vals))\n    mask = vals > thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.indices((h, w))\n    weights = vals * mask\n    total = float(weights.sum())\n    if total <= eps:\n        # fallback to unweighted centroid of mask\n        total = float(mask.sum())\n        if total <= 0:\n            return 0.0\n        cx = float((xs * mask).sum()) / total\n        cy = float((ys * mask).sum()) / total\n        dists = np.hypot(xs[mask] - cx, ys[mask] - cy)\n        mean_dist = float(dists.mean())\n    else:\n        cx = float((xs * weights).sum()) / total\n        cy = float((ys * weights).sum()) / total\n        dists = np.hypot(xs[mask] - cx, ys[mask] - cy)\n        mean_dist = float(dists.mean())\n    diag = float(np.hypot(w, h)) + eps\n    result = mean_dist / diag\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of enclosed holes (connected background regions fully surrounded by ink), returns integer as float'\n    try:\n        if len(image.shape) == 3:\n            gray = image.mean(axis=2)\n        else:\n            gray = image.astype(float)\n        g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n        border = np.concatenate([g[0:1, :].ravel(), g[-1:, :].ravel(), g[:, 0:1].ravel(), g[:, -1:].ravel()])\n        border_mean = float(np.mean(border)) if border.size else 0.5\n        if border_mean > 0.5:\n            ink = g < max(0.0, border_mean - 0.15)\n        else:\n            ink = g > min(1.0, border_mean + 0.15)\n        h, w = ink.shape\n        bg = ~ink\n        ext = np.zeros_like(bg, dtype=bool)\n        stack = []\n        # initialize from borders\n        for i in range(h):\n            for j in (0, w-1):\n                if bg[i, j] and not ext[i, j]:\n                    stack.append((i, j))\n                    ext[i, j] = True\n        for j in range(w):\n            for i in (0, h-1):\n                if bg[i, j] and not ext[i, j]:\n                    stack.append((i, j))\n                    ext[i, j] = True\n        while stack:\n            y, x = stack.pop()\n            for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                ny, nx = y+dy, x+dx\n                if 0 <= ny < h and 0 <= nx < w and bg[ny, nx] and not ext[ny, nx]:\n                    ext[ny, nx] = True\n                    stack.append((ny, nx))\n        enclosed = bg & (~ext)\n        # count enclosed connected components\n        visited = np.zeros_like(enclosed, dtype=bool)\n        holes = 0\n        for i in range(h):\n            for j in range(w):\n                if enclosed[i, j] and not visited[i, j]:\n                    holes += 1\n                    # flood fill\n                    q = [(i, j)]\n                    visited[i, j] = True\n                    while q:\n                        y, x = q.pop()\n                        for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                            ny, nx = y+dy, x+dx\n                            if 0 <= ny < h and 0 <= nx < w and enclosed[ny, nx] and not visited[ny, nx]:\n                                visited[ny, nx] = True\n                                q.append((ny, nx))\n        return float(holes)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of non-zero pixels (sparsity of content)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    # collapse channels if present\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    total = a.size\n    if total == 0:\n        return 0.0\n    nonzero = float(np.count_nonzero(a))\n    result = nonzero / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation entropy (16 bins), weighted by gradient magnitude (higher = more varied directions)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(img)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = mag.sum()\n    if total <= 0:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # [-pi, pi]\n    bins = 16\n    hist, _ = np.histogram(theta.ravel(), bins=bins, range=(-np.pi, np.pi), weights=mag.ravel())\n    p = hist.astype(float) / (hist.sum() + 1e-12)\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -np.sum(p_nonzero * np.log2(p_nonzero))\n    # normalize by max entropy = log2(bins)\n    result = entropy / (np.log2(bins) + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical mirror symmetry: absolute normalized correlation with left-right flipped image'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    b = np.fliplr(a)\n    if a.shape != b.shape or a.size == 0:\n        return 0.0\n    af = a.ravel()\n    bf = b.ravel()\n    afm = af - af.mean()\n    bfm = bf - bf.mean()\n    denom = np.sqrt((afm**2).sum() * (bfm**2).sum()) + 1e-12\n    corr = float((afm * bfm).sum() / denom)\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal edge energy in the upper half vs lower half (upper_energy / (lower_energy + eps))'\n    eps = 1e-9\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    if image.ndim == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gm = gray.max()\n    norm = gray / float(gm) if gm != 0 else gray\n    # horizontal gradient magnitude (differences along columns)\n    grad_h = np.abs(np.diff(norm, axis=1))\n    mid = h // 2\n    upper_energy = grad_h[:mid, :].sum()\n    lower_energy = grad_h[mid:, :].sum()\n    return float(upper_energy / (lower_energy + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized radial variance of ink pixels around centroid (lower => more circular shape)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    fg = gray < thresh\n    if np.count_nonzero(fg) > 0.5 * h * w:\n        fg = ~fg\n    ys, xs = np.nonzero(fg)\n    if ys.size == 0:\n        return 0.0\n    cy = ys.mean()\n    cx = xs.mean()\n    d = np.sqrt((ys - cy)**2 + (xs - cx)**2)\n    mean_d = d.mean() + 1e-8\n    var_d = d.var()\n    # normalized variance\n    return float(var_d / (mean_d**2))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity percentile spread: (P90 - P10) / (P50 + eps)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        flat = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(arr.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    p10 = float(np.percentile(flat, 10))\n    p50 = float(np.percentile(flat, 50))\n    p90 = float(np.percentile(flat, 90))\n    result = (p90 - p10) / (abs(p50) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry correlation mapped to [0,1] (1 => perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    mid = w // 2\n    if w % 2 == 0:\n        left = a[:, :mid]\n        right = a[:, mid:]\n    else:\n        left = a[:, :mid]\n        right = a[:, mid+1:]\n    # match widths\n    minw = min(left.shape[1], right.shape[1])\n    if minw == 0:\n        return 0.0\n    L = left[:, :minw].ravel()\n    R = np.fliplr(right)[:, :minw].ravel()\n    Lm = L - L.mean()\n    Rm = R - R.mean()\n    denom = (np.sqrt((Lm**2).sum() * (Rm**2).sum()) + eps)\n    corr = float((Lm * Rm).sum() / denom)\n    # map [-1,1] to [0,1]\n    return float(np.clip((corr + 1.0) / 2.0, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized column-wise average of vertical gradient magnitude in the center third (helps detect round loops vs straight vertical strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gmin, gmax = float(np.min(gray)), float(np.max(gray))\n    if gmax > gmin:\n        gray = (gray - gmin) / (gmax - gmin)\n    else:\n        gray = gray * 0.0\n    # compute vertical gradient magnitude\n    gy = np.gradient(gray, axis=0)\n    mag = np.abs(gy)\n    h, w = mag.shape\n    r0, r1 = h // 3, (2 * h) // 3\n    center_mag = mag[r0:r1, :]\n    if center_mag.size == 0:\n        return 0.0\n    # normalize by max to be scale-invariant\n    maxv = float(np.max(center_mag))\n    if maxv == 0:\n        return 0.0\n    score = float(np.mean(center_mag) / (maxv + 1e-12))\n    return score\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of local bright peaks (local maxima stronger than neighbors)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape if arr.size else (0, 0)\n    if h < 3 or w < 3:\n        return 0.0\n    center = arr\n    # compare to 8 neighbors using rolls\n    neigh_max = np.maximum.reduce([\n        np.roll(center, 1, axis=0),\n        np.roll(center, -1, axis=0),\n        np.roll(center, 1, axis=1),\n        np.roll(center, -1, axis=1),\n        np.roll(np.roll(center, 1, axis=0), 1, axis=1),\n        np.roll(np.roll(center, 1, axis=0), -1, axis=1),\n        np.roll(np.roll(center, -1, axis=0), 1, axis=1),\n        np.roll(np.roll(center, -1, axis=0), -1, axis=1),\n    ])\n    peaks = (center > neigh_max)\n    # threshold peaks to be reasonably bright\n    thr = center.mean() + center.std()\n    peaks = peaks & (center > thr)\n    count = int(np.count_nonzero(peaks))\n    density = count / float(max(1, h * w))\n    return float(density)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Row fragmentation: fraction of row-to-row presence transitions (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h <= 1:\n        return 0.0\n    mn = float(a.min())\n    mx = float(a.max())\n    rng = mx - mn\n    if rng <= 1e-12:\n        return 0.0\n    # a row is considered 'present' if its max exceeds near-min threshold\n    thresh = mn + rng * 0.02\n    row_present = np.max(a, axis=1) > thresh\n    transitions = np.count_nonzero(row_present[:-1] != row_present[1:])\n    result = float(transitions) / float(h - 1)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Robust contrast: (90th - 10th percentile) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).ravel().astype(float))\n    else:\n        arr = np.nan_to_num(img.ravel().astype(float))\n    if arr.size == 0:\n        return 0.0\n    p90 = float(np.percentile(arr, 90))\n    p10 = float(np.percentile(arr, 10))\n    gstd = float(arr.std()) + eps\n    result = (p90 - p10) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of principal axis eigenvalues (major / minor) of ink pixel covariance (linear strokes like 7 have high ratio)'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    border_mean = float(np.mean(np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])))\n    med = float(np.median(gray))\n    if border_mean > med:\n        ink = (gray < np.percentile(gray, 60)).astype(np.uint8)\n    else:\n        ink = (gray > np.percentile(gray, 40)).astype(np.uint8)\n    ys, xs = np.where(ink)\n    if xs.size < 3:\n        return 0.0\n    x = xs.astype(float)\n    y = ys.astype(float)\n    xm = x.mean()\n    ym = y.mean()\n    cov_xx = np.mean((x - xm) ** 2)\n    cov_yy = np.mean((y - ym) ** 2)\n    cov_xy = np.mean((x - xm) * (y - ym))\n    cov = np.array([[cov_xx, cov_xy], [cov_xy, cov_yy]])\n    # eigenvalues\n    try:\n        vals = np.linalg.eigvalsh(cov)\n        vals = np.sort(vals)[::-1]  # descending\n        major = float(vals[0])\n        minor = float(vals[1])\n        eps = 1e-10\n        ratio = major / (minor + eps)\n        return float(ratio)\n    except Exception:\n        return 0.0\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal gradient balance: (energy along 45deg - energy along 135deg) / total diagonal energy'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    diag45 = np.sum(np.abs(gx + gy))\n    diag135 = np.sum(np.abs(gx - gy))\n    tot = diag45 + diag135 + 1e-9\n    return float((diag45 - diag135) / tot)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of border pixels brighter than global mean (object touching border or bright frame)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mu = float(a.mean())\n    # border mask\n    top = a[0, :]\n    bottom = a[-1, :]\n    left = a[:, 0]\n    right = a[:, -1]\n    border_vals = np.concatenate([top.ravel(), bottom.ravel(), left.ravel(), right.ravel()])\n    if border_vals.size == 0:\n        return 0.0\n    count = float(np.count_nonzero(border_vals > mu))\n    result = count / float(border_vals.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean horizontal edge strength (|vertical derivative|) in the bottom third of the image'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    start = (2 * h) // 3\n    bottom = gray[start:h, :]\n    gy, gx = np.gradient(bottom.astype(float))\n    horiz_edge = np.abs(gy)\n    return float(np.mean(horiz_edge))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Central vertical-strip left-right L1 symmetry score (lower = more symmetric)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image, dtype=float)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    c0 = w // 3\n    c1 = w - c0\n    region = gray[:, c0:c1]\n    if region.size == 0:\n        return 0.0\n    # normalize region intensity\n    mn, mx = float(np.min(region)), float(np.max(region))\n    if mx <= mn:\n        return 0.0\n    regn = (region - mn) / (mx - mn)\n    mid = regn.shape[1] // 2\n    left = regn[:, :mid]\n    right = regn[:, -mid:] if mid > 0 else regn[:, :mid]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # flip right horizontally and compute mean absolute difference\n    right_flipped = np.flip(right, axis=1)\n    # if shapes mismatch due to odd width, crop to min width\n    minw = min(left.shape[1], right_flipped.shape[1])\n    left = left[:, :minw]\n    right_flipped = right_flipped[:, :minw]\n    diff = np.mean(np.abs(left - right_flipped))\n    # invert so higher -> more symmetric\n    return float(1.0 - diff)\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum horizontal run length of ink in the top 20% of rows, normalized by image width'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    p40, p60 = np.percentile(gray, 40), np.percentile(gray, 60)\n    dark = gray < p40\n    light = gray > p60\n    dcount = np.count_nonzero(dark)\n    lcount = np.count_nonzero(light)\n    if dcount == 0 and lcount == 0:\n        thr = np.mean(gray)\n        dark = gray < thr\n        dcount = np.count_nonzero(dark)\n        if dcount == 0:\n            return 0.0\n    mask = dark if (0 < dcount <= max(lcount, 1)) else light\n    top_k = max(1, h // 5)\n    top_region = mask[:top_k, :]\n    max_run = 0\n    for r in range(top_region.shape[0]):\n        row = top_region[r, :].astype(int)\n        if row.sum() == 0:\n            continue\n        # compute runs by difference trick\n        padded = np.concatenate([[0], row, [0]])\n        diff = np.diff(padded)\n        starts = np.where(diff == 1)[0]\n        ends = np.where(diff == -1)[0]\n        if starts.size and ends.size:\n            runs = ends - starts\n            max_run = max(max_run, runs.max())\n    return float(max_run / max(1, w))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted centroid offset normalized by image diagonal (0..1), 0=centered'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total = float(a.sum())\n    if total <= eps:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = float((ys * a).sum()) / total\n    cx = float((xs * a).sum()) / total\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = float(np.hypot(cy - center_y, cx - center_x))\n    maxd = float(np.hypot(center_y, center_x)) + eps\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast of bright tail: (mean of top 5% - median) normalized by std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    thr = float(np.percentile(a, 95))\n    top = a[a >= thr]\n    if top.size == 0:\n        top_mean = float(thr)\n    else:\n        top_mean = float(top.mean())\n    med = float(np.median(a))\n    sd = float(a.std()) + eps\n    result = (top_mean - med) / sd\n    return float(np.clip(result, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground bounding-box area fraction (mask by median threshold)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    med = float(np.median(img)) if img.size else 0.0\n    mask = img > med\n    if not mask.any():\n        return 0.0\n    rows = np.any(mask, axis=1)\n    cols = np.any(mask, axis=0)\n    rmin = int(np.argmax(rows))\n    rmax = int(len(rows) - 1 - np.argmax(rows[::-1]))\n    cmin = int(np.argmax(cols))\n    cmax = int(len(cols) - 1 - np.argmax(cols[::-1]))\n    bbox_area = float((rmax - rmin + 1) * (cmax - cmin + 1))\n    total_area = float(h * w) + eps\n    result = bbox_area / total_area\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance of intensity center-of-mass from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    total = arr.sum() + eps\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    com_x = float((arr * xs).sum() / total)\n    com_y = float((arr * ys).sum() / total)\n    dist = np.hypot(com_x - cx, com_y - cy)\n    norm = np.hypot(w, h) / 2.0 + eps\n    result = dist / norm\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum relative background gap width in the top third (captures top concavities/openings)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = (gray < thresh).astype(np.uint8)\n    if np.count_nonzero(ink) == 0:\n        return 1.0\n    top = max(1, h // 3)\n    max_gap_rel = 0.0\n    for i in range(top):\n        row = ink[i, :]\n        if np.any(row):\n            left = np.argmax(row > 0)\n            # find rightmost ink: search from right\n            rev = row[::-1]\n            right = w - 1 - np.argmax(rev > 0)\n            gap = max(0, right - left + 1 - int(np.sum(row[left:right+1] > 0)))\n            # alternatively, compute largest sequence of zeros between left and right\n            if right > left:\n                seg = row[left:right+1] == 0\n                # find longest run of True in seg\n                max_run = 0\n                run = 0\n                for v in seg:\n                    if v:\n                        run += 1\n                    else:\n                        if run > max_run: max_run = run\n                        run = 0\n                if run > max_run: max_run = run\n                gap_width = max_run\n            else:\n                gap_width = 0\n            rel = float(gap_width) / float(w)\n            if rel > max_gap_rel:\n                max_gap_rel = rel\n    return float(max_gap_rel)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry: normalized correlation between left and mirrored right (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = img[:, :mid]\n    right = img[:, w-mid:]\n    right_flipped = np.fliplr(right)\n    if left.size != right_flipped.size:\n        # ensure same shape by cropping larger\n        min_w = min(left.shape[1], right_flipped.shape[1])\n        left = left[:, :min_w]\n        right_flipped = right_flipped[:, :min_w]\n    x = left.ravel().astype(float)\n    y = right_flipped.ravel().astype(float)\n    if x.size == 0:\n        return 0.0\n    xm = x.mean()\n    ym = y.mean()\n    num = float(((x - xm) * (y - ym)).sum())\n    den = float(np.sqrt(((x - xm) ** 2).sum() * ((y - ym) ** 2).sum())) + eps\n    corr = num / den\n    corr = max(min(corr, 1.0), -1.0)\n    result = (corr + 1.0) / 2.0\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of total mass that lies in the bottom half of the image (measures lower-loop prominence)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    total = np.sum(gray)\n    if total == 0:\n        return 0.0\n    bottom = np.sum(gray[h//2:, :])\n    return float(bottom / (total + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Corner uniformity: 1 - (mean corner std / overall std), clipped (1=center-uniform)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    ch = max(1, h // 8)\n    cw = max(1, w // 8)\n    c1 = arr[:ch, :cw]\n    c2 = arr[:ch, -cw:]\n    c3 = arr[-ch:, :cw]\n    c4 = arr[-ch:, -cw:]\n    corners = [c for c in (c1, c2, c3, c4) if c.size]\n    if not corners:\n        return 0.0\n    corner_stds = [float(np.std(c)) for c in corners]\n    mean_corner_std = float(np.mean(corner_stds))\n    overall_std = float(np.std(arr))\n    if overall_std <= eps:\n        return 1.0\n    result = 1.0 - (mean_corner_std / (overall_std + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Upper-quarter vs lower-quarter ink imbalance: (upper_quarter - lower_quarter) / (total + eps), range [-1,1]'\n    import numpy as _np\n    if len(image.shape) == 3:\n        gray = _np.mean(image, axis=2)\n    else:\n        gray = image.astype(_np.float32)\n    h, w = gray.shape\n    m = _np.mean(gray)\n    ink = (gray < m).astype(_np.float32)\n    q = max(1, h // 4)\n    upper = float(ink[:q, :].sum())\n    lower = float(ink[-q:, :].sum())\n    total = float(ink.sum()) + 1e-6\n    imbalance = float((upper - lower) / total)\n    return imbalance\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of quadrant mean intensities normalized by global std (higher => asymmetric quadrant lighting)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    hy, wy = h // 2, w // 2\n    q1 = a[:hy, :wy]\n    q2 = a[:hy, wy:]\n    q3 = a[hy:, :wy]\n    q4 = a[hy:, wy:]\n    means = []\n    for q in (q1, q2, q3, q4):\n        if q.size:\n            means.append(float(q.mean()))\n        else:\n            means.append(0.0)\n    qvar = float(np.var(np.array(means)))\n    gstd = float(np.std(a)) + eps\n    return float(qvar / gstd)\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized standard deviation of rightmost ink column index across rows (captures bottom-right loop variability)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = float(np.percentile(gray, 50.0))\n    ink = gray < thresh\n    if np.count_nonzero(ink) == 0:\n        ink = gray > float(np.percentile(gray, 50.0))\n    rightmost = []\n    for i in range(h):\n        row = ink[i, :]\n        cols = np.nonzero(row)[0]\n        if cols.size > 0:\n            rightmost.append(float(cols.max()))\n    if len(rightmost) == 0:\n        return 0.0\n    sd = float(np.std(rightmost))\n    result = sd / float(max(1.0, w - 1))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels significantly brighter than local statistics (sparse highlights)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    mu = float(flat.mean())\n    sigma = float(flat.std()) + eps\n    thr = mu + sigma\n    count = int(np.count_nonzero(flat > thr))\n    frac = float(count) / float(flat.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 64-bin histogram'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size == 0:\n        return 0.0\n    bins = 64\n    mn, mx = float(arr.min()), float(arr.max())\n    if mx <= mn:\n        return 0.0\n    hist, _ = np.histogram(arr, bins=bins, range=(mn, mx))\n    total = float(hist.sum()) + eps\n    p = hist.astype(float) / total\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -float((p_nonzero * np.log(p_nonzero + eps)).sum())\n    max_ent = float(np.log(len(hist) + eps))\n    result = entropy / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global intensity skewness (third standardized moment), clipped to [-10,10]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    mu = float(a.mean())\n    sd = float(a.std()) + eps\n    skew = float(np.mean(((a - mu) / sd) ** 3))\n    skew = float(np.clip(skew, -10.0, 10.0))\n    return float(skew)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 16 histogram bins'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    vals = a.ravel()\n    if vals.size == 0:\n        return 0.0\n    bins = 16\n    hist, _ = np.histogram(vals, bins=bins, density=False)\n    prob = hist.astype(float) / (hist.sum() + 1e-12)\n    prob = prob[prob > 0]\n    if prob.size == 0:\n        return 0.0\n    entropy = -float(np.sum(prob * np.log(prob + 1e-12)))\n    # normalize by max entropy = log(bins)\n    max_ent = np.log(float(bins))\n    result = entropy / (max_ent + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson correlation between intensity and distance from center in [-1..1]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    d = np.hypot(ys - cy, xs - cx).ravel()\n    if d.size == 0:\n        return 0.0\n    d = d / (d.max() + eps)\n    vals = a.ravel().astype(float)\n    if vals.std() < eps or d.std() < eps:\n        return 0.0\n    cov = np.mean((vals - vals.mean()) * (d - d.mean()))\n    corr = cov / (vals.std() * d.std() + eps)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical position (normalized) of the largest interior hole centroid, -1 if no hole'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # determine foreground\n    p40 = np.percentile(gray, 40)\n    p60 = np.percentile(gray, 60)\n    dark = (gray < p40)\n    light = (gray > p60)\n    if dark.sum() > 0 and (dark.sum() <= max(1, light.sum())):\n        fg = dark\n    elif light.sum() > 0:\n        fg = light\n    else:\n        fg = (gray < np.mean(gray))\n    bg = (~fg).astype(np.uint8)\n    visited = np.zeros_like(bg, dtype=bool)\n    holes = []\n    # flood fill background components\n    for y in range(h):\n        for x in range(w):\n            if bg[y, x] and not visited[y, x]:\n                # BFS\n                stack = [(y, x)]\n                visited[y, x] = True\n                coords = []\n                touches_border = False\n                while stack:\n                    cy, cx = stack.pop()\n                    coords.append((cy, cx))\n                    if cy == 0 or cy == h-1 or cx == 0 or cx == w-1:\n                        touches_border = True\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny = cy + dy\n                            nx = cx + dx\n                            if 0 <= ny < h and 0 <= nx < w and not visited[ny, nx] and bg[ny, nx]:\n                                visited[ny, nx] = True\n                                stack.append((ny, nx))\n                if not touches_border:\n                    ys = [c[0] for c in coords]\n                    xs = [c[1] for c in coords]\n                    holes.append((len(coords), np.mean(ys), np.mean(xs)))\n    if len(holes) == 0:\n        return -1.0\n    # pick largest hole\n    holes.sort(reverse=True, key=lambda t: t[0])\n    _, yc, _ = holes[0]\n    return float(yc / float(max(1, h - 1)))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for grayscale)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    R = a[:, :, 0]\n    G = a[:, :, 1]\n    B = a[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    metric = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    return float(max(0.0, metric))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarseness ratio: mean long-distance difference / mean adjacent difference (distance 2 / distance 1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 1 or w < 1:\n        return 0.0\n    # adjacent diffs (vertical and horizontal)\n    dh = np.abs(arr[1:, :] - arr[:-1, :]).ravel()\n    dw = np.abs(arr[:, 1:] - arr[:, :-1]).ravel()\n    fine = np.concatenate([dh, dw]) if (dh.size + dw.size) > 0 else np.array([0.0])\n    # distance-2 diffs\n    dh2 = np.abs(arr[2:, :] - arr[:-2, :]).ravel() if h > 2 else np.array([])\n    dw2 = np.abs(arr[:, 2:] - arr[:, :-2]).ravel() if w > 2 else np.array([])\n    coarse = np.concatenate([dh2, dw2]) if (dh2.size + dw2.size) > 0 else np.array([0.0])\n    fine_mean = float(np.mean(fine)) if fine.size else 0.0\n    coarse_mean = float(np.mean(coarse)) if coarse.size else 0.0\n    result = coarse_mean / (fine_mean + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted centroid offset from image center normalized by diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    weight = arr\n    total = float(weight.sum())\n    if total <= eps:\n        return 0.0\n    mean_y = float((weight * ys).sum() / (total + eps))\n    mean_x = float((weight * xs).sum() / (total + eps))\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    dist = np.hypot(mean_y - cy, mean_x - cx)\n    diag = np.hypot(h, w) / 2.0 + eps\n    result = dist / diag\n    result = float(np.clip(result, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted eccentricity of mass (0=centered circular .. 1=elongated)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total = float(arr.sum())\n    if total <= eps:\n        return 0.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    cy = float((ys * arr).sum() / (total + eps))\n    cx = float((xs * arr).sum() / (total + eps))\n    rx = (xs - cx)\n    ry = (ys - cy)\n    # broadcast to shape\n    RX = np.repeat(rx, h, axis=0).T if rx.shape[1] == w and ry.shape[0] == h else None\n    # compute centralized moments\n    # more direct computation:\n    dx = (xs - cx)\n    dy = (ys - cy)\n    cov_xx = float(((dx**2) * arr).sum() / (total + eps))\n    cov_yy = float(((dy**2) * arr).sum() / (total + eps))\n    cov_xy = float(((dx * dy) * arr).sum() / (total + eps))\n    trace = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    disc = max(trace * trace - 4.0 * det, 0.0)\n    l1 = (trace + np.sqrt(disc)) / 2.0\n    l2 = (trace - np.sqrt(disc)) / 2.0\n    if l1 <= eps:\n        return 0.0\n    ecc = float(np.sqrt(max(0.0, 1.0 - max(0.0, l2) / (l1 + eps))))\n    return float(np.clip(ecc, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground-background contrast using median split normalized by image std (>=0)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    thr = float(np.median(flat))\n    fg = flat[flat > thr]\n    bg = flat[flat <= thr]\n    if fg.size == 0 or bg.size == 0:\n        return 0.0\n    mean_fg = float(fg.mean())\n    mean_bg = float(bg.mean())\n    overall_std = float(flat.std()) + eps\n    contrast = (mean_fg - mean_bg) / overall_std\n    result = float(np.clip(abs(contrast), 0.0, 10.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Peakiness: ratio of 99th percentile minus median to global std (higher => strong peaks)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    med = float(np.median(a))\n    p99 = float(np.percentile(a, 99))\n    std = float(a.std()) + eps\n    result = (p99 - med) / std\n    return float(np.clip(result, 0.0, 50.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Largest thresholded component fraction using mean intensity threshold (0..1)'\n    import numpy as np\n    from collections import deque\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        gray = np.nan_to_num(arr.astype(float))\n    h, w = gray.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(gray.mean())\n    mask = gray > thr\n    if not mask.any():\n        return 0.0\n    visited = np.zeros_like(mask, dtype=bool)\n    max_area = 0\n    # 4-connected flood fill\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                area = 0\n                dq = deque()\n                dq.append((y, x))\n                visited[y, x] = True\n                while dq:\n                    cy, cx = dq.popleft()\n                    area += 1\n                    # neighbors\n                    if cy > 0 and mask[cy-1, cx] and not visited[cy-1, cx]:\n                        visited[cy-1, cx] = True\n                        dq.append((cy-1, cx))\n                    if cy < h-1 and mask[cy+1, cx] and not visited[cy+1, cx]:\n                        visited[cy+1, cx] = True\n                        dq.append((cy+1, cx))\n                    if cx > 0 and mask[cy, cx-1] and not visited[cy, cx-1]:\n                        visited[cy, cx-1] = True\n                        dq.append((cy, cx-1))\n                    if cx < w-1 and mask[cy, cx+1] and not visited[cy, cx+1]:\n                        visited[cy, cx+1] = True\n                        dq.append((cy, cx+1))\n                if area > max_area:\n                    max_area = area\n    frac = float(max_area) / float(h * w + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of energy in high spatial frequencies via 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    F = np.fft.fft2(a)\n    P = np.abs(F) ** 2\n    P_shift = np.fft.fftshift(P)\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    cutoff = max(1.0, min(h, w) / 8.0)\n    high = P_shift[r > cutoff].sum()\n    total = P_shift.sum() + eps\n    result = float(high) / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right (vertical) symmetry: average absolute column difference between left and flipped right halves (normalized)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    # normalize 0..1\n    mn, mx = float(gray.min()), float(gray.max())\n    if mx == mn:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    h, w = norm.shape\n    mid = w // 2\n    left = norm[:, :mid]\n    if w % 2 == 0:\n        right = norm[:, mid:]\n    else:\n        right = norm[:, mid+1:]\n    # flip right horizontally to compare\n    right_flipped = np.fliplr(right)\n    # crop to common width\n    minw = min(left.shape[1], right_flipped.shape[1])\n    if minw == 0:\n        return 0.0\n    diff = np.abs(left[:, :minw] - right_flipped[:, :minw])\n    # normalize by mean intensity to avoid scale effects\n    return float(np.mean(diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal component strength: ratio of largest to smallest eigenvalue of foreground coordinate covariance (>=1.0)'\n    import numpy as np\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    gray_n = (gray - mn) / (mx - mn) if mx - mn > 1e-8 else np.zeros_like(gray)\n    thr = np.mean(gray_n)\n    fg = (gray_n < thr) if np.mean(gray_n) > 0.5 else (gray_n > thr)\n    ys, xs = np.where(fg)\n    if xs.size < 2:\n        return 1.0\n    coords = np.vstack([xs.astype(float), ys.astype(float)])\n    coords -= np.mean(coords, axis=1, keepdims=True)\n    cov = np.cov(coords)\n    # numerical stability\n    try:\n        vals = np.linalg.eigvalsh(cov)\n        vals = np.clip(vals, 1e-12, None)\n        ratio = float(vals[-1] / vals[0])\n    except Exception:\n        ratio = 1.0\n    return float(ratio)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near global min or max intensity (saturation at both ends)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    vmin = float(a.min()); vmax = float(a.max())\n    if vmax <= vmin + eps:\n        return 0.0\n    tol = 0.05 * (vmax - vmin)\n    near_min = (a <= vmin + tol)\n    near_max = (a >= vmax - tol)\n    frac = float(np.count_nonzero(near_min | near_max)) / float(a.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local peak fraction: fraction of pixels greater than 8 neighbors and reasonably bright (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    m = a.mean()\n    s = a.std()\n    bright_thr = m + 0.1 * s\n    center = a\n    nlist = [\n        np.roll(a, 1, axis=0),\n        np.roll(a, -1, axis=0),\n        np.roll(a, 1, axis=1),\n        np.roll(a, -1, axis=1),\n        np.roll(np.roll(a, 1, axis=0), 1, axis=1),\n        np.roll(np.roll(a, 1, axis=0), -1, axis=1),\n        np.roll(np.roll(a, -1, axis=0), 1, axis=1),\n        np.roll(np.roll(a, -1, axis=0), -1, axis=1),\n    ]\n    greater = np.ones_like(a, dtype=bool)\n    for n in nlist:\n        greater &= (center > n)\n    peaks = greater & (center > bright_thr)\n    # exclude wrap-around artifacts by zeroing borders where rolls introduced wraps\n    peaks[0, :] = False\n    peaks[-1, :] = False\n    peaks[:, 0] = False\n    peaks[:, -1] = False\n    result = float(np.count_nonzero(peaks)) / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate branch-point count: fraction of ink pixels with 4 or more neighbors in 8-connectivity'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        th = np.mean(gray)\n        ink = (gray < th).astype(np.uint8)\n        if ink.sum() == 0:\n            ink = (gray > th).astype(np.uint8)\n        if ink.sum() == 0:\n            return 0.0\n        padded = np.pad(ink, 1, mode='constant', constant_values=0)\n        # sum of 8-neighbors\n        neigh = (\n            padded[:-2, :-2] + padded[:-2, 1:-1] + padded[:-2, 2:] +\n            padded[1:-1, :-2] +                 0 + padded[1:-1, 2:] +\n            padded[2:, :-2] +  padded[2:, 1:-1] + padded[2:, 2:]\n        )\n        # restrict to original ink pixels\n        neigh = neigh * ink\n        branch_points = np.count_nonzero(neigh >= 4)\n        return float(branch_points / (ink.sum() + 1e-9))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average absolute horizontal gradient magnitude in the middle third of the image (captures middle bars like in \"4\")'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    # compute horizontal gradient (difference along columns)\n    gx = np.abs(np.diff(gray, axis=1))\n    # pad to original width\n    gx = np.pad(gx, ((0,0),(0,1)), mode='constant', constant_values=0)\n    # middle third rows\n    r0 = h // 3\n    r1 = min(h, r0 * 2)\n    if r1 <= r0:\n        return float(np.mean(gx)) if gx.size else 0.0\n    mid_region = gx[r0:r1, :]\n    return float(np.mean(mid_region))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of total enclosed hole area to ink area (how big holes are relative to ink)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.mean(gray))\n    cand = gray < thr\n    if np.sum(cand) > gray.size / 2:\n        ink = ~cand\n    else:\n        ink = cand\n    ink = ink.astype(bool)\n    # Flood fill exterior background\n    exterior = np.zeros_like(ink, dtype=bool)\n    from collections import deque\n    q = deque()\n    for i in range(h):\n        for j in (0, w-1):\n            if not ink[i, j] and not exterior[i, j]:\n                exterior[i, j] = True\n                q.append((i, j))\n    for j in range(w):\n        for i in (0, h-1):\n            if not ink[i, j] and not exterior[i, j]:\n                exterior[i, j] = True\n                q.append((i, j))\n    while q:\n        i, j = q.popleft()\n        for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n            ni, nj = i+di, j+dj\n            if 0 <= ni < h and 0 <= nj < w and (not ink[ni, nj]) and (not exterior[ni, nj]):\n                exterior[ni, nj] = True\n                q.append((ni, nj))\n    internal_bg = (~ink) & (~exterior)\n    hole_area = float(np.sum(internal_bg))\n    ink_area = float(np.sum(ink))\n    if ink_area <= 0.0:\n        return 0.0\n    return float(hole_area / ink_area)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of non-overlapping 8x8 patches with low contrast (patch std < 10% of global std)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    gstd = float(a.std())\n    if gstd <= 1e-12:\n        return 1.0\n    ph = 8\n    pw = 8\n    # if image smaller than patch, treat whole image as one patch\n    if h < ph or w < pw:\n        pstdev = float(a.std())\n        return float(1.0 if pstdev < 0.1 * gstd else 0.0)\n    # non-overlapping grid\n    nh = h // ph\n    nw = w // pw\n    total_patches = nh * nw\n    if total_patches == 0:\n        return 0.0\n    low = 0\n    for i in range(nh):\n        for j in range(nw):\n            patch = a[i*ph:(i+1)*ph, j*pw:(j+1)*pw]\n            if patch.size == 0:\n                continue\n            if float(patch.std()) < 0.1 * gstd:\n                low += 1\n    result = float(low) / float(total_patches)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical gradient magnitude to horizontal gradient magnitude (large for vertical strokes); clipped to avoid div-by-zero'\n    import numpy as np\n    h, w = image.shape[:2]\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute simple finite differences\n    gy = np.abs(np.diff(gray, axis=0))\n    gx = np.abs(np.diff(gray, axis=1))\n    # pad to original size using zeros\n    gy_sum = float(gy.mean() if gy.size else 0.0)\n    gx_sum = float(gx.mean() if gx.size else 0.0)\n    denom = gx_sum + 1e-12\n    return float(gy_sum / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average pixel-wise left-right and top-bottom symmetry score (1=perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 1 or w < 1:\n        return 0.0\n    gstd = float(img.std()) + eps\n    # left-right\n    midw = w // 2\n    if midw == 0:\n        lr_sym = 1.0\n    else:\n        left = img[:, :midw]\n        right = img[:, -midw:]\n        right_flipped = np.fliplr(right)\n        lr_diff = np.mean(np.abs(left - right_flipped))\n        lr_sym = max(0.0, 1.0 - (lr_diff / (gstd + eps)))\n    # top-bottom\n    midh = h // 2\n    if midh == 0:\n        tb_sym = 1.0\n    else:\n        top = img[:midh, :]\n        bot = img[-midh:, :]\n        bot_flipped = np.flipud(bot)\n        tb_diff = np.mean(np.abs(top - bot_flipped))\n        tb_sym = max(0.0, 1.0 - (tb_diff / (gstd + eps)))\n    result = (lr_sym + tb_sym) / 2.0\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of horizontal-gradient sign changes down columns within the right quarter (captures alternating curvature)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    c0 = max(0, 3 * w // 4)\n    band = gray[:, c0:w]\n    if band.size == 0:\n        return 0.0\n    # horizontal gradient (difference along x)\n    hgrad = np.diff(band, axis=1)\n    # sign of gradient per row\n    s = np.sign(hgrad)\n    # count sign changes vertically per column position (ignore zeros by replacing with previous non-zero sign)\n    # propagate last non-zero sign downwards to avoid zero noise\n    s_proc = s.copy()\n    for col in range(s_proc.shape[1]):\n        last = 0\n        for row in range(s_proc.shape[0]):\n            if s_proc[row, col] == 0:\n                s_proc[row, col] = last\n            else:\n                last = s_proc[row, col]\n    sign_changes = np.sum(np.abs(np.diff(s_proc, axis=0)) > 0)\n    # normalize by possible maximum changes = (h-1)*(width of band)\n    denom = float(max(1, (h - 1) * s_proc.shape[1]))\n    return float(sign_changes / denom)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink mass in the top-right quadrant to the total ink in the top half (right bias in top area)'\n    import numpy as np\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    thr = mn + 0.5 * (mx - mn)\n    top_half = gray[:h // 2, :]\n    if top_half.size == 0:\n        return 0.0\n    tr = top_half[:, w // 2:]\n    ink_top = (top_half > thr).astype(float)\n    ink_tr = (tr > thr).astype(float)\n    sum_top = float(np.sum(ink_top))\n    sum_tr = float(np.sum(ink_tr))\n    eps = 1e-9\n    return float(sum_tr / (sum_top + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Compactness of bright region: area to perimeter proxy for mask > mean'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean())\n    mask = a > thr\n    area = float(mask.sum())\n    if area <= 0.0:\n        return 0.0\n    # approximate perimeter via XOR with shifted masks (vertical + horizontal)\n    perim_v = np.sum(mask != np.roll(mask, 1, axis=0))\n    perim_h = np.sum(mask != np.roll(mask, 1, axis=1))\n    perimeter = float(perim_v + perim_h) + eps\n    # normalized compactness: area/(perimeter * sqrt(area)) -> roughly scale-invariant\n    result = (area / perimeter) / (np.sqrt(max(1.0, area)))\n    # clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Rotational symmetry (180-degree): absolute normalized correlation with image rotated 180 degrees'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    b = np.rot90(a, 2)\n    if a.shape != b.shape:\n        # ensure same shape (should be same)\n        h = min(a.shape[0], b.shape[0])\n        w = min(a.shape[1], b.shape[1])\n        a = a[:h, :w]\n        b = b[:h, :w]\n    a_flat = a.ravel()\n    b_flat = b.ravel()\n    if a_flat.size == 0:\n        return 0.0\n    a_m = a_flat - a_flat.mean()\n    b_m = b_flat - b_flat.mean()\n    denom = np.sqrt((a_m**2).sum() * (b_m**2).sum()) + 1e-12\n    corr = float((a_m * b_m).sum() / denom)\n    return float(np.clip(abs(corr), 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry score (1.0 = perfectly symmetric)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    flipped = np.flipud(np.fliplr(a))\n    diff = np.abs(a - flipped)\n    rng = float(a.max() - a.min()) + eps\n    mean_diff = float(diff.mean())\n    score = 1.0 - (mean_diff / rng)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of binary transitions along a horizontal line at 75% height normalized by width (captures bottom stroke crossings)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    row = min(h-1, max(0, int(h*0.75)))\n    line = gray[row, :]\n    thr = float(np.median(line))\n    mask = line < thr\n    # if inverted or degenerate, adjust threshold\n    if mask.mean() > 0.6 or mask.mean() < 0.01:\n        thr = float(np.mean(line))\n        mask = line < thr\n    # count transitions 0->1 or 1->0\n    trans = np.count_nonzero(mask[1:] != mask[:-1])\n    return float(trans / (w + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density in a central annulus (fraction of annulus pixels that are edge)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    # threshold edges adaptively\n    thr = mag.mean() + 0.5 * mag.std()\n    # radial annulus: between 0.2*min_dim and 0.5*min_dim\n    ys = np.arange(h)[:, None] - (h / 2.0)\n    xs = np.arange(w)[None, :] - (w / 2.0)\n    dist = np.hypot(ys, xs)\n    min_dim = float(min(h, w))\n    r0 = 0.2 * min_dim\n    r1 = 0.5 * min_dim\n    mask = (dist >= r0) & (dist <= r1)\n    if not np.any(mask):\n        return 0.0\n    edge_frac = float(np.count_nonzero((mag > thr) & mask)) / (float(np.count_nonzero(mask)) + 1e-12)\n    return float(np.clip(edge_frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized x-position (0..1) of the topmost ink pixels averaged across that top row (helps identify left/right top stroke starts)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.5\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border))\n    global_min, global_max = float(np.min(gray)), float(np.max(gray))\n    if border_mean > (global_min + global_max) / 2:\n        thresh = 0.5 * (border_mean + global_min)\n        binary = (gray < thresh).astype(np.uint8)\n    else:\n        thresh = 0.5 * (border_mean + global_max)\n        binary = (gray > thresh).astype(np.uint8)\n    rows_with_ink = np.where(np.any(binary == 1, axis=1))[0]\n    if rows_with_ink.size == 0:\n        return 0.5\n    top_row = rows_with_ink[0]\n    xs = np.where(binary[top_row, :] == 1)[0]\n    if xs.size == 0:\n        return 0.5\n    mean_x = float(np.mean(xs))\n    return float(mean_x / (w - 1 + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson correlation between pixel intensity and distance from image center (positive => edges brighter)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys = np.arange(h) - (h - 1) / 2.0\n    xs = np.arange(w) - (w - 1) / 2.0\n    dy = ys[:, None] ** 2\n    dx = xs[None, :] ** 2\n    dist = np.sqrt(dy + dx)\n    x = dist.ravel()\n    y = arr.ravel()\n    if x.size == 0 or y.size == 0:\n        return 0.0\n    xm = x.mean()\n    ym = y.mean()\n    xstd = x.std() + eps\n    ystd = y.std() + eps\n    cov = ((x - xm) * (y - ym)).mean()\n    corr = cov / (xstd * ystd)\n    # clamp to reasonable numeric range\n    return float(np.clip(corr, -5.0, 5.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative brightness of top 5% pixels: (mean_top - mean_all)/(|mean_all|+eps)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    p = 95.0\n    thr = float(np.percentile(a, p))\n    top = a[a >= thr]\n    if top.size == 0:\n        return 0.0\n    mean_all = float(a.mean())\n    mean_top = float(top.mean())\n    eps = 1e-12\n    result = (mean_top - mean_all) / (abs(mean_all) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink contained in bottom-left quadrant (useful to detect 6-like fills)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx <= mn:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    h, w = norm.shape\n    br = h // 2\n    bc = w // 2\n    bottom_left = float(norm[br:, :bc].sum())\n    total = float(norm.sum())\n    if total <= 1e-8:\n        return 0.0\n    return float(bottom_left / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry (1 = perfect symmetry, 0 = very different)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    try:\n        rotated = np.rot90(arr, 2)\n    except Exception:\n        return 0.0\n    denom = np.mean(np.abs(arr)) + eps\n    diff = np.mean(np.abs(arr - rotated)) / denom\n    result = 1.0 - float(np.clip(diff, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Saturation ratio: fraction of pixels near the image maximum intensity (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    vmin = float(a.min())\n    vmax = float(a.max())\n    if vmax - vmin < eps:\n        return 0.0\n    thresh = vmin + 0.95 * (vmax - vmin)\n    sat_count = float(np.count_nonzero(a >= thresh))\n    total = float(a.size)\n    result = sat_count / max(eps, total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram peak contrast: prominence of top peak vs second peak weighted by their separation (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 64\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    vmin = float(vals.min())\n    vmax = float(vals.max())\n    if vmax <= vmin:\n        return 0.0\n    hist, edges = np.histogram(vals, bins=bins, range=(vmin, vmax))\n    if hist.sum() == 0:\n        return 0.0\n    idx = np.argsort(hist)[::-1]\n    p1_idx = int(idx[0])\n    p1 = float(hist[p1_idx])\n    p2 = float(hist[idx[1]]) if idx.size > 1 else 0.0\n    sep = abs(p1_idx - (idx[1] if idx.size > 1 else p1_idx))\n    sep_norm = float(sep) / float(bins)\n    score = (p1 - p2) / (float(hist.sum()) + eps)\n    result = float(np.clip(score * sep_norm, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation concentration (0..1); 1 = all gradients aligned'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.size == 0 or mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # map to [0, pi) since orientation 180deg == same\n    theta = np.mod(theta, np.pi)\n    bins = 16\n    hist, _ = np.histogram(theta.ravel(), bins=bins, range=(0.0, np.pi), weights=mag.ravel())\n    total = hist.sum() + eps\n    concentration = float(hist.max() / total)\n    return float(np.clip(concentration, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant global gradient orientation mapped to [-1..1] (-1 = -90deg, 1 = +90deg)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    Jxx = (gx * gx).sum()\n    Jyy = (gy * gy).sum()\n    Jxy = (gx * gy).sum()\n    denom = (Jxx - Jyy)\n    angle = 0.5 * np.arctan2(2.0 * Jxy, denom + eps)  # radians in [-pi/2, pi/2]\n    result = float(angle / (np.pi / 2.0))\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute vertical gradient in the central horizontal band (high for strong horizontal strokes like crossbars)'\n    import numpy as np\n    # prepare grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # avoid uniform images\n    p10, p90 = np.percentile(gray, (10, 90))\n    if (p90 - p10) < 1e-6 or h < 3:\n        return 0.0\n    # gradients\n    gy, gx = np.gradient(gray.astype(float))\n    # central band (middle third)\n    r0, r1 = h // 3, (2 * h) // 3\n    center_abs_gy = np.mean(np.abs(gy[r0:r1, :]))\n    global_abs_gy = np.mean(np.abs(gy)) + 1e-9\n    return float(center_abs_gy / global_abs_gy)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio: energy in high-pass (3x3) divided by total energy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # local 3x3 mean via rolling\n    s = np.zeros_like(a, dtype=float)\n    shifts = [(0,0),(1,0),(-1,0),(0,1),(0,-1),(1,1),(1,-1),(-1,1),(-1,-1)]\n    for dy, dx in shifts:\n        s += np.roll(np.roll(a, dy, axis=0), dx, axis=1)\n    low = s / 9.0\n    high = a - low\n    energy_high = float((high ** 2).sum())\n    energy_total = float((a ** 2).sum()) + eps\n    result = energy_high / energy_total\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'L1-normalized 180-degree rotational asymmetry: mean absolute difference between image and rotated 180'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    rot = np.rot90(gray, 2)\n    diff = np.abs(gray - rot)\n    denom = float(np.mean(np.abs(gray)) + 1e-6)\n    return float(np.mean(diff) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian variance normalized by global std (focus/high-frequency measure)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    gy, gx = np.gradient(a)\n    gyy, gyx = np.gradient(gy)\n    gxy, gxx = np.gradient(gx)\n    lap = gxx + gyy\n    lap_var = float(np.var(lap))\n    gstd = float(a.std()) + eps\n    result = lap_var / (gstd + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy fraction from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image, dtype=float)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2))\n    else:\n        a = np.nan_to_num(arr)\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    mag2 = (np.abs(F) ** 2)\n    total = float(mag2.sum()) + eps\n    k = max(1, min(h, w) // 8)\n    cy = h // 2\n    cx = w // 2\n    low = mag2[cy - k:cy + k + 1, cx - k:cx + k + 1]\n    low_energy = float(low.sum())\n    hf_frac = 1.0 - (low_energy / total)\n    return float(np.clip(hf_frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of ink vertical thickness per column in the lower quarter normalized by image height'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    bg = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    ink_dark = float(np.mean(gray)) < bg\n    if ink_dark:\n        thr = max(np.min(gray), bg - 0.15 * (bg - np.min(gray)))\n        binary = (gray < thr).astype(int)\n    else:\n        thr = min(np.max(gray), bg + 0.15 * (np.max(gray) - bg))\n        binary = (gray > thr).astype(int)\n    lower = slice(max(0, (3 * h) // 4), h)\n    heights = []\n    for col in range(w):\n        colv = binary[lower, col]\n        heights.append(np.sum(colv))\n    if len(heights) == 0:\n        return 0.0\n    std_h = float(np.std(heights))\n    return float(std_h / max(1.0, h))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative depth of the central valley between top and bottom density peaks in the row profile (strong valley suggests two separate loops as in \"8\")'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    eps = 1e-8\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    g = (gray - mn) / (mx - mn + eps)\n    border = np.concatenate([g[0, :], g[-1, :], g[:, 0], g[:, -1]]) if h > 1 and w > 1 else g.flatten()\n    border_mean = float(np.mean(border)) if border.size else 1.0\n    if border_mean > 0.5:\n        ink = g < 0.5\n    else:\n        ink = g > 0.5\n    row_density = ink.sum(axis=1).astype(float) / (w + eps)\n    if h < 3 or np.max(row_density) < eps:\n        return 0.0\n    mid = h // 2\n    top_region = row_density[:mid] if mid > 1 else row_density[:1]\n    bottom_region = row_density[mid:] if mid < h - 1 else row_density[-1:]\n    top_idx = int(np.argmax(top_region)) if top_region.size > 0 else 0\n    bottom_idx = int(np.argmax(bottom_region)) + mid if bottom_region.size > 0 else h - 1\n    if bottom_idx <= top_idx + 1:\n        return 0.0\n    valley = float(np.min(row_density[top_idx:bottom_idx + 1]))\n    depth = (float(row_density[top_idx]) + float(row_density[bottom_idx]) - 2.0 * valley) / (float(np.max(row_density)) + eps)\n    return float(max(0.0, depth))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Orientation entropy of gradients (0..1, higher = more diverse edge directions)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    ang = np.mod(ang, np.pi)  # map to [0, pi)\n    nbins = 16\n    hist, _ = np.histogram(ang.ravel(), bins=nbins, range=(0.0, np.pi))\n    total = float(hist.sum()) + eps\n    p = hist / total\n    # entropy normalized to [0,1]\n    ent = -float(np.sum(np.where(p > 0, p * np.log(p + eps), 0.0)))\n    max_ent = float(np.log(nbins) + eps)\n    result = ent / max_ent\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-spot compactness: 1 - (mean distance of top 2% brightest pixels to center normalized by diagonal)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    thr = float(np.percentile(img.ravel(), 98))\n    mask = (img >= thr)\n    if not mask.any():\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    d = np.hypot(xs - cx, ys - cy)\n    mean_d = float(d.mean())\n    diag = np.hypot(w, h) + eps\n    norm = mean_d / diag\n    result = 1.0 - float(np.clip(norm, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong diagonal edge energy around \u00b145 degrees (captures diagonal tails/joins)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # gradient\n    gy, gx = np.gradient(gray.astype(float))\n    mag = np.hypot(gx, gy)\n    total_energy = mag.sum() + 1e-9\n    # orientation in degrees\n    ang = np.degrees(np.arctan2(gy, gx))  # -180..180\n    # select energy near +45 or -45 (within 25 degrees)\n    mask_pos = (np.abs(ang - 45) <= 25)\n    mask_neg = (np.abs(ang + 45) <= 25)\n    diag_energy = mag[mask_pos].sum() + mag[mask_neg].sum()\n    return float(diag_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ink density inside the lower-right triangular region (captures lower-right diagonal strokes)'\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img.astype(float)\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.count_nonzero(ink) == 0:\n        ink = gray > thresh\n    # define lower-right triangle: rows r and cols c where (c/w) + ( (h-1-r)/h ) > 1\n    rows = np.arange(h).reshape(-1, 1)\n    cols = np.arange(w).reshape(1, -1)\n    mask = (cols / max(1, w - 1)) + ((h - 1 - rows) / max(1, h - 1)) > 1.0\n    tri = ink & mask\n    total = np.count_nonzero(ink)\n    if total == 0:\n        return 0.0\n    return float(np.count_nonzero(tri) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (Hasler & S\u00fcsstrunk); returns 0 for grayscale inputs'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    # ensure float channels\n    arr = np.nan_to_num(img.astype(float))\n    R = arr[:, :, 0].ravel()\n    G = arr[:, :, 1].ravel()\n    B = arr[:, :, 2].ravel()\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    std_root = np.sqrt(std_rg ** 2 + std_yb ** 2)\n    mean_root = np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    result = std_root + 0.3 * mean_root\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian variance (measure of local high-frequency content / focus)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # discrete Laplacian via 4-neighbor stencil\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) +\n           np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    lap_var = float(np.var(lap))\n    img_var = float(np.var(a)) + eps\n    result = lap_var / img_var\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average vertical position (0..1) of centroids of internal holes (0 = top), 0.0 when no internal holes'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.percentile(gray, 50)\n    lower = gray <= th\n    if lower.sum() == 0 or (~lower).sum() == 0:\n        foreground = np.zeros_like(gray, dtype=bool)\n    else:\n        foreground = lower if np.mean(gray[lower]) < np.mean(gray[~lower]) else ~lower\n    background = ~foreground\n    # mark border-connected background\n    visited = np.zeros_like(background, dtype=bool)\n    from collections import deque\n    q = deque()\n    # enqueue border background pixels\n    for c in range(w):\n        if background[0, c]:\n            visited[0, c] = True; q.append((0, c))\n        if background[h-1, c]:\n            visited[h-1, c] = True; q.append((h-1, c))\n    for r in range(h):\n        if background[r, 0]:\n            visited[r, 0] = True; q.append((r, 0))\n        if background[r, w-1]:\n            visited[r, w-1] = True; q.append((r, w-1))\n    while q:\n        rr, cc = q.popleft()\n        for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n            nr, nc = rr+dr, cc+dc\n            if 0 <= nr < h and 0 <= nc < w and background[nr, nc] and not visited[nr, nc]:\n                visited[nr, nc] = True\n                q.append((nr, nc))\n    # remaining background pixels are internal holes\n    holes_mask = np.logical_and(background, ~visited)\n    if np.count_nonzero(holes_mask) == 0:\n        return 0.0\n    # label holes and compute centroids (simple flood fill)\n    holes_centroids_y = []\n    visited_holes = np.zeros_like(holes_mask, dtype=bool)\n    for r in range(h):\n        for c in range(w):\n            if holes_mask[r, c] and not visited_holes[r, c]:\n                # flood fill this hole\n                stack = [(r, c)]\n                visited_holes[r, c] = True\n                coords = []\n                while stack:\n                    rr, cc = stack.pop()\n                    coords.append((rr, cc))\n                    for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n                        nr, nc = rr+dr, cc+dc\n                        if 0 <= nr < h and 0 <= nc < w and holes_mask[nr, nc] and not visited_holes[nr, nc]:\n                            visited_holes[nr, nc] = True\n                            stack.append((nr, nc))\n                coords = np.array(coords)\n                cent_y = coords[:,0].mean() / float(h)\n                holes_centroids_y.append(cent_y)\n    if len(holes_centroids_y) == 0:\n        return 0.0\n    return float(np.mean(holes_centroids_y))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of significant peaks in the vertical projection (row-sum peaks), smoothed and normalized'\n    import numpy as np\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img.astype(float)\n    med = np.median(gray)\n    prop = float(np.mean(gray < med))\n    thr = np.percentile(gray, 20) if prop > 0.5 else med\n    bw = (gray < thr).astype(np.uint8)\n    if bw.sum() == 0:\n        bw = (gray > thr).astype(np.uint8)\n    proj = bw.sum(axis=1).astype(float)\n    if proj.max() == 0:\n        return 0.0\n    # smooth projection\n    kernel = np.ones(5) / 5.0\n    smooth = np.convolve(proj, kernel, mode='same')\n    meanv = smooth.mean()\n    # count local maxima above a fraction of mean\n    peaks = 0\n    for i in range(1, len(smooth)-1):\n        if smooth[i] > smooth[i-1] and smooth[i] > smooth[i+1] and smooth[i] > max(1e-6, 0.5*meanv):\n            peaks += 1\n    # normalize by plausible max (3 or h/10)\n    norm = max(1.0, float(min(5, h/10.0)))\n    return float(peaks / norm)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian zero-crossing rate: normalized count of sign changes in Laplacian (edge complexity)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    gyy = np.gradient(gy, axis=0)\n    gxx = np.gradient(gx, axis=1)\n    lap = gxx + gyy\n    s = np.sign(lap)\n    # treat zeros as no sign to avoid false crossings\n    s[s == 0] = 0\n    hz = (s[:, :-1] * s[:, 1:]) < 0\n    vt = (s[:-1, :] * s[1:, :]) < 0\n    count = int(np.count_nonzero(hz)) + int(np.count_nonzero(vt))\n    result = float(count) / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of prominent peaks in the horizontal (column) ink projection; helps separate wide loops from narrow strokes'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    if border_mean > np.median(gray):\n        thr = (border_mean + float(np.min(gray))) / 2.0\n        ink = gray < thr\n    else:\n        thr = (border_mean + float(np.max(gray))) / 2.0\n        ink = gray > thr\n    ink = ink.astype(np.uint8)\n    col_sum = np.sum(ink, axis=0).astype(float)\n    if w < 3 or np.max(col_sum) <= 0:\n        return 0.0\n    smooth = np.convolve(col_sum, np.array([1.0, 1.0, 1.0]) / 3.0, mode='same')\n    mean_val = np.mean(smooth)\n    peaks = 0\n    for i in range(1, len(smooth) - 1):\n        if smooth[i] > smooth[i - 1] and smooth[i] > smooth[i + 1] and smooth[i] > 0.25 * mean_val:\n            peaks += 1\n    return float(peaks)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from 2D FFT (outer frequencies / total)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute power spectrum\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    ps = (np.abs(F) ** 2)\n    ys, xs = np.indices(ps.shape)\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    dist = np.hypot(xs - cx, ys - cy)\n    maxd = float(np.hypot(cx, cy)) + eps\n    # define high frequency as >50% of max radius\n    hf_mask = dist > (0.5 * maxd)\n    total = float(ps.sum()) + eps\n    hf = float(ps[hf_mask].sum())\n    result = hf / total\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of ink/background transitions per row in the central third of rows (measures stroke complexity and crossings like the crossbar in \"4\")'\n    import numpy as np\n    h, w = image.shape[:2]\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    thr = np.mean(gray)\n    mask = gray < thr\n    prop = mask.mean()\n    if prop > 0.9 or prop < 0.01:\n        mask = gray > thr\n    r1 = h // 3; r2 = min(h, 2 * h // 3)\n    if r2 <= r1:\n        return 0.0\n    region = mask[r1:r2, :]\n    # transitions per row: sum of absolute diffs along columns\n    diffs = np.abs(np.diff(region.astype(np.int8), axis=1))\n    transitions_per_row = diffs.sum(axis=1)\n    avg_trans = float(transitions_per_row.mean() / (w + 1e-9))\n    return avg_trans\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative energy of gradients aligned near -45 degrees (normalized 0..1)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gx, gy = np.gradient(gray)\n    mag = np.hypot(gx, gy)\n    total_energy = mag.sum()\n    if total_energy <= 0:\n        return 0.0\n    orient = np.arctan2(gy, gx)\n    target = -np.pi / 4.0\n    # angular difference in [-pi, pi]\n    diff = np.arctan2(np.sin(orient - target), np.cos(orient - target))\n    angle_tol = np.pi / 8.0  # 22.5 degrees tolerance\n    mask = np.abs(diff) <= angle_tol\n    energy_aligned = mag[mask].sum()\n    return float(energy_aligned / (total_energy + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest continuous horizontal ink run in the top third normalized by image width (0..1)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    p30, p70 = np.percentile(gray, 30), np.percentile(gray, 70)\n    dark_mask = gray < p30\n    light_mask = gray > p70\n    ink = dark_mask if dark_mask.sum() >= light_mask.sum() else light_mask\n    h, w = ink.shape\n    top = ink[:max(1, h//3), :]\n    if top.size == 0 or top.sum() == 0:\n        return 0.0\n    max_run = 0\n    # compute runs per row\n    for row in top:\n        # convert bool row to int and find max consecutive ones\n        r = row.astype(np.uint8)\n        # find edges\n        if r.sum() == 0:\n            continue\n        # run-length via diff\n        diff = np.diff(np.concatenate(([0], r, [0])))\n        starts = np.where(diff == 1)[0]\n        ends = np.where(diff == -1)[0]\n        if starts.size and ends.size:\n            runs = ends - starts\n            max_run = max(max_run, runs.max())\n    return float(max_run / float(w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation concentration (0=uniform, 1=all edges same orientation)'\n    import numpy as np\n    eps = 1e-12\n    bins = 16\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(image.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(image.astype(float))\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    hist, _ = np.histogram(theta, bins=bins, range=(-np.pi, np.pi), weights=mag)\n    total = hist.sum() + eps\n    max_bin = float(hist.max())\n    result = max_bin / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized histogram entropy of intensities (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    a_flat = a.ravel()\n    mn = float(a_flat.min())\n    mx = float(a_flat.max())\n    if mx - mn < eps:\n        return 0.0\n    bins = 32\n    counts, _ = np.histogram(a_flat, bins=bins, range=(mn, mx))\n    total = float(counts.sum()) + eps\n    p = counts.astype(float) / total\n    p_nonzero = p[p > 0.0]\n    ent = -float((p_nonzero * np.log(p_nonzero)).sum())\n    # normalize by log(bins)\n    norm = float(np.log(bins)) + eps\n    result = ent / norm\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant global gradient orientation strength (0..1): anisotropy * alignment to horizontal'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    Sxx = float(np.sum(gx * gx))\n    Syy = float(np.sum(gy * gy))\n    Sxy = float(np.sum(gx * gy))\n    trace = Sxx + Syy\n    diff = np.sqrt(max((Sxx - Syy) ** 2 + 4.0 * Sxy ** 2, 0.0))\n    lam1 = 0.5 * (trace + diff)\n    lam2 = 0.5 * (trace - diff)\n    anis = (lam1 - lam2) / (lam1 + lam2 + eps)\n    angle = 0.5 * np.arctan2(2.0 * Sxy, (Sxx - Syy))\n    align = abs(np.cos(angle))\n    result = anis * align\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center vs border contrast normalized by overall mean'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ch, cw = h // 4, w // 4\n    center = img[ch:3*ch or None, cw:3*cw or None]\n    if center.size == 0:\n        return 0.0\n    mask = np.ones_like(img, dtype=bool)\n    mask[ch:3*ch or None, cw:3*cw or None] = False\n    border = img[mask]\n    if border.size == 0:\n        return 0.0\n    center_mean = float(center.mean())\n    border_mean = float(border.mean())\n    overall_mean = float(img.mean()) + eps\n    result = (center_mean - border_mean) / overall_mean\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of left-third columns that contain any ink (indicates presence of a left vertical stroke)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    h, w = gray.shape[:2]\n    left_w = max(1, w // 3)\n    border = np.concatenate([gray[:3, :].ravel(), gray[-3:, :].ravel(), gray[:, :3].ravel(), gray[:, -3:].ravel()]) if h>=3 and w>=3 else gray.ravel()\n    center = gray[h//4:3*h//4, w//4:3*w//4] if h>=4 and w>=4 else gray\n    border_mean = float(border.mean()) if border.size else 0.0\n    thresh = float(np.percentile(gray, 50)) if gray.size else 0.5\n    ink = (gray < thresh) if border_mean > (center.mean() if center.size else 0.0) else (gray > thresh)\n    ink = ink.astype(np.uint8)\n    left_block = ink[:, :left_w]\n    if left_block.size == 0:\n        return 0.0\n    cols_with_ink = np.sum(np.any(left_block, axis=0))\n    return float(cols_with_ink / left_w)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation entropy (0..1), 0=single dominant orientation, 1=uniform'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = mag.sum()\n    if total <= eps:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    bins = 16\n    hist, _ = np.histogram(ang, bins=bins, range=(-np.pi, np.pi), weights=mag)\n    probs = hist.astype(float) / (hist.sum() + eps)\n    probs = probs[probs > 0.0]\n    if probs.size == 0:\n        return 0.0\n    ent = -np.sum(probs * np.log(probs))\n    result = float(ent / (np.log(bins) + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate circularity: 4*pi*area / (perimeter^2) where 1.0 is perfect circle, 0 if undefined'\n    import numpy as _np\n    if len(image.shape) == 3:\n        gray = _np.mean(image, axis=2)\n    else:\n        gray = image.astype(_np.float32)\n    m = _np.mean(gray)\n    ink = (gray < m).astype(_np.uint8)\n    area = float(ink.sum())\n    if area <= 0.0:\n        return 0.0\n    # perimeter estimate: ink pixels that have at least one 4-neighbor background\n    padded = _np.pad(ink, pad_width=1, mode='constant', constant_values=0)\n    perim = 0\n    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n        neighbor = padded[1+dy:padded.shape[0]-1+dy, 1+dx:padded.shape[1]-1+dx]\n        perim += _np.sum((ink == 1) & (neighbor == 0))\n    perim = float(perim)\n    if perim <= 0.0:\n        return 0.0\n    circ = float((4.0 * _np.pi * area) / (perim * perim))\n    return circ\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity slope from center: linear slope of annular means normalized by std'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    yy = np.arange(h)[:, None]\n    xx = np.arange(w)[None, :]\n    r = np.hypot(yy - cy, xx - cx)\n    rmax = float(r.max()) + eps\n    # bin into up to 10 annuli\n    nbins = min(10, max(2, int(rmax)))\n    bins = np.linspace(0.0, rmax, nbins + 1)\n    inds = np.digitize(r.ravel(), bins) - 1\n    means = []\n    centers = []\n    flat = a.ravel()\n    for i in range(nbins):\n        mask = inds == i\n        if not np.any(mask):\n            continue\n        means.append(float(flat[mask].mean()))\n        centers.append(float((bins[i] + bins[i+1]) / 2.0))\n    if len(means) < 2:\n        return 0.0\n    x = np.array(centers)\n    y = np.array(means)\n    xm = x.mean()\n    ym = y.mean()\n    denom = np.sum((x - xm) ** 2) + eps\n    slope = np.sum((x - xm) * (y - ym)) / denom\n    result = slope / (float(a.std()) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Robust contrast: interquartile range divided by image std (clipped)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    p25 = float(np.percentile(a, 25))\n    p75 = float(np.percentile(a, 75))\n    iqr = p75 - p25\n    std = float(a.std()) + eps\n    result = iqr / std\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Slope of the bottom contour (rows of lowest ink pixel per column) normalized to image aspect (positive = downward to right)'\n    import numpy as np\n    try:\n        h, w = image.shape[:2]\n        if h < 2 or w < 2:\n            return 0.0\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        p40, p60 = np.percentile(gray, 40), np.percentile(gray, 60)\n        midpoint = (gray.max() + gray.min()) / 2.0\n        if np.mean(gray) > midpoint:\n            ink = gray < p40\n        else:\n            ink = gray > p60\n        bottom_rows = np.full(w, np.nan, dtype=float)\n        for c in range(w):\n            col = ink[:, c]\n            ys = np.where(col)[0]\n            if ys.size:\n                bottom_rows[c] = float(ys.max())\n        valid = ~np.isnan(bottom_rows)\n        if valid.sum() < 2:\n            return 0.0\n        xs = np.arange(w)[valid].astype(float)\n        ys = bottom_rows[valid]\n        # linear fit ys = m*xs + b\n        try:\n            m, b = np.polyfit(xs, ys, 1)\n        except Exception:\n            return 0.0\n        # normalize slope by image aspect: convert rows/col to fraction of height per width: (m * w) / h\n        slope_norm = float(m * (w / float(max(1, h))))\n        return slope_norm\n    except Exception:\n        return 0.0\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean horizontal gradient magnitude in the top-right quadrant to bottom-right quadrant (right-side curvature balance)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2 or np.all(gray == gray.flat[0]):\n        return 0.0\n    grad_row, grad_col = np.gradient(gray)\n    right = slice(w//2, w)\n    top = slice(0, h//2)\n    bottom = slice(h//2, h)\n    top_right = np.abs(grad_col[top, right])\n    bottom_right = np.abs(grad_col[bottom, right])\n    top_mean = float(np.mean(top_right)) if top_right.size > 0 else 0.0\n    bottom_mean = float(np.mean(bottom_right)) if bottom_right.size > 0 else 0.0\n    eps = 1e-6\n    return float(top_mean / (bottom_mean + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-to-border variance ratio: var(center) / (var(border) + eps), capped at 100'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    ch0, ch1 = h // 4, 3 * h // 4\n    cw0, cw1 = w // 4, 3 * w // 4\n    center = a[ch0:ch1, cw0:cw1]\n    border_mask = np.ones_like(a, dtype=bool)\n    border_mask[ch0:ch1, cw0:cw1] = False\n    border = a[border_mask]\n    if center.size == 0 or border.size == 0:\n        return 0.0\n    var_center = float(np.var(center))\n    var_border = float(np.var(border))\n    result = var_center / (var_border + eps)\n    return float(np.clip(result, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Eccentricity proxy: ratio of principal covariance eigenvalues of ink coordinates (>=1)'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(gray.min()), float(gray.max())\n    rng = mx - mn + eps\n    norm = (gray - mn) / rng\n    ink = norm < 0.5 if np.mean(norm) > 0.5 else norm > 0.5\n    ys, xs = np.where(ink)\n    if ys.size < 3:\n        return 0.0\n    coords = np.stack([xs.astype(float), ys.astype(float)], axis=0)\n    cov = np.cov(coords)\n    # numerical safety\n    trace = cov.trace() + eps\n    # eigenvalues of 2x2 symmetric matrix\n    a, b = cov[0,0], cov[0,1]\n    c = cov[1,1]\n    term = np.sqrt(max(0.0, (a - c)**2 + 4*b*b))\n    l1 = 0.5 * (a + c + term)\n    l2 = 0.5 * (a + c - term)\n    l1, l2 = max(l1, eps), max(l2, eps)\n    return float(l1 / l2)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference between number of non-empty rows and columns (normalized)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.median(a.ravel())\n    row_nonzero = np.count_nonzero(np.any(a > thr, axis=1))\n    col_nonzero = np.count_nonzero(np.any(a > thr, axis=0))\n    denom = max(1, max(row_nonzero, col_nonzero))\n    result = (row_nonzero - col_nonzero) / denom\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio score of the foreground bounding box (1.0 = square, lower = elongated)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # foreground defined as pixels > median to be robust\n    med = np.median(arr)\n    mask = arr > med\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    ymin, ymax = ys.min(), ys.max()\n    xmin, xmax = xs.min(), xs.max()\n    bh = max(1, ymax - ymin + 1)\n    bw = max(1, xmax - xmin + 1)\n    ratio = min(bw / float(bh + eps), bh / float(bw + eps))\n    # normalize ratio to [0,1], where 1 is square\n    result = float(np.clip(ratio, 0.0, 1.0))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of enclosed white regions (holes) inside the ink strokes'\n    import numpy as np\n    h, w = image.shape[:2]\n    # convert to grayscale float\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    # simple adaptive threshold\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    # if too many pixels are classified as ink, invert assumption\n    if np.mean(ink) > 0.75:\n        ink = ~ink\n    # mark background pixels reachable from image border\n    visited = np.zeros((h, w), dtype=bool)\n    stack = []\n    # push border background pixels\n    for i in range(h):\n        for j in (0, w - 1):\n            if not ink[i, j] and not visited[i, j]:\n                visited[i, j] = True\n                stack.append((i, j))\n    for j in range(w):\n        for i in (0, h - 1):\n            if not ink[i, j] and not visited[i, j]:\n                visited[i, j] = True\n                stack.append((i, j))\n    while stack:\n        i, j = stack.pop()\n        for di in (-1, 0, 1):\n            ni = i + di\n            if ni < 0 or ni >= h:\n                continue\n            for dj in (-1, 0, 1):\n                nj = j + dj\n                if nj < 0 or nj >= w:\n                    continue\n                if not ink[ni, nj] and not visited[ni, nj]:\n                    visited[ni, nj] = True\n                    stack.append((ni, nj))\n    # holes are background pixels not reachable from border\n    holes = (~visited) & (~ink)\n    # count connected components among holes\n    visited_holes = np.zeros_like(holes, dtype=bool)\n    hole_count = 0\n    for i in range(h):\n        for j in range(w):\n            if holes[i, j] and not visited_holes[i, j]:\n                hole_count += 1\n                stack = [(i, j)]\n                visited_holes[i, j] = True\n                while stack:\n                    x, y = stack.pop()\n                    for di in (-1, 0, 1):\n                        nx = x + di\n                        if nx < 0 or nx >= h:\n                            continue\n                        for dj in (-1, 0, 1):\n                            ny = y + dj\n                            if ny < 0 or ny >= w:\n                                continue\n                            if holes[nx, ny] and not visited_holes[nx, ny]:\n                                visited_holes[nx, ny] = True\n                                stack.append((nx, ny))\n    return float(hole_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the central horizontal band (middle 30% of rows) vs whole ink mass (detects open-center 3/5)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    p5, p95 = np.percentile(gray, 5), np.percentile(gray, 95)\n    th = (p5 + p95) / 2.0\n    mask = gray < th\n    if mask.sum() > 0.9 * gray.size:\n        mask = gray > th\n    if mask.sum() == 0:\n        mask = gray < np.mean(gray)\n    top = int(h * 0.35)\n    bottom = int(h * 0.65)\n    central = mask[top:bottom, :]\n    central_count = float(np.sum(central))\n    total = float(np.sum(mask))\n    if total == 0:\n        return 0.0\n    return float(central_count / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient angle as a fraction of full circle (0..1), weighted by gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    bins = 36\n    hist, edges = np.histogram(theta, bins=bins, range=(-np.pi, np.pi), weights=mag)\n    if hist.sum() <= 0:\n        return 0.0\n    dominant_idx = int(np.argmax(hist))\n    # map bin center to fraction of circle\n    bin_center = 0.5 * (edges[dominant_idx] + edges[dominant_idx + 1])\n    frac = (bin_center + np.pi) / (2 * np.pi)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness score (Hasler & S\u00fcsstrunk) for RGB images, 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    # use first three channels as R,G,B\n    R = np.nan_to_num(img[..., 0].astype(float))\n    G = np.nan_to_num(img[..., 1].astype(float))\n    B = np.nan_to_num(img[..., 2].astype(float))\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.abs(np.mean(rg)))\n    mean_yb = float(np.abs(np.mean(yb)))\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    return float(colorfulness + eps)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1, higher => more texture/variety)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    bins = 64\n    vmin, vmax = float(a.min()), float(a.max())\n    if vmax <= vmin:\n        return 0.0\n    hist, _ = np.histogram(a, bins=bins, range=(vmin, vmax))\n    p = hist.astype(float) + eps\n    p = p / p.sum()\n    entropy = -np.sum(p * np.log2(p))\n    norm = np.log2(bins) + eps\n    result = float(entropy / norm)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast of the brightest quadrant: (max_quadrant_mean - global_mean) / global_std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    midy, midx = h // 2, w // 2\n    q1 = a[:midy, :midx]    # top-left\n    q2 = a[:midy, midx:]    # top-right\n    q3 = a[midy:, :midx]    # bottom-left\n    q4 = a[midy:, midx:]    # bottom-right\n    means = []\n    for q in (q1, q2, q3, q4):\n        means.append(float(q.mean()) if q.size else 0.0)\n    global_mean = float(a.mean())\n    global_std = float(a.std()) + eps\n    max_q = max(means)\n    result = (max_q - global_mean) / global_std\n    # crop to reasonable range\n    return float(np.clip(result, -5.0, 5.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-region compactness: normalized compactness = (perimeter^2) / (4*pi*area) (1 => compact like circle)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = (a > thr)\n    area = float(mask.sum())\n    if area < 1.0:\n        return 0.0\n    # approximate perimeter: mask pixels that have at least one 4-neighbor False\n    up = np.roll(mask, 1, axis=0)\n    down = np.roll(mask, -1, axis=0)\n    left = np.roll(mask, 1, axis=1)\n    right = np.roll(mask, -1, axis=1)\n    neighbor_all = up & down & left & right\n    # perimeter pixels are mask True with any neighbor False\n    perimeter = float(((mask) & (~neighbor_all)).sum())\n    compactness = (perimeter ** 2) / (4.0 * np.pi * area + 1e-12)\n    return float(np.clip(compactness, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Euler number: number of connected ink components minus number of holes'\n    import numpy as _np\n    if len(image.shape) == 3:\n        gray = _np.mean(image, axis=2)\n    else:\n        gray = image.astype(_np.float32)\n    h, w = gray.shape\n    m = _np.mean(gray)\n    ink = (gray < m).astype(_np.uint8)\n    if ink.sum() == 0:\n        return 0.0\n    visited = _np.zeros_like(ink, dtype=_np.uint8)\n    components = 0\n    for y in range(h):\n        for x in range(w):\n            if ink[y, x] and not visited[y, x]:\n                components += 1\n                stack = [(y, x)]\n                visited[y, x] = 1\n                while stack:\n                    cy, cx = stack.pop()\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = cy + dy, cx + dx\n                            if 0 <= ny < h and 0 <= nx < w:\n                                if ink[ny, nx] and not visited[ny, nx]:\n                                    visited[ny, nx] = 1\n                                    stack.append((ny, nx))\n    # count holes using inverted components that do not touch border\n    bg = (ink == 0).astype(_np.uint8)\n    visited_bg = _np.zeros_like(bg, dtype=_np.uint8)\n    holes = 0\n    for y in range(h):\n        for x in range(w):\n            if bg[y, x] and not visited_bg[y, x]:\n                stack = [(y, x)]\n                visited_bg[y, x] = 1\n                touches_border = False\n                while stack:\n                    cy, cx = stack.pop()\n                    if cy == 0 or cx == 0 or cy == h - 1 or cx == w - 1:\n                        touches_border = True\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = cy + dy, cx + dx\n                            if 0 <= ny < h and 0 <= nx < w:\n                                if bg[ny, nx] and not visited_bg[ny, nx]:\n                                    visited_bg[ny, nx] = 1\n                                    stack.append((ny, nx))\n                if not touches_border:\n                    holes += 1\n    euler = float(components - holes)\n    return euler\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation fraction (0..1), measured in 12 orientation bins'\n    import numpy as np\n    eps = 1e-12\n    bins = 12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    ang = np.degrees(np.arctan2(gy, gx)) % 180.0  # unsigned orientations\n    hist, _ = np.histogram(ang.ravel(), bins=bins, range=(0.0, 180.0), weights=mag.ravel())\n    total = float(hist.sum()) + eps\n    result = float(hist.max()) / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box fill ratio: ink pixel count divided by bounding box area containing ink (compactness)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    mask_lo = gray < th\n    mask_hi = gray > th\n    mask = (mask_lo if np.count_nonzero(mask_lo) <= np.count_nonzero(mask_hi) else mask_hi)\n    coords = np.column_stack(np.nonzero(mask))\n    if coords.size == 0:\n        return 0.0\n    y0, x0 = coords.min(axis=0)\n    y1, x1 = coords.max(axis=0)\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    ink_count = float(np.count_nonzero(mask))\n    return float(ink_count / max(1e-6, bbox_area))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right (vertical axis) symmetry: 1 - normalized mean abs difference (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 1.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 1.0\n    try:\n        mirror = np.fliplr(a)\n    except Exception:\n        return 0.0\n    diff = np.abs(a - mirror)\n    mean_diff = float(diff.mean())\n    mean_val = float(np.mean(np.abs(a))) + eps\n    score = 1.0 - (mean_diff / mean_val)\n    return float(np.clip(score, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of intensity centroid from image center (0..1), 1 => far from center'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    ys, xs = np.indices((h, w))\n    weights = a.copy()\n    total = float(weights.sum())\n    if total == 0:\n        return 0.0\n    cy = float((ys * weights).sum()) / total\n    cx = float((xs * weights).sum()) / total\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    maxd = np.hypot(center_x, center_y) + 1e-12\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation score (-1 vertical .. +1 horizontal), weighted by confidence'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() < eps:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    # compute resultant vector of angle doubled so that 180deg apart orientations align\n    cx = np.sum(np.cos(2.0 * ang) * mag)\n    sy = np.sum(np.sin(2.0 * ang) * mag)\n    R = np.hypot(cx, sy)\n    Rnorm = R / (mag.sum() + eps)  # [0..1] confidence\n    theta = 0.5 * np.arctan2(sy, cx + eps)  # mean angle\n    # use cos(2*theta) to map to [-1..1] where +1 ~ horizontal, -1 ~ vertical\n    orient = np.cos(2.0 * theta)\n    result = float(np.clip(orient * Rnorm, -1.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Angle in degrees from global ink centroid to the top-right ink centroid (captures diagonal down-right of 7)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    pad_h = max(1, h // 10)\n    pad_w = max(1, w // 10)\n    border = np.concatenate([gray[:pad_h, :].ravel(), gray[-pad_h:, :].ravel(),\n                             gray[:, :pad_w].ravel(), gray[:, -pad_w:].ravel()])\n    border_mean = float(np.mean(border)) if border.size else float(np.mean(gray))\n    rng = float(np.max(gray) - np.min(gray) + 1e-8)\n    if np.median(gray) < border_mean:\n        thresh = border_mean - 0.08 * rng\n        ink = (gray < thresh).astype(np.uint8)\n    else:\n        thresh = border_mean + 0.08 * rng\n        ink = (gray > thresh).astype(np.uint8)\n    ys, xs = np.nonzero(ink)\n    if ys.size == 0:\n        return 0.0\n    cx_global = float(np.mean(xs))\n    cy_global = float(np.mean(ys))\n    # top-right region (top half, right half)\n    mask_tr = np.zeros_like(ink)\n    mask_tr[:h//2, w//2:] = 1\n    ys_tr, xs_tr = np.nonzero(ink * mask_tr)\n    if ys_tr.size == 0:\n        return 0.0\n    cx_tr = float(np.mean(xs_tr))\n    cy_tr = float(np.mean(ys_tr))\n    dx = cx_tr - cx_global\n    dy = cy_tr - cy_global\n    angle = np.degrees(np.arctan2(dy, dx))\n    return float(angle)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fill ratio of bright pixels within their bounding box (1 => box full, 0 => empty)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.median(a.ravel()) + 0.1 * (a.std() + eps))\n    ys, xs = np.nonzero(a > thr)\n    if ys.size == 0:\n        return 0.0\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bbox_area = max(1, (y1 - y0 + 1) * (x1 - x0 + 1))\n    bright_count = ys.size\n    result = float(bright_count) / float(bbox_area + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance of foreground centroid (mean-thresholded) from image center (0=center..1=edge)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        gray = np.nan_to_num(arr.astype(float))\n    h, w = gray.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(gray.mean())\n    mask = (gray > thr)\n    if not mask.any():\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    cy = float(ys.mean())\n    cx = float(xs.mean())\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    max_dist = np.hypot(center_x, center_y) + eps\n    result = dist / max_dist\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized entropy of edge orientation histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    total = mag.sum()\n    if total <= 0:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    theta = theta.ravel()\n    weights = mag.ravel()\n    # map to 0..2pi\n    theta = theta + np.pi\n    bins = 16\n    hist, _ = np.histogram(theta, bins=bins, range=(0.0, 2.0 * np.pi), weights=weights)\n    probs = hist / (hist.sum() + eps)\n    # entropy normalized by log(bins)\n    ent = -np.sum(np.where(probs > 0, probs * np.log(probs), 0.0))\n    norm_ent = ent / (np.log(bins) + eps)\n    return float(norm_ent)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of ink runs (background->ink segments) across the central vertical columns'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    scale = (gray - mn) / (mx - mn + 1e-9)\n    thr = scale.mean()\n    cand = scale < thr\n    if cand.sum() > 0.5 * h * w:\n        ink = ~cand\n    else:\n        ink = cand\n    cols = [w // 2 - 1, w // 2, w // 2 + 1]\n    cols = [c for c in cols if 0 <= c < w]\n    runs = []\n    for c in cols:\n        col = ink[:, c].astype(np.int8)\n        # count runs of consecutive 1s\n        if col.size == 0:\n            runs.append(0)\n            continue\n        diff = np.diff(np.concatenate(([0], col, [0])))\n        starts = np.where(diff == 1)[0]\n        ends = np.where(diff == -1)[0]\n        runs.append(float(len(starts)))\n    if len(runs) == 0:\n        return 0.0\n    return float(np.mean(runs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean intensity of top 1% brightest pixels normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    vals = a.ravel()\n    n = vals.size\n    if n == 0:\n        return 0.0\n    k = max(1, int(0.01 * n))\n    # partial sort for efficiency\n    thresh = np.partition(vals, -k)[-k]\n    topk = vals[vals >= thresh]\n    if topk.size == 0:\n        return 0.0\n    mean_top = float(topk.mean())\n    gstd = float(vals.std()) + eps\n    result = (mean_top - float(vals.mean())) / gstd\n    return float(np.clip(result, -50.0, 50.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity slope: linear fit slope of mean intensity vs radius (normalized)'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    dist = np.hypot(xs - cx, ys - cy)\n    maxd = float(dist.max()) + eps\n    # bin into 8 concentric rings\n    bins = np.linspace(0.0, maxd, num=9)\n    means = []\n    centers = []\n    for i in range(len(bins)-1):\n        mask = (dist >= bins[i]) & (dist < bins[i+1])\n        if not mask.any():\n            continue\n        centers.append(0.5*(bins[i]+bins[i+1]) / maxd)\n        means.append(float(a[mask].mean()))\n    if len(means) < 2:\n        return 0.0\n    x = np.array(centers)\n    y = np.array(means)\n    # linear fit\n    A = np.vstack([x, np.ones_like(x)]).T\n    try:\n        m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n    except Exception:\n        return 0.0\n    # normalize slope by intensity range\n    intensity_range = float(y.max() - y.min()) + eps\n    result = float(m * (1.0 / intensity_range))\n    # clamp to reasonable range\n    return float(np.clip(result, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal-component variance ratio of bright pixels (fraction of variance explained by first PC, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.median(a))\n    ys, xs = np.where(a > thr)\n    if xs.size < 2:\n        return 0.0\n    xs_f = xs.astype(float)\n    ys_f = ys.astype(float)\n    mx = xs_f.mean()\n    my = ys_f.mean()\n    X = np.vstack([xs_f - mx, ys_f - my])\n    cov = np.cov(X)\n    # handle degenerate\n    if cov.shape != (2, 2):\n        return 0.0\n    vals = np.linalg.eigvalsh(cov)\n    vals = np.sort(vals)[::-1]  # descending\n    total = float(vals.sum()) + eps\n    ratio = float(vals[0]) / total\n    return float(np.clip(ratio, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute vertical gradient in right quarter to left quarter (detects right-side vertical strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    gy, gx = np.gradient(gray)\n    abs_v = np.abs(gy)\n    midc = w // 2\n    left = abs_v[:, :midc]\n    right = abs_v[:, midc:]\n    mean_left = np.mean(left) + 1e-9\n    mean_right = np.mean(right)\n    return float(mean_right / mean_left)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0..1), 0 for grayscale inputs'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    # Use first three channels as R,G,B\n    try:\n        R = np.nan_to_num(img[:, :, 0].astype(float))\n        G = np.nan_to_num(img[:, :, 1].astype(float))\n        B = np.nan_to_num(img[:, :, 2].astype(float))\n    except Exception:\n        return 0.0\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    # Hasler and S\u00fcsstrunk colorfulness\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    # normalize by dynamic range estimate\n    max_chan = max(float(R.max()), float(G.max()), float(B.max()), eps)\n    result = colorfulness / (max_chan + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Perceptual colorfulness metric (normalized), 0..~1 for typical images'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    # use first three channels as R,G,B\n    try:\n        R = np.nan_to_num(img[..., 0].astype(float))\n        G = np.nan_to_num(img[..., 1].astype(float))\n        B = np.nan_to_num(img[..., 2].astype(float))\n    except Exception:\n        return 0.0\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    raw = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    # normalize by dynamic range estimate\n    maxval = float(np.max(img)) if img.size else 1.0\n    denom = max(maxval, 1.0)\n    result = raw / (denom + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between mean of top10% and bottom10% intensities normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    p90 = np.percentile(flat, 90)\n    p10 = np.percentile(flat, 10)\n    top_mean = float(flat[flat >= p90].mean()) if np.any(flat >= p90) else float(np.mean(flat))\n    bot_mean = float(flat[flat <= p10].mean()) if np.any(flat <= p10) else float(np.mean(flat))\n    std = float(np.std(flat)) + eps\n    result = (top_mean - bot_mean) / std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Binary mask eccentricity (1 - minor/major eigenvalue) of median-based mask (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    med = float(np.median(a))\n    mask = a > med\n    if mask.sum() < 3:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    dx = xs.astype(float) - float(xs.mean())\n    dy = ys.astype(float) - float(ys.mean())\n    cov_xx = float((dx * dx).mean())\n    cov_xy = float((dx * dy).mean())\n    cov_yy = float((dy * dy).mean())\n    trace = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    # eigenvalues of 2x2 covariance\n    disc = max(0.0, trace * trace / 4.0 - det)\n    l1 = trace / 2.0 + np.sqrt(disc)\n    l2 = trace / 2.0 - np.sqrt(disc)\n    major = float(max(l1, l2))\n    minor = float(min(l1, l2)) + eps\n    ecc = 1.0 - (minor / (major + eps))\n    return float(np.clip(ecc, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum continuous horizontal ink run in the bottom 20% rows normalized by image width (bottom-stroke indicator)'\n    import numpy as np\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img.astype(float)\n    med = np.median(gray)\n    prop = float(np.mean(gray < med))\n    thr = np.percentile(gray, 20) if prop > 0.5 else med\n    bw = (gray < thr).astype(np.uint8)\n    if bw.sum() == 0:\n        bw = (gray > thr).astype(np.uint8)\n    bottom_rows = max(1, int(np.ceil(0.20 * h)))\n    region = bw[-bottom_rows:, :]\n    max_run = 0\n    for r in region:\n        if r.sum() == 0:\n            continue\n        diff = np.diff(np.concatenate(([0], r, [0])))\n        starts = np.where(diff == 1)[0]\n        ends = np.where(diff == -1)[0]\n        if len(starts) and len(ends):\n            runs = (ends - starts)\n            max_run = max(max_run, runs.max())\n    return float(max_run / max(1, w))\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of prominent histogram peaks (modes) using 64 bins, returned as a small float'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        flat = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(img.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    amin, amax = flat.min(), flat.max()\n    if amax <= amin:\n        return 0.0\n    nb = 64\n    hist, edges = np.histogram(flat, bins=nb, range=(amin, amax))\n    # small smoothing\n    kern = np.array([1, 2, 1], dtype=float)\n    hist_s = np.convolve(hist.astype(float), kern, mode='same')\n    thr = max(hist_s.mean() * 0.1, 1.0)\n    peaks = 0\n    for i in range(1, hist_s.size - 1):\n        if hist_s[i] > hist_s[i - 1] and hist_s[i] > hist_s[i + 1] and hist_s[i] >= thr:\n            peaks += 1\n    return float(peaks)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right mirror symmetry correlation mapped to [0..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = img.mean(axis=2).astype(float)\n    else:\n        a = img.astype(float)\n    h, w = a.shape\n    if w < 2 or h < 1:\n        return 0.0\n    left = a[:, : (w // 2)]\n    right = a[:, (w - (w // 2)):]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    right_flipped = np.fliplr(right)\n    # ensure same shape\n    if left.shape != right_flipped.shape:\n        # crop larger to match smaller\n        mh = min(left.shape[0], right_flipped.shape[0])\n        mw = min(left.shape[1], right_flipped.shape[1])\n        left = left[:mh, :mw]\n        right_flipped = right_flipped[:mh, :mw]\n    L = left.ravel()\n    R = right_flipped.ravel()\n    Lm = L.mean()\n    Rm = R.mean()\n    Lc = L - Lm\n    Rc = R - Rm\n    num = float((Lc * Rc).sum())\n    den = float(np.sqrt((Lc * Lc).sum() * (Rc * Rc).sum()))\n    if den <= 0.0:\n        return 0.0\n    corr = num / (den + eps)\n    # map from [-1,1] to [0,1]\n    result = float(np.clip((corr + 1.0) / 2.0, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average row-wise periodicity score (0..1) based on strongest non-DC FFT peak'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    scores = []\n    for row in a:\n        r = row - row.mean()\n        P = np.abs(np.fft.rfft(r)) ** 2\n        if P.size <= 1:\n            scores.append(0.0)\n            continue\n        # exclude DC (index 0)\n        total = P.sum() + eps\n        peak = P[1:].max()\n        scores.append(float(peak / total))\n    if len(scores) == 0:\n        return 0.0\n    return float(np.clip(np.mean(scores), 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score via normalized cross-correlation ( -1..1, 1 => perfect symmetric)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    # mirror right to align\n    right_mirror = np.fliplr(right)\n    # crop to same shape\n    min_w = min(left.shape[1], right_mirror.shape[1])\n    left_c = left[:, :min_w].ravel()\n    right_c = right_mirror[:, :min_w].ravel()\n    if left_c.size == 0 or right_c.size == 0:\n        return 0.0\n    left_c = left_c - left_c.mean()\n    right_c = right_c - right_c.mean()\n    denom = (np.linalg.norm(left_c) * np.linalg.norm(right_c) + eps)\n    corr = float(np.dot(left_c, right_c) / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram peakiness: how dominated the image is by a single intensity bin (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    mn = float(a.min()); mx = float(a.max())\n    if mx <= mn + eps:\n        return 0.0\n    hist, _ = np.histogram(a.flatten(), bins=bins, range=(mn, mx))\n    if hist.sum() == 0:\n        return 0.0\n    peak_ratio = float(hist.max()) / (float(hist.mean()) + eps)\n    # map to 0..1 smoothly\n    result = float(np.tanh((peak_ratio - 1.0) / 5.0))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity skewness (third standardized moment) clipped to [-5,5]'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2)).ravel()\n    else:\n        arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size < 2:\n        return 0.0\n    mu = float(arr.mean())\n    std = float(arr.std())\n    if std <= 0:\n        return 0.0\n    m3 = float(((arr - mu) ** 3).mean())\n    skew = m3 / (std ** 3)\n    skew = max(min(skew, 5.0), -5.0)\n    return float(skew)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of horizontal spread to vertical spread of ink (var_x / var_y) to indicate whether digit is wider or taller'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = float(np.percentile(gray, 40))\n    ink = (gray <= thresh).astype(np.uint8)\n    ys, xs = np.nonzero(ink)\n    if xs.size == 0:\n        return 0.0\n    var_x = float(np.var(xs))\n    var_y = float(np.var(ys))\n    if var_y < 1e-6:\n        return float(var_x / (var_y + 1e-6))\n    return float(var_x / var_y)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density: fraction of pixels with gradient magnitude above local threshold'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    mean = float(mag.mean())\n    std = float(mag.std())\n    thresh = mean + std  # adapt to image\n    count = float(np.count_nonzero(mag > thresh))\n    result = count / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Balance between dark and bright pixels: fraction_above_median - fraction_below_median (-1..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        flat = np.nan_to_num(img.mean(axis=2).ravel().astype(float))\n    else:\n        flat = np.nan_to_num(img.ravel().astype(float))\n    if flat.size == 0:\n        return 0.0\n    med = float(np.median(flat))\n    above = float(np.count_nonzero(flat > med))\n    below = float(np.count_nonzero(flat < med))\n    total = float(flat.size)\n    result = (above - below) / (total + 1e-12)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of connected ink runs along the central column region (average over central 3 cols); loops produce multiple runs, strokes usually one'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        flat = gray.flatten()\n        t1 = np.percentile(flat, 30)\n        t2 = np.percentile(flat, 70)\n        cand1 = gray < t1\n        cand2 = gray > t2\n        total = h * w\n        if 0 < cand1.sum() <= total // 2:\n            ink = cand1\n        elif 0 < cand2.sum() <= total // 2:\n            ink = cand2\n        else:\n            med = np.median(flat)\n            ink = gray < med\n        mid = w // 2\n        cols = list(range(max(0, mid - 1), min(w, mid + 2)))\n        run_counts = []\n        for c in cols:\n            col = ink[:, c]\n            # count runs of True\n            runs = 0\n            in_run = False\n            for val in col:\n                if val and not in_run:\n                    in_run = True\n                    runs += 1\n                elif not val:\n                    in_run = False\n            run_counts.append(runs)\n        if len(run_counts) == 0:\n            return 0.0\n        return float(np.mean(run_counts))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial symmetry: variability of mean intensities across concentric annuli around image center (higher = more radial structure)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h)[:, None] - cy\n    xs = np.arange(w)[None, :] - cx\n    dist = np.hypot(ys, xs)\n    maxr = float(np.max(dist)) if dist.size else 0.0\n    if maxr <= 0:\n        return 0.0\n    nbins = max(4, int(min(h, w) / 4))\n    edges = np.linspace(0.0, maxr + eps, nbins + 1)\n    ring_means = []\n    for i in range(nbins):\n        mask = (dist >= edges[i]) & (dist < edges[i + 1])\n        if mask.any():\n            ring_means.append(float(arr[mask].mean()))\n    if len(ring_means) < 2:\n        return 0.0\n    ring_means = np.array(ring_means)\n    result = float(ring_means.std() / (arr.std() + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted elongation (1 - minor/major eigenvalue), 0..1'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if a.sum() == 0 or h < 2 or w < 2:\n        return 0.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    total = float(a.sum()) + eps\n    mean_y = float((ys * a).sum() / total)\n    mean_x = float((xs * a).sum() / total)\n    yy = (ys - mean_y)\n    xx = (xs - mean_x)\n    # compute covariance elements\n    Iyy = float((a * (yy ** 2)).sum() / total)\n    Ixx = float((a * (xx ** 2)).sum() / total)\n    Ixy = float((a * (xx * yy)).sum() / total)\n    # covariance matrix eigenvalues\n    trace = Ixx + Iyy\n    det = Ixx * Iyy - Ixy * Ixy\n    tmp = max(trace * trace / 4.0 - det, 0.0)\n    diff = float(np.sqrt(tmp))\n    lam1 = trace / 2.0 + diff\n    lam2 = trace / 2.0 - diff\n    if lam1 <= 0:\n        return 0.0\n    elong = 1.0 - (lam2 + eps) / (lam1 + eps)\n    return float(np.clip(elong, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center ring contrast: difference between average ring intensity and center disk intensity (positive if center is background hole)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    r = max(1, int(min(h, w) / 6.0))\n    yy, xx = np.ogrid[0:h, 0:w]\n    dist = np.sqrt((yy - cy)**2 + (xx - cx)**2)\n    center_mask = dist <= r\n    ring_mask = (dist > r) & (dist <= 2*r)\n    if np.sum(center_mask) == 0 or np.sum(ring_mask) == 0:\n        return 0.0\n    center_mean = float(np.mean(gray[center_mask]))\n    ring_mean = float(np.mean(gray[ring_mask]))\n    # use border to determine polarity: if border is lighter than mean then ink is dark; then hole means center is bright\n    border = np.concatenate([gray[0,:], gray[-1,:], gray[:,0], gray[:,-1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    # if border is light, background is large values; so a hole has center mean close to border_mean and ring mean is ink (low)\n    polarity = 1.0 if border_mean > np.mean(gray) else -1.0\n    contrast = polarity * (center_mean - ring_mean)\n    # normalize by global intensity range\n    denom = (np.max(gray) - np.min(gray)) + 1e-9\n    return float(contrast / denom)\n",
    "def feature(image: np.ndarray) -> float:\n    'Otsu foreground fraction: proportion of pixels above an automatically found threshold (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    a_flat = a.ravel()\n    mn = float(a_flat.min())\n    mx = float(a_flat.max())\n    if mx - mn < eps:\n        return 0.0\n    counts, bin_edges = np.histogram(a_flat, bins=256, range=(mn, mx))\n    bins = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n    total = counts.sum()\n    if total == 0:\n        return 0.0\n    prob = counts.astype(float) / float(total)\n    omega = np.cumsum(prob)\n    mu = np.cumsum(prob * bins)\n    mu_t = mu[-1]\n    # between-class variance\n    denom = omega * (1.0 - omega) + eps\n    sigma_b = (mu_t * omega - mu) ** 2 / denom\n    idx = int(np.argmax(sigma_b))\n    thresh = bins[idx]\n    fg_count = int((a_flat > thresh).sum())\n    result = float(fg_count) / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio via 3x3 mean high-pass filter (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    # compute 3x3 mean using shifts\n    s = np.zeros_like(arr, dtype=float)\n    s += arr\n    s += np.roll(arr, 1, axis=0)\n    s += np.roll(arr, -1, axis=0)\n    s += np.roll(arr, 1, axis=1)\n    s += np.roll(arr, -1, axis=1)\n    s += np.roll(np.roll(arr, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(arr, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(arr, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(arr, -1, axis=0), -1, axis=1)\n    low = s / 9.0\n    high = arr - low\n    high_energy = float(np.sum(np.abs(high)))\n    total_energy = float(np.sum(np.abs(arr))) + eps\n    result = high_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Texture coarseness: ratio of fine-scale mean abs-gradient to coarse-scale mean abs-gradient'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    fine = np.mean(np.hypot(gx, gy))\n    # simple 2x2 average pooling to make coarse image\n    ph = 2\n    pw = 2\n    h2 = h - (h % ph)\n    w2 = w - (w % pw)\n    if h2 < ph or w2 < pw:\n        coarse = a.copy()\n    else:\n        a_crop = a[:h2, :w2]\n        a_pool = a_crop.reshape(h2 // ph, ph, w2 // pw, pw).mean(axis=(1, 3))\n        coarse = a_pool\n    if coarse.size < 2:\n        coarse_grad = eps\n    else:\n        try:\n            gyc, gxc = np.gradient(coarse)\n            coarse_grad = np.mean(np.hypot(gxc, gyc))\n        except Exception:\n            coarse_grad = eps\n    result = fine / (coarse_grad + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of center-region pixels that are high contrast relative to global stats'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ch0 = h // 4\n    cw0 = w // 4\n    center = a[ch0:3*ch0 if 3*ch0>ch0 else h, cw0:3*cw0 if 3*cw0>cw0 else w]\n    if center.size == 0:\n        return 0.0\n    gmean = float(a.mean())\n    gstd = float(a.std()) + eps\n    thr = gmean + 0.75 * gstd\n    count = float(np.count_nonzero(center >= thr))\n    result = count / float(center.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference of horizontal edge energy between right and left halves ((right-left)/(right+left+eps))'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    abs_gx = np.abs(gx)\n    left = np.sum(abs_gx[:, :w//2])\n    right = np.sum(abs_gx[:, w//2:])\n    return float((right - left) / (right + left + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box area ratio of the top 5% brightest pixels (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    try:\n        thr = float(np.percentile(a, 95))\n    except Exception:\n        thr = float(a.mean())\n    mask = a > thr\n    if np.count_nonzero(mask) < 3:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    result = bbox_area / float(h * w)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical linearity score: how consistently bright centroids align vertically across columns (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    col_means = a.mean(axis=0)\n    thr = float(col_means.mean() + 0.25 * col_means.std())\n    ys = np.arange(h).reshape(h, 1)\n    centroids = []\n    for j in range(w):\n        col = a[:, j]\n        mask = col > thr\n        if mask.sum() < max(1, h // 20):\n            continue\n        weights = col[mask].astype(float)\n        ys_sel = ys[mask, 0].astype(float)\n        c = (weights * ys_sel).sum() / (weights.sum() + 1e-12)\n        centroids.append(c)\n    if len(centroids) < 2:\n        return 0.0\n    centroids = np.array(centroids, dtype=float)\n    stdc = centroids.std()\n    # normalize: if stdc small relative to height, score high\n    score = 1.0 - (stdc / (h / 2.0 + 1e-12))\n    return float(np.clip(score, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of bright local maxima above mean+2*std normalized by image area'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m + 2.0 * s\n    # compare to 8 neighbors using rolls; then zero out border to avoid wrap-around artifacts\n    center = a\n    neighs = []\n    neighs.append(np.roll(center, 1, axis=0))\n    neighs.append(np.roll(center, -1, axis=0))\n    neighs.append(np.roll(center, 1, axis=1))\n    neighs.append(np.roll(center, -1, axis=1))\n    neighs.append(np.roll(np.roll(center, 1, axis=0), 1, axis=1))\n    neighs.append(np.roll(np.roll(center, 1, axis=0), -1, axis=1))\n    neighs.append(np.roll(np.roll(center, -1, axis=0), 1, axis=1))\n    neighs.append(np.roll(np.roll(center, -1, axis=0), -1, axis=1))\n    mask = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        mask &= (center > n)\n    mask &= (center > thr)\n    # remove border rows/cols because rolls wrap\n    mask[0, :] = False\n    mask[-1, :] = False\n    mask[:, 0] = False\n    mask[:, -1] = False\n    count = float(np.count_nonzero(mask))\n    result = count / (float(a.size) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average of the largest white run lengths across rows in the top 25% of the image, normalized by width'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy()\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = float(np.percentile(gray.flatten(), 50))\n    bin_img = (gray <= thresh).astype(np.uint8)  # ink=1, white=0\n    top_h = max(1, h // 4)\n    top_region = bin_img[:top_h, :]\n    # for each row compute longest contiguous zeros (white)\n    max_runs = []\n    for r in range(top_region.shape[0]):\n        row = top_region[r, :]\n        # invert to runs of white\n        white = (row == 0).astype(np.uint8)\n        if white.sum() == 0:\n            max_runs.append(0)\n            continue\n        # compute run lengths\n        diffs = np.diff(np.concatenate(([0], white, [0])))\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        runs = (ends - starts).tolist()\n        if runs:\n            max_runs.append(max(runs))\n        else:\n            max_runs.append(0)\n    if len(max_runs) == 0:\n        return 0.0\n    avg_max = float(np.mean(max_runs))\n    return float(avg_max / (w + 1e-12))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry score (1.0 = perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    rotated = np.rot90(a, 2)\n    if a.shape != rotated.shape:\n        # fall back to center-cropped comparison\n        h, w = a.shape\n        rh, rw = rotated.shape\n        h0 = min(h, rh)\n        w0 = min(w, rw)\n        a = a[:h0, :w0]\n        rotated = rotated[:h0, :w0]\n    diff = np.abs(a - rotated)\n    denom = float(np.mean(np.abs(a)) + eps)\n    score = 1.0 - float(np.mean(diff)) / denom\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gini coefficient of absolute intensities (0 = equal, 1 = highly unequal)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        vals = np.ravel(np.nan_to_num(img.mean(axis=2).astype(float)))\n    else:\n        vals = np.ravel(np.nan_to_num(img.astype(float)))\n    vals = np.abs(vals)\n    if vals.size == 0:\n        return 0.0\n    total = float(vals.sum())\n    if total == 0.0:\n        return 0.0\n    sorted_v = np.sort(vals)\n    n = sorted_v.size\n    idx = np.arange(1, n + 1, dtype=float)\n    gini = (np.sum((2.0 * idx - n - 1.0) * sorted_v)) / (n * total)\n    result = float(np.clip(gini, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Strength of a descending diagonal stroke (top-left to bottom-right) measured by mean absolute of gx+gy'\n    import numpy as np\n    # convert to single-channel gray\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gx, gy = np.gradient(gray)\n    # use absolute of gx+gy: edges oriented along -45/45 degrees produce large same-sign gradients\n    diag = np.abs(gx + gy)\n    # normalize by overall gradient energy to be robust to contrast\n    denom = np.mean(np.abs(gx)) + np.mean(np.abs(gy)) + 1e-9\n    return float(np.mean(diag) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels that lie in the right half of the image (right density ratio)'\n    import numpy as np\n    # Grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    # Robust threshold estimation\n    p40, p60 = np.percentile(gray, 40), np.percentile(gray, 60)\n    left_vals = gray[gray <= p40]\n    right_vals = gray[gray >= p60]\n    if left_vals.size == 0: left_mean = gray.min()\n    else: left_mean = left_vals.mean()\n    if right_vals.size == 0: right_mean = gray.max()\n    else: right_mean = right_vals.mean()\n    thr = (left_mean + right_mean) / 2.0\n    ink_is_dark = left_mean < right_mean\n    ink = (gray < thr) if ink_is_dark else (gray > thr)\n    if np.count_nonzero(ink) == 0:\n        return 0.0\n    right_half = ink[:, w//2:]\n    result = float(np.count_nonzero(right_half) / (np.count_nonzero(ink) + 1e-9))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top/bottom 1% contrast normalized by dynamic range (signed)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    N = flat.size\n    if N == 0:\n        return 0.0\n    k = max(1, int(0.01 * N))\n    # get means of top and bottom k\n    idx_top = np.argpartition(flat, -k)[-k:]\n    idx_bot = np.argpartition(flat, k)[:k]\n    top_mean = float(flat[idx_top].mean())\n    bot_mean = float(flat[idx_bot].mean())\n    rng = float(flat.max() - flat.min()) + eps\n    contrast = (top_mean - bot_mean) / rng\n    return float(np.clip(contrast, -10.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top-quarter horizontal edge strength: average absolute horizontal gradient magnitude in top 25% of image'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    top_h = max(1, h // 4)\n    top_region = gray[:top_h, :]\n    # horizontal gradient: difference along columns\n    horiz_grad = np.abs(np.diff(top_region, axis=1))\n    # average normalized by intensity range\n    denom = max(1.0, float(np.ptp(gray)))\n    score = float(horiz_grad.mean()) / denom\n    return score\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate Euler number: number of ink connected components minus number of holes (helps detect closed 9 loop)'\n    import numpy as np\n    # grayscale and normalization\n    if len(image.shape) == 3:\n        g = image.mean(axis=2).astype(np.float32)\n    else:\n        g = image.astype(np.float32)\n    mx = g.max() if g.size else 1.0\n    if mx > 1.0:\n        g = g / mx\n    med = np.median(g) if g.size else 0.0\n    ink = (g < 0.5) if med > 0.5 else (g > 0.5)\n    h, w = ink.shape\n    # simple 4-connected flood fill for ink components\n    seen = np.zeros_like(ink, dtype=bool)\n    comps = 0\n    for y in range(h):\n        for x in range(w):\n            if ink[y, x] and not seen[y, x]:\n                comps += 1\n                # stack flood\n                stack = [(y, x)]\n                seen[y, x] = True\n                while stack:\n                    cy, cx = stack.pop()\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ny, nx = cy+dy, cx+dx\n                        if 0 <= ny < h and 0 <= nx < w and ink[ny, nx] and not seen[ny, nx]:\n                            seen[ny, nx] = True\n                            stack.append((ny, nx))\n    # count background components that are holes (background components not touching border)\n    bg = ~ink\n    seen_bg = np.zeros_like(bg, dtype=bool)\n    holes = 0\n    for y in range(h):\n        for x in range(w):\n            if bg[y, x] and not seen_bg[y, x]:\n                stack = [(y, x)]\n                seen_bg[y, x] = True\n                touches_border = False\n                while stack:\n                    cy, cx = stack.pop()\n                    if cy == 0 or cy == h-1 or cx == 0 or cx == w-1:\n                        touches_border = True\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ny, nx = cy+dy, cx+dx\n                        if 0 <= ny < h and 0 <= nx < w and bg[ny, nx] and not seen_bg[ny, nx]:\n                            seen_bg[ny, nx] = True\n                            stack.append((ny, nx))\n                if not touches_border:\n                    holes += 1\n    euler = comps - holes\n    return float(euler)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation dispersion (circular variance 0..1), weighted by gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    mag_sum = float(mag.sum()) + eps\n    if mag_sum <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)\n    cos_sum = float((np.cos(theta) * mag).sum())\n    sin_sum = float((np.sin(theta) * mag).sum())\n    R = np.hypot(cos_sum, sin_sum) / mag_sum\n    circ_var = 1.0 - R\n    return float(np.clip(circ_var, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of local bright peaks (strict local maxima above adaptive thresh) normalized by image area'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    # pad with very small values so edges can be peaks\n    pad = np.pad(a, pad_width=1, mode='constant', constant_values=a.min() - 1.0)\n    center = pad[1:-1, 1:-1]\n    neighs = [\n        pad[0:-2, 0:-2], pad[0:-2, 1:-1], pad[0:-2, 2:],\n        pad[1:-1, 0:-2],                 pad[1:-1, 2:],\n        pad[2:, 0:-2],   pad[2:, 1:-1],  pad[2:, 2:]\n    ]\n    comp = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        comp &= (center > n)\n    comp &= (center > thr)\n    count = int(np.count_nonzero(comp))\n    result = float(count) / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the bottom quarter of the image (lower density ratio)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gmax = gray.max()\n    if gmax > 1.5:\n        gray = gray / gmax\n    thresh = float(np.mean(gray))\n    dark_frac = float(np.mean(gray < thresh))\n    if 0.01 < dark_frac < 0.99:\n        ink = (gray < thresh) if dark_frac < 0.5 else (gray > thresh)\n    else:\n        ink = gray < thresh\n    h, w = gray.shape\n    if h < 4:\n        return float(np.count_nonzero(ink) / max(1.0, h*w))\n    bottom_start = (3 * h) // 4\n    bottom_count = float(np.count_nonzero(ink[bottom_start:h, :]))\n    total = float(np.count_nonzero(ink))\n    if total == 0.0:\n        return 0.0\n    return float(bottom_count / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Perimeter-to-area ratio: number of edge (boundary) ink pixels divided by total ink pixels (higher => more complex or broken strokes)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    thresh = np.percentile(gray, 40)\n    binary = (gray < thresh).astype(np.uint8)\n    if np.count_nonzero(binary) == 0:\n        thresh = np.mean(gray)\n        binary = (gray < thresh).astype(np.uint8)\n    area = float(np.count_nonzero(binary))\n    if area == 0.0:\n        return 0.0\n    pad = np.pad(binary, ((1, 1), (1, 1)), mode='constant', constant_values=0)\n    neigh_sum = (pad[:-2, :-2] + pad[:-2, 1:-1] + pad[:-2, 2:] +\n                 pad[1:-1, :-2] + pad[1:-1, 2:] +\n                 pad[2:, :-2] + pad[2:, 1:-1] + pad[2:, 2:])\n    # edge pixels have at least one background neighbor => neigh_sum < 8\n    edge_pixels = np.logical_and(binary == 1, neigh_sum < 8)\n    perimeter = float(np.count_nonzero(edge_pixels))\n    return perimeter / area\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gini coefficient of pixel intensities (0..1, 0 equal, 1 very unequal)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    # shift to non-negative\n    mn = float(vals.min())\n    if not np.isfinite(mn):\n        return 0.0\n    vals = vals - mn\n    if vals.sum() <= eps:\n        return 0.0\n    y = np.sort(vals)\n    n = y.size\n    index = np.arange(1, n + 1, dtype=float)\n    G = (2.0 * np.sum(index * y) / (n * np.sum(y))) - (n + 1.0) / n\n    result = float(np.clip(G, 0.0, 1.0))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative ink density in the top-left quadrant compared to overall density (helps detect top-left hooks or strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    meanv = np.mean(gray)\n    if np.std(gray) < 1e-6:\n        return 0.0\n    dark_count = np.sum(gray < meanv)\n    if dark_count <= (gray.size / 2):\n        ink = gray < meanv\n    else:\n        ink = gray > meanv\n    mid_h = max(1, h // 2)\n    mid_w = max(1, w // 2)\n    tl = ink[0:mid_h, 0:mid_w]\n    overall = ink\n    denom = np.sum(overall)\n    if denom == 0:\n        return 0.0\n    return float(np.sum(tl) / denom)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels that lie within the rightmost quarter of the image width (right-border density)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    p40, p60 = np.percentile(gray, 40), np.percentile(gray, 60)\n    left_vals = gray[gray <= p40]\n    right_vals = gray[gray >= p60]\n    left_mean = left_vals.mean() if left_vals.size else gray.min()\n    right_mean = right_vals.mean() if right_vals.size else gray.max()\n    thr = (left_mean + right_mean) / 2.0\n    ink_is_dark = left_mean < right_mean\n    ink = (gray < thr) if ink_is_dark else (gray > thr)\n    right_strip = ink[:, int(3*w/4):]\n    total_ink = np.count_nonzero(ink)\n    if total_ink == 0:\n        return 0.0\n    return float(np.count_nonzero(right_strip) / total_ink)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative energy of image gradients aligned with -45\u00b0 diagonal vs +45\u00b0 diagonal (captures diagonal strokes like in 7)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    mag = np.hypot(gx, gy)\n    # angles in [-pi, pi]\n    ang = np.arctan2(gy, gx)\n    # Gaussian-like weighting around -45deg (-pi/4) and +45deg (+pi/4)\n    target1 = -np.pi / 4\n    target2 = np.pi / 4\n    sigma = 0.35\n    w1 = np.exp(-0.5 * ((ang - target1) ** 2) / (sigma ** 2))\n    w2 = np.exp(-0.5 * ((ang - target2) ** 2) / (sigma ** 2))\n    e1 = float(np.sum(mag * w1))\n    e2 = float(np.sum(mag * w2))\n    tot = e1 + e2 + 1e-8\n    return float((e1 - e2) / tot)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized number of binary transitions along the anti-diagonal (top-right to bottom-left)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.asarray(image, dtype=float)\n    h, w = arr.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    thresh = np.mean(gray)\n    band = (gray < thresh).astype(np.uint8)\n    if np.count_nonzero(band) == 0:\n        band = (gray > thresh).astype(np.uint8)\n    # sample along anti-diagonal from top-right to bottom-left\n    L = max(h, w)\n    transitions = 0\n    prev = None\n    for k in range(L):\n        # map k to a point on anti-diagonal: row = int(k * h / L), col = w-1 - int(k * w / L)\n        r = int(round(k * (h - 1) / max(1, L - 1)))\n        c = int(round((w - 1) - k * (w - 1) / max(1, L - 1)))\n        r = min(max(r, 0), h - 1)\n        c = min(max(c, 0), w - 1)\n        val = int(band[r, c])\n        if prev is None:\n            prev = val\n        else:\n            if val != prev:\n                transitions += 1\n            prev = val\n    return float(transitions) / float(max(1, L))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of columns that contain a vertical ink run covering at least 60% of image height (indicates strong vertical strokes)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.count_nonzero(ink) > 0.9 * h * w:\n        ink = gray > thr\n    count = 0\n    minrun = max(1, int(0.6 * h))\n    for c in range(w):\n        col = ink[:, c].astype(int)\n        diffs = np.diff(np.concatenate(([0], col, [0])))\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        lengths = ends - starts\n        if np.any(lengths >= minrun):\n            count += 1\n    return float(count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels brighter than mean+std (foreground fill ratio)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    m = float(np.mean(arr))\n    s = float(np.std(arr))\n    thresh = m + s\n    total = arr.size\n    if total == 0:\n        return 0.0\n    count = int(np.count_nonzero(arr > thresh))\n    result = count / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Largest connected edge-component size (by pixels) inside the top-right quadrant normalized by quadrant area'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    gray = gray.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    mag = np.hypot(gx, gy)\n    # threshold edges relative to median\n    try:\n        thr = np.percentile(mag.flatten(), 70)\n    except Exception:\n        thr = np.mean(mag)\n    r0, r1 = 0, max(1, h // 2)\n    c0, c1 = max(0, w // 2), w\n    sub_mag = mag[r0:r1, c0:c1]\n    edge = sub_mag > max(1e-8, thr * 0.4)\n    H, W = edge.shape[:2]\n    if edge.size == 0:\n        return 0.0\n    visited = np.zeros_like(edge, dtype=bool)\n    max_comp = 0\n    for i in range(H):\n        for j in range(W):\n            if edge[i, j] and not visited[i, j]:\n                # BFS\n                stack = [(i, j)]\n                visited[i, j] = True\n                cnt = 0\n                while stack:\n                    y, x = stack.pop()\n                    cnt += 1\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = y + dy, x + dx\n                            if 0 <= ny < H and 0 <= nx < W and (dy != 0 or dx != 0):\n                                if edge[ny, nx] and not visited[ny, nx]:\n                                    visited[ny, nx] = True\n                                    stack.append((ny, nx))\n                if cnt > max_comp:\n                    max_comp = cnt\n    quad_area = float(max(1, H * W))\n    return float(max_comp) / quad_area\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of binary transitions across rows (mean transitions per row normalized by width)'\n    import numpy as np\n    img = image.astype(float)\n    h, w = img.shape[:2]\n    if img.max() > 1.0:\n        img = img / 255.0\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    thr = gray.mean()\n    cand1 = gray < thr\n    cand2 = gray > thr\n    mask = cand1 if cand1.sum() <= cand2.sum() else cand2\n    if w <= 1:\n        return 0.0\n    transitions = np.abs(mask[:, :-1].astype(int) - mask[:, 1:].astype(int)).sum(axis=1)\n    avg_trans = float(transitions.mean()) / max(1.0, (w - 1))\n    return float(avg_trans)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top contour variability: std dev of topmost ink row per column normalized by image height (higher -> more peaks/valleys)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    h, w = gray.shape[:2]\n    thr = np.percentile(gray, 45)\n    mask = gray < thr if np.mean(gray) < thr else gray > thr\n    top_idx = np.full(w, h, dtype=int)\n    for col in range(w):\n        col_vals = mask[:, col]\n        nz = np.nonzero(col_vals)[0]\n        if nz.size:\n            top_idx[col] = nz[0]\n    valid = top_idx < h\n    if valid.sum() == 0:\n        return 0.0\n    std = float(np.std(top_idx[valid]))\n    return std / max(1.0, h)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient-orientation entropy: normalized entropy of gradient orientations weighted by magnitude (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 18\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # [-pi, pi]\n    # orientation modulo pi: map to [0, pi)\n    orient = (theta % np.pi)\n    # binning\n    bins_edges = np.linspace(0.0, np.pi, bins + 1)\n    inds = np.minimum(bins - 1, np.floor((orient / np.pi) * bins).astype(int))\n    hist = np.zeros(bins, dtype=float)\n    flat_inds = inds.ravel()\n    flat_mag = mag.ravel()\n    for i, m in zip(flat_inds, flat_mag):\n        hist[int(i)] += float(m)\n    p = hist / (hist.sum() + eps)\n    entropy = -float(np.sum(np.where(p > 0, p * np.log(p + eps), 0.0)))\n    max_ent = float(np.log(bins))\n    result = entropy / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest continuous horizontal ink run in the middle band (40%-60% height) normalized by image width (detects crossbar typical of 4)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image, dtype=float)\n    h, w = arr.shape[:2]\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    thresh = (p10 + p90) / 2.0\n    ink = (gray < thresh) if p90 > p10 else (gray > thresh)\n    top = max(0, int(h * 0.4))\n    bottom = min(h, int(h * 0.6))\n    region = ink[top:bottom, :]\n    max_run = 0\n    for row in region:\n        if row.size == 0:\n            continue\n        r = np.concatenate(([0], row.astype(int), [0]))\n        dif = np.diff(r)\n        starts = np.where(dif == 1)[0]\n        ends = np.where(dif == -1)[0]\n        if starts.size:\n            runs = ends - starts\n            max_run = max(max_run, int(runs.max()))\n    return float(max_run / max(1, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry score: normalized correlation between image and its 180-degree rotation'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # normalize\n    g = gray.astype(float)\n    g = (g - g.mean())\n    rot = np.rot90(g, 2)\n    num = np.sum(g * rot)\n    denom = np.sqrt(np.sum(g * g) * np.sum(rot * rot)) + 1e-12\n    return float(num / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of intensity center-of-mass from geometric center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0 or (h == 0 and w == 0):\n        return 0.0\n    # use nonnegative weights\n    weights = a - float(a.min())\n    s = float(weights.sum())\n    if s <= eps:\n        return 0.0\n    ys = np.arange(h, dtype=float)[:, None]\n    xs = np.arange(w, dtype=float)[None, :]\n    cy = float((weights * ys).sum()) / s\n    cx = float((weights * xs).sum()) / s\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dx = cx - center_x\n    dy = cy - center_y\n    dist = np.hypot(dx, dy)\n    max_dist = np.hypot(center_x, center_y) + eps\n    result = dist / max_dist\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical-edge asymmetry: (sum of vertical edge strength right - left) / total vertical edge strength'\n    import numpy as np\n    if image is None:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gy = np.gradient(gray.astype(float))[1]  # dI/dx approximates vertical edges\n    left_sum = float(np.sum(np.abs(gy[:, :w//2])))\n    right_sum = float(np.sum(np.abs(gy[:, w//2:])))\n    return float((right_sum - left_sum) / (left_sum + right_sum + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized mean radial projection of gradients (higher => edges point outward, circularity)'\n    import numpy as np\n    gray = np.mean(image, axis=2) if len(image.shape) == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    # gradients\n    gy, gx = np.gradient(gray.astype(float))\n    # center coordinates\n    ys = np.arange(h)[:, None].repeat(w, axis=1)\n    xs = np.arange(w)[None, :].repeat(h, axis=0)\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    dx = xs - cx\n    dy = ys - cy\n    dist = np.sqrt(dx**2 + dy**2) + 1e-6\n    radial_proj = (gx * dx + gy * dy) / dist\n    # focus on strong edge areas (high gradient magnitude)\n    grad_mag = np.hypot(gx, gy)\n    thr = np.percentile(grad_mag.flatten(), 80)\n    mask = grad_mag >= thr\n    if np.sum(mask) == 0:\n        return 0.0\n    mean_proj = np.mean(np.abs(radial_proj[mask]))\n    norm = np.mean(grad_mag[mask]) + 1e-6\n    return float(mean_proj / norm)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of 2D FFT energy concentrated in low-frequency band (centered)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    F = np.fft.fftshift(np.fft.fft2(a))\n    power = np.abs(F) ** 2\n    cy, cx = h // 2, w // 2\n    maxr = max(1, min(h, w) // 8)\n    ys, xs = np.ogrid[:h, :w]\n    r = np.hypot(ys - cy, xs - cx)\n    low_mask = (r <= maxr)\n    total = float(power.sum()) + eps\n    low = float(power[low_mask].sum())\n    result = low / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the upper half of the image (upper density ratio)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    thr = 0.5 * (mn + mx)\n    foreground_is_dark = float(np.mean(gray)) < thr\n    if foreground_is_dark:\n        ink = gray < thr\n    else:\n        ink = gray > thr\n    total = float(np.count_nonzero(ink))\n    if total == 0.0:\n        return 0.0\n    upper = float(np.count_nonzero(ink[:h//2, :]))\n    return float(upper / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box occupancy: proportion of nonzero pixels inside their tight bbox (compactness)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = img.mean(axis=2)\n    else:\n        arr = img\n    arr = np.nan_to_num(arr.astype(float))\n    nz = arr != 0\n    if not np.any(nz):\n        return 0.0\n    ys, xs = np.where(nz)\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    count = float(np.count_nonzero(nz))\n    result = count / (bbox_area + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Solidity: fraction of foreground pixels within their bounding box (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.median(a))\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    ymin, ymax = ys.min(), ys.max()\n    xmin, xmax = xs.min(), xs.max()\n    bbox_area = float((ymax - ymin + 1) * (xmax - xmin + 1)) + eps\n    fill = float(mask.sum()) / bbox_area\n    return float(np.clip(fill, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of low-variance patches in a 4x4 grid (indicates smoothness / texture sparsity)'\n    import numpy as np\n    eps = 1e-12\n    GRID = 4\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    global_var = float(a.var()) + eps\n    ph = max(1, h // GRID)\n    pw = max(1, w // GRID)\n    low_count = 0\n    total = 0\n    for y in range(0, h, ph):\n        for x in range(0, w, pw):\n            patch = a[y:min(h, y+ph), x:min(w, x+pw)]\n            if patch.size == 0:\n                continue\n            total += 1\n            if float(patch.var()) < 0.5 * global_var:\n                low_count += 1\n    if total == 0:\n        return 0.0\n    result = float(low_count) / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density: fraction of pixels with gradient magnitude above 1.5 * median'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    med = float(np.median(mag))\n    if not np.isfinite(med):\n        med = 0.0\n    thresh = med * 1.5 + eps\n    edge_count = float((mag > thresh).sum())\n    area = float(h * w)\n    result = edge_count / (area + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (squareness) of the bounding box of bright pixels (0..1, 1 => square)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = a > thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    miny, maxy = ys.min(), ys.max()\n    minx, maxx = xs.min(), xs.max()\n    box_h = float(max(1, maxy - miny + 1))\n    box_w = float(max(1, maxx - minx + 1))\n    ratio = min(box_h, box_w) / max(box_h, box_w)\n    result = float(np.clip(ratio, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of vertical foreground runs per column in the central third of the image'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.percentile(gray, 75))\n    mask = gray >= thr\n    if mask.sum() > 0.6 * (h * w):\n        mask = ~mask\n    mask = mask.astype(int)\n    c1 = w // 3\n    c2 = w - c1\n    if c2 <= c1:\n        cols = mask\n    else:\n        cols = mask[:, c1:c2]\n    # For each column count vertical runs of 1s\n    runs_per_col = []\n    for col in range(cols.shape[1]):\n        colarr = cols[:, col]\n        if colarr.size == 0:\n            runs_per_col.append(0)\n            continue\n        # transitions from 0->1 indicate start of run\n        starts = np.sum((colarr == 1) & (np.pad(colarr, (1, 0), mode='constant')[:-1] == 0))\n        runs_per_col.append(int(starts))\n    # return average runs per column\n    return float(np.mean(runs_per_col))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Row-wise intensity variation: mean(std across rows) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    row_stds = np.std(a, axis=1)\n    mean_row_std = float(np.mean(row_stds)) if row_stds.size else 0.0\n    global_std = float(np.std(a)) + eps\n    result = mean_row_std / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of strict local intensity peaks (local max over 8 neighbors), normalized by area'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 1 or w < 1:\n        return 0.0\n    # compare to 8 neighbors\n    center = a\n    neighs = [\n        np.roll(np.roll(a,  0, axis=0),  1, axis=1),\n        np.roll(np.roll(a,  0, axis=0), -1, axis=1),\n        np.roll(np.roll(a,  1, axis=0),  0, axis=1),\n        np.roll(np.roll(a, -1, axis=0),  0, axis=1),\n        np.roll(np.roll(a,  1, axis=0),  1, axis=1),\n        np.roll(np.roll(a,  1, axis=0), -1, axis=1),\n        np.roll(np.roll(a, -1, axis=0),  1, axis=1),\n        np.roll(np.roll(a, -1, axis=0), -1, axis=1),\n    ]\n    is_peak = np.ones_like(a, dtype=bool)\n    for n in neighs:\n        is_peak &= (center > n)\n    # also require peaks to be above a modest threshold to avoid noise\n    thr = float(a.mean()) + 0.5 * float(a.std())\n    is_peak &= (a > thr)\n    count = float(np.count_nonzero(is_peak))\n    result = count / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation coherence (0..1): how aligned gradient directions are'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return float(0.0)\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    sum_gx = float(gx.sum())\n    sum_gy = float(gy.sum())\n    vec_mag = float(np.hypot(sum_gx, sum_gy))\n    total_mag = float(mag.sum()) + eps\n    result = vec_mag / total_mag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local peak count: normalized count of strict 3x3 local maxima (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center = a\n    # compare to 8 neighbors using rolls\n    neighs = []\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            if dy == 0 and dx == 0:\n                continue\n            neighs.append(np.roll(np.roll(a, dy, axis=0), dx, axis=1))\n    is_max = np.ones_like(a, dtype=bool)\n    for n in neighs:\n        is_max &= (center > n)\n    # avoid counting border artifacts caused by roll (treat rolled comparisons as valid but normalize)\n    count = int(is_max.sum())\n    area = float(h * w)\n    result = float(count) / (area + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of gradient angles (variation in stroke orientation); high for rounded digits'\n    img = image.astype(float)\n    if len(img.shape) == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    gy, gx = np.gradient(gray)\n    mag = np.hypot(gx, gy)\n    maxmag = mag.max() if mag.size else 0.0\n    if maxmag <= 1e-8:\n        return 0.0\n    # consider only significant gradients to reduce noise\n    thresh = max(1e-8, 0.15 * maxmag)\n    mask = mag > thresh\n    if not np.any(mask):\n        return 0.0\n    angles = np.arctan2(gy[mask], gx[mask])  # -pi..pi\n    return float(np.std(angles))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border-to-interior variance ratio (border variance / interior variance)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    bw = max(1, min(h, w) // 8)\n    top = a[:bw, :]\n    bot = a[-bw:, :]\n    left = a[:, :bw]\n    right = a[:, -bw:]\n    border = np.concatenate([top.ravel(), bot.ravel(), left.ravel(), right.ravel()])\n    interior = a[bw:-bw, bw:-bw]\n    border_var = float(np.var(border)) if border.size else 0.0\n    interior_var = float(np.var(interior)) if interior.size else 0.0\n    if interior_var <= eps:\n        result = float(border_var / (interior_var + eps))\n    else:\n        result = float(border_var / interior_var)\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of small bright components (count of components with area <1% image area)'\n    import numpy as np\n    from collections import deque\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        gray = np.nan_to_num(arr.astype(float))\n    h, w = gray.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(gray.mean())\n    mask = gray > thr\n    if not mask.any():\n        return 0.0\n    visited = np.zeros_like(mask, dtype=bool)\n    small_count = 0\n    max_small = max(1, (h * w) // 100)  # 1% area threshold\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                area = 0\n                dq = deque()\n                dq.append((y, x))\n                visited[y, x] = True\n                while dq:\n                    cy, cx = dq.popleft()\n                    area += 1\n                    if cy > 0 and mask[cy-1, cx] and not visited[cy-1, cx]:\n                        visited[cy-1, cx] = True\n                        dq.append((cy-1, cx))\n                    if cy < h-1 and mask[cy+1, cx] and not visited[cy+1, cx]:\n                        visited[cy+1, cx] = True\n                        dq.append((cy+1, cx))\n                    if cx > 0 and mask[cy, cx-1] and not visited[cy, cx-1]:\n                        visited[cy, cx-1] = True\n                        dq.append((cy, cx-1))\n                    if cx < w-1 and mask[cy, cx+1] and not visited[cy, cx+1]:\n                        visited[cy, cx+1] = True\n                        dq.append((cy, cx+1))\n                if area < max_small:\n                    small_count += 1\n    # normalize by image area to keep value small and comparable\n    result = float(small_count) / (float(h * w) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Rotation-180 self-correlation (circular symmetry), -1..1'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    b = np.rot90(a, 2)\n    if b.shape != a.shape:\n        # align shapes if odd/even by cropping to min dims\n        min_h = min(a.shape[0], b.shape[0])\n        min_w = min(a.shape[1], b.shape[1])\n        a = a[:min_h, :min_w]\n        b = b[:min_h, :min_w]\n    A = a.ravel()\n    B = b.ravel()\n    if A.size == 0:\n        return 0.0\n    Am = float(A.mean())\n    Bm = float(B.mean())\n    Ac = A - Am\n    Bc = B - Bm\n    denom = (np.sqrt((Ac ** 2).sum() * (Bc ** 2).sum()) + eps)\n    corr = float((Ac * Bc).sum() / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of vertical gradient energy concentrated in the center third of the image'\n    if image is None:\n        return 0.0\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    if h < 2 or w < 2:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    gy, gx = np.gradient(gray)\n    vert_energy = np.abs(gy)\n    total_energy = vert_energy.sum() + 1e-9\n    c1 = w // 3\n    c2 = 2 * w // 3\n    center_energy = vert_energy[:, c1:c2].sum()\n    return float(center_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-region spread: fraction of rows and columns touched by pixels > mean (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return float(0.0)\n    med = float(np.mean(a))\n    mask = a > med\n    if not np.any(mask):\n        return float(0.0)\n    rows_with = float(np.any(mask, axis=1).sum())\n    cols_with = float(np.any(mask, axis=0).sum())\n    result = (rows_with / float(h)) * (cols_with / float(w))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Elongation ratio from PCA (largest eigenvalue / smallest eigenvalue) of foreground coordinates; high for thin digits like \"1\"'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.count_nonzero(ink) > 0.6 * h * w:\n        ink = ~ink\n    coords = np.argwhere(ink).astype(float)\n    if coords.shape[0] < 3:\n        return 0.0\n    # compute covariance of (x,y) where we use columns as x, rows as y\n    ys = coords[:, 0]\n    xs = coords[:, 1]\n    X = np.column_stack((xs - np.mean(xs), ys - np.mean(ys)))\n    cov = np.cov(X, rowvar=False)\n    # ensure 2x2\n    if cov.shape != (2,2):\n        return 0.0\n    eig = np.linalg.eigvals(cov)\n    eig = np.real(eig)\n    eig = np.sort(eig)\n    eps = 1e-9\n    ratio = (float(eig[-1]) + eps) / (float(eig[0]) + eps)\n    return float(ratio)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Median row index of the topmost ink in center third columns, normalized by height (captures approximate crossbar vertical position)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gmin, gmax = gray.min(), gray.max()\n    norm = (gray - gmin) / (gmax - gmin + 1e-12)\n    if np.mean(norm) > 0.5:\n        ink = norm < 0.5\n    else:\n        ink = norm > 0.5\n    h, w = gray.shape\n    c0, c1 = w // 3, (2 * w) // 3\n    if c1 <= c0:\n        return 0.0\n    top_indices = []\n    for c in range(c0, c1):\n        col = ink[:, c]\n        ys = np.where(col)[0]\n        if ys.size:\n            top_indices.append(ys.min())\n    if len(top_indices) == 0:\n        return 0.0\n    med = float(np.median(top_indices))\n    return float(med / max(1.0, h))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink mass in right half to left half (captures right-weighted digits like 2 or 3)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    fg = gray < thr\n    if fg.sum() == 0 or fg.sum() > 0.9 * gray.size:\n        fg = gray > thr\n    left = fg[:, :w//2].sum()\n    right = fg[:, w//2:].sum()\n    # Avoid division by zero\n    if left + right == 0:\n        return 0.0\n    return float((right + 1e-6) / (left + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio deviation from square, in [0..1) (0 => square)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    try:\n        h, w = arr.shape[:2]\n    except Exception:\n        return 0.0\n    if h <= 0 or w <= 0:\n        return 0.0\n    ratio = float(h) / float(w)\n    # normalized deviation: |r-1|/(r+1) yields 0..1\n    result = abs(ratio - 1.0) / (ratio + 1.0)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near extremes (saturation / clipping indicator)'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    mn = float(a.min())\n    mx = float(a.max())\n    if not np.isfinite(mn) or not np.isfinite(mx):\n        return 0.0\n    rng = mx - mn\n    if rng <= eps:\n        return 0.0\n    # consider pixels within 5% of range from either extreme\n    low_thr = mn + 0.05 * rng\n    high_thr = mx - 0.05 * rng\n    frac_low = float((a <= low_thr).sum()) / float(a.size)\n    frac_high = float((a >= high_thr).sum()) / float(a.size)\n    result = frac_low + frac_high\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average signed product of x and y gradients (negative values favor top-right to bottom-left diagonals)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    # Normalize contrast to avoid scale issues\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    grayn = (gray - mn) / (mx - mn)\n    gy, gx = np.gradient(grayn)\n    prod = gx * gy\n    # We want a signed measure; negative average indicates dominant negative-slope diagonal strokes\n    return float(np.mean(prod))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of distinct connected ink components restricted to the right half'\n    import numpy as np\n    from collections import deque\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    rng = mx - mn + 1e-9\n    norm = (gray - mn) / rng\n    ink = (1.0 - norm) > 0.25\n    # restrict to right half\n    x0 = w // 2\n    sub = ink[:, x0:]\n    sh, sw = sub.shape\n    visited = np.zeros_like(sub, dtype=bool)\n    comps = 0\n    for i in range(sh):\n        for j in range(sw):\n            if sub[i, j] and not visited[i, j]:\n                comps += 1\n                # BFS\n                q = deque()\n                visited[i, j] = True\n                q.append((i, j))\n                while q:\n                    a, b = q.popleft()\n                    if a > 0 and sub[a - 1, b] and not visited[a - 1, b]:\n                        visited[a - 1, b] = True; q.append((a - 1, b))\n                    if a + 1 < sh and sub[a + 1, b] and not visited[a + 1, b]:\n                        visited[a + 1, b] = True; q.append((a + 1, b))\n                    if b > 0 and sub[a, b - 1] and not visited[a, b - 1]:\n                        visited[a, b - 1] = True; q.append((a, b - 1))\n                    if b + 1 < sw and sub[a, b + 1] and not visited[a, b + 1]:\n                        visited[a, b + 1] = True; q.append((a, b + 1))\n    return float(comps)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian magnitude normalized by mean intensity (texture strength)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # discrete Laplacian kernel convolution (4-neighbor)\n    lap = -4 * a\n    lap += np.roll(a, 1, axis=0)\n    lap += np.roll(a, -1, axis=0)\n    lap += np.roll(a, 1, axis=1)\n    lap += np.roll(a, -1, axis=1)\n    mag = np.mean(np.abs(lap))\n    mean_int = np.mean(np.abs(a)) + eps\n    result = mag / mean_int\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity distribution (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(img.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    # use fixed 256 bins for robustness\n    try:\n        hist, _ = np.histogram(a, bins=256, density=False)\n    except Exception:\n        return 0.0\n    p = hist.astype(float)\n    p_sum = p.sum()\n    if p_sum <= 0:\n        return 0.0\n    p = p / (p_sum + eps)\n    ent = -float(np.sum(np.where(p > 0, p * np.log2(p), 0.0)))\n    max_ent = float(np.log2(len(p)))\n    result = ent / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy fraction: fraction of total absolute energy in (image - 3x3 box blur) (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    blur = s / 9.0\n    high = a - blur\n    high_energy = float(np.sum(np.abs(high)))\n    total_energy = float(np.sum(np.abs(a))) + eps\n    result = high_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right Pearson correlation between left half and flipped right half (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:] if mid > 0 else a[:, :mid]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # flip right horizontally to compare symmetry\n    right_flipped = np.fliplr(right)\n    # if shapes differ (odd width), crop to min columns\n    mincols = min(left.shape[1], right_flipped.shape[1])\n    left_c = left[:, :mincols].ravel()\n    right_c = right_flipped[:, :mincols].ravel()\n    if left_c.size < 2:\n        return 0.0\n    lv = left_c - left_c.mean()\n    rv = right_c - right_c.mean()\n    denom = (np.sqrt((lv * lv).sum() * (rv * rv).sum()) + eps)\n    corr = float((lv * rv).sum() / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Eccentricity (0..1) of the largest enclosed hole: 0 for circle, closer to 1 for elongated; 0 if none'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy().astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = (np.min(gray) + np.max(gray)) / 2.0\n    ink = gray < thresh\n    background = ~ink\n    visited = np.zeros_like(background, dtype=bool)\n    best_e = 0.0\n    for r in range(h):\n        for c in range(w):\n            if background[r, c] and not visited[r, c]:\n                stack = [(r, c)]\n                comp = []\n                touches_border = False\n                visited[r, c] = True\n                while stack:\n                    y, x = stack.pop()\n                    comp.append((y, x))\n                    if y == 0 or y == h-1 or x == 0 or x == w-1:\n                        touches_border = True\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ny, nx = y+dy, x+dx\n                        if 0 <= ny < h and 0 <= nx < w and background[ny, nx] and not visited[ny, nx]:\n                            visited[ny, nx] = True\n                            stack.append((ny, nx))\n                if not touches_border and len(comp) >= 5:\n                    comp = np.array(comp, dtype=float)\n                    cy = comp[:,0].mean()\n                    cx = comp[:,1].mean()\n                    coords = comp - np.array([[cy, cx]])\n                    cov = np.dot(coords.T, coords) / coords.shape[0]\n                    # eigenvalues\n                    tr = cov[0,0] + cov[1,1]\n                    det = cov[0,0]*cov[1,1] - cov[0,1]*cov[1,0]\n                    # numerical robust eigenvalues\n                    disc = max(0.0, tr*tr/4.0 - det)\n                    l1 = tr/2.0 + np.sqrt(disc)\n                    l2 = tr/2.0 - np.sqrt(disc)\n                    if l1 > 1e-8:\n                        e = np.sqrt(max(0.0, 1.0 - max(0.0, l2)/max(1e-12, l1)))\n                        if e > best_e:\n                            best_e = e\n    return float(best_e)\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity correlation: Pearson corr between radius and intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    r_flat = r.ravel()\n    v_flat = a.ravel()\n    if r_flat.size == 0 or v_flat.size == 0:\n        return 0.0\n    r_mean = float(r_flat.mean())\n    v_mean = float(v_flat.mean())\n    r_dev = r_flat - r_mean\n    v_dev = v_flat - v_mean\n    num = float((r_dev * v_dev).sum())\n    den = float(np.sqrt((r_dev ** 2).sum() * (v_dev ** 2).sum())) + eps\n    corr = num / den\n    corr = max(-1.0, min(1.0, corr))\n    return float(corr)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 16 bins'\n    import numpy as np\n    bins = 16\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    mn, mx = a.min(), a.max()\n    if mx <= mn:\n        return 0.0\n    hist, _ = np.histogram(a, bins=bins, range=(mn, mx))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p_nonzero = p[p > 0]\n    ent = -float((p_nonzero * np.log(p_nonzero)).sum())\n    max_ent = np.log(float(bins))\n    result = ent / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Autocorrelation decay along horizontal shifts (positive => faster decay)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 5:\n        return 0.0\n    shifts = [1, 2, 3, 4]\n    corrs = []\n    for dx in shifts:\n        left = a[:, :-dx].ravel()\n        right = a[:, dx:].ravel()\n        if left.size == 0:\n            corrs.append(0.0)\n            continue\n        Lm = float(left.mean())\n        Rm = float(right.mean())\n        Lc = left - Lm\n        Rc = right - Rm\n        denom = (np.sqrt((Lc ** 2).sum() * (Rc ** 2).sum()) + eps)\n        corrs.append(float((Lc * Rc).sum() / denom))\n    corrs = np.array(corrs, dtype=float)\n    if not np.isfinite(corrs).any():\n        return 0.0\n    # fit slope of correlation vs shift\n    try:\n        slope = float(np.polyfit(shifts, corrs, 1)[0])\n    except Exception:\n        return 0.0\n    # normalize by corr at shift=1 magnitude\n    denom = (abs(corrs[0]) + eps)\n    result = -slope / denom\n    return float(np.clip(result, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows that are nearly uniform (low row-wise std)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0:\n        return 0.0\n    row_std = a.std(axis=1)\n    thresh = float(row_std.mean()) * 0.5\n    count = float(np.count_nonzero(row_std < thresh))\n    result = count / (float(h) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized displacement of intensity centroid from image center (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    total = float(a.sum())\n    if total == 0.0 or h == 0 or w == 0:\n        return 0.0\n    yy, xx = np.indices((h, w))\n    cx = (a * xx).sum() / total\n    cy = (a * yy).sum() / total\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    norm = (np.hypot(w, h) / 2.0) + 1e-12\n    result = np.clip(dist / norm, 0.0, 1.0)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized directional diagonal bias: (energy along / diagonal - energy along \\\\ diagonal) / total diagonal energy'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    # gradients\n    gy, gx = np.gradient(gray.astype(float))\n    diag1 = np.abs(gx + gy)  # one diagonal direction\n    diag2 = np.abs(gx - gy)  # other diagonal direction\n    s1 = diag1.sum()\n    s2 = diag2.sum()\n    denom = s1 + s2 + 1e-9\n    return float((s1 - s2) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for grayscale), higher => more colorful'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    R = a[..., 0].ravel()\n    G = a[..., 1].ravel()\n    B = a[..., 2].ravel()\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = np.std(rg)\n    std_yb = np.std(yb)\n    mean_rg = np.abs(np.mean(rg))\n    mean_yb = np.abs(np.mean(yb))\n    std_root = np.sqrt(std_rg * std_rg + std_yb * std_yb)\n    mean_root = np.sqrt(mean_rg * mean_rg + mean_yb * mean_yb)\n    colorfulness = std_root + 0.3 * mean_root\n    return float(max(0.0, colorfulness + eps))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink density in the top third to the middle third of the image (top_density / (middle_density+eps))'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        meanv = float(np.mean(gray))\n        dark_mask = gray < meanv\n        light_mask = gray > meanv\n        ink = dark_mask if np.count_nonzero(dark_mask) <= np.count_nonzero(light_mask) else light_mask\n        if np.count_nonzero(ink) == 0:\n            return 1.0\n        t = h // 3\n        top = np.count_nonzero(ink[:t, :]) / max(1.0, (t * w))\n        mid = np.count_nonzero(ink[t:2*t, :]) / max(1.0, (t * w))\n        return float(top / (mid + 1e-6))\n    except Exception:\n        return 1.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of local intensity peaks (peaks per pixel) using 8-neighbor test'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # threshold to ignore tiny fluctuations\n    mean = float(a.mean())\n    std = float(a.std()) + eps\n    thresh = mean + 0.5 * std\n    # compare to 8 neighbors via roll (fast; wrap-around acceptable as edge case)\n    neighs = []\n    shifts = [(0,1),(0,-1),(1,0),(-1,0),(1,1),(1,-1),(-1,1),(-1,-1)]\n    for dy, dx in shifts:\n        neighs.append(np.roll(np.roll(a, dy, axis=0), dx, axis=1))\n    neigh_max = np.maximum.reduce(neighs)\n    peaks = (a > neigh_max) & (a > thresh)\n    count = float(np.count_nonzero(peaks))\n    result = count / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Nonzero compactness: fraction of bbox area occupied by nonzero pixels (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2))\n    else:\n        a = np.nan_to_num(arr)\n    nz_count = int(np.count_nonzero(a))\n    if nz_count == 0:\n        return 0.0\n    rows = np.any(a != 0, axis=1)\n    cols = np.any(a != 0, axis=0)\n    r_idx = np.where(rows)[0]\n    c_idx = np.where(cols)[0]\n    if r_idx.size == 0 or c_idx.size == 0:\n        return 0.0\n    bbox_area = float((r_idx[-1] - r_idx[0] + 1) * (c_idx[-1] - c_idx[0] + 1)) + eps\n    result = float(nz_count) / bbox_area\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Upper-right quadrant ink fraction (top-right density) normalized by total ink'\n    import numpy as np\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img.astype(float)\n    med = np.median(gray)\n    prop = float(np.mean(gray < med))\n    thr = np.percentile(gray, 20) if prop > 0.5 else med\n    bw = (gray < thr).astype(np.uint8)\n    if bw.sum() == 0:\n        bw = (gray > thr).astype(np.uint8)\n    top = slice(0, max(1, h//3))\n    right = slice((2*w)//3, w)\n    ur = bw[top, right].sum()\n    total = max(1.0, bw.sum())\n    return float(ur / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of pixels that are strong edges (edge density)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(np.mean(mag) + np.std(mag))\n    count = float(np.count_nonzero(mag > thr))\n    return float(np.clip(count / (h * w + eps), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score (1.0 = perfect mirror symmetry)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2 or h == 0:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:] if mid > 0 else np.empty_like(left)\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    right_flipped = np.fliplr(right)\n    # ensure same shape\n    if left.shape != right_flipped.shape:\n        # trim larger to match smaller\n        min_cols = min(left.shape[1], right_flipped.shape[1])\n        left = left[:, :min_cols]\n        right_flipped = right_flipped[:, :min_cols]\n    diff = np.abs(left - right_flipped)\n    denom = np.mean(np.abs(a)) + eps\n    score = 1.0 - float(np.mean(diff) / denom)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative ink density bottom-left vs bottom-right: bottom-left / (bottom-right + eps)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0,:], gray[-1,:], gray[:,0], gray[:,-1]])\n    thresh = (np.mean(border) + np.mean(gray)) / 2.0\n    ink = (gray < thresh) if (np.mean(border) > np.mean(gray)) else (gray > thresh)\n    mid_h = h * 2 // 3\n    mid_w = w // 2\n    bottom_slice = slice(mid_h, h)\n    bl = float(np.count_nonzero(ink[bottom_slice, :mid_w]))\n    br = float(np.count_nonzero(ink[bottom_slice, mid_w:]))\n    eps = 1e-6\n    return float(bl / (br + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local peak count: proportion of strict local maxima (8-neighborhood) after padding'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # pad with very small value so edges are handled (no wrap)\n    pad = np.pad(a, 1, mode='constant', constant_values=-np.inf)\n    center = pad[1:-1, 1:-1]\n    neighs = [\n        pad[:-2, :-2], pad[:-2, 1:-1], pad[:-2, 2:],\n        pad[1:-1, :-2],               pad[1:-1, 2:],\n        pad[2:, :-2],  pad[2:, 1:-1], pad[2:, 2:]\n    ]\n    is_peak = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        is_peak &= (center > n)\n    count = float(np.count_nonzero(is_peak))\n    result = count / (float(center.size) + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean color saturation for color images (0..1), 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    img = np.nan_to_num(arr.astype(float))\n    # take first three channels if more present\n    ch = img[..., :3]\n    mn = ch.min(axis=2)\n    mx = ch.max(axis=2)\n    sat = (mx - mn) / (mx + eps)\n    mean_sat = float(np.mean(sat))\n    return float(np.clip(mean_sat, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical edge strength to horizontal edge strength (mean absolute dy / mean absolute dx)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # gradients\n    try:\n        gy, gx = np.gradient(gray)\n    except Exception:\n        gy = np.zeros_like(gray)\n        gx = np.zeros_like(gray)\n    v_strength = float(np.mean(np.abs(gy)))\n    h_strength = float(np.mean(np.abs(gx)))\n    if h_strength <= 1e-9:\n        return float(v_strength / (1e-9))\n    return float(v_strength / h_strength)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of horizontal ink/background transitions per row (normalized)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    minv = float(np.min(gray))\n    meanv = float(np.mean(gray))\n    if meanv == minv:\n        return 0.0\n    thresh = (minv + meanv) / 2.0\n    ink = ((gray < thresh) if meanv > minv else (gray > thresh)).astype(int)\n    # transitions per row equals number of 0<->1 changes\n    row_trans = np.sum(np.abs(np.diff(ink, axis=1)), axis=1)\n    # normalize by width to get fraction per row\n    avg_trans_per_row = float(np.mean(row_trans) / max(1.0, w))\n    return avg_trans_per_row\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Largest hole area normalized by image area (holes are background components not touching the border)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    mn, mx = arr.min(), arr.max()\n    if mx <= mn:\n        return 0.0\n    gray = (arr - mn) / (mx - mn)\n    ink_is_dark = np.mean(gray) > 0.5\n    fg = (gray < 0.5) if ink_is_dark else (gray > 0.5)\n    bg = ~fg\n    h, w = bg.shape\n    visited = np.zeros_like(bg, dtype=bool)\n    max_hole = 0\n    # 4- or 8-connectivity? use 8-connectivity for robustness\n    for r in range(h):\n        for c in range(w):\n            if not bg[r, c] or visited[r, c]:\n                continue\n            # flood fill\n            stack = [(r, c)]\n            visited[r, c] = True\n            size = 0\n            touches_border = False\n            while stack:\n                y, x = stack.pop()\n                size += 1\n                if y == 0 or y == h - 1 or x == 0 or x == w - 1:\n                    touches_border = True\n                # iterate 8 neighbors\n                for dy in (-1, 0, 1):\n                    for dx in (-1, 0, 1):\n                        ny, nx = y + dy, x + dx\n                        if ny < 0 or ny >= h or nx < 0 or nx >= w:\n                            continue\n                        if not visited[ny, nx] and bg[ny, nx]:\n                            visited[ny, nx] = True\n                            stack.append((ny, nx))\n            if not touches_border:\n                if size > max_hole:\n                    max_hole = size\n    area = float(h * w)\n    if area <= 0:\n        return 0.0\n    return float(max_hole / area)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels significantly brighter than image mean (foreground sparsity)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m + 0.5 * s  # modest threshold above mean\n    count = float((a > thr).sum())\n    result = count / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of enclosed background components (holes) detected inside the foreground'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = float(np.mean(gray))\n    mask = gray < thresh\n    prop = np.count_nonzero(mask) / float(h * w) if h * w > 0 else 0.0\n    if prop > 0.6:\n        mask = ~mask\n    # background mask: True where background\n    bg = ~mask\n    # flood-fill external background from borders\n    visited = np.zeros_like(bg, dtype=bool)\n    from collections import deque\n    q = deque()\n    # add border background pixels\n    for c in range(w):\n        if bg[0, c] and not visited[0, c]:\n            visited[0, c] = True\n            q.append((0, c))\n        if bg[h - 1, c] and not visited[h - 1, c]:\n            visited[h - 1, c] = True\n            q.append((h - 1, c))\n    for r in range(h):\n        if bg[r, 0] and not visited[r, 0]:\n            visited[r, 0] = True\n            q.append((r, 0))\n        if bg[r, w - 1] and not visited[r, w - 1]:\n            visited[r, w - 1] = True\n            q.append((r, w - 1))\n    # 4-neighbor flood\n    while q:\n        r, c = q.popleft()\n        for dr, dc in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n            nr, nc = r + dr, c + dc\n            if 0 <= nr < h and 0 <= nc < w and bg[nr, nc] and not visited[nr, nc]:\n                visited[nr, nc] = True\n                q.append((nr, nc))\n    # any background pixel not visited is a hole; count connected hole components\n    holes_mask = bg & (~visited)\n    if not np.any(holes_mask):\n        return 0.0\n    hole_visited = np.zeros_like(holes_mask, dtype=bool)\n    hole_count = 0\n    for r in range(h):\n        for c in range(w):\n            if holes_mask[r, c] and not hole_visited[r, c]:\n                hole_count += 1\n                # flood this hole\n                dq = deque([(r, c)])\n                hole_visited[r, c] = True\n                while dq:\n                    rr, cc = dq.popleft()\n                    for dr, dc in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n                        nr, nc = rr + dr, cc + dc\n                        if 0 <= nr < h and 0 <= nc < w and holes_mask[nr, nc] and not hole_visited[nr, nc]:\n                            hole_visited[nr, nc] = True\n                            dq.append((nr, nc))\n    return float(hole_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box aspect ratio of the ink (width / height), 0 if no ink'\n    import numpy as np\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    # estimate background from border\n    bw = max(1, min(h, w) // 10)\n    border = np.concatenate([\n        gray[:bw, :].ravel(),\n        gray[-bw:, :].ravel(),\n        gray[:, :bw].ravel(),\n        gray[:, -bw:].ravel()\n    ])\n    bg_mean = np.mean(border) if border.size else np.mean(gray)\n    bg_min = np.min(border) if border.size else np.min(gray)\n    thr = bg_mean - 0.25 * (bg_mean - bg_min + 1e-9)\n    mask = gray < thr\n    if np.count_nonzero(mask) == 0:\n        mask = gray < np.percentile(gray, 50)\n    inds = np.argwhere(mask)\n    if inds.size == 0:\n        return 0.0\n    rows, cols = inds[:,0], inds[:,1]\n    minr, maxr = rows.min(), rows.max()\n    minc, maxc = cols.min(), cols.max()\n    bw_box = float(maxc - minc + 1)\n    bh_box = float(maxr - minr + 1)\n    if bh_box == 0:\n        return 0.0\n    return float(bw_box / bh_box)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-region aspect ratio of thresholded area (1 => square, 0 => very elongated or absent)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    mu = float(np.mean(a))\n    sigma = float(np.std(a))\n    thresh = mu + 0.5 * sigma\n    mask = a > thresh\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    minr, maxr = ys.min(), ys.max()\n    minc, maxc = xs.min(), xs.max()\n    bh = maxr - minr + 1\n    bw = maxc - minc + 1\n    if bh <= 0 or bw <= 0:\n        return 0.0\n    ar = float(min(bw, bh)) / float(max(bw, bh))\n    return float(np.clip(ar, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean 45-degree diagonal edge energy in the right half normalized by global diagonal energy (detects diagonal strokes like in 7)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mi, ma = float(np.min(gray)), float(np.max(gray))\n    gray = (gray - mi) / (ma - mi + 1e-8)\n    gy, gx = np.gradient(gray)\n    diag_energy = np.abs(gx + gy)  # energy along one diagonal direction\n    h, w = gray.shape[:2]\n    right = diag_energy[:, w//2:]\n    global_mean = float(np.mean(diag_energy) + 1e-8)\n    right_mean = float(np.mean(right))\n    return float(right_mean / global_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial spread of ink: standard deviation of distances of ink pixels to ink centroid normalized by image diagonal (lower for ring-like shapes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    ys, xs = np.nonzero(ink)\n    if xs.size <= 1:\n        return 0.0\n    cx = xs.mean()\n    cy = ys.mean()\n    d = np.sqrt((xs - cx) ** 2 + (ys - cy) ** 2)\n    std = d.std()\n    diag = np.sqrt(h * h + w * w)\n    return float(std / (diag + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of low-frequency energy to total energy in the 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image, dtype=float)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2))\n    else:\n        a = np.nan_to_num(img)\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # remove DC bias\n    a = a - a.mean()\n    F = np.fft.fftshift(np.fft.fft2(a))\n    power = np.abs(F) ** 2\n    kh = max(1, min(h, w) // 8)\n    kw = kh\n    ch = h // 2; cw = w // 2\n    low = power[ch - kh: ch + kh + 1, cw - kw: cw + kw + 1]\n    low_energy = float(low.sum())\n    total_energy = float(power.sum()) + eps\n    result = low_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal centroid offset of ink relative to tight bounding box center (positive -> centroid to the right), normalized by bbox width'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray) if h * w > 0 else 0.0\n    ink_mask_candidate = gray < thr\n    if np.sum(ink_mask_candidate) > (h * w / 2):\n        ink = (~ink_mask_candidate).astype(np.uint8)\n    else:\n        ink = ink_mask_candidate.astype(np.uint8)\n    if np.sum(ink) == 0:\n        return 0.0\n    rows = np.any(ink, axis=1)\n    cols = np.any(ink, axis=0)\n    if not np.any(rows) or not np.any(cols):\n        return 0.0\n    r0, r1 = int(np.argmax(rows)), int(len(rows) - np.argmax(rows[::-1]))\n    c0, c1 = int(np.argmax(cols)), int(len(cols) - np.argmax(cols[::-1]))\n    bbox = ink[r0:r1, c0:c1]\n    ys, xs = np.nonzero(bbox)\n    if len(xs) == 0:\n        return 0.0\n    centroid_x = float(np.mean(xs))\n    bbox_width = max(1.0, bbox.shape[1])\n    center_x = (bbox_width - 1) / 2.0\n    offset = (centroid_x - center_x) / bbox_width\n    return float(offset)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation entropy: lower entropy -> dominant stroke direction (e.g., 7 has low entropy)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    mag = np.hypot(gx, gy)\n    mask = mag > (np.percentile(mag, 50) * 0.1 + 1e-12)\n    if not np.any(mask):\n        return 0.0\n    angles = np.arctan2(gy[mask], gx[mask])  # range -pi..pi\n    # histogram and entropy\n    bins = 16\n    hist, _ = np.histogram(angles, bins=bins, range=(-np.pi, np.pi))\n    p = hist.astype(float) / (hist.sum() + 1e-12)\n    p_nonzero = p[p > 0]\n    entropy = -np.sum(p_nonzero * np.log(p_nonzero + 1e-12))\n    # normalize by max entropy\n    max_ent = np.log(bins)\n    return float(entropy / (max_ent + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian energy ratio: sum(|Laplacian|) / (sum(|image|)+eps)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    lap = np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) + np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a\n    lap_energy = float(np.sum(np.abs(lap)))\n    total = float(np.sum(np.abs(a))) + eps\n    result = lap_energy / total\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Eccentricity of bright region (0..1, 0=circular, 1=elongated) using weighted second moments'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    thr = float(a.mean() + a.std())\n    mask = a > thr\n    if np.count_nonzero(mask) < 3:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    weights = a[mask] - thr\n    weights = np.maximum(weights, 0.0)\n    wsum = float(weights.sum()) + eps\n    cy = float((weights * ys).sum()) / wsum\n    cx = float((weights * xs).sum()) / wsum\n    dy = ys - cy\n    dx = xs - cx\n    # weighted covariance\n    c00 = float((weights * dx * dx).sum()) / wsum\n    c11 = float((weights * dy * dy).sum()) / wsum\n    c01 = float((weights * dx * dy).sum()) / wsum\n    cov = np.array([[c00, c01], [c01, c11]])\n    # eigenvalues\n    try:\n        vals = np.linalg.eigvalsh(cov)\n    except Exception:\n        return 0.0\n    lam1, lam2 = float(max(vals)), float(min(vals))\n    if lam1 + lam2 <= eps:\n        return 0.0\n    ecc = (np.sqrt(lam1) - np.sqrt(lam2)) / (np.sqrt(lam1) + np.sqrt(lam2) + eps)\n    return float(np.clip(ecc, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized entropy of intensity histogram (32 bins, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    a_min = float(a.min())\n    a_max = float(a.max())\n    if a_max <= a_min + eps:\n        return 0.0\n    hist, _ = np.histogram(a, bins=bins, range=(a_min, a_max))\n    prob = hist.astype(float) / (hist.sum() + eps)\n    prob = prob[prob > 0.0]\n    ent = -float((prob * np.log(prob)).sum())\n    norm = np.log(float(bins) + eps)\n    result = ent / (norm + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Verticality ratio: vertical gradient energy / total gradient energy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    vy = float(np.abs(gy).sum())\n    hx = float(np.abs(gx).sum())\n    total = vy + hx + eps\n    result = vy / total\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal orientation angle (radians) of ink pixels computed by PCA (range approx -pi/2..pi/2)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    t = (np.percentile(gray, 30) + np.percentile(gray, 70)) / 2.0\n    lower_mean = gray[gray <= t].mean() if np.any(gray <= t) else t\n    upper_mean = gray[gray > t].mean() if np.any(gray > t) else t\n    if lower_mean < upper_mean:\n        ink = (gray <= t)\n    else:\n        ink = (gray >= t)\n    coords = np.argwhere(ink)\n    if coords.shape[0] < 2:\n        return 0.0\n    # coords rows are (r, c) -> treat x = c, y = r\n    y = coords[:, 0].astype(float)\n    x = coords[:, 1].astype(float)\n    x = x - x.mean()\n    y = y - y.mean()\n    cov = np.array([[np.dot(x, x), np.dot(x, y)], [np.dot(y, x), np.dot(y, y)]]) / max(1.0, len(x) - 1)\n    eigvals, eigvecs = np.linalg.eigh(cov + 1e-12 * np.eye(2))\n    # principal eigenvector is last one\n    v = eigvecs[:, np.argmax(eigvals)]\n    angle = float(np.arctan2(v[1], v[0]))  # angle of principal axis\n    # normalize to [-pi/2, pi/2]\n    if angle > np.pi/2:\n        angle -= np.pi\n    if angle <= -np.pi/2:\n        angle += np.pi\n    return float(angle)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate edge fractal complexity: scale ratio of edge counts (0..1 scaled)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr1 = float(mag.mean())\n    N1 = float(np.count_nonzero(mag > thr1))\n    # downsample by 2x2 averaging where possible\n    hh = (h // 2) * 2\n    ww = (w // 2) * 2\n    if hh == 0 or ww == 0 or N1 <= 0:\n        return 0.0\n    small = a[:hh, :ww].reshape(hh // 2, 2, ww // 2, 2).mean(axis=(1, 3))\n    try:\n        gy2, gx2 = np.gradient(small)\n    except Exception:\n        return 0.0\n    mag2 = np.hypot(gx2, gy2)\n    thr2 = float(mag2.mean()) + 1e-12\n    N2 = float(np.count_nonzero(mag2 > thr2))\n    if N2 <= 0 or N1 <= 0:\n        return 0.0\n    # fractal-like exponent estimate\n    fd = np.log(N1 / N2) / np.log(2.0)\n    # normalize to a bounded range [0,1] assuming reasonable range up to 4\n    result = float(np.clip(fd / 4.0, 0.0, 1.0))\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels within 2% of the dynamic range around the median (flatness)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    amin, amax = flat.min(), flat.max()\n    dr = max(eps, amax - amin)\n    thr = 0.02 * dr\n    med = float(np.median(flat))\n    frac = float(np.sum(np.abs(flat - med) <= thr)) / float(flat.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-intensity pixel proportion: fraction of pixels below the 10th percentile'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        vals = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(img.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    thr = float(np.percentile(vals, 10))\n    result = float((vals < thr).sum()) / float(vals.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of empty (background) pixels in the right-middle region vs left-middle region (close to 1 => more empty on right)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    rng = float(gray.max() - gray.min())\n    if rng == 0:\n        return 0.5\n    med = float(np.median(gray)); mean = float(np.mean(gray)); delta = rng * 0.05\n    if mean < med:\n        fg = (gray < (med - delta)).astype(int)\n    else:\n        fg = (gray > (med + delta)).astype(int)\n    y0, y1 = h // 3, max(h // 3 + 1, 2 * h // 3)\n    mid_x0, mid_x1 = w // 3, max(w // 3 + 1, 2 * w // 3)\n    band = fg[y0:y1, mid_x0:mid_x1]\n    if band.size == 0:\n        return 0.5\n    mid = band.shape[1] // 2\n    left_band = band[:, :mid]\n    right_band = band[:, mid:]\n    left_bg = float((left_band == 0).sum())\n    right_bg = float((right_band == 0).sum())\n    total = left_bg + right_bg\n    if total == 0:\n        return 0.5\n    return float(right_bg / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-spot density: fraction of pixels that are strict local maxima above the 95th percentile'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.percentile(arr, 95)\n    # pad with -inf so edges can be maxima\n    pad = np.full((h + 2, w + 2), -np.inf, dtype=float)\n    pad[1:-1, 1:-1] = arr\n    center = pad[1:-1, 1:-1]\n    neighs = []\n    neighs.append(pad[:-2, :-2]); neighs.append(pad[:-2, 1:-1]); neighs.append(pad[:-2, 2:])\n    neighs.append(pad[1:-1, :-2]); neighs.append(pad[1:-1, 2:])\n    neighs.append(pad[2:, :-2]); neighs.append(pad[2:, 1:-1]); neighs.append(pad[2:, 2:])\n    greater = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        greater &= (center > n)\n    mask = (center > thr) & greater\n    count = float(np.count_nonzero(mask))\n    denom = float(center.size) if center.size else 1.0\n    result = count / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson correlation between pixel radius from center and intensity (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    r = np.sqrt((ys - cy) ** 2 + (xs - cx) ** 2).ravel()\n    vals = a.ravel()\n    if vals.size == 0:\n        return 0.0\n    r_mean = float(r.mean())\n    v_mean = float(vals.mean())\n    r_std = float(r.std()) + eps\n    v_std = float(vals.std()) + eps\n    cov = float(((r - r_mean) * (vals - v_mean)).mean())\n    corr = cov / (r_std * v_std + eps)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal vs vertical gradient energy (-1..1, + => more horizontal)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    gx_energy = float(np.sum(np.abs(gx)))\n    gy_energy = float(np.sum(np.abs(gy)))\n    denom = gx_energy + gy_energy + eps\n    result = (gx_energy - gy_energy) / denom\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of total edge energy located in a small circular region near the lower-right (detects 9 lower loop)'\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    grad = np.sqrt(gx * gx + gy * gy)\n    total = float(np.sum(grad)) + 1e-9\n    # circle centered toward lower-right\n    cy, cx = int(3 * h / 4), int(3 * w / 4)\n    r = max(1, min(h, w) // 8)\n    yy, xx = np.ogrid[:h, :w]\n    mask = (yy - cy) ** 2 + (xx - cx) ** 2 <= r * r\n    region_sum = float(np.sum(grad[mask]))\n    return float(region_sum) / total\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute vertical edge strength to mean absolute diagonal (descending) edge strength'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn < 1e-9:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    gx, gy = np.gradient(norm)\n    vert = np.mean(np.abs(gx))\n    diag_desc = np.mean(np.abs(gx + gy))\n    eps = 1e-9\n    return float((vert + eps) / (diag_desc + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Quadrant imbalance: normalized standard deviation of the four quadrant means'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    hm = h // 2\n    wm = w // 2\n    q1 = a[:hm, :wm]\n    q2 = a[:hm, wm:]\n    q3 = a[hm:, :wm]\n    q4 = a[hm:, wm:]\n    means = np.array([float(np.mean(x)) if x.size else 0.0 for x in (q1, q2, q3, q4)], dtype=float)\n    std_q = float(means.std())\n    gstd = float(a.std()) + eps\n    result = std_q / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of bounding box of nonzero pixels (height/width), returns 0 if no foreground'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2))\n    else:\n        a = np.nan_to_num(arr)\n    nz = np.count_nonzero(a)\n    if nz == 0:\n        return 0.0\n    rows = np.any(a != 0, axis=1)\n    cols = np.any(a != 0, axis=0)\n    r_idx = np.where(rows)[0]\n    c_idx = np.where(cols)[0]\n    if r_idx.size == 0 or c_idx.size == 0:\n        return 0.0\n    height = float(r_idx[-1] - r_idx[0] + 1)\n    width = float(c_idx[-1] - c_idx[0] + 1)\n    if width == 0.0:\n        return 0.0\n    result = height / width\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Peak prominence: (max - mean) / std clipped to [0..100]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    mx = float(flat.max())\n    mu = float(flat.mean())\n    sigma = float(flat.std()) + eps\n    val = (mx - mu) / sigma\n    result = float(np.clip(val, 0.0, 100.0))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0..1), 0 for grayscale'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    img = np.nan_to_num(arr.astype(float))\n    R = img[..., 0]\n    G = img[..., 1]\n    B = img[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    # Hasenfratz colorfulness measure\n    cf = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    # normalize by typical dynamic range\n    denom = (np.iinfo(img.dtype).max if np.issubdtype(img.dtype, np.integer) else 255.0) if hasattr(img, 'dtype') else 255.0\n    norm = cf / (denom + 1e-12)\n    return float(np.clip(np.tanh(norm * 2.0), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(arr.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    vmin = float(vals.min())\n    vmax = float(vals.max())\n    if vmax <= vmin:\n        return 0.0\n    bins = 256\n    hist, _ = np.histogram(vals, bins=bins, range=(vmin, vmax))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -float(np.sum(p_nonzero * np.log2(p_nonzero)))\n    max_entropy = np.log2(float(bins))\n    result = entropy / (max_entropy + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation coherence (0..1): proportion of gradient energy in main orientation bin'\n    import numpy as np\n    eps = 1e-12\n    bins = 12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    # map angles to 0..pi (orientation, not direction)\n    ang = np.abs(ang)\n    # histogram weighted by magnitude\n    hist, _ = np.histogram(ang.ravel(), bins=bins, range=(0.0, np.pi), weights=mag.ravel())\n    total = hist.sum() + eps\n    result = float(hist.max() / total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted horizontal centroid offset normalized to image half-width (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    xs = np.arange(w)[None, :]\n    total = float(img.sum())\n    if total == 0 or w <= 1:\n        return 0.0\n    centroid_x = float((img * xs).sum() / total)\n    cx = (w - 1) / 2.0\n    dist = abs(centroid_x - cx)\n    max_dist = cx if cx > 0 else 1.0\n    norm = dist / (max_dist + eps)\n    return float(np.clip(norm, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity moment elongation: ratio of major/minor eigenvalues of weighted covariance (>=1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        wimg = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        wimg = np.nan_to_num(img.astype(float))\n    h, w = wimg.shape\n    flat = wimg.ravel()\n    if flat.size == 0 or np.all(flat == 0):\n        return 0.0\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    weight = wimg\n    total = float(weight.sum())\n    if total <= eps:\n        return 0.0\n    mean_y = float((weight * ys).sum() / (total + eps))\n    mean_x = float((weight * xs).sum() / (total + eps))\n    dy = (ys - mean_y)\n    dx = (xs - mean_x)\n    cov_xx = float((weight * (dx ** 2)).sum() / (total + eps))\n    cov_yy = float((weight * (dy ** 2)).sum() / (total + eps))\n    cov_xy = float((weight * (dx * dy)).sum() / (total + eps))\n    cov = np.array([[cov_xx, cov_xy], [cov_xy, cov_yy]])\n    try:\n        vals = np.linalg.eigvalsh(cov)\n    except Exception:\n        return 0.0\n    vals = np.sort(vals)\n    small = max(vals[0], eps)\n    ratio = max(vals[-1] / small, 1.0)\n    # clamp to avoid extreme values\n    return float(min(ratio, 100.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Prominence of the darkest pixel relative to its local neighborhood (positive = pronounced dark spot)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    idx = np.argmin(arr)\n    y, x = np.unravel_index(idx, arr.shape)\n    r = 2  # neighborhood radius => 5x5\n    y0 = max(0, y - r); y1 = min(h, y + r + 1)\n    x0 = max(0, x - r); x1 = min(w, x + r + 1)\n    local = arr[y0:y1, x0:x1]\n    if local.size == 0:\n        return 0.0\n    local_mean = float(np.mean(local))\n    overall_std = float(np.std(arr)) + eps\n    prominence = (local_mean - float(arr[y, x])) / overall_std\n    return float(prominence)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of edge orientation histogram (0..1), weighted by gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    bins = 8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    total_mag = mag.sum()\n    if total_mag < eps:\n        return 0.0\n    ang = np.arctan2(gy, gx)\n    # orientation modulo pi (ignore direction)\n    ang = np.mod(ang, np.pi)\n    hist, _ = np.histogram(ang, bins=bins, range=(0.0, np.pi), weights=mag)\n    p = hist / (hist.sum() + eps)\n    ppos = p[p > 0]\n    entropy = -float(np.sum(ppos * np.log(ppos)))\n    norm = float(np.log(bins) + eps)\n    return float(np.clip(entropy / norm, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative ink density in the left-middle quadrant vs the whole left half (low for digits like 3 which avoid the left center)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image, dtype=float)\n    if len(arr.shape) == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    denom = mx - mn if mx != mn else 1.0\n    ink = (((mx - gray) / denom) > 0.2).astype(np.float32)\n    top = h // 4\n    bottom = (3 * h) // 4\n    mid_left = ink[top:bottom, 0:w//2]\n    left_half = ink[:, 0:w//2]\n    area_mid = float(max(1, mid_left.size))\n    area_left = float(max(1, left_half.size))\n    density_mid = float(np.sum(mid_left) / area_mid)\n    density_left = float(np.sum(left_half) / area_left)\n    eps = 1e-8\n    return float(density_mid / (density_left + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with gradient magnitude above mean+std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    if img.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(img)\n        mag = np.hypot(gx, gy)\n    except Exception:\n        return 0.0\n    thr = float(mag.mean() + mag.std())\n    count = float(np.count_nonzero(mag > thr))\n    result = count / float(img.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation dispersion (0 coherent -> 1 highly dispersed)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(img)\n    mag = np.hypot(gx, gy)\n    total_mag = float(mag.sum()) + eps\n    if total_mag <= eps:\n        return 0.0\n    cx = (mag * np.cos(np.arctan2(gy, gx))).sum() / total_mag\n    cy = (mag * np.sin(np.arctan2(gy, gx))).sum() / total_mag\n    R = float(np.hypot(cx, cy))\n    R = min(max(R, 0.0), 1.0)\n    dispersion = 1.0 - R\n    return float(np.clip(dispersion, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Percentile contrast (p90-p10)/(p90+p10) (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    flat = arr.ravel()\n    if flat.size == 0:\n        return 0.0\n    p10, p90 = np.percentile(flat, [10.0, 90.0])\n    denom = (p90 + p10 + eps)\n    result = (p90 - p10) / denom\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference in mean absolute vertical gradient between right and left thirds, normalized by total gradient energy'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float32)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape\n    try:\n        gy, gx = np.gradient(gray)\n    except Exception:\n        return 0.0\n    left_end = w // 3\n    right_start = 2 * w // 3\n    left_energy = np.abs(gy[:, :left_end]).mean() if left_end > 0 else 0.0\n    right_energy = np.abs(gy[:, right_start:]).mean() if right_start < w else 0.0\n    total = (np.abs(gx).mean() + np.abs(gy).mean()) + 1e-9\n    return float((right_energy - left_energy) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy fraction in 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    power = np.abs(F) ** 2\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    rmax = float(r.max()) + eps\n    high_mask = r >= (0.5 * rmax)\n    high_energy = float(power[high_mask].sum())\n    total_energy = float(power.sum()) + eps\n    result = high_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left/right (vertical) symmetry: normalized mean absolute difference between left half and mirrored right half (0 symmetric, larger = asymmetric)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = gray[:, :mid]\n    right = gray[:, w-mid:][:, ::-1]  # mirrored right\n    # if halves mismatched shapes (odd width), pad smaller\n    if left.shape[1] != right.shape[1]:\n        minw = min(left.shape[1], right.shape[1])\n        left = left[:, :minw]\n        right = right[:, :minw]\n    diff = np.abs(left - right)\n    # normalize by mean intensity range to make scale-invariant\n    denom = (np.mean(gray) + np.std(gray) + 1e-9)\n    score = np.mean(diff) / denom\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal left-right symmetry score (1 = perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 1.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    if left.size == 0 or right.size == 0:\n        return 1.0\n    # flip right for comparison\n    right_flipped = np.fliplr(right)\n    # if widths differ (odd), center column ignored\n    min_w = min(left.shape[1], right_flipped.shape[1])\n    left = left[:, :min_w]\n    right_flipped = right_flipped[:, :min_w]\n    diff = np.abs(left - right_flipped)\n    denom = float(np.mean(np.abs(a))) + eps\n    norm_diff = float(np.mean(diff)) / denom\n    score = 1.0 - np.clip(norm_diff, 0.0, 1.0)\n    return float(score)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute vertical gradient in right half divided by left half ( >1 means stronger vertical changes on right side )'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray.astype(float))\n    mag_v = np.abs(gy)\n    mid = w // 2\n    left_mean = float(np.mean(mag_v[:, 0:mid])) if mid > 0 else 0.0\n    right_mean = float(np.mean(mag_v[:, mid:])) if mid < w else 0.0\n    denom = left_mean + 1e-9\n    return float(right_mean / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal shift of centroid between top and bottom halves (captures diagonal/leaning strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    mn, mx = gray.min(), gray.max()\n    thresh = (mn + mx) / 2.0\n    ink = gray < thresh if gray.mean() > thresh else gray > thresh\n    h, w = ink.shape\n    top = ink[:h//2, :]\n    bot = ink[h//2:, :]\n    def centroid_x(arr):\n        coords = np.argwhere(arr)\n        if coords.size == 0:\n            return w / 2.0\n        return float(coords[:, 1].mean())\n    cx_top = centroid_x(top)\n    cx_bot = centroid_x(bot) + 0.0\n    # return signed shift normalized by width\n    return float((cx_top - cx_bot) / (w + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest continuous horizontal ink run within the top quarter center zone normalized by width'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    top_h = max(1, h // 4)\n    center_w1 = max(0, w//4)\n    center_w2 = min(w, 3*w//4)\n    zone = gray[0:top_h, center_w1:center_w2]\n    if zone.size == 0:\n        return 0.0\n    thresh = float(np.mean(zone))\n    low = int(np.count_nonzero(zone < thresh))\n    high = int(np.count_nonzero(zone > thresh))\n    if low < high:\n        ink_zone = (zone < thresh).astype(np.uint8)\n    else:\n        ink_zone = (zone > thresh).astype(np.uint8)\n    # compute longest horizontal run across all rows in zone\n    longest = 0\n    for row in ink_zone:\n        # find longest run of ones in row\n        current = 0\n        maxr = 0\n        for v in row:\n            if v:\n                current += 1\n            else:\n                if current > maxr:\n                    maxr = current\n                current = 0\n        if current > maxr:\n            maxr = current\n        if maxr > longest:\n            longest = maxr\n    norm = float(longest / max(1, center_w2 - center_w1))\n    return norm\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local diagonal (down-right) stroke strength in the top-right quadrant (detects 4-like diagonal)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image, dtype=float)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    # choose a small top-right window\n    r0, r1 = 0, max(1, h//2)\n    c0, c1 = max(0, w//2), min(w, max(1, 3*w//4))\n    region = gray[r0:r1, c0:c1]\n    if region.size == 0:\n        return 0.0\n    gy, gx = np.gradient(region.astype(float))\n    mag = np.sqrt(gx*gx + gy*gy) + 1e-12\n    angle = np.arctan2(gy, gx)  # -pi..pi\n    # target diagonal down-right is -pi/4 (~ -0.785)\n    target = -0.7853981633974483\n    # weight by magnitude and compute similarity via Gaussian\n    diff = angle - target\n    # wrap to [-pi, pi]\n    diff = (diff + np.pi) % (2*np.pi) - np.pi\n    sim = np.exp(- (diff**2) / (0.6 + 0.5))  # moderate width\n    score = np.sum(sim * mag) / (np.sum(mag) + 1e-12)\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of per-row ink density normalized by the mean row density (higher => more vertical sparsity)'\n    if image is None:\n        return 0.0\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    if h == 0 or w == 0:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(np.float64)\n    flat = gray.flatten()\n    thr = np.percentile(flat, 50)\n    low_mean = np.mean(flat[:max(1, len(flat)//10)])\n    high_mean = np.mean(flat[-max(1, len(flat)//10):])\n    if low_mean < high_mean:\n        ink = (gray < thr).astype(np.uint8)\n    else:\n        ink = (gray > thr).astype(np.uint8)\n    row_counts = ink.sum(axis=1).astype(np.float64)\n    mean_row = row_counts.mean() + 1e-9\n    std_row = row_counts.std()\n    return float(std_row / mean_row)\n",
    "def feature(image: np.ndarray) -> float:\n    'Bias of ink lying near the anti-diagonal (top-right -> bottom-left) versus main diagonal (-1..1)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn < 1e-8:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    low_count = np.sum(norm < 0.5)\n    high_count = norm.size - low_count\n    if low_count < high_count:\n        ink = (norm < 0.5)\n    else:\n        ink = (norm > 0.5)\n    Y, X = np.indices((h, w))\n    # normalized coordinates 0..1\n    xn = X / max(1.0, (w - 1))\n    yn = Y / max(1.0, (h - 1))\n    # distance to main diagonal y ~= x and anti-diagonal y ~= 1-x\n    dist_main = np.abs(yn - xn)\n    dist_anti = np.abs(yn - (1.0 - xn))\n    # choose a band width relative to image diag span\n    band = 0.15\n    near_main = np.logical_and(ink, dist_main < band)\n    near_anti = np.logical_and(ink, dist_anti < band)\n    nm = float(np.sum(near_main))\n    na = float(np.sum(near_anti))\n    if nm + na < 1e-6:\n        return 0.0\n    val = (na - nm) / (nm + na)\n    return float(val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by mean absolute intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n        gxx = np.gradient(gx, axis=1)\n        gyy = np.gradient(gy, axis=0)\n        lap = gxx + gyy\n    except Exception:\n        return 0.0\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    mean_abs_img = float(np.mean(np.abs(arr))) + eps\n    result = mean_abs_lap / mean_abs_img\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio: mean absolute Laplacian divided by mean absolute intensity (higher -> more detail)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # discrete Laplacian via roll (4-neighbor)\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) + np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    hf = float(np.mean(np.abs(lap)))\n    base = float(np.mean(np.abs(a))) + eps\n    result = hf / base\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical transition rate: normalized count of binary transitions along columns (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w == 0:\n        return 0.0\n    thr = float(np.median(a))\n    b = (a > thr).astype(np.int8)\n    transitions = np.abs(np.diff(b, axis=0))\n    count = float(transitions.sum())\n    norm = float((h - 1) * w) + eps\n    return float(np.clip(count / norm, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized histogram entropy of intensities (0..1), uses 32 bins'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    flat = arr.ravel()\n    if flat.size == 0:\n        return 0.0\n    bins = 32\n    mn = float(flat.min()); mx = float(flat.max())\n    if mn == mx:\n        return 0.0\n    hist, _ = np.histogram(flat, bins=bins, range=(mn, mx))\n    probs = hist.astype(float) / (hist.sum() + 1e-12)\n    probs = probs[probs > 0.0]\n    ent = -np.sum(probs * np.log(probs))\n    # normalize by log(bins)\n    result = float(ent / (np.log(bins) + 1e-12))\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strict local intensity maxima among pixels (bright spots density)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # pad with -inf so borders are handled\n    pad = np.pad(a, pad_width=1, mode='constant', constant_values=-np.inf)\n    center = pad[1:-1, 1:-1]\n    neighs = [\n        pad[0:-2, 0:-2], pad[0:-2, 1:-1], pad[0:-2, 2:],\n        pad[1:-1, 0:-2],                 pad[1:-1, 2:],\n        pad[2:  , 0:-2], pad[2:  , 1:-1], pad[2:  , 2:]\n    ]\n    greater_than_all = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        greater_than_all &= (center > n)\n    # threshold to avoid tiny peaks: require value > global mean + std\n    thr = float(np.mean(a)) + float(np.std(a)) * 0.5\n    peaks = greater_than_all & (a > thr)\n    frac = float(np.count_nonzero(peaks)) / float(a.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 64 histogram bins'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    # choose bins based on data range\n    mn, mx = float(flat.min()), float(flat.max())\n    if mx <= mn:\n        return 0.0\n    bins = 64\n    hist, _ = np.histogram(flat, bins=bins, range=(mn, mx))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p_nonzero = p[p > 0.0]\n    entropy = -np.sum(p_nonzero * np.log(p_nonzero + eps))\n    # normalize by log(bins) to get [0,1]\n    result = entropy / (np.log(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio using Laplacian (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # simple 4-neighbor Laplacian\n    neigh = (np.roll(a, 1, 0) + np.roll(a, -1, 0) + np.roll(a, 1, 1) + np.roll(a, -1, 1)) / 4.0\n    lap = a - neigh\n    hf_energy = float((lap ** 2).sum())\n    total_energy = float((a ** 2).sum()) + eps\n    result = hf_energy / (total_energy + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score: normalized average absolute column difference between left and flipped right halves'\n    # Convert to grayscale safely\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # split columns\n    mid = w // 2\n    left = gray[:, :mid]\n    right = gray[:, w - mid:w][:, ::-1]  # flipped right part to align with left\n    # if mismatch in sizes (odd width), pad smaller one\n    if left.shape[1] != right.shape[1]:\n        minw = min(left.shape[1], right.shape[1])\n        left = left[:, :minw]\n        right = right[:, :minw]\n    # compute normalized L1 difference\n    denom = np.maximum(1.0, np.mean(np.abs(left)) + 1e-6)\n    score = np.mean(np.abs(left - right)) / denom\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (0 for grayscale), normalized by overall intensity std'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim < 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    R = a[:, :, 0]\n    G = a[:, :, 1]\n    B = a[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    norm = float(a.mean() if float(a.std()) <= 0 else a.std()) + 1e-8\n    result = colorfulness / norm\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 32 bins'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    mn = float(vals.min())\n    mx = float(vals.max())\n    if mx <= mn:\n        return 0.0\n    hist, _ = np.histogram(vals, bins=bins, range=(mn, mx))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0]\n    if p.size == 0:\n        return 0.0\n    entropy = -float((p * np.log2(p)).sum())\n    max_ent = np.log2(bins)\n    result = float(np.clip(entropy / (max_ent + eps), 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized aspect ratio: (height/width - 1), clipped to [-5,5]'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        h, w = a.shape\n    except Exception:\n        return 0.0\n    if w == 0:\n        return 0.0\n    val = float(h) / float(w) - 1.0\n    return float(np.clip(val, -5.0, 5.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-region bounding-box elongation (0..1): 0=square, 1=very elongated, based on pixels > mean+std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    thr = float(a.mean() + a.std())\n    mask = a > thr\n    if np.count_nonzero(mask) < 3:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bh = max(1, y1 - y0 + 1)\n    bw = max(1, x1 - x0 + 1)\n    aspect = float(min(bw, bh) / (max(bw, bh) + eps))\n    # elongation: 0 => square, 1 => line-like\n    result = float(1.0 - aspect)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy fraction via discrete Laplacian normalized by total energy'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # discrete Laplacian using roll trick\n    lap = -4.0 * a\n    lap += np.roll(a, 1, axis=0)\n    lap += np.roll(a, -1, axis=0)\n    lap += np.roll(a, 1, axis=1)\n    lap += np.roll(a, -1, axis=1)\n    high_energy = float(np.sum(np.abs(lap)))\n    total_energy = float(np.sum(np.abs(a))) + eps\n    result = high_energy / total_energy\n    return float(np.clip(result, 0.0, 1e6))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with gradient magnitude above the 75th percentile'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy).ravel()\n    if mag.size == 0:\n        return 0.0\n    thresh = float(np.percentile(mag, 75))\n    frac = float(np.count_nonzero(mag > thresh)) / float(mag.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of horizontal edge strength in top third to bottom third (5 often has strong top horizontal stroke)'\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    gray = gray.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3:\n        return 0.0\n    grad_y, grad_x = np.gradient(gray)\n    horiz = np.abs(grad_y)  # horizontal edges where intensity changes top-bottom\n    third = max(1, h // 3)\n    top_sum = np.sum(horiz[:third, :])\n    bot_sum = np.sum(horiz[-third:, :])\n    eps = 1e-6\n    return float((top_sum + eps) / (bot_sum + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of discrete Laplacian (focus/sharpness measure)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    up = np.roll(img, -1, axis=0)\n    down = np.roll(img, 1, axis=0)\n    left = np.roll(img, -1, axis=1)\n    right = np.roll(img, 1, axis=1)\n    lap = 4.0 * img - (up + down + left + right)\n    var = float(np.var(lap))\n    # normalize by image dynamic range to be robust across scales\n    dyn = float(np.max(img) - np.min(img)) + eps\n    result = var / (dyn ** 2 + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by image std (higher => sharper)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # Laplacian via 4-neighbor difference: neighbors_sum - 4*center\n    up = np.roll(a, -1, axis=0)\n    down = np.roll(a, 1, axis=0)\n    left = np.roll(a, -1, axis=1)\n    right = np.roll(a, 1, axis=1)\n    lap = (up + down + left + right) - 4.0 * a\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    overall_std = float(a.std()) + eps\n    result = mean_abs_lap / overall_std\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of non-zero pixel density in center region to non-zero density in border (>=0)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ch = max(1, h // 4)\n    cw = max(1, w // 4)\n    r0 = max(0, h//2 - ch//2)\n    r1 = min(h, r0 + ch)\n    c0 = max(0, w//2 - cw//2)\n    c1 = min(w, c0 + cw)\n    center = a[r0:r1, c0:c1]\n    border_mask = np.ones_like(a, dtype=bool)\n    border_mask[r0:r1, c0:c1] = False\n    border = a[border_mask]\n    if center.size == 0:\n        return 0.0\n    center_nonzero = float(np.count_nonzero(center)) / float(center.size + eps)\n    border_nonzero = float(np.count_nonzero(border)) / (float(border.size) + eps)\n    # if border is almost empty (very dark), return center density\n    if border_nonzero < eps:\n        return float(np.clip(center_nonzero, 0.0, 1.0))\n    result = center_nonzero / (border_nonzero + eps)\n    return float(np.clip(result, 0.0, 100.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of strong edges (edge density) using gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(np.mean(mag) + 0.5 * mag.std())\n    strong = (mag > thr)\n    result = float(np.count_nonzero(strong)) / float(a.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized x-coordinate of the ink centroid relative to image center (centroid_x - 0.5)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[:3, :].ravel(), gray[-3:, :].ravel(), gray[:, :3].ravel(), gray[:, -3:].ravel()]) if h>=3 and w>=3 else gray.ravel()\n    center = gray[h//4:3*h//4, w//4:3*w//4] if h>=4 and w>=4 else gray\n    border_mean = float(border.mean()) if border.size else 0.0\n    thresh = float(np.percentile(gray, 50)) if gray.size else 0.5\n    ink = (gray < thresh) if border_mean > (center.mean() if center.size else 0.0) else (gray > thresh)\n    ink = ink.astype(np.float64)\n    total = ink.sum()\n    if total <= 1e-9:\n        return 0.0\n    cols = np.arange(w)\n    cx = (ink.sum(axis=0) * cols).sum() / (total + 1e-9)\n    # normalized relative to center: range approx [-0.5,0.5]\n    return float((cx / max(1, w - 1)) - 0.5)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal edge energy in top third normalized by overall horizontal edge energy (detects top bars)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3 or w < 2:\n        return 0.0\n    dx = np.abs(np.diff(gray, axis=1))\n    top_dx = dx[0:max(1, h//3), :]\n    total = dx.sum() + 1e-8\n    return float(top_dx.sum() / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of border pixels with strong gradient (edge activity concentrated near image borders)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    # border width as 1/8 of min dimension, at least 1\n    bw = max(1, min(h, w) // 8)\n    mask = np.zeros_like(a, dtype=bool)\n    mask[:bw, :] = True\n    mask[-bw:, :] = True\n    mask[:, :bw] = True\n    mask[:, -bw:] = True\n    if not np.any(mask):\n        return 0.0\n    # threshold for strong gradient\n    thr = float(mag.mean() + mag.std())\n    strong = (mag > thr) & mask\n    result = float(np.count_nonzero(strong)) / float(np.count_nonzero(mask) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density: fraction of pixels with gradient magnitude above adaptive threshold'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    thr = float(mag.mean() + 0.5 * mag.std())\n    mask = mag > thr\n    result = float(np.count_nonzero(mask)) / float(mag.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized strength of a continuous horizontal stroke in the top 25% rows (detects top bar of \"7\")'\n    import numpy as np\n    arr = np.array(image, dtype=float)\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    fg = gray < th\n    if np.count_nonzero(fg) > gray.size / 2:\n        fg = ~fg\n    top_rows = max(1, h // 4)\n    # for each top row compute fraction of columns that are foreground; take the maximum\n    row_sums = np.sum(fg[:top_rows, :], axis=1).astype(float)\n    max_frac = np.max(row_sums) / float(w)\n    # Also scale by how many top rows have above-median fill\n    median_row = np.median(row_sums)\n    high_rows = np.count_nonzero(row_sums > median_row)\n    score = max_frac * (high_rows / float(top_rows))\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of local peaks (strict local maxima among 8-neighbors), normalized by image area'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    pad = np.pad(a, 1, mode='constant', constant_values=np.min(a) - 1.0)\n    center = pad[1:-1, 1:-1]\n    # neighbors\n    n1 = pad[0:-2, 0:-2]; n2 = pad[0:-2, 1:-1]; n3 = pad[0:-2, 2:]\n    n4 = pad[1:-1, 0:-2]; n5 = pad[1:-1, 2:]\n    n6 = pad[2:, 0:-2]; n7 = pad[2:, 1:-1]; n8 = pad[2:, 2:]\n    peaks = (center > n1) & (center > n2) & (center > n3) & (center > n4) & (center > n5) & (center > n6) & (center > n7) & (center > n8)\n    count = int(np.count_nonzero(peaks))\n    area = float(max(1, h * w))\n    result = count / area\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near the image maximum (indicates saturation/highlights)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    mn = float(a.min())\n    mx = float(a.max())\n    rng = mx - mn + eps\n    # consider pixels within top 2% of range as near-saturated\n    thr = mx - 0.02 * rng\n    count = int(np.count_nonzero(a >= thr))\n    frac = float(count) / float(a.size)\n    return float(frac)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-surround contrast normalized by image std (center minus border)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    ch0, ch1 = h // 4, w // 4\n    cy0, cy1 = ch0, h - ch0\n    cx0, cx1 = ch1, w - ch1\n    center = img[cy0:cy1, cx0:cx1]\n    if center.size == 0:\n        return 0.0\n    mask = np.ones_like(img, dtype=bool)\n    mask[cy0:cy1, cx0:cx1] = False\n    border = img[mask]\n    center_mean = float(np.mean(center)) if center.size else 0.0\n    border_mean = float(np.mean(border)) if border.size else 0.0\n    overall_std = float(np.std(img)) + eps\n    result = (center_mean - border_mean) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance of intensity center-of-mass from geometric center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total = float(img.sum()) + eps\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    mx = float((img * xs).sum()) / total\n    my = float((img * ys).sum()) / total\n    dx = mx - cx\n    dy = my - cy\n    # normalize by image diagonal\n    diag = np.hypot(w, h) + eps\n    result = np.hypot(dx, dy) / diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of horizontal projection peaks in the middle third of the image (how many separated horizontal strokes), normalized by image height'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    thresh = np.mean(gray)\n    ink = (gray < thresh) if np.max(gray) > np.min(gray) else (gray != 0)\n    c1, c2 = w // 3, 2 * w // 3\n    band = ink[:, c1:c2]\n    proj = band.sum(axis=1).astype(float)\n    if proj.max() == 0:\n        return 0.0\n    # smooth with 3-point median-ish smoothing\n    sm = np.convolve(proj, np.ones(3)/3.0, mode='same')\n    # threshold peaks relative to max and mean\n    peak_thresh = max(1.0, 0.3 * sm.max(), sm.mean())\n    above = sm > peak_thresh\n    # count upward transitions\n    peaks = int(np.sum((~above[:-1]) & (above[1:]))) if above.size > 1 else int(above[0])\n    return float(peaks / max(1.0, h))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-spot proportion: fraction of pixels brighter than mean+std (captures sparse highlights)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    n = a.size\n    if n == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thresh = m + s\n    count = float((a > thresh).sum())\n    result = count / float(n)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-region mean intensity minus global mean (positive when center is lighter -> possible loop/hole)'\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    global_mean = float(np.mean(gray))\n    ch0, cw0 = max(1, h // 6), max(1, w // 6)\n    cy0, cx0 = h // 2 - ch0, w // 2 - cw0\n    cy1, cx1 = h // 2 + ch0 + 1, w // 2 + cw0 + 1\n    cy0, cx0 = max(0, cy0), max(0, cx0)\n    cy1, cx1 = min(h, cy1), min(w, cx1)\n    center = gray[cy0:cy1, cx0:cx1]\n    if center.size == 0:\n        return 0.0\n    center_mean = float(np.mean(center))\n    return float(center_mean - global_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized mean absolute Laplacian (high-frequency energy relative to mean intensity)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    # discrete Laplacian via neighbor rolls\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) +\n           np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    mean_abs = float(np.mean(np.abs(a))) + eps\n    result = mean_abs_lap / mean_abs\n    return float(np.clip(result, 0.0, 50.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local 3x3 standard deviation normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute local mean and mean of squares using rolling sums (3x3)\n    def local_mean(X):\n        s = np.zeros_like(X)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    local_m = local_mean(a)\n    local_m2 = local_mean(a * a)\n    local_var = np.maximum(0.0, local_m2 - (local_m ** 2))\n    local_std = np.sqrt(local_var)\n    mean_local_std = float(np.mean(local_std))\n    gstd = float(a.std()) + eps\n    result = mean_local_std / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of intensity-weighted center-of-mass from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    # use nonnegative weights\n    weights = a - float(a.min())\n    wsum = float(weights.sum())\n    if wsum <= eps:\n        return 0.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    cy = float((weights * ys).sum()) / wsum\n    cx = float((weights * xs).sum()) / wsum\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    maxrad = np.hypot(h, w) / 2.0 + eps\n    result = dist / maxrad\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Otsu-based normalized separation: (mean_high - mean_low) / (overall_mean+eps)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    # map to 256 bins based on data range\n    amin, amax = arr.min(), arr.max()\n    if amax <= amin:\n        return 0.0\n    nbins = 256\n    hist, edges = np.histogram(arr, bins=nbins, range=(amin, amax))\n    hist = hist.astype(float)\n    total = hist.sum()\n    if total <= 0:\n        return 0.0\n    probs = hist / total\n    bin_centers = (edges[:-1] + edges[1:]) / 2.0\n    cumulative = np.cumsum(probs)\n    cumulative_mean = np.cumsum(probs * bin_centers)\n    global_mean = cumulative_mean[-1]\n    # compute between-class variance and best threshold\n    sigma_b = (global_mean * cumulative - cumulative_mean) ** 2 / (cumulative * (1 - cumulative) + eps)\n    idx = np.nanargmax(sigma_b)\n    thresh = bin_centers[idx]\n    low = arr[arr <= thresh]\n    high = arr[arr > thresh]\n    if low.size == 0 or high.size == 0:\n        return 0.0\n    mean_low = low.mean()\n    mean_high = high.mean()\n    overall_mean = arr.mean()\n    result = (mean_high - mean_low) / (abs(overall_mean) + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variation of local block contrasts: std of block stds normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # choose 4x4 blocks (or fewer if small)\n    bh = max(1, h // 4)\n    bw = max(1, w // 4)\n    block_stds = []\n    for y in range(0, h, bh):\n        for x in range(0, w, bw):\n            block = a[y:min(h, y + bh), x:min(w, x + bw)]\n            if block.size:\n                block_stds.append(block.std())\n    if not block_stds:\n        return 0.0\n    block_stds = np.array(block_stds, dtype=float)\n    global_std = float(a.std()) + eps\n    result = float(block_stds.std() / global_std)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of diagonal-edge energy vs total edge energy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    diag1 = np.abs(gx + gy)\n    diag2 = np.abs(gx - gy)\n    diag_energy = float(np.sum(diag1 + diag2))\n    axis_energy = float(np.sum(np.abs(gx) + np.abs(gy)))\n    denom = diag_energy + axis_energy + eps\n    result = diag_energy / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of isolated bright pixels above mean+2*std (isolated means no neighboring bright pixels)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    thr = float(a.mean() + 2.0 * a.std())\n    mask = (a > thr).astype(np.int32)\n    # neighbor count in 3x3 (including self)\n    s = np.zeros_like(mask)\n    s += mask\n    s += np.roll(mask, 1, axis=0)\n    s += np.roll(mask, -1, axis=0)\n    s += np.roll(mask, 1, axis=1)\n    s += np.roll(mask, -1, axis=1)\n    s += np.roll(np.roll(mask, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(mask, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(mask, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(mask, -1, axis=0), -1, axis=1)\n    isolated = (mask == 1) & (s == 1)\n    count = float(np.count_nonzero(isolated))\n    denom = float(a.size)\n    result = count / (denom + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average distance of top-right quadrant ink pixels to the top-right corner (smaller if strokes start near corner)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = gray.min(), gray.max()\n    if mx - mn <= 1e-8:\n        return 1.0\n    norm = (gray - mn) / (mx - mn)\n    bin_img = norm < 0.5\n    if np.sum(bin_img) == 0:\n        bin_img = norm > 0.5\n    tr = bin_img[0:h//2, w//2:w]\n    ys, xs = np.nonzero(tr)\n    if ys.size == 0:\n        return 1.0\n    # coordinates relative to full image\n    ys_full = ys\n    xs_full = xs + (w//2)\n    dists = np.hypot((ys_full - 0), (xs_full - (w - 1)))\n    maxd = np.hypot(h, w) + 1e-8\n    result = float(np.mean(dists) / maxd)\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Correlation between radial distance from center and mean intensity of annuli (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    yy, xx = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(yy - cy, xx - cx)\n    # bin radii into up to 10 annuli\n    nbins = min(10, max(2, int(min(h, w) // 2)))\n    # use percentiles of r to ensure bins have samples\n    edges = np.percentile(r.ravel(), np.linspace(0, 100, nbins + 1))\n    means = []\n    centers = []\n    for i in range(nbins):\n        mask = (r >= edges[i]) & (r <= edges[i + 1])\n        if np.count_nonzero(mask) == 0:\n            means.append(0.0)\n        else:\n            means.append(float(img[mask].mean()))\n        centers.append(float((edges[i] + edges[i + 1]) / 2.0))\n    means = np.array(means)\n    centers = np.array(centers)\n    if np.allclose(means, means[0]) or np.allclose(centers, centers[0]):\n        return 0.0\n    # Pearson correlation\n    cm = centers - centers.mean()\n    mm = means - means.mean()\n    denom = (np.sqrt((cm * cm).sum() * (mm * mm).sum()) + eps)\n    corr = float((cm * mm).sum() / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average diagonal orientation score (high when gradients align near 45\u00b0 or 225\u00b0)'\n    import numpy as np\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # gradients\n    try:\n        gy, gx = np.gradient(gray)\n    except Exception:\n        gx = np.zeros_like(gray)\n        gy = np.zeros_like(gray)\n    mag = np.hypot(gx, gy)\n    if mag.sum() == 0:\n        return 0.0\n    ang = np.abs(np.arctan2(gy, gx))  # range [0, pi]\n    # distance from diagonal (pi/4), normalized to [0,1] where 1 means perfect diagonal\n    dist = np.abs(ang - (np.pi / 4.0)) / (np.pi / 4.0)\n    diag_score = 1.0 - np.clip(dist, 0.0, 1.0)\n    # weighted mean by magnitude\n    return float((diag_score * mag).sum() / mag.sum())\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity correlation: absolute Pearson correlation between radius and mean ring intensity (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    r = r.ravel()\n    vals = a.ravel()\n    # bin radii into integer bins\n    rbins = np.unique(np.floor(r).astype(int))\n    if rbins.size < 2:\n        return 0.0\n    ring_means = []\n    ring_centers = []\n    for b in rbins:\n        mask = (np.floor(r) == b)\n        if mask.sum() == 0:\n            continue\n        ring_means.append(vals[mask].mean())\n        ring_centers.append(float(b))\n    ring_means = np.array(ring_means, dtype=float)\n    ring_centers = np.array(ring_centers, dtype=float)\n    if ring_means.size < 2:\n        return 0.0\n    # Pearson correlation\n    rm = ring_means.mean()\n    rc = ring_centers.mean()\n    num = ((ring_means - rm) * (ring_centers - rc)).sum()\n    den = np.sqrt(((ring_means - rm) ** 2).sum() * ((ring_centers - rc) ** 2).sum()) + 1e-12\n    corr = num / den\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Eccentricity of bright region from intensity-weighted covariance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = a > thr\n    if not np.any(mask):\n        # fallback to all pixels weighted by intensity above min\n        weights = np.maximum(a - a.min(), 0.0).ravel()\n        coords_y = np.repeat(np.arange(h), w).astype(float)\n        coords_x = np.tile(np.arange(w), h).astype(float)\n    else:\n        weights = a[mask].astype(float).ravel()\n        ys, xs = np.nonzero(mask)\n        coords_y = ys.astype(float)\n        coords_x = xs.astype(float)\n    total_w = weights.sum() + eps\n    if total_w <= eps:\n        return 0.0\n    cy = (weights * coords_y).sum() / total_w\n    cx = (weights * coords_x).sum() / total_w\n    dy = coords_y - cy\n    dx = coords_x - cx\n    cov_yy = (weights * (dy * dy)).sum() / total_w\n    cov_xx = (weights * (dx * dx)).sum() / total_w\n    cov_xy = (weights * (dx * dy)).sum() / total_w\n    # 2x2 covariance eigenvalues\n    trace = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    disc = max(0.0, trace * trace - 4.0 * det)\n    sqrt_disc = np.sqrt(disc)\n    lam1 = 0.5 * (trace + sqrt_disc)\n    lam2 = 0.5 * (trace - sqrt_disc)\n    lam1 = max(lam1, 0.0)\n    lam2 = max(lam2, 0.0)\n    result = 1.0 - (lam2 + eps) / (lam1 + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate corner density (0..1): fraction of strong Harris-like corners'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    A = gx * gx\n    B = gx * gy\n    C = gy * gy\n    # local sum over 3x3 via shifts\n    shifts = [(0,0),(-1,0),(1,0),(0,-1),(0,1),(-1,-1),(-1,1),(1,-1),(1,1)]\n    As = sum(np.roll(np.roll(A, r, axis=0), c, axis=1) for r,c in shifts)\n    Bs = sum(np.roll(np.roll(B, r, axis=0), c, axis=1) for r,c in shifts)\n    Cs = sum(np.roll(np.roll(C, r, axis=0), c, axis=1) for r,c in shifts)\n    k = 0.04\n    R = (As * Cs) - (Bs * Bs) - k * ((As + Cs) ** 2)\n    # threshold relative to robust statistics\n    thr = np.median(R) + 0.5 * (np.std(R) + 1e-12)\n    corners = (R > thr)\n    result = float(corners.sum()) / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean ink density in the lower-left quadrant (captures loops or low-left strokes like 6)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    m, med = np.mean(gray), np.median(gray)\n    thresh = (m + med) / 2.0\n    mask = (gray < thresh) if (m < med) else (gray > thresh)\n    h, w = gray.shape[:2]\n    r0, r1 = h//2, h\n    c0, c1 = 0, w//2\n    region = mask[r0:r1, c0:c1]\n    if region.size == 0:\n        return 0.0\n    return float(np.mean(region))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance of bright-pixel centroid to image center (0=center, 1=corner or undefined)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 1.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    flat = a.ravel()\n    if flat.size == 0:\n        return 1.0\n    # choose bright pixels as top 5% by value\n    thr = float(np.percentile(flat, 95))\n    mask = a >= thr\n    if not np.any(mask):\n        return 1.0\n    ys, xs = np.nonzero(mask)\n    cy = ys.mean()\n    cx = xs.mean()\n    # center coordinates\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dy = cy - center_y\n    dx = cx - center_x\n    dist = np.hypot(dy, dx)\n    # normalize by image diagonal / 2 (max distance from center to corner)\n    maxd = np.hypot(center_y, center_x) + 1e-12\n    result = float(np.clip(dist / maxd, 0.0, 1.0))\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized vertical position of the strongest horizontal stroke (row index of max horizontal edge energy)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    # horizontal strokes create strong vertical gradients (change across rows) -> use |gy|\n    row_energy = np.sum(np.abs(gy), axis=1)\n    if np.all(row_energy == 0):\n        return 0.0\n    max_row = int(np.argmax(row_energy))\n    # normalized distance from center (0=center, 1=top or bottom edge)\n    center = (h - 1) / 2.0\n    norm = abs(max_row - center) / (center + 1e-8)\n    # invert so lower values mean it's centered\n    return float(1.0 - norm)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels within half a std of the mean (concentration around mean)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    mean = float(a.mean())\n    std = float(a.std()) + eps\n    thr = 0.5 * std\n    mask = np.abs(a - mean) <= thr\n    result = float(np.count_nonzero(mask)) / float(a.size + eps)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels in the bottom-left quadrant (helps detect heavy lower-left strokes)'\n    # Robust grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # Robust binarization: prefer darker-than-median as ink, but adapt if inverted\n    thr = float(np.percentile(gray, 50))\n    mask_dark = gray < thr\n    ink_ratio = float(mask_dark.mean())\n    if ink_ratio > 0.6 or ink_ratio < 0.01:\n        # try alternate threshold near mean\n        thr2 = float(np.mean(gray))\n        mask_dark = gray < thr2\n        ink_ratio = float(mask_dark.mean())\n    mask = mask_dark if ink_ratio <= 0.6 else (~mask_dark)\n    mask = mask.astype(bool)\n    if mask.sum() == 0:\n        return 0.0\n    bl = mask[h//2:, :w//2]\n    return float(bl.sum() / (mask.sum() + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with gradient magnitude above median'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n        mag = np.hypot(gx, gy)\n    except Exception:\n        return 0.0\n    thr = float(np.median(mag.ravel()))\n    count = float(np.count_nonzero(mag > thr))\n    frac = count / (mag.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (width / height) of the minimal bounding box of the ink (clipped to [0,10])'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    dark_mask = gray < thresh\n    ink = dark_mask if dark_mask.sum() <= (h * w) / 2 else ~dark_mask\n    coords = np.nonzero(ink)\n    if len(coords[0]) == 0:\n        return 0.0\n    min_r, max_r = coords[0].min(), coords[0].max()\n    min_c, max_c = coords[1].min(), coords[1].max()\n    bw = max_c - min_c + 1\n    bh = max_r - min_r + 1\n    if bh == 0:\n        return 0.0\n    ratio = float(bw) / float(bh)\n    return float(np.clip(ratio, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box aspect ratio (width/height) of bright region (>median), 0 if none'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    med = float(np.median(a))\n    mask = a > med\n    if not np.any(mask):\n        return 0.0\n    rows = np.any(mask, axis=1)\n    cols = np.any(mask, axis=0)\n    r_indices = np.where(rows)[0]\n    c_indices = np.where(cols)[0]\n    if r_indices.size == 0 or c_indices.size == 0:\n        return 0.0\n    r0, r1 = int(r_indices[0]), int(r_indices[-1])\n    c0, c1 = int(c_indices[0]), int(c_indices[-1])\n    height = float(r1 - r0 + 1)\n    width = float(c1 - c0 + 1)\n    result = width / (height + eps)\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity entropy (normalized to [0,1]) using a moderate histogram resolution'\n    import numpy as np\n    eps = 1e-12\n    NB = 32\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        flat = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(arr.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    vmin = float(flat.min())\n    vmax = float(flat.max())\n    if vmax <= vmin:\n        return 0.0\n    hist, _ = np.histogram(flat, bins=NB, range=(vmin, vmax))\n    total = float(hist.sum()) + eps\n    p = hist.astype(float) / total\n    ent = -float(np.sum(p * np.log(p + eps)))\n    norm = float(np.log(NB))\n    return float(np.clip(ent / (norm + eps), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical gradient asymmetry: normalized difference between top-half and bottom-half mean vertical gradients'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    try:\n        gy, gx = np.gradient(img)\n    except Exception:\n        return 0.0\n    h = img.shape[0]\n    mid = h // 2\n    top = gy[:mid, :]\n    bottom = gy[mid:, :]\n    if top.size == 0 or bottom.size == 0:\n        return 0.0\n    top_mean = float(np.mean(top))\n    bottom_mean = float(np.mean(bottom))\n    denom = (abs(top_mean) + abs(bottom_mean) + eps)\n    result = (top_mean - bottom_mean) / denom\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry: normalized correlation between left and right halves (1 = symmetric)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = np.nan_to_num(img.mean(axis=2))\n    else:\n        img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = img[:, :mid]\n    right = img[:, w - mid:]\n    # flip right horizontally to align with left\n    right_flipped = np.fliplr(right)\n    a = left.ravel().astype(float)\n    b = right_flipped.ravel().astype(float)\n    if a.size == 0 or b.size == 0:\n        return 0.0\n    a = a - a.mean()\n    b = b - b.mean()\n    denom = np.sqrt((a * a).sum() * (b * b).sum()) + eps\n    corr = float((a * b).sum() / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-cross gradient product: product of mean absolute vertical and horizontal gradients in the center region (high for digit-4 intersection)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image, dtype=np.float64)\n    h, w = arr.shape[:2]\n    if h < 3 or w < 3:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    ch0, ch1 = h // 4, w // 4\n    cen = gray[ch0:3 * ch0 if 3 * ch0 > ch0 else h, ch1:3 * ch1 if 3 * ch1 > ch1 else w]\n    if cen.size == 0:\n        return 0.0\n    # gradients\n    gx = np.abs(np.diff(cen, axis=1))\n    gy = np.abs(np.diff(cen, axis=0))\n    mean_gx = float(np.mean(gx)) if gx.size else 0.0\n    mean_gy = float(np.mean(gy)) if gy.size else 0.0\n    # scale to avoid huge numbers\n    denom = (np.max(gray) - np.min(gray)) + 1e-9\n    return float((mean_gx * mean_gy) / (denom + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gini coefficient of intensity distribution (0 equal, 1 extremely unequal)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        vals = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(img.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    # shift to non-negative\n    v = vals - vals.min()\n    if np.allclose(v, 0.0):\n        return 0.0\n    v_sorted = np.sort(v)\n    n = v_sorted.size\n    index = np.arange(1, n + 1)\n    total = v_sorted.sum()\n    if total <= eps:\n        return 0.0\n    gini = (2.0 * np.sum(index * v_sorted) - (n + 1) * total) / (n * total + eps)\n    return float(np.clip(gini, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local contrast: average absolute difference to 3x3 neighborhood normalized by global mean intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    # compute 3x3 local sum via rolling shifts\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    local_diff = np.abs(a - local_mean)\n    mean_local_diff = float(np.mean(local_diff))\n    global_mean_abs = float(np.mean(np.abs(a))) + eps\n    result = mean_local_diff / global_mean_abs\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of pixels brighter than mean+std (bright-sparsity)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    thr = float(img.mean() + img.std())\n    count = float(np.count_nonzero(img > thr))\n    result = count / float(h * w + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of horizontal variance to vertical variance of foreground points (var_x / (var_y + eps))'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    mask = (gray < thr) if np.count_nonzero(gray < thr) >= 1 else (gray > thr)\n    ys, xs = np.nonzero(mask)\n    if xs.size < 2:\n        return 1.0\n    var_x = float(np.var(xs.astype(float)))\n    var_y = float(np.var(ys.astype(float)))\n    eps = 1e-8\n    return float(var_x / (var_y + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast spread: (90th percentile - 10th percentile) normalized by mean intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    p90 = np.percentile(arr, 90)\n    p10 = np.percentile(arr, 10)\n    mean = arr.mean()\n    result = (p90 - p10) / (abs(mean) + eps)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local patch contrast normalized by global std (higher => more local variation)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    global_std = float(a.std()) + 1e-8\n    # choose block size ~ max(2, min(h,w)//8)\n    bs = max(2, min(h, w) // 8)\n    H = (h // bs) * bs\n    W = (w // bs) * bs\n    if H == 0 or W == 0:\n        # fallback: local contrast = global std / global std = 1.0\n        return 1.0 if global_std > 0 else 0.0\n    crops = a[:H, :W].reshape(H // bs, bs, W // bs, bs)\n    # compute std per block efficiently\n    block_std = np.nan_to_num(crops.std(axis=(1, 3)))\n    mean_block_std = float(block_std.mean())\n    result = mean_block_std / global_std\n    # clamp to reasonable range\n    return float(np.clip(result, 0.0, 5.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute vertical gradient in the left third to the right third (detects left vertical stroke in \"5\")'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    abs_gy = np.abs(gy)\n    left_w = max(1, w // 3)\n    right_w = max(1, w - (2 * w // 3))\n    left_mean = np.mean(abs_gy[:, :left_w]) if left_w > 0 else 0.0\n    right_mean = np.mean(abs_gy[:, w - right_w:]) if right_w > 0 else 0.0\n    eps = 1e-6\n    return float((left_mean + eps) / (right_mean + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fill fraction of mean-thresholded foreground inside its bounding box (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        gray = np.nan_to_num(arr.astype(float))\n    h, w = gray.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(gray.mean())\n    mask = (gray > thr)\n    if not mask.any():\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    if bbox_area <= 0.0:\n        return 0.0\n    fill = float(mask.sum()) / bbox_area\n    return float(np.clip(fill, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink width at mid-height to ink width in upper third (helps detect tails that narrow midline)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mu, s = np.mean(gray), np.std(gray)\n    thr = mu + 0.2*s\n    fg = (gray > thr) if np.count_nonzero(gray > thr) < np.count_nonzero(gray < thr) else (gray < (mu - 0.2*s))\n    fg = fg if np.count_nonzero(fg) > 0 else (gray < np.percentile(gray,50))\n    def row_width(row):\n        cols = np.where(fg[row,:])[0]\n        if cols.size == 0:\n            return 0\n        return cols.max() - cols.min() + 1\n    mid = h // 2\n    up = max(0, h // 4)\n    mid_w = row_width(mid)\n    up_w = row_width(up)\n    if up_w == 0:\n        return float(mid_w)\n    return float(mid_w / (up_w + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local variance in a kxk window (k=3 or 5) normalized by global variance'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    # convert to grayscale if color\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    k = 3 if min(h, w) >= 3 else 1\n    if min(h, w) >= 5:\n        k = 5\n    pad = k // 2\n    P = np.pad(arr, pad_width=pad, mode='reflect')\n    S = P.cumsum(axis=0).cumsum(axis=1)\n    # window sum using integral image: sums for all centers\n    sum_ = S[k:, k:] - S[:-k, k:] - S[k:, :-k] + S[:-k, :-k]\n    P2 = np.pad(arr * arr, pad_width=pad, mode='reflect')\n    S2 = P2.cumsum(axis=0).cumsum(axis=1)\n    sum2 = S2[k:, k:] - S2[:-k, k:] - S2[k:, :-k] + S2[:-k, :-k]\n    area = float(k * k)\n    local_mean = sum_ / area\n    local_mean_sq = sum2 / area\n    local_var = local_mean_sq - (local_mean * local_mean)\n    # clamp tiny negatives\n    local_var = np.maximum(local_var, 0.0)\n    mean_local_var = float(np.mean(local_var))\n    global_var = float(np.var(arr)) + eps\n    result = mean_local_var / global_var\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal centroid offset: normalized x-centroid of ink minus 0.5 (negative = left bias, positive = right bias)'\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    bin_img = (gray < thresh).astype(np.float32)\n    if np.sum(bin_img) < 1:\n        bin_img = (gray > thresh).astype(np.float32)\n        if np.sum(bin_img) < 1:\n            return 0.0\n    cols = np.arange(w, dtype=float)\n    x_centroid = np.sum(np.sum(bin_img, axis=0) * cols) / (np.sum(bin_img) + 1e-8)\n    return float((x_centroid / max(1.0, w)) - 0.5)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in top-right quadrant to top-left quadrant (captures right-facing bulges seen in \"3\")'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx > mn:\n        norm = (gray - mn) / (mx - mn)\n    else:\n        norm = gray * 0.0\n    ink = (norm < 0.5).astype(np.uint8)\n    h, w = ink.shape\n    top_half = slice(0, max(1, h // 2))\n    left = slice(0, w // 2)\n    right = slice(w // 2, w)\n    left_top = ink[top_half, left].sum()\n    right_top = ink[top_half, right].sum()\n    return float(right_top / (left_top + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Prominence of brightest pixels: mean of top 1% divided by mean of remaining pixels (>=1.0, higher -> more prominent)'\n    import numpy as np\n    eps = 1e-12\n    pct = 0.01\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        vals = np.ravel(np.nan_to_num(img.mean(axis=2).astype(float)))\n    else:\n        vals = np.ravel(np.nan_to_num(img.astype(float)))\n    n = vals.size\n    if n == 0:\n        return 0.0\n    k = max(1, int(np.ceil(pct * n)))\n    # use partition for efficiency\n    idx = np.argpartition(vals, -k)[-k:]\n    top = vals[idx]\n    top_mean = float(top.mean())\n    if n > k:\n        rest_mean = float((vals.sum() - top.sum()) / (n - k))\n    else:\n        rest_mean = top_mean\n    result = (top_mean + eps) / (rest_mean + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top-bottom brightness bias normalized by image std (positive => top brighter)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 2:\n        return 0.0\n    mid = h // 2\n    top_mean = float(np.mean(arr[:mid, :])) if arr[:mid, :].size else 0.0\n    bot_mean = float(np.mean(arr[-mid:, :])) if arr[-mid:, :].size else 0.0\n    overall_std = float(np.std(arr)) + eps\n    result = (top_mean - bot_mean) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized row index of the densest horizontal slice (0 at top, 1 at bottom) \u2014 7 tends to have a very high-density row near top'\n    if image is None:\n        return 0.0\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if len(img.shape) == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    fg = (gray < thresh).astype(np.uint8)\n    if fg.sum() > 0.6 * fg.size:\n        fg = (gray > thresh).astype(np.uint8)\n    row_counts = fg.sum(axis=1)\n    if row_counts.max() == 0:\n        return 0.0\n    densest_row = int(np.argmax(row_counts))\n    return float(densest_row / max(1.0, h - 1))\n",
    "def feature(image: np.ndarray) -> float:\n    'Pearson correlation between pixel intensity and radial distance from image center (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys = np.arange(h) - (h - 1) / 2.0\n    xs = np.arange(w) - (w - 1) / 2.0\n    yv = ys[:, None]\n    xv = xs[None, :]\n    dist = np.hypot(yv, xv)\n    dist = dist.ravel()\n    vals = a.ravel()\n    if vals.size < 2:\n        return 0.0\n    dist = (dist - dist.mean()) / (dist.std() + eps)\n    vals = (vals - vals.mean()) / (vals.std() + eps)\n    corr = float(np.sum(dist * vals) / (vals.size - 1 + eps))\n    # clip to [-1,1]\n    return float(max(-1.0, min(1.0, corr)))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels that are strong local maxima (strict local max and > mean+std)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    # pad with -inf so edges are handled without wrap\n    pad = np.pad(a, 1, mode='constant', constant_values=-np.inf)\n    center = pad[1:-1, 1:-1]\n    neighs = [\n        pad[0:-2, 0:-2], pad[0:-2, 1:-1], pad[0:-2, 2:],\n        pad[1:-1, 0:-2],                 pad[1:-1, 2:],\n        pad[2:, 0:-2], pad[2:, 1:-1],   pad[2:, 2:]\n    ]\n    local_max = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        local_max &= (center > n)\n    thr = float(a.mean() + a.std())\n    strong_mask = local_max & (center > thr)\n    count = float(np.count_nonzero(strong_mask))\n    result = count / (float(a.size) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry of intensity (1 => perfectly symmetric, -1 => perfectly anti-symmetric)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:] if mid > 0 else np.empty_like(left)\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # flip right horizontally to compare with left\n    right_flipped = np.fliplr(right)\n    # if shapes differ (odd width), crop to min width\n    minw = min(left.shape[1], right_flipped.shape[1])\n    left_c = left[:, :minw].ravel()\n    right_c = right_flipped[:, :minw].ravel()\n    if left_c.size == 0:\n        return 0.0\n    # zero-mean normalized cross-correlation\n    L = left_c - left_c.mean()\n    R = right_c - right_c.mean()\n    denom = (np.linalg.norm(L) * np.linalg.norm(R) + eps)\n    score = float(np.dot(L, R) / denom)\n    return float(np.clip(score, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    flat = arr.ravel()\n    if flat.size == 0:\n        return 0.0\n    bins = 64\n    hist, _ = np.histogram(flat, bins=bins, range=(flat.min(), flat.max()) if flat.min() != flat.max() else (0.0, 1.0))\n    total = hist.sum()\n    if total <= 0:\n        return 0.0\n    p = hist.astype(float) / (total + eps)\n    p_nonzero = p[p > 0]\n    entropy = -np.sum(p_nonzero * np.log2(p_nonzero))\n    result = entropy / (np.log2(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio via discrete Laplacian (sum|L| / sum|I|)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    I = np.nan_to_num(img.astype(float))\n    h, w = I.shape\n    if h < 3 or w < 3:\n        # fallback to gradient-based high freq estimate\n        try:\n            gy, gx = np.gradient(I)\n            hf = np.sum(np.hypot(gx, gy))\n        except Exception:\n            return 0.0\n        denom = np.sum(np.abs(I)) + eps\n        return float(hf / denom)\n    # pad with reflect to compute Laplacian\n    P = np.pad(I, 1, mode='reflect')\n    center = P[1:-1, 1:-1]\n    up = P[0:-2, 1:-1]\n    down = P[2:, 1:-1]\n    left = P[1:-1, 0:-2]\n    right = P[1:-1, 2:]\n    lap = 4 * center - (up + down + left + right)\n    hf_energy = np.sum(np.abs(lap))\n    denom = np.sum(np.abs(I)) + eps\n    ratio = hf_energy / denom\n    return float(ratio)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-to-border brightness fraction (center mean over center+outer)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    ys = np.arange(h)[:, None] - cy\n    xs = np.arange(w)[None, :] - cx\n    R = np.hypot(ys, xs)\n    maxr = float(R.max()) if R.size else 1.0\n    if maxr <= 0:\n        return 0.0\n    center_rad = max(1.0, maxr * 0.2)\n    outer_mask = (R >= (maxr * 0.6))\n    center_mask = (R <= center_rad)\n    center_mean = float(a[center_mask].mean()) if np.any(center_mask) else 0.0\n    outer_mean = float(a[outer_mask].mean()) if np.any(outer_mask) else 0.0\n    result = center_mean / (center_mean + outer_mean + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong corner responses (Harris-like) normalized 0..1'\n    import numpy as np\n    eps = 1e-12\n    k = 0.04\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    gy, gx = np.gradient(a)\n    Jxx = gx * gx\n    Jyy = gy * gy\n    Jxy = gx * gy\n    # local 3x3 mean\n    def local_mean(X):\n        s = np.zeros_like(X)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    Sxx = local_mean(Jxx)\n    Syy = local_mean(Jyy)\n    Sxy = local_mean(Jxy)\n    det = Sxx * Syy - Sxy * Sxy\n    trace = Sxx + Syy\n    R = det - k * (trace ** 2)\n    thr = float(R.mean() + R.std())\n    strong = np.count_nonzero(R > thr)\n    result = strong / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average mirror similarity (left-right and top-bottom) scaled to [0..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # left-right\n    midc = w // 2\n    if w % 2 == 0:\n        left = a[:, :midc]\n        right = a[:, midc:]\n    else:\n        left = a[:, :midc]\n        right = a[:, midc + 1:]\n    if left.size and right.size and left.shape == right.shape:\n        left_flip = np.fliplr(left)\n        mad_lr = float(np.mean(np.abs(left_flip - right)))\n    else:\n        mad_lr = float(np.mean(np.abs(a - np.fliplr(a))))  # fallback\n    # top-bottom\n    midr = h // 2\n    if h % 2 == 0:\n        top = a[:midr, :]\n        bottom = a[midr:, :]\n    else:\n        top = a[:midr, :]\n        bottom = a[midr + 1:, :]\n    if top.size and bottom.size and top.shape == bottom.shape:\n        top_flip = np.flipud(top)\n        mad_tb = float(np.mean(np.abs(top_flip - bottom)))\n    else:\n        mad_tb = float(np.mean(np.abs(a - np.flipud(a))))  # fallback\n    mean_abs = float(np.mean(np.abs(a))) + eps\n    score_lr = max(0.0, 1.0 - (mad_lr / mean_abs))\n    score_tb = max(0.0, 1.0 - (mad_tb / mean_abs))\n    result = (score_lr + score_tb) / 2.0\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average local 3x3 variance normalized by global variance (0 if too small)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = img.mean(axis=2).astype(float)\n    else:\n        a = img.astype(float)\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # compute sum and sumsq for each 3x3 block via shifted slices\n    s00 = a[:-2, :-2]; s01 = a[:-2, 1:-1]; s02 = a[:-2, 2:]\n    s10 = a[1:-1, :-2]; s11 = a[1:-1, 1:-1]; s12 = a[1:-1, 2:]\n    s20 = a[2:, :-2]; s21 = a[2:, 1:-1]; s22 = a[2:, 2:]\n    sum_block = s00 + s01 + s02 + s10 + s11 + s12 + s20 + s21 + s22\n    sumsq_block = (s00*s00 + s01*s01 + s02*s02 + s10*s10 + s11*s11 + s12*s12 + s20*s20 + s21*s21 + s22*s22)\n    mean_block = sum_block / 9.0\n    mean_sq_block = sumsq_block / 9.0\n    var_block = mean_sq_block - mean_block * mean_block\n    local_var_mean = float(np.mean(var_block))\n    global_var = float(a.var())\n    result = local_var_mean / (global_var + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Centrality of intensity: higher when intensity concentrated near image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    rx = xs - cx\n    ry = ys - cy\n    r = np.hypot(rx, ry)\n    maxr = float(r.max()) + eps\n    weights = a.clip(min=0.0)\n    s = float(weights.sum())\n    if s <= eps:\n        return 0.0\n    weighted_r = float((weights * r).sum())\n    # centrality: 1 when weighted_r very small, 0 when weighted_r close to max possible (maxr*s)\n    centrality = 1.0 - (weighted_r / (maxr * s + eps))\n    return float(np.clip(centrality, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of binary transitions along the image center row and center column normalized by perimeter'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    thr = 0.5 * (mn + mx)\n    foreground_is_dark = float(np.mean(gray)) < thr\n    if foreground_is_dark:\n        ink = (gray < thr)\n    else:\n        ink = (gray > thr)\n    cr = h // 2\n    cc = w // 2\n    row = ink[cr, :]\n    col = ink[:, cc]\n    row_trans = float(np.sum(row[:-1] != row[1:]))\n    col_trans = float(np.sum(col[:-1] != col[1:]))\n    norm = float(w + h)\n    return float((row_trans + col_trans) / max(1.0, norm))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Column-wise vertical stroke density: fraction of columns with a contiguous strong vertical gradient'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 2 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.abs(gy)  # vertical gradient magnitude\n    thr = mag.mean() + mag.std()\n    k = max(1, h // 10)\n    cols_with_run = 0\n    for c in range(w):\n        col = mag[:, c] > thr\n        if not np.any(col):\n            continue\n        dif = np.diff(np.concatenate(([0], col.view(np.int8), [0])))\n        starts = np.where(dif == 1)[0]\n        ends = np.where(dif == -1)[0]\n        if starts.size and ends.size:\n            maxrun = int((ends - starts).max())\n        else:\n            maxrun = 0\n        if maxrun >= k:\n            cols_with_run += 1\n    result = cols_with_run / float(w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of total spectral energy concentrated in low-frequency band (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute centered FFT magnitude squared\n    F = np.fft.fft2(a)\n    F = np.fft.fftshift(F)\n    mag2 = np.abs(F) ** 2\n    yy, xx = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(yy - cy, xx - cx)\n    cutoff = max(1.0, min(h, w) / 8.0)\n    low_mask = r <= cutoff\n    total = float(mag2.sum()) + eps\n    low = float(mag2[low_mask].sum())\n    result = low / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum consecutive background gap (in columns) in the central 50% columns within the top 25% rows, normalized by width'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    thr = np.percentile(gray, 50)\n    ink = (gray < thr)\n    if np.count_nonzero(ink) == 0:\n        thr = np.mean(gray)\n        ink = (gray < thr)\n    top_rows = max(1, h // 4)\n    c0 = w // 4\n    c1 = w - c0\n    region = ~ink[0:top_rows, c0:c1]  # True where background\n    if region.size == 0:\n        return 0.0\n    # find max consecutive True in each row, take max across rows\n    max_gap = 0\n    for r in range(region.shape[0]):\n        row = region[r, :]\n        cur = 0\n        for v in row:\n            if v:\n                cur += 1\n                if cur > max_gap:\n                    max_gap = cur\n            else:\n                cur = 0\n    return float(max_gap / max(1, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominance of largest intensity histogram bin (16 bins) (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    bins = 16\n    lo = float(a.min())\n    hi = float(a.max())\n    if hi <= lo:\n        return 1.0\n    hist, _ = np.histogram(a, bins=bins, range=(lo, hi))\n    top = float(hist.max())\n    result = top / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows that are mostly zero (sparse horizontal stripes)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    zero_mask = (a == 0)\n    row_zero_frac = zero_mask.sum(axis=1) / float(w)\n    stripe_rows = float((row_zero_frac >= 0.9).sum())\n    result = stripe_rows / float(h)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by image std (texture roughness)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    pa = np.pad(a, 1, mode='reflect')\n    center = pa[1:-1, 1:-1]\n    up = pa[:-2, 1:-1]\n    down = pa[2:, 1:-1]\n    left = pa[1:-1, :-2]\n    right = pa[1:-1, 2:]\n    lap = (up + down + left + right) - 4.0 * center\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    norm = float(a.std()) + eps\n    result = mean_abs_lap / norm\n    return float(np.clip(result, 0.0, 100.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian zero-crossing fraction (edges from sign changes) normalized to [0,1]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # discrete Laplacian using 4-neighbors\n    lap = np.zeros_like(a)\n    lap += np.roll(a, 1, axis=0)\n    lap += np.roll(a, -1, axis=0)\n    lap += np.roll(a, 1, axis=1)\n    lap += np.roll(a, -1, axis=1)\n    lap -= 4.0 * a\n    # check sign changes with 4-neighbors\n    sign = np.sign(lap)\n    zx = (sign * np.roll(sign, 1, axis=0)) < 0\n    zy = (sign * np.roll(sign, 1, axis=1)) < 0\n    crossings = np.logical_or(zx, zy)\n    count = float(np.count_nonzero(crossings))\n    result = count / (float(h * w) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean color saturation (0..1), 0 for grayscale images'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 2:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    # use first three channels if more\n    ch = a[..., :3]\n    mx = np.max(ch, axis=2)\n    mn = np.min(ch, axis=2)\n    # saturation per pixel: (max-min)/max or 0 if max==0\n    denom = mx.copy()\n    denom[denom == 0] = np.nan\n    sat = (mx - mn) / denom\n    sat = np.nan_to_num(sat)  # pixels with max==0 become 0\n    result = float(np.clip(sat.mean(), 0.0, 1.0))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (Hasler & S\u00fcsstrunk) normalized to [0..1], 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    R = a[:, :, 0]\n    G = a[:, :, 1]\n    B = a[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    metric = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    rng = float(a.max() - a.min()) + eps\n    result = metric / rng\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average horizontal run length of ink in the top third of the image (normalized by width)'\n    import numpy as np\n    arr = np.asarray(image)\n    h, w = arr.shape[:2]\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2).astype(float)\n    else:\n        gray = arr.astype(float)\n    mn, mx = gray.min(), gray.max()\n    rng = mx - mn + 1e-9\n    g = (gray - mn) / rng\n    fg = (g < 0.5) if (g.mean() > 0.5) else (g > 0.5)\n    top_h = max(1, h // 3)\n    run_lengths = []\n    for r in range(top_h):\n        row = fg[r].astype(np.int32)\n        if row.sum() == 0:\n            continue\n        # find run lengths\n        dif = np.diff(np.concatenate(([0], row, [0])))\n        starts = np.where(dif == 1)[0]\n        ends = np.where(dif == -1)[0]\n        lengths = (ends - starts).tolist()\n        run_lengths.extend(lengths)\n    if len(run_lengths) == 0:\n        return 0.0\n    avg_len = float(np.mean(run_lengths))\n    return float(avg_len / float(w + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right brightness bias normalized by image std (positive => left brighter)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left_mean = float(np.mean(img[:, :mid])) if img[:, :mid].size else 0.0\n    right_mean = float(np.mean(img[:, -mid:])) if img[:, -mid:].size else 0.0\n    overall_std = float(np.std(img)) + eps\n    result = (left_mean - right_mean) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative ink density in the middle horizontal third compared to overall density (detects middle bar like in 5)'\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = image.mean(axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gmin, gmax = float(gray.min()), float(gray.max())\n    if gmax - gmin < 1e-8:\n        return 0.0\n    gnorm = (gray - gmin) / (gmax - gmin)\n    high = np.count_nonzero(gnorm > 0.5)\n    ink = (gnorm > 0.5) if (high < (h * w - high)) else (gnorm <= 0.5)\n    ink = ink.astype(bool)\n    total_ink = float(np.count_nonzero(ink))\n    if total_ink < 1e-8:\n        return 0.0\n    y0, y1 = h // 3, max(h // 3 + 1, 2 * h // 3)\n    mid_count = float(np.count_nonzero(ink[y0:y1, :]))\n    mid_area = float((y1 - y0) * w)\n    mid_density = mid_count / (mid_area + 1e-8)\n    overall_density = total_ink / float(h * w)\n    return float(mid_density / (overall_density + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Max horizontal run length fraction weighted to emphasize runs near the top (long top bar detection)'\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.percentile(gray, 50))\n    ink = (gray < thr)\n    if np.count_nonzero(ink) < 1:\n        ink = (gray > thr)\n    max_run = 0\n    max_row = 0\n    for r in range(h):\n        row = ink[r, :]\n        # find longest contiguous True sequence\n        cur = 0\n        best = 0\n        for val in row:\n            if val:\n                cur += 1\n            else:\n                if cur > best:\n                    best = cur\n                cur = 0\n        if cur > best:\n            best = cur\n        if best > max_run:\n            max_run = int(best)\n            max_row = r\n    run_frac = float(max_run) / float(max(w, 1))\n    # weight toward top rows: if max_row near top -> boost\n    row_norm = float(max_row) / float(max(h - 1, 1))\n    weighted = run_frac * (1.0 + (1.0 - row_norm))\n    return float(weighted)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near the minimum intensity (bottom 1% of range) measuring background sparsity (0..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.ravel(np.nan_to_num(img.mean(axis=2).astype(float)))\n    else:\n        arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    amin, amax = arr.min(), arr.max()\n    if amax <= amin:\n        # constant image: if constant is zero then all are near-min -> 1.0, else none\n        return 1.0 if amin == 0.0 else 0.0\n    thr = amin + 0.01 * (amax - amin)\n    count = float((arr <= thr).sum())\n    frac = count / float(arr.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of Laplacian blob centers per 1000 pixels (detects blob-like structures)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, gyx = np.gradient(gy)\n        gxy, gxx = np.gradient(gx)\n        lap = gxx + gyy\n    except Exception:\n        return 0.0\n    mu = float(lap.mean())\n    sd = float(lap.std())\n    if sd <= 0:\n        return 0.0\n    # blobs often correspond to strong negative Laplacian (dark blob on bright bg)\n    thresh = mu - sd\n    count = int(np.count_nonzero(lap < thresh))\n    density = count / float(max(1, h * w)) * 1000.0\n    return float(density)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance between intensity centroid and image center (0=centered, up to 1=corner)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    eps = 1e-12\n    total = float(a.sum())\n    if total <= eps:\n        return 0.0\n    ys = np.arange(h).reshape(h, 1)\n    xs = np.arange(w).reshape(1, w)\n    cy = float((a * ys).sum() / (total + eps))\n    cx = float((a * xs).sum() / (total + eps))\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = float(np.hypot(cy - center_y, cx - center_x))\n    max_dist = float(np.hypot(center_y, center_x)) + eps\n    result = float(np.clip(dist / max_dist, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientations (0..1 normalized) measuring directional disorder'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    ang = np.arctan2(gy, gx).ravel()  # -pi..pi\n    # map to [0, 2pi)\n    ang = (ang + np.pi) % (2 * np.pi)\n    bins = 36\n    hist, _ = np.histogram(ang, bins=bins, range=(0.0, 2 * np.pi), density=True)\n    p = hist.astype(float)\n    p = p[p > 0]\n    if p.size == 0:\n        return 0.0\n    ent = -float(np.sum(p * np.log(p + eps)))\n    result = ent / (np.log(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial monotonicity: Pearson correlation between ring radius and mean ring intensity (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    dist = np.hypot(ys - cy, xs - cx)\n    maxd = float(dist.max()) if dist.size else 1.0\n    if maxd <= 0:\n        return 0.0\n    nbins = min(20, int(max(4, round(maxd))))\n    bins = np.linspace(0, maxd, nbins + 1)\n    ring_means = []\n    ring_r = []\n    for i in range(nbins):\n        mask = (dist >= bins[i]) & (dist < bins[i + 1])\n        if np.any(mask):\n            ring_means.append(np.mean(img[mask]))\n            ring_r.append(0.5 * (bins[i] + bins[i + 1]))\n    if len(ring_means) <= 1:\n        return 0.0\n    r = np.array(ring_r)\n    m = np.array(ring_means)\n    rm = (r - r.mean())\n    mm = (m - m.mean())\n    denom = (np.sqrt((rm ** 2).sum() * (mm ** 2).sum()) + eps)\n    corr = float(np.sum(rm * mm) / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized horizontal edge strength in the top quarter (captures a top bar)'\n    import numpy as np\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # gradients\n    gy, gx = np.gradient(gray)\n    edge = np.hypot(gx, gy)\n    top_region = edge[:max(1, h//4), :]\n    total = edge.sum() + 1e-9\n    return float(top_region.sum() / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute vertical to horizontal gradient magnitudes calculated on the right half'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2).astype(float)\n    else:\n        gray = img.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    right = slice(w//2, w)\n    abs_vert = np.abs(gy[:, right])\n    abs_horz = np.abs(gx[:, right])\n    mean_vert = float(np.mean(abs_vert)) if abs_vert.size else 0.0\n    mean_horz = float(np.mean(abs_horz)) if abs_horz.size else 0.0\n    eps = 1e-9\n    return float(mean_vert / (mean_horz + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Sharpness around the brightest pixel: local std in small window normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    idx = np.argmax(a)\n    r = int(idx // w)\n    c = int(idx % w)\n    win = 3\n    r0 = max(0, r - win)\n    r1 = min(h, r + win + 1)\n    c0 = max(0, c - win)\n    c1 = min(w, c + win + 1)\n    local = a[r0:r1, c0:c1]\n    if local.size == 0:\n        return 0.0\n    local_std = float(local.std())\n    global_std = float(a.std()) + eps\n    result = local_std / global_std\n    return float(np.clip(result, 0.0, 100.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Annular prominence: how much an outer ring differs from the center (signed, clipped)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    maxr = float(r.max()) if r.size else 1.0\n    center_r = max(1.0, min(h, w) / 8.0)\n    inner_r = max(center_r + 1.0, 0.25 * maxr)\n    outer_r = max(inner_r + 1.0, 0.6 * maxr)\n    center_mask = r <= center_r\n    ann_mask = (r >= inner_r) & (r <= outer_r)\n    center_mean = float(a[center_mask].mean()) if center_mask.any() else 0.0\n    ann_mean = float(a[ann_mask].mean()) if ann_mask.any() else 0.0\n    gstd = float(a.std()) + eps\n    result = (ann_mean - center_mean) / gstd\n    return float(np.clip(result, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of 3x3 local maxima (strict peaks) as fraction of image area'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center = a\n    neighbors = []\n    neighbors.append(np.roll(center, 1, axis=0))\n    neighbors.append(np.roll(center, -1, axis=0))\n    neighbors.append(np.roll(center, 1, axis=1))\n    neighbors.append(np.roll(center, -1, axis=1))\n    neighbors.append(np.roll(np.roll(center, 1, axis=0), 1, axis=1))\n    neighbors.append(np.roll(np.roll(center, 1, axis=0), -1, axis=1))\n    neighbors.append(np.roll(np.roll(center, -1, axis=0), 1, axis=1))\n    neighbors.append(np.roll(np.roll(center, -1, axis=0), -1, axis=1))\n    mask = np.ones_like(center, dtype=bool)\n    for n in neighbors:\n        mask &= (center > n)\n    # zero out border to avoid wrap-around artifacts\n    mask[0, :] = False\n    mask[-1, :] = False\n    mask[:, 0] = False\n    mask[:, -1] = False\n    count = float(np.count_nonzero(mask))\n    result = count / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarseness measure: mean gradient after 3x3 blur divided by mean gradient (higher => coarse)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    # small 3x3 box blur implemented with shifts (no padding artifacts due to roll but acceptable)\n    up = np.roll(a, 1, axis=0)\n    down = np.roll(a, -1, axis=0)\n    left = np.roll(a, 1, axis=1)\n    right = np.roll(a, -1, axis=1)\n    up_left = np.roll(up, 1, axis=1)\n    up_right = np.roll(up, -1, axis=1)\n    down_left = np.roll(down, 1, axis=1)\n    down_right = np.roll(down, -1, axis=1)\n    blur = (a + up + down + left + right + up_left + up_right + down_left + down_right) / 9.0\n    try:\n        gy_o, gx_o = np.gradient(a)\n        gy_b, gx_b = np.gradient(blur)\n    except Exception:\n        return 0.0\n    mag_o = np.hypot(gx_o, gy_o)\n    mag_b = np.hypot(gx_b, gy_b)\n    mean_o = float(np.mean(mag_o)) + eps\n    mean_b = float(np.mean(mag_b))\n    result = mean_b / mean_o\n    # coarser textures -> higher ratio; clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average structure-tensor coherence (0..1) indicating directional dominance'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    Jxx = gx * gx\n    Jyy = gy * gy\n    Jxy = gx * gy\n    # local averaging 3x3\n    def local_mean(X):\n        s = np.zeros_like(X)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    Sxx = local_mean(Jxx)\n    Syy = local_mean(Jyy)\n    Sxy = local_mean(Jxy)\n    trace = Sxx + Syy\n    diff = np.sqrt(np.maximum(trace * trace / 4.0 - (Sxx * Syy - Sxy * Sxy), 0.0))\n    # eigenvalues lambda1 >= lambda2\n    lam1 = trace / 2.0 + diff\n    lam2 = trace / 2.0 - diff\n    coherence = (lam1 - lam2) / (lam1 + lam2 + eps)\n    # ignore low-signal pixels by weighting with trace\n    weight = trace / (trace.mean() + eps)\n    if np.any(weight > 0):\n        mean_coh = float(np.sum(coherence * (weight > 0)) / (np.count_nonzero(weight > 0) + eps))\n    else:\n        mean_coh = 0.0\n    result = np.clip(mean_coh, 0.0, 1.0)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal mirror symmetry score (0..1), 1 means perfect horizontal mirror'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2 or h < 1:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    # flip right horizontally to compare\n    right = right[:, ::-1]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    # ensure shapes match\n    if left.shape != right.shape:\n        # crop to smallest common shape\n        mh = min(left.shape[0], right.shape[0])\n        mw = min(left.shape[1], right.shape[1])\n        left = left[:mh, :mw]\n        right = right[:mh, :mw]\n    # normalized cross-correlation\n    Lm = left.mean()\n    Rm = right.mean()\n    Lz = left - Lm\n    Rz = right - Rm\n    num = float((Lz * Rz).sum())\n    den = float(np.sqrt((Lz * Lz).sum() * (Rz * Rz).sum()) + eps)\n    score = num / den\n    score = max(-1.0, min(1.0, score))\n    return float(abs(score))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of the intensity histogram (bits, 0 for constant images)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = img.mean(axis=2).astype(float).ravel()\n    else:\n        arr = img.astype(float).ravel()\n    if arr.size == 0:\n        return 0.0\n    vmin = arr.min()\n    vmax = arr.max()\n    if vmax == vmin:\n        return 0.0\n    bins = 256\n    try:\n        hist, _ = np.histogram(arr, bins=bins, range=(vmin, vmax))\n    except Exception:\n        hist, _ = np.histogram(arr, bins=bins)\n    p = hist.astype(float)\n    s = p.sum()\n    if s <= 0:\n        return 0.0\n    p = p / s\n    p = p[p > 0.0]\n    entropy = -float(np.sum(p * np.log2(p)))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of positive Harris-like corner energy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    k = 0.04\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    Jxx = gx * gx\n    Jyy = gy * gy\n    Jxy = gx * gy\n    # local average 3x3\n    def local_mean(X):\n        s = np.zeros_like(X, dtype=float)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    Sxx = local_mean(Jxx)\n    Syy = local_mean(Jyy)\n    Sxy = local_mean(Jxy)\n    det = Sxx * Syy - Sxy * Sxy\n    trace = Sxx + Syy\n    R = det - k * (trace ** 2)\n    pos_energy = np.sum(R * (R > 0))\n    total_energy = np.sum(np.abs(R)) + eps\n    result = float(pos_energy / total_energy)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local contrast (mean of 3x3 local std) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # local sums using 3x3 neighborhood by rolling (fast, avoids convolution lib)\n    def local_sum(X):\n        s = np.zeros_like(X, dtype=float)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s\n    s1 = local_sum(a)\n    s2 = local_sum(a * a)\n    local_mean = s1 / 9.0\n    local_var = (s2 / 9.0) - (local_mean ** 2)\n    local_var = np.maximum(local_var, 0.0)\n    local_std = np.sqrt(local_var)\n    mean_local_std = float(local_std.mean())\n    global_std = float(a.std()) + eps\n    result = mean_local_std / global_std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average absolute normalized autocorrelation with small shifts (0..1)'\n    import numpy as np\n    eps = 1e-12\n    maxshift = 5\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    shifts = []\n    rng = range(1, min(maxshift, max(h, w) - 1) + 1)\n    for dy in rng:\n        shifts.append((dy, 0))\n    for dx in rng:\n        shifts.append((0, dx))\n    for d in rng:\n        shifts.append((d, d))\n    corrs = []\n    mu = a.mean()\n    sdev = a.std() + eps\n    for dy, dx in shifts:\n        ys1 = slice(0, h - dy)\n        xs1 = slice(0, w - dx)\n        ys2 = slice(dy, h)\n        xs2 = slice(dx, w)\n        A = a[ys1, xs1]\n        B = a[ys2, xs2]\n        if A.size == 0:\n            continue\n        Am = A.mean()\n        Bm = B.mean()\n        As = A.std() + eps\n        Bs = B.std() + eps\n        num = ((A - Am) * (B - Bm)).mean()\n        corr = num / (As * Bs + eps)\n        corrs.append(abs(corr))\n    if len(corrs) == 0:\n        return 0.0\n    result = float(np.clip(float(np.mean(corrs)), 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box occupancy of bright region (area of bbox containing bright pixels / image area)'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = a > thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    img_area = float(h * w) + eps\n    result = bbox_area / img_area\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientations (normalized 0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if np.all(mag == 0):\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # map to [0, pi) because orientation ambiguous by sign of gradient\n    theta = np.mod(theta, np.pi)\n    # weight histogram by magnitude\n    nbins = 18\n    hist, _ = np.histogram(theta.ravel(), bins=nbins, range=(0.0, np.pi), weights=mag.ravel())\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0]\n    ent = -np.sum(p * np.log(p + eps))\n    norm = ent / (np.log(nbins) + eps)\n    return float(np.clip(norm, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Color channel imbalance: mean absolute pairwise channel difference normalized by mean intensity (0 for grayscale)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 2:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # use first three channels if more exist\n    ch = a[..., :3]\n    # channel means\n    m = ch.mean(axis=(0, 1))\n    # mean pairwise absolute differences\n    pd = (abs(m[0] - m[1]) + abs(m[0] - m[2]) + abs(m[1] - m[2])) / 3.0\n    overall = float(ch.mean()) + eps\n    result = float(pd) / overall\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal symmetry: normalized correlation between left half and mirrored right half (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    mid = w // 2\n    if w % 2 == 0:\n        left = a[:, :mid].astype(float)\n        right = a[:, mid:].astype(float)\n    else:\n        left = a[:, :mid].astype(float)\n        right = a[:, mid+1:].astype(float)\n    # resize smaller to match if shapes differ\n    minw = min(left.shape[1], right.shape[1])\n    if minw == 0:\n        return 0.0\n    L = left[:, :minw].ravel()\n    R = np.fliplr(right)[:, :minw].ravel()\n    L = L.astype(float); R = R.astype(float)\n    Lm = L.mean() if L.size else 0.0\n    Rm = R.mean() if R.size else 0.0\n    num = np.sum((L - Lm) * (R - Rm))\n    den = np.sqrt(np.sum((L - Lm) ** 2) * np.sum((R - Rm) ** 2)) + eps\n    corr = num / den\n    # map from [-1,1] to [0,1]\n    result = float(np.clip((corr + 1.0) / 2.0, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal symmetry: 1.0 = perfect left-right mirror, 0.0 = very asymmetric'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 1:\n        return 0.0\n    flipped = np.fliplr(a)\n    diff = np.abs(a - flipped)\n    denom = float(a.max() - a.min()) + eps\n    # if constant image, treat as perfectly symmetric\n    if denom <= eps:\n        return 1.0\n    norm_diff = float(diff.mean()) / denom\n    result = 1.0 - np.clip(norm_diff, 0.0, 1.0)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border uniform fraction: fraction of border pixels within 0.5*std of median'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    bw = max(1, min(h, w) // 10)\n    top = a[:bw, :].ravel()\n    bottom = a[-bw:, :].ravel()\n    left = a[:, :bw].ravel()\n    right = a[:, -bw:].ravel()\n    border = np.concatenate([top, bottom, left, right]) if (top.size + bottom.size + left.size + right.size) > 0 else np.array([], dtype=float)\n    if border.size == 0:\n        return 0.0\n    med = float(np.median(border))\n    std = float(np.std(border)) + eps\n    thr = 0.5 * std\n    frac = float(np.count_nonzero(np.abs(border - med) <= thr)) / float(border.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarseness: mean absolute residual between image and local 5x5 blur, normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if arr.size == 0:\n        return 0.0\n    # 5x5 uniform blur via summed rolls (approx, efficient)\n    s = np.zeros_like(arr)\n    for dy in (-2, -1, 0, 1, 2):\n        for dx in (-2, -1, 0, 1, 2):\n            s += np.roll(np.roll(arr, dy, axis=0), dx, axis=1)\n    blurred = s / 25.0\n    residual = np.abs(arr - blurred).mean()\n    denom = float(arr.std() + eps)\n    result = residual / denom\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative difference in ink compactness between upper and lower halves: (compactness_upper - compactness_lower) where compactness = ink_area / boundary_count'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    med = np.median(gray); mean = np.mean(gray); thresh = 0.5*(mean+med)\n    if mean >= med:\n        ink = (gray > thresh).astype(np.int8)\n    else:\n        ink = (gray < thresh).astype(np.int8)\n    upper = ink[:h//2, :]\n    lower = ink[h//2:, :]\n    def compactness(region):\n        if region.size == 0:\n            return 0.0\n        area = np.count_nonzero(region)\n        pad = np.pad(region, 1, mode='constant', constant_values=0)\n        boundary = 0\n        for dy in (-1, 0, 1):\n            for dx in (-1, 0, 1):\n                if dx == 0 and dy == 0:\n                    continue\n                boundary += (pad[1+dy:1+dy+region.shape[0], 1+dx:1+dx+region.shape[1]] != region)\n        # boundary_count approximation: number of ink pixels that touch background\n        # compute neighbors that are background\n        neigh_sum = np.zeros_like(region, dtype=int)\n        for dy in (-1, 0, 1):\n            for dx in (-1, 0, 1):\n                if dx == 0 and dy == 0:\n                    continue\n                neigh_sum += pad[1+dy:1+dy+region.shape[0], 1+dx:1+dx+region.shape[1]]\n        boundary_count = np.sum((region == 1) & (neigh_sum < 8))\n        if boundary_count == 0:\n            return float(area)\n        return float(area) / float(boundary_count)\n    cu = compactness(upper)\n    cl = compactness(lower)\n    return float(cu - cl)\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative dominance of 45-degree diagonal gradient energy (sum|dx+dy| / (sum|dx+dy|+sum|dx-dy|))'\n    import numpy as np\n    eps = 1e-9\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray.astype(float))\n    diag1 = np.abs(gx + gy)\n    diag2 = np.abs(gx - gy)\n    s1 = np.sum(diag1)\n    s2 = np.sum(diag2)\n    return float(s1 / (s1 + s2 + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score: 1 - normalized L1 difference between left and mirrored right (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    if w % 2 == 0:\n        right = a[:, mid:]\n    else:\n        right = a[:, mid+1:]\n    # make shapes equal\n    minw = min(left.shape[1], right.shape[1])\n    if minw == 0:\n        return 0.0\n    left = left[:, :minw]\n    right = right[:, :minw]\n    right_flip = np.fliplr(right)\n    diff = np.abs(left - right_flip)\n    denom = np.mean(np.abs(a)) + 1e-12\n    score = 1.0 - (np.mean(diff) / denom)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of foreground pixels inside a narrow central vertical strip (detects vertical strokes like \"1\")'\n    import numpy as np\n    # Grayscale conversion\n    arr = np.array(image, dtype=float)\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    # Robust foreground: pick minority side of mean\n    th = np.mean(gray)\n    fg = gray < th\n    if np.count_nonzero(fg) > gray.size / 2:\n        fg = ~fg\n    # central vertical strip width ~ w//8 (at least 1)\n    strip_w = max(1, w // 8)\n    c1 = w // 2 - strip_w // 2\n    c2 = c1 + strip_w\n    central = fg[:, c1:c2]\n    central_count = np.count_nonzero(central)\n    total_fg = np.count_nonzero(fg)\n    if total_fg == 0:\n        return 0.0\n    return float(central_count) / float(total_fg)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of strong local maxima (pixels greater than all 8 neighbors and above mean+0.5*std)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    # compare to 8 neighbors\n    center = a\n    n1 = np.roll(center, 1, axis=0)\n    n2 = np.roll(center, -1, axis=0)\n    n3 = np.roll(center, 1, axis=1)\n    n4 = np.roll(center, -1, axis=1)\n    n5 = np.roll(n1, 1, axis=1)\n    n6 = np.roll(n1, -1, axis=1)\n    n7 = np.roll(n2, 1, axis=1)\n    n8 = np.roll(n2, -1, axis=1)\n    mask = (center > n1) & (center > n2) & (center > n3) & (center > n4) & (center > n5) & (center > n6) & (center > n7) & (center > n8)\n    mask = mask & (center > thr)\n    count = float(mask.sum())\n    area = float(a.size) + eps\n    result = count / area\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Local gradient-orientation variability in the central region (high when strokes cross like in 8)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx > mn:\n        norm = (gray - mn) / (mx - mn)\n    else:\n        norm = gray - mn\n    gy, gx = np.gradient(norm)\n    # compute orientation in radians\n    orient = np.arctan2(gy, gx)\n    r0, r1 = h // 3, (2 * h) // 3\n    c0, c1 = w // 3, (2 * w) // 3\n    cen = orient[r0:r1, c0:c1]\n    if cen.size == 0:\n        return 0.0\n    # circular variance approximation: 1 - R where R = sqrt(mean(cos)^2 + mean(sin)^2)\n    cos_mean = float(np.mean(np.cos(cen)))\n    sin_mean = float(np.mean(np.sin(cen)))\n    R = np.sqrt(cos_mean * cos_mean + sin_mean * sin_mean)\n    circ_var = 1.0 - R\n    return float(circ_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Principal orientation of ink strokes (angle normalized to [0,1], 0=horizontal, 0.5=vertical)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    dark_mask = gray < thresh\n    ink = dark_mask if dark_mask.sum() <= (h * w) / 2 else ~dark_mask\n    ys, xs = np.nonzero(ink)\n    if ys.size < 2:\n        return 0.0\n    xc = xs.mean()\n    yc = ys.mean()\n    x = xs - xc\n    y = ys - yc\n    cov_xx = (x * x).mean()\n    cov_yy = (y * y).mean()\n    cov_xy = (x * y).mean()\n    # angle of principal eigenvector\n    theta = 0.5 * np.arctan2(2 * cov_xy, cov_xx - cov_yy)\n    # normalize to [0,1]\n    val = (theta + np.pi/2) / np.pi\n    return float(val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity histogram entropy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size == 0:\n        return 0.0\n    amin = float(arr.min())\n    amax = float(arr.max())\n    if amax <= amin:\n        return 0.0\n    nbins = 64\n    hist, _ = np.histogram(arr, bins=nbins, range=(amin, amax))\n    total = float(hist.sum()) + eps\n    probs = hist.astype(float) / total\n    ent = -float(np.sum(probs * np.log(probs + eps)))\n    norm = float(np.log(nbins) + eps)\n    result = ent / norm\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows with strong vertical transitions (texture/striping indicator)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    row_diff_means = np.mean(np.abs(np.diff(a, axis=1)), axis=1)\n    overall_mean = float(row_diff_means.mean()) + eps\n    # a row is \"high-transition\" if its mean diffs exceed 1.5x overall mean\n    high = row_diff_means > (1.5 * overall_mean)\n    result = float(np.count_nonzero(high)) / float(h)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean of signed product of x and y gradients in the lower-left quadrant (captures diagonal stroke orientation)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3 or w < 3:\n        return 0.0\n    # focus on lower-left quadrant\n    sub = gray[h//2:, :w//2]\n    gy, gx = np.gradient(sub.astype(float))\n    prod = gx * gy\n    if prod.size == 0:\n        return 0.0\n    return float(np.mean(prod))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized ink density in the lower-right quadrant (detects 9-like tails)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mu, sigma = float(np.mean(gray)), float(np.std(gray))\n    thr = mu - 0.25*(sigma + 1e-9)\n    mask = gray < thr if np.count_nonzero(gray < thr) > 5 else gray > (mu + 0.25*(sigma+1e-9))\n    lr = mask[2*h//3:h, 2*w//3:w]\n    return float(np.count_nonzero(lr) / (np.count_nonzero(mask) + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-pixel compactness: ratio of bright pixel count to bounding-box area (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = a > thr\n    count = int(np.count_nonzero(mask))\n    if count == 0:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1)) + eps\n    compactness = float(count) / bbox_area\n    # clip to [0,1]\n    return float(np.clip(compactness, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by mean absolute intensity (higher => more detail)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # discrete Laplacian via 4-neighbor: lap = 4*center - sum(neighbors)\n    center = a\n    up = np.roll(a, -1, axis=0)\n    down = np.roll(a, 1, axis=0)\n    left = np.roll(a, -1, axis=1)\n    right = np.roll(a, 1, axis=1)\n    lap = (4.0 * center) - (up + down + left + right)\n    mad = float(np.mean(np.abs(lap)))\n    mean_abs = float(np.mean(np.abs(a))) + 1e-12\n    result = mad / mean_abs\n    # reasonable clipping\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of vertical ink runs per column in the right third (counts 0->1 transitions down each column)'\n    import numpy as np\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    lo, hi = float(np.min(gray)), float(np.max(gray))\n    if hi == lo:\n        return 0.0\n    thr = (hi + lo) / 2.0\n    bin1 = gray < thr\n    ink = bin1 if np.sum(bin1) <= 0.6 * h * w else ~bin1\n    c0 = 2 * (w // 3)\n    region = ink[:, c0:w]\n    if region.size == 0:\n        return 0.0\n    diffs = np.diff(region.astype(np.int8), axis=0)\n    runs_per_col = np.sum(diffs == 1, axis=0)  # count 0->1 transitions\n    return float(np.mean(runs_per_col))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with gradient magnitude in top quartile'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy).ravel()\n    if mag.size == 0:\n        return 0.0\n    thresh = float(np.percentile(mag, 75))\n    high = mag > thresh\n    result = high.sum() / float(mag.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of near-maximum (saturated) pixels to total pixels, robust to dynamic range'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    mn = float(a.min())\n    mx = float(a.max())\n    if mx - mn <= 1e-12:\n        return 0.0\n    high_thresh = mn + 0.98 * (mx - mn)\n    count = float(np.count_nonzero(a >= high_thresh))\n    result = count / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of columns that contain a single long foreground run (>50% of height) (helps detect vertical sticks)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    gmin, gmax = float(np.min(gray)), float(np.max(gray))\n    norm = (gray - gmin) / (gmax - gmin) if gmax > gmin else np.zeros_like(gray)\n    thr = 0.5\n    less_count = np.count_nonzero(norm < thr)\n    greater_count = norm.size - less_count\n    fg = (norm < thr) if less_count <= greater_count else (norm > thr)\n    h, w = fg.shape\n    if w == 0:\n        return 0.0\n    long_count = 0\n    for c in range(w):\n        col = fg[:, c].astype(int)\n        if col.sum() == 0:\n            continue\n        diffs = np.diff(np.concatenate(([0], col, [0])))\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        lengths = ends - starts\n        if lengths.size == 1 and lengths[0] >= 0.5 * h:\n            long_count += 1\n    return float(long_count / float(w))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels brighter than the median (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    med = float(np.median(a))\n    frac = float(np.count_nonzero(a > med)) / float(a.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # subtract mean to emphasize texture\n    a0 = a - a.mean()\n    F = np.fft.fftshift(np.fft.fft2(a0))\n    P = np.abs(F) ** 2\n    center_h = max(1, h // 8)\n    center_w = max(1, w // 8)\n    ch0 = h // 2 - center_h\n    ch1 = h // 2 + center_h + (0 if center_h * 2 == center_h * 2 else 0)\n    cw0 = w // 2 - center_w\n    cw1 = w // 2 + center_w + (0 if center_w * 2 == center_w * 2 else 0)\n    # sum low-frequency in central rectangle\n    lf = P[ch0:ch1, cw0:cw1].sum()\n    total = P.sum() + eps\n    hf = float(max(0.0, total - lf))\n    return float(np.clip(hf / total, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of horizontal transitions per row (captures horizontal stroke complexity)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    rng = mx - mn + 1e-8\n    norm = (gray - mn) / rng\n    stroke_darker = np.mean(norm) < 0.5\n    mask = (norm < 0.5) if stroke_darker else (norm > 0.5)\n    # compute row-wise transitions\n    diffs = np.abs(np.diff(mask.astype(np.int8), axis=1))\n    transitions_per_row = np.sum(diffs, axis=1)  # length h\n    avg_trans = float(np.mean(transitions_per_row) / (w + 1e-8))\n    return avg_trans\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical-edge energy to total edge energy (weighted by gradient magnitude)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = float(mag.sum()) + eps\n    if total <= 0:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # vertical directions are near +/- pi/2\n    ang_diff = np.abs(np.abs(theta) - (np.pi / 2.0))\n    mask_vert = ang_diff <= (np.pi / 8.0)  # within 22.5 degrees of vertical\n    vert_energy = float(np.sum(mag[mask_vert]))\n    result = vert_energy / total\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial gradient alignment: how strongly gradients point toward/away from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    rx = xs - cx\n    ry = ys - cy\n    rnorm = np.hypot(rx, ry) + eps\n    # unit radial vector\n    ux = rx / rnorm\n    uy = ry / rnorm\n    # dot product between gradient direction and radial direction\n    dot = (gx * ux + gy * uy) / mag\n    # weight by magnitude and absolute alignment (inward/outward both count)\n    weighted = np.abs(dot) * mag\n    result = float(weighted.sum()) / float(mag.sum() + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of local intensity peaks (local maxima) per pixel in [0..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    # local maxima strict: greater than all 8 neighbors\n    center = a\n    neigh_max = np.maximum.reduce([\n        np.roll(np.roll(a, -1, axis=0), -1, axis=1),\n        np.roll(np.roll(a, -1, axis=0), 0, axis=1),\n        np.roll(np.roll(a, -1, axis=0), 1, axis=1),\n        np.roll(np.roll(a, 0, axis=0), -1, axis=1),\n        np.roll(np.roll(a, 0, axis=0), 1, axis=1),\n        np.roll(np.roll(a, 1, axis=0), -1, axis=1),\n        np.roll(np.roll(a, 1, axis=0), 0, axis=1),\n        np.roll(np.roll(a, 1, axis=0), 1, axis=1),\n    ])\n    peaks = (center > neigh_max) & (center > (a.mean() + 0.5 * a.std()))\n    count = float(peaks.sum())\n    result = count / (float(a.size) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Width of largest continuous background gap on the central row normalized by image width (detects open center in 3)'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    th = np.percentile(gray, 50)\n    mid = 0.5 * (np.max(gray) + np.min(gray))\n    fg = (gray < th) if np.mean(gray) > mid else (gray > th)\n    fg = fg.astype(np.uint8)\n    if h == 0 or w == 0:\n        return 0.0\n    r = h // 2\n    row = fg[r, :]\n    # background segments (zeros)\n    inv = 1 - row\n    if inv.sum() == 0:\n        return 0.0\n    d = np.diff(np.concatenate(([0], inv, [0])))\n    starts = np.where(d == 1)[0]\n    ends = np.where(d == -1)[0]\n    runs = (ends - starts)\n    if runs.size == 0:\n        return 0.0\n    max_run = runs.max()\n    return float(max_run / max(1, w))\n",
    "def feature(image: np.ndarray) -> float:\n    'Average normalized count of binary intensity transitions per row (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    thr = float(a.mean())\n    binrows = (a > thr).astype(np.int8)\n    transitions = np.abs(np.diff(binrows, axis=1))\n    row_counts = transitions.sum(axis=1).astype(float)\n    norm = max(1.0, float(w - 1))\n    avg_trans = float(row_counts.mean()) / norm\n    return float(np.clip(avg_trans, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Lower-left quadrant ink density: fraction of ink pixels located in the bottom-left quadrant'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        th = np.mean(gray)\n        ink = gray < th\n        if np.count_nonzero(ink) == 0:\n            ink = gray > th\n        total = np.count_nonzero(ink)\n        if total == 0:\n            return 0.0\n        lower_half = np.s_[h//2: h, 0: w//2]\n        lower_left = ink[lower_half]\n        return float(np.count_nonzero(lower_left) / (total + 1e-9))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink located in the rightmost third of the image (useful to detect right-side tails/strokes like 4 and 9)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    img = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    h, w = img.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(img)\n    ink = img < thresh\n    total = ink.sum()\n    if total == 0:\n        return 0.0\n    right = ink[:, (2*w)//3 : w].sum()\n    return float(right / float(total))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of background (empty) pixels in the bottom-center region (bottom 20% rows, center third columns); higher means open bottom'\n    import numpy as np\n    if image is None:\n        return 0.0\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img.astype(float)\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = np.mean(border) if border.size else np.mean(gray)\n    thresh = (border_mean + np.mean(gray)) / 2.0\n    fg = gray < thresh if border_mean > np.mean(gray) else gray > thresh\n    bottom_start = int(h * 0.8)\n    left = w // 3\n    right = max(left + 1, 2 * w // 3)\n    region = fg[bottom_start:h, left:right]\n    region_size = region.size\n    if region_size == 0:\n        return 0.0\n    bg_fraction = 1.0 - (np.count_nonzero(region) / region_size)\n    return float(bg_fraction)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Peakiness: normalized (max - mean) relative to dynamic range (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    mx = float(a.max())\n    mn = float(a.min())\n    mean = float(a.mean())\n    eps = 1e-12\n    denom = (mx - mn) + eps\n    if denom <= eps:\n        return 0.0\n    result = (mx - mean) / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for grayscale), higher = more colorful'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    # use first three channels as R,G,B (handle other channel orders by assumption)\n    rgb = np.nan_to_num(arr[..., :3].astype(float))\n    R = rgb[..., 0].ravel()\n    G = rgb[..., 1].ravel()\n    B = rgb[..., 2].ravel()\n    # Hasler & Suesstrunk metric\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = rg.std() if rg.size else 0.0\n    std_yb = yb.std() if yb.size else 0.0\n    mean_rg = rg.mean() if rg.size else 0.0\n    mean_yb = yb.mean() if yb.size else 0.0\n    result = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    # normalize mildly by image size to avoid huge numbers, but keep meaningful scale\n    norm = float(max(1.0, np.sqrt(rgb.shape[0] * rgb.shape[1])))\n    return float(result / norm)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated count of stroke endpoints (pixels with exactly one ink neighbor) normalized by sqrt(ink count)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    thr = 0.5 * (mn + mx)\n    foreground_is_dark = float(np.mean(gray)) < thr\n    if foreground_is_dark:\n        ink = (gray < thr).astype(int)\n    else:\n        ink = (gray > thr).astype(int)\n    ink_cnt = int(np.count_nonzero(ink))\n    if ink_cnt == 0:\n        return 0.0\n    p = np.pad(ink, 1, mode='constant', constant_values=0)\n    center = p[1:-1, 1:-1]\n    neighbors = (\n        p[0:-2, 0:-2] + p[0:-2, 1:-1] + p[0:-2, 2:] +\n        p[1:-1, 0:-2] + p[1:-1, 2:] +\n        p[2:, 0:-2] + p[2:, 1:-1] + p[2:, 2:]\n    )\n    endpoints = np.sum((center == 1) & (neighbors == 1))\n    return float(endpoints) / (np.sqrt(float(ink_cnt)) + 1e-9)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels in the top-right quadrant (upper-right density ratio)'\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    if image.ndim == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gm = gray.max()\n    norm = gray / float(gm) if gm != 0 else gray\n    thresh = np.mean(norm)\n    ink = (norm < thresh).astype(np.float32)\n    if np.mean(ink) < 1e-3:\n        ink = 1.0 - ink\n    mid_h, mid_w = h // 2, w // 2\n    top_right = ink[0:mid_h, mid_w:w]\n    total = ink.sum()\n    if total <= 0:\n        return 0.0\n    return float(top_right.sum() / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical mirror symmetry correlation between left and right halves (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(1.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return float(1.0)\n    mid = w // 2\n    if w % 2 == 0:\n        left = a[:, :mid]\n        right = a[:, mid:]\n    else:\n        left = a[:, :mid]\n        right = a[:, mid+1:]\n    # mirror right horizontally\n    right_mirror = np.fliplr(right)\n    # resize if shapes differ\n    if left.shape != right_mirror.shape:\n        try:\n            right_mirror = np.resize(right_mirror, left.shape)\n        except Exception:\n            min_h = min(left.shape[0], right_mirror.shape[0])\n            min_w = min(left.shape[1], right_mirror.shape[1])\n            left = left[:min_h, :min_w]\n            right_mirror = right_mirror[:min_h, :min_w]\n    L = left.ravel()\n    R = right_mirror.ravel()\n    Lz = L - L.mean()\n    Rz = R - R.mean()\n    num = float((Lz * Rz).sum())\n    den = float(np.sqrt((Lz ** 2).sum() * (Rz ** 2).sum()) + eps)\n    corr = num / den\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance between intensity-weighted centroid and image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    ys, xs = np.indices((h, w))\n    weights = a - a.min()\n    W = float(weights.sum())\n    if W <= 0.0:\n        return 0.0\n    cx = float((weights * xs).sum()) / W\n    cy = float((weights * ys).sum()) / W\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    norm = np.hypot(center_x, center_y) + eps\n    result = float(np.clip(dist / norm, 0.0, 1.0))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized row index (0..1) where the row-sum of ink is maximal (top=0, bottom=1)'\n    import numpy as np\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img.astype(float)\n    m = np.mean(gray)\n    dark_count = np.sum(gray < m)\n    ink = (gray < m) if dark_count <= (h * w / 2) else (gray > m)\n    rowsum = np.sum(ink.astype(float), axis=1)\n    if np.all(rowsum == 0):\n        return 0.0\n    ridx = int(np.argmax(rowsum))\n    return float(ridx / max(1, h - 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean pairwise distance among top-brightest pixels (top 1%), normalized by image diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    flat = a.ravel()\n    n = flat.size\n    k = max(2, int(max(2, n * 0.01)))\n    # get indices of top-k brightest\n    idx = np.argpartition(-flat, k - 1)[:k]\n    ys = (idx // w).astype(float)\n    xs = (idx % w).astype(float)\n    if xs.size < 2:\n        return 0.0\n    # compute mean pairwise distance efficiently\n    vx = xs[:, None] - xs[None, :]\n    vy = ys[:, None] - ys[None, :]\n    dists = np.sqrt(vx * vx + vy * vy)\n    # take upper triangle excluding diagonal\n    iu = np.triu_indices(dists.shape[0], k=1)\n    if iu[0].size == 0:\n        return 0.0\n    mean_dist = float(np.mean(dists[iu]))\n    diag = np.hypot(h - 1, w - 1) + eps\n    result = mean_dist / diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of vertical ink/background transitions along center column (normalized by height)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    flat = gray.flatten()\n    p50 = np.percentile(flat, 50) if flat.size else 0.0\n    lower_mean = np.mean(flat[flat <= p50]) if np.any(flat <= p50) else p50\n    upper_mean = np.mean(flat[flat >= p50]) if np.any(flat >= p50) else p50\n    if lower_mean < upper_mean:\n        mask = gray <= p50\n    else:\n        mask = gray >= p50\n    col = mask[:, w//2].astype(int)\n    if col.size < 2:\n        return 0.0\n    transitions = np.sum(np.abs(np.diff(col)))\n    return float(transitions) / float(h)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of foreground pixels located in the top 20% rows (detect top bars)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    thr = np.mean(gray)\n    mask = gray < thr\n    if np.count_nonzero(mask) == 0:\n        thr = np.median(gray)\n        mask = gray < thr\n    h, w = gray.shape[:2]\n    if np.count_nonzero(mask) == 0:\n        return 0.0\n    top_h = max(1, int(np.ceil(0.2 * h)))\n    top_mask = mask[:top_h, :]\n    return float(np.count_nonzero(top_mask) / max(1, np.count_nonzero(mask)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized offset of bright-pixel centroid from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # threshold at median to get bright region\n    flat = a.ravel()\n    thr = float(np.median(flat)) if flat.size else 0.0\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    cy = ys.mean()\n    cx = xs.mean()\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    maxdist = np.hypot(center_y, center_x) + eps\n    return float(np.clip(dist / maxdist, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border uniformity: fraction of 1-pixel border pixels within 10% intensity range of border median (1 = uniform)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # collect border pixels\n    top = a[0, :]\n    bottom = a[-1, :]\n    left = a[:, 0]\n    right = a[:, -1]\n    border = np.concatenate((top.ravel(), bottom.ravel(), left.ravel(), right.ravel()))\n    if border.size == 0:\n        return 0.0\n    med = float(np.median(border))\n    span = float(border.max() - border.min())\n    tol = 0.1 * (span if span > 0 else (np.std(border) + 1e-8))\n    within = float(np.count_nonzero(np.abs(border - med) <= tol))\n    result = within / float(border.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of total intensity contained in top 5% brightest pixels'\n    import numpy as np\n    frac = 0.05\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    n = vals.size\n    if n == 0:\n        return 0.0\n    k = max(1, int(np.ceil(frac * n)))\n    if k >= n:\n        top_sum = float(vals.sum())\n    else:\n        thresh = np.partition(vals, -k)[-k]\n        top_sum = float(vals[vals >= thresh].sum())\n    total = float(vals.sum()) + eps\n    result = top_sum / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of corner-like points (high both-horizontal-and-vertical gradient)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(np.percentile(mag, 70))\n    corners = (np.abs(gx) > thr) & (np.abs(gy) > thr)\n    count = float(np.count_nonzero(corners))\n    return float(np.clip(count / (h * w + eps), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial symmetry score: similarity between image and its 180-degree rotation (1 => perfectly symmetric)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    # compare with 180-degree rotated version\n    rev = a[::-1, ::-1]\n    if a.shape != rev.shape or a.size == 0:\n        return 0.0\n    diff = np.abs(a - rev)\n    mean_diff = float(diff.mean())\n    mean_mag = float(np.abs(a).mean()) + eps\n    score = 1.0 - (mean_diff / mean_mag)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute vertical gradient (horizontal edge strength) in the bottom third of the image'\n    # handle grayscale/RGB and normalize to [0,1]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = gray.min(), gray.max()\n    norm = (gray - mn) / (mx - mn + 1e-9)\n    gy, gx = np.gradient(norm)\n    bottom = norm[2*h//3:h, :]\n    bottom_gy = gy[2*h//3:h, :]\n    if bottom_gy.size == 0:\n        return 0.0\n    return float(np.mean(np.abs(bottom_gy)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity contrast: (max-min) divided by mean intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    mn = float(a.min())\n    mx = float(a.max())\n    mean = float(np.mean(np.abs(a))) + eps\n    result = (mx - mn) / mean\n    return float(np.clip(result, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of border pixels (10% width) that are nonzero (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    bw = max(1, min(h, w) // 10)\n    top = a[0:bw, :]\n    bot = a[-bw:, :]\n    left = a[:, 0:bw]\n    right = a[:, -bw:]\n    border = np.concatenate([top.ravel(), bot.ravel(), left.ravel(), right.ravel()])\n    if border.size == 0:\n        return 0.0\n    tol = (np.nanmax(a) - np.nanmin(a)) * 0.02 + eps\n    nonzero = float(np.count_nonzero(np.abs(border) > tol))\n    result = nonzero / float(border.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated hole count inside ink strokes (counts background components not touching image border)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    mx = gray.max()\n    scale = 255.0 if mx > 1.5 else 1.0\n    if gray.mean() > scale * 0.5:\n        thr = np.percentile(gray, 30)\n        ink = (gray < thr)\n    else:\n        thr = np.percentile(gray, 70)\n        ink = (gray > thr)\n    # background mask\n    bg = ~ink\n    visited = np.zeros((h, w), dtype=np.uint8)\n    holes = 0\n    # flood-fill background components\n    for i in range(h):\n        for j in range(w):\n            if bg[i, j] and not visited[i, j]:\n                stack = [(i, j)]\n                visited[i, j] = 1\n                touches_border = False\n                while stack:\n                    y, x = stack.pop()\n                    if y == 0 or y == h-1 or x == 0 or x == w-1:\n                        touches_border = True\n                    # iterate neighbors 8-neighborhood\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = y + dy, x + dx\n                            if (0 <= ny < h) and (0 <= nx < w) and (not visited[ny, nx]) and bg[ny, nx]:\n                                visited[ny, nx] = 1\n                                stack.append((ny, nx))\n                if not touches_border:\n                    holes += 1\n    return float(holes)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of ink/background transitions per row in the central horizontal band (captures loop multiplicity)'\n    import numpy as np\n    # Convert to grayscale float\n    if image is None:\n        return 0.0\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = img.mean(axis=2)\n    else:\n        gray = img\n    # Robust binarization: decide whether ink is darker than background\n    med = np.median(gray)\n    mean = np.mean(gray)\n    thresh = np.percentile(gray, 50)\n    if (med - mean) > 0:\n        ink = gray < thresh\n    else:\n        ink = gray > thresh\n    # central band (middle 1/5 of rows)\n    band_h = max(1, h // 5)\n    start = max(0, h // 2 - band_h // 2)\n    band = ink[start:start + band_h, :]\n    # transitions per row\n    diffs = np.abs(np.diff(band.astype(np.int32), axis=1))\n    transitions_per_row = diffs.sum(axis=1)\n    if transitions_per_row.size == 0:\n        return 0.0\n    return float(np.mean(transitions_per_row))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the bottom-right quadrant'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = (float(gray.max()) + float(gray.min())) / 2.0\n    ink = (gray < thresh).astype(np.float32)\n    br = ink[h//2:, w//2:]\n    total = float(np.sum(ink))\n    if total == 0.0:\n        return 0.0\n    return float(np.sum(br) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of horizontal transitions along the central row (captures number of stroke segments)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    h, w = gray.shape[:2]\n    # threshold\n    border = np.concatenate([gray[:3, :].ravel(), gray[-3:, :].ravel(), gray[:, :3].ravel(), gray[:, -3:].ravel()]) if h>=3 and w>=3 else gray.ravel()\n    center = gray[h//4:3*h//4, w//4:3*w//4] if h>=4 and w>=4 else gray\n    border_mean = float(border.mean()) if border.size else 0.0\n    thresh = float(np.percentile(gray, 50)) if gray.size else 0.5\n    ink = (gray < thresh) if border_mean > (center.mean() if center.size else 0.0) else (gray > thresh)\n    ink = ink.astype(np.int32)\n    row_idx = h//2\n    if row_idx < 0 or row_idx >= h:\n        return 0.0\n    row = ink[row_idx, :]\n    if row.size < 2:\n        return 0.0\n    transitions = np.sum(np.abs(np.diff(row)))\n    # normalize by width\n    return float(transitions / (w - 1 + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Orientation of principal axis of ink pixels (normalized angle 0..1 where 0=horizontal, 1=vertical)'\n    try:\n        h, w = image.shape[:2]\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        thr = np.percentile(gray, 40)\n        ink_mask = (gray < thr)\n        if np.count_nonzero(ink_mask) < 4:\n            thr = np.percentile(gray, 60)\n            ink_mask = (gray > thr)\n        ys, xs = np.where(ink_mask)\n        if xs.size < 2:\n            return 0.0\n        x = xs.astype(float)\n        y = ys.astype(float)\n        x = x - x.mean()\n        y = y - y.mean()\n        cov_xx = np.mean(x * x)\n        cov_xy = np.mean(x * y)\n        cov_yy = np.mean(y * y)\n        cov = np.array([[cov_xx, cov_xy], [cov_xy, cov_yy]])\n        # eigen decomposition\n        try:\n            vals, vecs = np.linalg.eigh(cov)\n            # principal eigenvector corresponds to largest eigenvalue\n            principal = vecs[:, np.argmax(vals)]\n            angle = np.arctan2(principal[1], principal[0])  # -pi..pi\n            # convert to 0..pi/2 (orientation without direction)\n            angle = abs(angle)\n            if angle > np.pi/2:\n                angle = np.pi - angle\n            # normalize: 0 -> horizontal, 1 -> vertical\n            return float(angle / (np.pi / 2.0))\n        except Exception:\n            return 0.0\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Distance between centroid of largest internal hole (if any) and ink centroid, normalized by image diagonal; returns large value if no hole'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    fg = (gray < thresh)\n    if np.count_nonzero(fg) > 0.6 * fg.size:\n        fg = (gray > thresh)\n    fg = fg.astype(bool)\n    eps = 1e-9\n    ink_coords = np.argwhere(fg)\n    if ink_coords.shape[0] == 0:\n        return float(max(h, w))\n    ink_centroid = ink_coords.mean(axis=0)\n    # find holes in background (components not touching border)\n    bg = ~fg\n    label = np.zeros_like(bg, dtype=np.int32)\n    cur = 0\n    best_hole_centroid = None\n    best_hole_area = 0\n    for r in range(h):\n        for c in range(w):\n            if bg[r, c] and label[r, c] == 0:\n                cur += 1\n                stack = [(r, c)]\n                label[r, c] = cur\n                pixels = []\n                touches_border = False\n                while stack:\n                    y, x = stack.pop()\n                    pixels.append((y, x))\n                    if y == 0 or x == 0 or y == h-1 or x == w-1:\n                        touches_border = True\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = y + dy, x + dx\n                            if 0 <= ny < h and 0 <= nx < w and bg[ny, nx] and label[ny, nx] == 0:\n                                label[ny, nx] = cur\n                                stack.append((ny, nx))\n                if not touches_border:\n                    area = len(pixels)\n                    if area > best_hole_area:\n                        best_hole_area = area\n                        best_hole_centroid = np.array(pixels).mean(axis=0)\n    if best_hole_centroid is None:\n        return float(max(h, w))\n    dist = np.linalg.norm(best_hole_centroid - ink_centroid)\n    diag = np.sqrt(float(h*h + w*w))\n    return float(dist) / (diag + eps)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Magnitude-weighted gradient orientation coherence (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(image.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(image.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    ang = np.arctan2(gy, gx)\n    vec = np.exp(1j * ang) * mag\n    s = vec.sum()\n    total = mag.sum() + eps\n    coherence = np.abs(s) / total\n    return float(np.clip(coherence, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of bright connected components (4-neighbors) normalized by image area'\n    import numpy as np\n    from collections import deque\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mean = float(a.mean())\n    std = float(a.std())\n    thr = mean + std\n    mask = a >= thr\n    visited = np.zeros_like(mask, dtype=bool)\n    comps = 0\n    for i in range(h):\n        for j in range(w):\n            if mask[i, j] and not visited[i, j]:\n                comps += 1\n                # BFS\n                dq = deque()\n                dq.append((i, j))\n                visited[i, j] = True\n                while dq:\n                    y, x = dq.popleft()\n                    # 4-neighbors\n                    if y > 0 and mask[y-1, x] and not visited[y-1, x]:\n                        visited[y-1, x] = True; dq.append((y-1, x))\n                    if y < h-1 and mask[y+1, x] and not visited[y+1, x]:\n                        visited[y+1, x] = True; dq.append((y+1, x))\n                    if x > 0 and mask[y, x-1] and not visited[y, x-1]:\n                        visited[y, x-1] = True; dq.append((y, x-1))\n                    if x < w-1 and mask[y, x+1] and not visited[y, x+1]:\n                        visited[y, x+1] = True; dq.append((y, x+1))\n    area = float(h * w) + 1e-12\n    result = comps / area\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized center-of-mass offset from image center (0=centered, 1=corner)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    yy, xx = np.indices((h, w))\n    mass = arr.sum()\n    if mass <= eps:\n        return 0.0\n    cy = (yy * arr).sum() / mass\n    cx = (xx * arr).sum() / mass\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dy = cy - center_y\n    dx = cx - center_x\n    dist = np.hypot(dy, dx)\n    maxdist = np.hypot(center_y, center_x) + eps\n    result = float(np.clip(dist / maxdist, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical centroid offset of ink relative to image center (negative means top, positive means bottom)'\n    try:\n        if len(image.shape) == 3:\n            gray = image.mean(axis=2)\n        else:\n            gray = image.astype(float)\n        g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n        border = np.concatenate([g[0:1, :].ravel(), g[-1:, :].ravel(), g[:, 0:1].ravel(), g[:, -1:].ravel()])\n        border_mean = float(np.mean(border)) if border.size else 0.5\n        if border_mean > 0.5:\n            ink = g < max(0.0, border_mean - 0.15)\n        else:\n            ink = g > min(1.0, border_mean + 0.15)\n        coords = np.argwhere(ink)\n        if coords.size == 0:\n            return 0.0\n        y_mean = coords[:, 0].mean()\n        h = ink.shape[0]\n        return float((y_mean / max(1.0, h)) - 0.5)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Quadrant contrast spread: (max quadrant mean - min quadrant mean) normalized by global std'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mh = h // 2\n    mw = w // 2\n    q1 = a[:mh, :mw]\n    q2 = a[:mh, mw:]\n    q3 = a[mh:, :mw]\n    q4 = a[mh:, mw:]\n    means = []\n    for q in (q1, q2, q3, q4):\n        means.append(float(q.mean()) if q.size else 0.0)\n    mx = max(means)\n    mn = min(means)\n    gstd = float(a.std()) + eps\n    result = (mx - mn) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute horizontal gradient energy in the top third to bottom third (top_horiz / (bottom_horiz+eps))'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # compute horizontal gradient (difference along cols)\n    gx = np.abs(np.diff(gray, axis=1))\n    # align shapes: pad one column to the right to match original width-1 -> we will average per region\n    top_cut = max(1, h // 3)\n    top_gx = gx[:top_cut, :]\n    bottom_gx = gx[-top_cut:, :] if top_cut <= h else gx\n    top_energy = float(np.mean(top_gx)) if top_gx.size else 0.0\n    bottom_energy = float(np.mean(bottom_gx)) if bottom_gx.size else 0.0\n    eps = 1e-6\n    return float(top_energy / (bottom_energy + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Spectral entropy of FFT magnitude (bits), higher for more complex frequency content'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    try:\n        F = np.fft.fft2(arr)\n        mag = np.abs(F).ravel()\n    except Exception:\n        return 0.0\n    mag_sum = mag.sum()\n    if mag_sum <= 0:\n        return 0.0\n    p = mag / (mag_sum + eps)\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -np.sum(p_nonzero * np.log2(p_nonzero))\n    return float(entropy)\n",
    "def feature(image: np.ndarray) -> float:\n    'Density ratio right-third / left-third of image (helps detect right-heavy digits like 9)'\n    import numpy as np\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    gray_n = (gray - mn) / (mx - mn) if mx - mn > 1e-8 else np.zeros_like(gray)\n    thr = np.mean(gray_n)\n    fg = (gray_n < thr) if np.mean(gray_n) > 0.5 else (gray_n > thr)\n    third = max(1, w // 3)\n    left = fg[:, :third]\n    right = fg[:, -third:]\n    left_count = float(np.count_nonzero(left))\n    right_count = float(np.count_nonzero(right))\n    eps = 1e-6\n    return float(right_count / (left_count + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local contrast: average of patch std-devs normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    patch = max(2, min(h, w) // 8)\n    local_stds = []\n    for y in range(0, h, patch):\n        for x in range(0, w, patch):\n            block = a[y:y+patch, x:x+patch]\n            if block.size:\n                local_stds.append(float(np.std(block)))\n    if len(local_stds) == 0:\n        return 0.0\n    mean_local = float(np.mean(local_stds))\n    global_std = float(a.std()) + eps\n    result = mean_local / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Compactness-aspect score: how box-filling and square the main bright region is (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.median(a))\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    ymin, ymax = int(ys.min()), int(ys.max())\n    xmin, xmax = int(xs.min()), int(xs.max())\n    bh = max(1, ymax - ymin + 1)\n    bw = max(1, xmax - xmin + 1)\n    bbox_area = float(bh * bw)\n    mask_area = float(mask.sum())\n    # compactness: how much of bbox is filled by mask (0..1)\n    fill = mask_area / (bbox_area + eps)\n    # aspect: closeness to square (1..0), compute min(width/height, height/width)\n    aspect = float(min(bh, bw) / (max(bh, bw) + eps))\n    result = fill * aspect\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of strong orthogonal crossings in the central box where both horizontal and vertical gradients are strong'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        if h < 3 or w < 3:\n            return 0.0\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        gy, gx = np.gradient(gray)\n        mag_h = np.abs(gx)\n        mag_v = np.abs(gy)\n        # central box (middle third)\n        r0, r1 = h//3, (2*h)//3\n        c0, c1 = w//3, (2*w)//3\n        box_h = mag_h[r0:r1, c0:c1]\n        box_v = mag_v[r0:r1, c0:c1]\n        if box_h.size == 0:\n            return 0.0\n        thr_h = np.percentile(box_h, 65)\n        thr_v = np.percentile(box_v, 65)\n        crossings = np.logical_and(box_h >= thr_h, box_v >= thr_v)\n        return float(np.count_nonzero(crossings) / box_h.size)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Height (in pixels) of continuous background gap at top center before first ink (normalized by image height)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    b = max(1, min(h, w) // 10)\n    border = np.concatenate([gray[:b, :].ravel(), gray[-b:, :].ravel(), gray[:, :b].ravel(), gray[:, -b:].ravel()])\n    border_mean = float(np.mean(border)) if border.size else float(np.mean(gray))\n    if border_mean >= np.mean(gray):\n        thr = (border_mean + np.min(gray)) / 2.0\n        ink = ~(gray < thr)  # background True where gray >= thr\n        ink = ~ink\n        ink = gray < thr\n    else:\n        thr = (border_mean + np.max(gray)) / 2.0\n        ink = gray > thr\n    ink = ink.astype(np.uint8)\n    # examine a narrow vertical strip around center\n    cx = w // 2\n    halfw = max(1, w // 10)\n    strip = ink[:h//3, max(0, cx-halfw):min(w, cx+halfw)]\n    if strip.size == 0:\n        return 0.0\n    # for each column, find first ink row\n    top_gaps = []\n    for col in range(strip.shape[1]):\n        col_pixels = strip[:, col]\n        ink_rows = np.where(col_pixels)[0]\n        if ink_rows.size == 0:\n            top_gaps.append(strip.shape[0])\n        else:\n            top_gaps.append(int(ink_rows[0]))\n    # take median top gap\n    gap = float(np.median(top_gaps))\n    return float(gap / (h + 1e-6))\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum horizontal run of pixels above the row mean normalized by image width'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = img.mean(axis=2).astype(float)\n    else:\n        a = img.astype(float)\n    h, w = a.shape\n    if w == 0 or h == 0:\n        return 0.0\n    max_run = 0\n    for row in a:\n        thr = float(row.mean())\n        b = (row > thr).astype(np.int8)\n        if b.sum() == 0:\n            continue\n        # pad with zeros to detect edges\n        padded = np.concatenate(([0], b, [0]))\n        diffs = np.diff(padded)\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        if starts.size and ends.size:\n            lengths = ends - starts\n            if lengths.size:\n                mr = int(lengths.max())\n                if mr > max_run:\n                    max_run = mr\n    result = float(max_run) / float(max(1, w))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink concentrated in a central vertical strip (middle 20% width) normalized by overall ink density'\n    import numpy as np\n    if image is None:\n        return 0.0\n    # grayscale conversion\n    arr = np.array(image, dtype=float)\n    h, w = arr.shape[:2]\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr\n    # adaptive binarization: decide whether ink is darker or lighter than background\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    thresh = (p10 + p90) / 2.0\n    if p90 > p10:\n        ink = (gray < thresh)  # ink darker\n    else:\n        ink = (gray > thresh)\n    # central vertical strip (middle 20%)\n    left = max(0, int(w * 0.4))\n    right = min(w, int(w * 0.6))\n    center_count = float(np.count_nonzero(ink[:, left:right]))\n    total_count = float(np.count_nonzero(ink)) + 1e-9\n    return float(center_count / total_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average corner-like response: mean(|Ix * Iy|) normalized by mean gradient energy (0..1 approx)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    gy, gx = np.gradient(arr)\n    prod = np.abs(gx * gy)\n    energy = (gx * gx + gy * gy)\n    mean_prod = float(np.mean(prod))\n    mean_energy = float(np.mean(energy)) + eps\n    score = mean_prod / mean_energy\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energy to combined horizontal+vertical gradient energy (higher = more diagonal strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    try:\n        gy, gx = np.gradient(gray.astype(float))\n    except Exception:\n        # fallback if gradient fails\n        gy = np.zeros_like(gray, dtype=float)\n        gx = np.zeros_like(gray, dtype=float)\n    # approximate diagonal energy as |gx + gy|\n    diag = np.mean(np.abs(gx + gy))\n    hv = np.mean(np.abs(gx)) + np.mean(np.abs(gy))\n    return float(diag / (hv + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientation histogram (normalized 0..1), low => dominant orientation'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= 0:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # bin orientations into 16 bins (fold sign since orientation modulo pi is often relevant)\n    orient = np.abs(theta)  # 0..pi\n    bins = 16\n    hist, _ = np.histogram(orient.ravel(), bins=bins, range=(0.0, np.pi), weights=mag.ravel())\n    probs = hist.astype(float) / (hist.sum() + 1e-12)\n    probs = probs[probs > 0]\n    if probs.size == 0:\n        return 0.0\n    entropy = -np.sum(probs * np.log(probs + 1e-12))\n    result = entropy / (np.log(bins) + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density: fraction of pixels with gradient magnitude above mean'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    try:\n        gy, gx = np.gradient(img)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean())\n    if mag.size == 0:\n        return 0.0\n    count = float((mag > thr).sum())\n    total = float(mag.size) + eps\n    result = count / total\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized variance of discrete Laplacian (focus / texture measure)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    # discrete 4-neighbor Laplacian via shifts\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) +\n           np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    var_lap = float(np.var(lap))\n    denom = (float(a.std()) ** 2) + eps\n    result = var_lap / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the bottom-right quadrant of the image'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = (gray < thr)\n    if ink.sum() > 0.6 * h * w:\n        ink = (gray > thr)\n    if ink.sum() == 0:\n        return 0.0\n    br = ink[h // 2:, w // 2:]\n    return float(np.count_nonzero(br) / max(1, np.count_nonzero(ink)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels within a narrow band around the median (flatness)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    lo = float(np.nanmin(arr))\n    hi = float(np.nanmax(arr))\n    if hi - lo <= 0:\n        return 1.0\n    med = float(np.median(arr))\n    delta = 0.05 * (hi - lo)\n    mask = np.abs(arr - med) <= delta\n    frac = float(np.count_nonzero(mask)) / float(arr.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute horizontal gradient magnitude in the right third of the image'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # compute x-gradient (axis=1)\n    gy = np.gradient(gray, axis=0)  # vertical gradient unused\n    gx = np.gradient(gray, axis=1)\n    right_third = gx[:, (2*w)//3:]\n    if right_third.size == 0:\n        return 0.0\n    return float(np.mean(np.abs(right_third)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density: fraction of pixels with gradient magnitude above local threshold'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return float(0.0)\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    mean_mag = float(np.mean(mag))\n    std_mag = float(np.std(mag))\n    threshold = mean_mag + std_mag\n    count = float((mag > threshold).sum())\n    total = float(mag.size) + eps\n    result = count / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of vertical gradient energy concentrated in the central vertical third (distinguishes centered vertical strokes like 1)'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 0.0\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        gy, gx = np.gradient(gray)\n        vert = np.abs(gy)\n        h, w = gray.shape\n        c0, c1 = w//3, 2*w//3\n        center_vert = np.sum(vert[:, c0:c1])\n        total = np.sum(vert) + 1e-8\n        return float(center_vert / total)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of topologically enclosed background regions (holes) in the ink strokes'\n    import numpy as np\n    # Convert to grayscale\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    # Heuristic threshold and ensure ink is the minority\n    thresh = np.mean(gray)\n    fg = gray < thresh\n    if np.count_nonzero(fg) > 0.5 * h * w:\n        fg = ~fg\n    fg = fg.astype(np.uint8)\n    bg = 1 - fg\n    visited = np.zeros_like(bg, dtype=bool)\n    holes = 0\n    # 4-neighbor flood fill for background components\n    for r in range(h):\n        for c in range(w):\n            if bg[r, c] and not visited[r, c]:\n                stack = [(r, c)]\n                visited[r, c] = True\n                touches_border = (r == 0 or c == 0 or r == h-1 or c == w-1)\n                while stack:\n                    rr, cc = stack.pop()\n                    for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n                        nr, nc = rr+dr, cc+dc\n                        if 0 <= nr < h and 0 <= nc < w and not visited[nr, nc] and bg[nr, nc]:\n                            visited[nr, nc] = True\n                            stack.append((nr, nc))\n                            if nr == 0 or nc == 0 or nr == h-1 or nc == w-1:\n                                touches_border = True\n                if not touches_border:\n                    holes += 1\n    return float(holes)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average length of longest horizontal ink run per row in the top quarter normalized by image width (captures long top bars)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.mean(gray)\n    dark_mask = gray < thr\n    light_mask = gray > thr\n    ink = dark_mask if np.count_nonzero(dark_mask) <= np.count_nonzero(light_mask) else light_mask\n    top_h = max(1, h // 4)\n    region = ink[0:top_h, :]\n    if region.size == 0:\n        return 0.0\n    longest_per_row = []\n    for r in range(region.shape[0]):\n        row = region[r, :].astype(np.uint8)\n        if not np.any(row):\n            longest_per_row.append(0)\n            continue\n        padded = np.concatenate(([0], row, [0]))\n        changes = np.flatnonzero(padded[1:] != padded[:-1]).reshape(-1, 2)\n        # runs correspond to segments where value == 1: starting at changes[0], every other\n        runs = changes[::2]\n        if runs.size == 0:\n            longest_per_row.append(0)\n        else:\n            lengths = runs[:,1] - runs[:,0]\n            longest_per_row.append(int(lengths.max()))\n    avg_longest = float(np.mean(longest_per_row))\n    return float(avg_longest / max(1.0, w))\n",
    "def feature(image: np.ndarray) -> float:\n    'Average longest continuous horizontal run length in the top 20% rows (normalized by width)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.asarray(image).astype(float)\n    h, w = arr.shape[:2]\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    mx = gray.max() if gray.max() != 0 else 1.0\n    gray = gray / float(mx)\n    mean = float(gray.mean())\n    std = float(gray.std()) if float(gray.std()) > 0 else 1e-6\n    if mean > 0.5:\n        ink = gray < (mean - 0.15 * std)\n    else:\n        ink = gray > (mean + 0.15 * std)\n    top_h = max(1, h // 5)\n    top_region = ink[:top_h, :]\n    if top_region.size == 0:\n        return 0.0\n    longest_runs = []\n    for row in top_region:\n        # find longest consecutive True in row\n        if not np.any(row):\n            longest_runs.append(0)\n            continue\n        # compute run lengths\n        diffs = np.diff(np.concatenate(([0], row.view(np.int8), [0])))\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        if starts.size == 0:\n            longest_runs.append(0)\n        else:\n            lengths = ends - starts\n            longest_runs.append(np.max(lengths))\n    avg_longest = float(np.mean(longest_runs)) / float(max(1, w))\n    return float(np.clip(avg_longest, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'L1 normalized vertical symmetry: average absolute column difference between left and flipped right'\n    import numpy as np\n    # Convert to grayscale and normalize to [0,1]\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn > 1e-8:\n        gray_n = (gray - mn) / (mx - mn)\n    else:\n        gray_n = np.zeros_like(gray)\n    # Foreground assumption adaptive to mean\n    thr = np.mean(gray_n)\n    fg = gray_n < thr if np.mean(gray_n) > 0.5 else gray_n > thr\n    # split left/right\n    mid = w // 2\n    left = fg[:, :mid].astype(float)\n    right = fg[:, w - mid:][:, ::-1].astype(float)  # flip right to compare\n    # pad to same shape if odd width\n    if left.shape[1] != right.shape[1]:\n        if left.shape[1] < right.shape[1]:\n            left = np.pad(left, ((0, 0), (0, right.shape[1] - left.shape[1])), mode='constant')\n        else:\n            right = np.pad(right, ((0, 0), (0, left.shape[1] - right.shape[1])), mode='constant')\n    # L1 normalized score\n    diff = np.abs(left - right)\n    score = np.mean(diff)\n    return float(score)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border uniformity: average normalized absolute difference between border strips and global mean (0..10)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    strip_h = max(1, h // 10)\n    strip_w = max(1, w // 10)\n    top = a[:strip_h, :].ravel()\n    bottom = a[-strip_h:, :].ravel()\n    left = a[:, :strip_w].ravel()\n    right = a[:, -strip_w:].ravel()\n    border = np.concatenate([top, bottom, left, right])\n    if border.size == 0:\n        return 0.0\n    global_mean = float(np.mean(a))\n    global_std = float(np.std(a)) + eps\n    diff = np.mean(np.abs(border - global_mean)) / global_std\n    return float(diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Structure-tensor coherence (0 = isotropic, 1 = strong single orientation)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(img)\n    Jxx = (gx * gx).mean()\n    Jyy = (gy * gy).mean()\n    Jxy = (gx * gy).mean()\n    trace = Jxx + Jyy\n    det = Jxx * Jyy - Jxy * Jxy\n    # eigenvalues of 2x2: (trace \u00b1 sqrt(trace^2 - 4 det))/2\n    disc = max(trace * trace - 4.0 * det, 0.0)\n    l1 = 0.5 * (trace + np.sqrt(disc))\n    l2 = 0.5 * (trace - np.sqrt(disc))\n    # coherence measure\n    result = (l1 - l2) / (l1 + l2 + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels in deep dark tail: below mean - 0.75*std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m - 0.75 * s\n    count = int(np.count_nonzero(a < thr))\n    result = float(count) / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of columns in the center region (middle 50% rows, center 50% cols) that are open (background) at the top 15% of that center region'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy().astype(float)\n    h, w = gray.shape[:2]\n    if h < 4 or w < 4:\n        return 0.0\n    thresh = (np.min(gray) + np.max(gray)) / 2.0\n    ink = gray < thresh\n    # define center box\n    r0, r1 = h//4, 3*h//4\n    c0, c1 = w//4, 3*w//4\n    center = ink[r0:r1, c0:c1]\n    ch, cw = center.shape\n    if ch == 0 or cw == 0:\n        return 0.0\n    top_rows = max(1, int(np.ceil(0.15 * ch)))\n    top_region = center[:top_rows, :]\n    # for each column check if many pixels are background (open)\n    col_open_fraction = np.mean(~top_region, axis=0)  # fraction of background per column\n    return float(np.mean(col_open_fraction))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean horizontal edge strength in the right half divided by left half (detects right-side lobes like 3)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray)  # gy: d/drow (vertical change -> horizontal edges), gx: d/dcol (vertical edges)\n    horiz_edge = np.abs(gy)\n    mid = w // 2\n    left_energy = np.mean(horiz_edge[:, :mid]) if mid > 0 else 0.0\n    right_energy = np.mean(horiz_edge[:, mid:]) if w - mid > 0 else 0.0\n    denom = left_energy + 1e-9\n    return float(right_energy / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of columns that contain a long vertical stroke (long contiguous ink run)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    low_mean = np.mean(gray[gray <= p10]) if np.any(gray <= p10) else p10\n    high_mean = np.mean(gray[gray >= p90]) if np.any(gray >= p90) else p90\n    ink_dark = low_mean < high_mean\n    thr = np.percentile(gray, 50)\n    fg = (gray <= thr) if ink_dark else (gray >= thr)\n    fg_i = fg.astype(np.uint8)\n    long_columns = 0\n    min_len = max(2, int(h * 0.35))\n    for col in range(w):\n        col_arr = fg_i[:, col]\n        if col_arr.sum() == 0:\n            continue\n        # run length calculation\n        padded = np.concatenate(([0], col_arr, [0]))\n        dif = np.diff(padded)\n        starts = np.where(dif == 1)[0]\n        ends = np.where(dif == -1)[0]\n        if starts.size and ends.size:\n            max_run = int(np.max(ends - starts))\n        else:\n            max_run = 0\n        if max_run >= min_len:\n            long_columns += 1\n    return float(long_columns / (w + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal edge strength in top third vs bottom third (mean abs horizontal gradient top / bottom)'\n    import numpy as np\n    h, w = image.shape[:2]\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    # compute horizontal gradient magnitude\n    gy, gx = np.gradient(gray)\n    abs_gx = np.abs(gx)\n    top_third = abs_gx[:max(1, h//3), :]\n    bottom_third = abs_gx[max(1, 2*h//3):, :]\n    top_mean = float(np.mean(top_third)) if top_third.size > 0 else 0.0\n    bottom_mean = float(np.mean(bottom_third)) if bottom_third.size > 0 else 1e-9\n    return float(top_mean / (bottom_mean + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Circular variance of gradient orientations (0=aligned, 1=uniformly random)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # angles in [-pi, pi]\n    # resultant length R of unit vectors exp(i*theta)\n    v = np.exp(1j * ang.ravel())\n    R = float(np.abs(v.mean()))\n    circ_var = float(1.0 - R)\n    return float(np.clip(circ_var, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Sum of positive Harris-like cornerness responses normalized by image area (more corners => larger)'\n    import numpy as np\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    h, w = gray.shape[:2]\n    # gradients\n    gy, gx = np.gradient(gray)\n    Ixx = gx * gx\n    Iyy = gy * gy\n    Ixy = gx * gy\n    # local 3x3 sums via shifts\n    pad = lambda arr: np.pad(arr, ((1, 1), (1, 1)), mode='constant', constant_values=0.0)\n    Pxx = np.zeros_like(Ixx)\n    Pyy = np.zeros_like(Iyy)\n    Pxy = np.zeros_like(Ixy)\n    arrs_xx = pad(Ixx); arrs_yy = pad(Iyy); arrs_xy = pad(Ixy)\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            Pxx += arrs_xx[1+dy:1+dy+h, 1+dx:1+dx+w]\n            Pyy += arrs_yy[1+dy:1+dy+h, 1+dx:1+dx+w]\n            Pxy += arrs_xy[1+dy:1+dy+h, 1+dx:1+dx+w]\n    # Harris response\n    k = 0.04\n    R = (Pxx * Pyy - Pxy * Pxy) - k * (Pxx + Pyy) ** 2\n    Rpos = np.sum(R[R > 0])\n    return float(Rpos / (h * w + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized mean absolute horizontal gradient in the top third minus middle third (positive -> top horizontal stroke)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    # compute horizontal gradient\n    gy, gx = np.gradient(gray)\n    abs_gx = np.abs(gx)\n    top = abs_gx[:max(1, h//3), :].mean() if h>0 else 0.0\n    mid = abs_gx[h//3:2*h//3, :].mean() if h>1 else 0.0\n    denom = (top + mid + 1e-8)\n    return float((top - mid) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of gradient magnitude concentrated in the lower-right quadrant'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    # Compute gradients on grayscale\n    gy, gx = np.gradient(gray.astype(float))\n    mag = np.sqrt(gx * gx + gy * gy)\n    total = np.sum(mag)\n    if total <= eps:\n        return 0.0\n    r0 = int(h * 0.5)\n    c0 = int(w * 0.5)\n    lower_right = mag[r0:, c0:]\n    return float(np.sum(lower_right) / total)\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of holes whose centroids fall in the upper half of the image (normalized by image height)'\n    import numpy as np\n    from collections import deque\n    eps = 1e-6\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    th = float(np.mean(gray))\n    cand = gray < th\n    ink = cand.astype(bool) if np.count_nonzero(cand) <= (h * w) / 2 else (gray >= th).astype(bool)\n    background = ~ink\n    visited = np.zeros_like(background, dtype=bool)\n    q = deque()\n    for r in range(h):\n        for c in (0, w - 1):\n            if background[r, c] and not visited[r, c]:\n                visited[r, c] = True\n                q.append((r, c))\n    for c in range(w):\n        for r in (0, h - 1):\n            if background[r, c] and not visited[r, c]:\n                visited[r, c] = True\n                q.append((r, c))\n    while q:\n        r, c = q.popleft()\n        for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n            rr, cc = r + dr, c + dc\n            if 0 <= rr < h and 0 <= cc < w and background[rr, cc] and not visited[rr, cc]:\n                visited[rr, cc] = True\n                q.append((rr, cc))\n    holes_mask = background & ~visited\n    visited_hole = np.zeros_like(holes_mask, dtype=bool)\n    upper_holes = 0\n    for r in range(h):\n        for c in range(w):\n            if holes_mask[r, c] and not visited_hole[r, c]:\n                dq = deque()\n                dq.append((r, c))\n                visited_hole[r, c] = True\n                sum_r = 0\n                cnt = 0\n                while dq:\n                    rr, cc = dq.popleft()\n                    sum_r += rr\n                    cnt += 1\n                    for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n                        r2, c2 = rr + dr, cc + dc\n                        if 0 <= r2 < h and 0 <= c2 < w and holes_mask[r2, c2] and not visited_hole[r2, c2]:\n                            visited_hole[r2, c2] = True\n                            dq.append((r2, c2))\n                if cnt > 0:\n                    centroid_r = sum_r / float(cnt)\n                    if centroid_r < h / 2.0:\n                        upper_holes += 1\n    return float(upper_holes / (1.0 + 0.0))  # return raw count as float\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Alignment of local gradients with the down-right / up-left diagonal direction (score 0..1)'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    mag = np.sqrt(gx * gx + gy * gy) + eps\n    # direction vector for (1, -1) diagonal normalized\n    ux, uy = 1.0 / np.sqrt(2.0), -1.0 / np.sqrt(2.0)\n    # projection of normalized gradient onto diagonal direction\n    proj = (gx * ux + gy * uy) / mag\n    # weight by magnitude to focus on edges\n    score = np.mean(np.abs(proj))\n    # clamp 0..1\n    return float(max(0.0, min(1.0, score)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Perimeter mean minus global mean normalized by global std (positive => edges brighter)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # build perimeter mask\n    mask = np.zeros_like(a, dtype=bool)\n    mask[0, :] = True\n    mask[-1, :] = True\n    mask[:, 0] = True\n    mask[:, -1] = True\n    per_mean = float(np.mean(a[mask])) if mask.any() else 0.0\n    gmean = float(a.mean())\n    gstd = float(a.std()) + eps\n    result = (per_mean - gmean) / gstd\n    return float(np.clip(result, -5.0, 5.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient angle (circular mean) normalized to [-1,1]; captures prevailing stroke orientation'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gx, gy = np.gradient(gray)\n    mag = np.hypot(gx, gy)\n    if np.sum(mag) == 0:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # [-pi, pi]\n    # circular mean\n    s = np.sum(np.sin(ang) * mag)\n    c = np.sum(np.cos(ang) * mag)\n    mean_ang = np.arctan2(s, c)\n    return float(mean_ang / np.pi)  # normalized to [-1,1]\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of the four quadrant mean intensities (captures off-center objects)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    hy, wx = h // 2, w // 2\n    q1 = img[:hy, :wx]\n    q2 = img[:hy, wx:]\n    q3 = img[hy:, :wx]\n    q4 = img[hy:, wx:]\n    means = []\n    for q in (q1, q2, q3, q4):\n        means.append(float(np.mean(q)) if q.size else 0.0)\n    overall_mean = float(np.mean(img)) if img.size else 0.0\n    result = float(np.std(means) / (abs(overall_mean) + eps))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'L1 normalized vertical symmetry score: average absolute column difference between left and flipped right'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn < 1e-8:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    h, w = norm.shape\n    # compare left half to flipped right half\n    mid = w // 2\n    left = norm[:, :mid]\n    right = norm[:, w - mid:]\n    right_flipped = right[:, ::-1]\n    # resize if they mismatch due to odd width\n    if left.shape[1] != right_flipped.shape[1]:\n        minc = min(left.shape[1], right_flipped.shape[1])\n        left = left[:, :minc]\n        right_flipped = right_flipped[:, :minc]\n    score = np.mean(np.abs(left - right_flipped))\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top-center gap fraction: fraction of central columns in the top quarter that are completely empty (useful to detect open tops)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    thr = gray.mean()\n    mask = (gray > thr)\n    if mask.mean() > 0.6 or mask.mean() < 0.001:\n        p30, p70 = np.percentile(gray.flatten(), [30, 70])\n        thr2 = (p30 + p70) / 2.0\n        mask = (gray > thr2)\n        if mask.mean() > 0.6:\n            mask = (gray < thr2)\n    mask = mask.astype(np.uint8)\n    top_h = max(1, h // 4)\n    c0 = w // 4\n    c1 = 3 * w // 4\n    central = mask[0:top_h, c0:c1]\n    if central.shape[1] == 0:\n        return 0.0\n    empty_cols = np.sum(np.all(central == 0, axis=0))\n    return float(empty_cols / (central.shape[1] + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink density in top-left quadrant to bottom-right quadrant (high for strokes in TL, low for BR-heavy shapes)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.count_nonzero(ink) > 0.6 * h * w:\n        ink = ~ink\n    mid_r, mid_c = h // 2, w // 2\n    tl = ink[0:mid_r, 0:mid_c]\n    br = ink[mid_r:h, mid_c:w]\n    tl_count = float(np.count_nonzero(tl))\n    br_count = float(np.count_nonzero(br))\n    # return ratio TL / (BR + 1) to avoid division by zero; scaled to reasonable magnitude\n    return float(tl_count / (br_count + 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between ink above vs below the main diagonal (positive => more above)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    dark_count = np.count_nonzero(gray < thresh)\n    bright_count = np.count_nonzero(gray > thresh)\n    ink = (gray < thresh) if dark_count < bright_count else (gray > thresh)\n    rows = np.arange(h)[:, None]\n    cols = np.arange(w)[None, :]\n    # Above main diagonal: col > row*(w/h) approximate diagonal mapping if non-square\n    # Map row index to corresponding column index along diagonal scaled by aspect ratio\n    diag_cols = (cols.shape[1] - 1) * (rows / max(1, h - 1))\n    above = cols > diag_cols\n    below = cols < diag_cols\n    ink_above = np.count_nonzero(np.logical_and(ink, above))\n    ink_below = np.count_nonzero(np.logical_and(ink, below))\n    total = ink_above + ink_below\n    if total == 0:\n        return 0.0\n    return float((ink_above - ink_below) / total)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of vertical gradient energy concentrated in the right third (distinguishes right-side vertical strokes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gy, gx = np.gradient(gray.astype(float))\n    vert_energy = gy ** 2\n    total = np.sum(vert_energy)\n    third = max(1, w // 3)\n    right_energy = np.sum(vert_energy[:, w-third:])\n    eps = 1e-9\n    if total <= 0:\n        return 0.0\n    return float(right_energy / (total + eps))\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference in mean absolute horizontal gradient between right and left halves normalized by global gradient energy'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.asarray(image).astype(float)\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    abs_gx = np.abs(gx)\n    left = abs_gx[:, :w//2]\n    right = abs_gx[:, w//2:]\n    mean_left = left.mean() if left.size else 0.0\n    mean_right = right.mean() if right.size else 0.0\n    global_mean = abs_gx.mean() + 1e-9\n    return float((mean_right - mean_left) / global_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal centroid offset of the ink normalized by image width (negative = left, positive = right)'\n    if image is None:\n        return 0.0\n    # Convert to grayscale if needed\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    if h == 0 or w == 0:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(np.float64)\n    # Robust binarization: determine whether ink is darker or lighter\n    flat = gray.flatten()\n    thr = np.percentile(flat, 50)\n    low_mean = np.mean(flat[:max(1, len(flat)//10)])\n    high_mean = np.mean(flat[-max(1, len(flat)//10):])\n    if low_mean < high_mean:\n        ink = gray < thr\n    else:\n        ink = gray > thr\n    ink = ink.astype(np.uint8)\n    total = ink.sum()\n    if total == 0:\n        return 0.0\n    cols = np.arange(w)\n    col_sum = ink.sum(axis=0)\n    centroid_x = (col_sum * cols).sum() / total\n    # normalize to [-0.5, 0.5] then return (centered) positive means right\n    norm = (centroid_x - (w - 1) / 2.0) / float(w)\n    return float(norm)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Centroid displacement: intensity-weighted center distance from image center normalized by half-diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if arr.size == 0:\n        return 0.0\n    total = arr.sum()\n    if total == 0:\n        return 0.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    cy = float((ys * arr).sum() / (total + eps))\n    cx = float((xs * arr).sum() / (total + eps))\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    half_diag = np.hypot(h, w) / 2.0 + eps\n    result = dist / half_diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels that are strong edges (gradient magnitude > mean+std)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(img)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thresh = mag.mean() + mag.std()\n    strong = np.count_nonzero(mag > thresh)\n    frac = strong / float(max(1, mag.size))\n    return float(frac)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean color saturation for RGB images (0..1), returns 0 for grayscale'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    # take first three channels if more present\n    a3 = a[:, :, :3]\n    mx = a3.max(axis=2)\n    mn = a3.min(axis=2)\n    sat = (mx - mn) / (mx + 1e-12)  # avoid division by zero\n    # where mx is zero, saturation defined as 0\n    sat = np.where(mx > 0, sat, 0.0)\n    result = float(np.mean(sat))\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows whose mean exceeds overall mean+std (captures horizontal strokes) (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h = a.shape[0] if a.size else 0\n    if h == 0:\n        return 0.0\n    row_means = np.mean(a, axis=1)\n    overall_mean = float(a.mean())\n    overall_std = float(a.std())\n    thr = overall_mean + overall_std\n    count = float((row_means > thr).sum())\n    result = count / float(h + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink mass on the top-right side of the anti-diagonal (c + r < w-1), useful to distinguish strokes reaching top-right vs bottom-left'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = float(np.percentile(gray, 50))\n    binary = (gray > thresh).astype(np.uint8)\n    total = int(np.count_nonzero(binary))\n    if total == 0:\n        return 0.0\n    rows = np.arange(h)[:, None]\n    cols = np.arange(w)[None, :]\n    mask_top_right = (cols + rows) < (w - 1)\n    count = int(np.count_nonzero(np.logical_and(binary == 1, mask_top_right)))\n    return float(count) / float(total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of Laplacian normalized by squared global std (focus/texture measure)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) + np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    var_lap = float(np.var(lap))\n    denom = float(a.std() ** 2) + eps\n    result = var_lap / denom\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of left half mass to total mass (0..1); >0.5 means left-heavy'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    rng = float(gray.max() - gray.min())\n    if rng == 0:\n        return 0.5\n    med = float(np.median(gray)); mean = float(np.mean(gray)); delta = rng * 0.05\n    if mean < med:\n        binar = (gray < (med - delta)).astype(float)\n    else:\n        binar = (gray > (med + delta)).astype(float)\n    half = w // 2\n    left = float(binar[:, :half].sum())\n    right = float(binar[:, half:].sum())\n    total = left + right\n    if total == 0:\n        return 0.5\n    return float(left / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 32 bins'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(arr.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    nbins = 32\n    hist, _ = np.histogram(vals, bins=nbins)\n    total = float(hist.sum())\n    if total <= 0:\n        return 0.0\n    p = hist.astype(float) / total\n    p = p[p > 0]\n    ent = -float(np.sum(p * np.log(p)))\n    max_ent = float(np.log(nbins))\n    result = ent / (max_ent + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local 3x3 variance normalized by global variance (0..inf)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    # local mean and local mean of squares via shift-sum\n    def local_mean(X):\n        s = np.zeros_like(X, dtype=float)\n        s += X\n        s += np.roll(X, 1, axis=0)\n        s += np.roll(X, -1, axis=0)\n        s += np.roll(X, 1, axis=1)\n        s += np.roll(X, -1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, 1, axis=0), -1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), 1, axis=1)\n        s += np.roll(np.roll(X, -1, axis=0), -1, axis=1)\n        return s / 9.0\n    M = local_mean(a)\n    M2 = local_mean(a * a)\n    local_var = M2 - M * M\n    mean_local_var = float(np.mean(local_var))\n    overall_var = float(a.var()) + eps\n    result = mean_local_var / overall_var\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels contained in the largest connected component (1.0 if only one component or all ink in one piece)'\n    import numpy as _np\n    if len(image.shape) == 3:\n        gray = _np.mean(image, axis=2)\n    else:\n        gray = image.astype(_np.float32)\n    h, w = gray.shape\n    m = _np.mean(gray)\n    ink = (gray < m).astype(_np.uint8)\n    total = int(ink.sum())\n    if total == 0:\n        return 0.0\n    visited = _np.zeros_like(ink, dtype=_np.uint8)\n    max_size = 0\n    for y in range(h):\n        for x in range(w):\n            if ink[y, x] and not visited[y, x]:\n                size = 0\n                stack = [(y, x)]\n                visited[y, x] = 1\n                while stack:\n                    cy, cx = stack.pop()\n                    size += 1\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = cy + dy, cx + dx\n                            if 0 <= ny < h and 0 <= nx < w:\n                                if ink[ny, nx] and not visited[ny, nx]:\n                                    visited[ny, nx] = 1\n                                    stack.append((ny, nx))\n                if size > max_size:\n                    max_size = size\n    frac = float(max_size / float(total))\n    return frac\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Interquartile intensity range divided by global std (contrast estimate)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    p25 = float(np.percentile(a, 25))\n    p75 = float(np.percentile(a, 75))\n    iqr = p75 - p25\n    gstd = float(a.std()) + eps\n    result = iqr / gstd\n    return float(np.clip(result, 0.0, 20.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Largest white (background) vertical gap in the center column normalized by height'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    center_col = w // 2\n    p = np.percentile(gray, 40)\n    ink = gray <= p\n    if not ink.any():\n        p = np.percentile(gray, 60)\n        ink = gray <= p\n    col = ink[:, center_col] if center_col < w else ink[:, -1]\n    # find longest run of False (background) in this column\n    padded = np.concatenate(([0], col.view(np.int8), [0]))\n    diffs = np.diff(padded)\n    starts = np.where(diffs == -1)[0]  # background run starts in padded representation\n    ends = np.where(diffs == 1)[0]\n    max_gap = 0\n    # because we inverted sign for padded, compute runs carefully\n    # alternative: compute runs directly\n    max_gap = 0\n    run = 0\n    for v in col:\n        if not v:\n            run += 1\n        else:\n            if run > max_gap:\n                max_gap = run\n            run = 0\n    if run > max_gap:\n        max_gap = run\n    result = float(max_gap) / max(1, h)\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Peak-to-mean normalized by std (how extreme the brightest pixel is)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    mx = float(a.max())\n    mean = float(a.mean())\n    std = float(a.std()) + eps\n    result = (mx - mean) / std\n    # clamp to reasonable range\n    return float(np.clip(result, 0.0, 50.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Top-left vs top-right foreground density difference normalized by total top-half foreground (positive if more top-left)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    mn, mx = np.min(gray), np.max(gray)\n    if mx > mn:\n        gray = (gray - mn) / (mx - mn)\n    m1 = gray < np.mean(gray)\n    m2 = gray > np.mean(gray)\n    mask = m1 if m1.sum() <= m2.sum() else m2\n    top_half = mask[:h//2, :]\n    left = top_half[:, :w//2].sum()\n    right = top_half[:, w//2:].sum()\n    denom = left + right\n    if denom == 0:\n        return 0.0\n    return float((left - right) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted anisotropy from spatial covariance (0..1), 0=isotropic'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    weights = img - float(img.min())\n    S = float(weights.sum())\n    if S <= eps:\n        return 0.0\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    x_mean = float((weights * xs).sum() / S)\n    y_mean = float((weights * ys).sum() / S)\n    dx = xs - x_mean\n    dy = ys - y_mean\n    # compute weighted covariance elements\n    cov_xx = float(((weights * (dx ** 2)).sum()) / S)\n    cov_yy = float(((weights * (dy ** 2)).sum()) / S)\n    # cross term\n    cov_xy = float(((weights * dx * dy).sum()) / S)\n    # eigenvalues of 2x2 covariance\n    tr = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    disc = max(0.0, (tr * tr) / 4.0 - det)\n    l1 = tr / 2.0 + np.sqrt(disc)\n    l2 = tr / 2.0 - np.sqrt(disc)\n    result = (float(l1) - float(l2)) / (float(l1) + float(l2) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variability of local patch means (std of patch means) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    patch = max(2, min(h, w) // 8)\n    # non-overlapping patches\n    means = []\n    for y in range(0, h, patch):\n        for x in range(0, w, patch):\n            block = a[y:y+patch, x:x+patch]\n            if block.size:\n                means.append(float(block.mean()))\n    if len(means) == 0:\n        return 0.0\n    local_std = float(np.std(means))\n    global_std = float(a.std()) + eps\n    result = local_std / global_std\n    # normalize into 0..1 via a smooth clamp\n    result = float(np.tanh(result))\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of bright local maxima per area: normalized number of local peaks (>neighbors and > mean+0.5*std)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mu = float(a.mean())\n    sigma = float(a.std())\n    thresh = mu + 0.5 * sigma\n    # local max: greater than 8 neighbors\n    center = a\n    neighs = []\n    neighs.append(np.roll(a, 1, axis=0))\n    neighs.append(np.roll(a, -1, axis=0))\n    neighs.append(np.roll(a, 1, axis=1))\n    neighs.append(np.roll(a, -1, axis=1))\n    neighs.append(np.roll(np.roll(a, 1, axis=0), 1, axis=1))\n    neighs.append(np.roll(np.roll(a, 1, axis=0), -1, axis=1))\n    neighs.append(np.roll(np.roll(a, -1, axis=0), 1, axis=1))\n    neighs.append(np.roll(np.roll(a, -1, axis=0), -1, axis=1))\n    greater = np.ones_like(a, dtype=bool)\n    for n in neighs:\n        greater &= (center > n)\n    peaks = greater & (center > thresh)\n    # suppress border wrap artifacts: zero out rows/cols that were rolled from opposite side\n    peaks[0, :] = peaks[-1, :] = peaks[:, 0] = peaks[:, -1] = False\n    count = float(np.count_nonzero(peaks))\n    area = float(h * w)\n    result = count / (area + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density (fraction of pixels with strong gradient)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(np.percentile(mag, 75))\n    count = float(np.count_nonzero(mag > thr))\n    result = count / (a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    P = np.abs(F) ** 2\n    cy, cx = h // 2, w // 2\n    ys = np.arange(h)[:, None] - cy\n    xs = np.arange(w)[None, :] - cx\n    r = np.hypot(ys, xs)\n    # define low-frequency radius as 0.25 * max dim\n    r0 = max(1.0, 0.25 * max(h, w))\n    high_energy = P[r > r0].sum()\n    total_energy = P.sum() + eps\n    ratio = high_energy / total_energy\n    return float(np.clip(ratio, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dispersion of gradient directions (circular variance: 0 aligned, 1 dispersed)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    M = mag.sum()\n    if M <= eps:\n        return 0.0\n    ux = (gx / (mag + eps)).ravel()\n    uy = (gy / (mag + eps)).ravel()\n    # resultant vector length normalized by total weight\n    R = np.hypot(ux.sum(), uy.sum()) / (mag.size + eps) * (mag.size / (M + eps))\n    # convert to circular variance like measure; clamp to [0,1]\n    circ_var = float(np.clip(1.0 - R, 0.0, 1.0))\n    return float(circ_var)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of columns containing at least one bright pixel (activity across width)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w == 0:\n        return 0.0\n    mean = float(a.mean())\n    std = float(a.std())\n    thr = mean + 0.5 * std\n    cols_active = np.count_nonzero(np.any(a >= thr, axis=0))\n    result = float(cols_active) / float(w + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant diagonal orientation ratio in the top-right quadrant (detects 7/9-style slanted strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    # select top-right quadrant\n    top = gray[:h//2, w//2:]\n    if top.size == 0:\n        return 0.0\n    gy, gx = np.gradient(top.astype(float))\n    diag_pos = np.sum(np.abs(gx + gy))\n    diag_neg = np.sum(np.abs(gx - gy))\n    return float((diag_pos + 1e-9) / (diag_neg + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels with strong gradients (adaptive threshold) (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + 0.5 * mag.std())\n    count = float((mag > thr).sum())\n    result = count / (float(mag.size) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio compactness of non-background bounding box (1=square, 0=very elongated)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mn = float(img.min())\n    rng = float(img.max() - mn)\n    eps = 1e-12\n    if rng <= eps:\n        return 0.0\n    fg = img > (mn + rng * 1e-6)  # treat strictly above min as foreground\n    if not np.any(fg):\n        return 0.0\n    ys, xs = np.where(fg)\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bw = float(x1 - x0 + 1)\n    bh = float(y1 - y0 + 1)\n    if bw <= 0 or bh <= 0:\n        return 0.0\n    ratio = min(bw, bh) / max(bw, bh)\n    return float(np.clip(ratio, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'L1 vertical symmetry score for the upper half: average absolute column difference between left and flipped right (normalized)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    half_h = max(1, h // 2)\n    upper = gray[0:half_h, :]\n    # Normalized to [0,1] by dividing by intensity range\n    amax = upper.max()\n    amin = upper.min()\n    rng = amax - amin if amax != amin else 1.0\n    norm = (upper - amin) / rng\n    left = norm[:, :w//2]\n    right = norm[:, w - (w//2):]  # ensure same width when w odd\n    # flip right horizontally to compare with left\n    right_flipped = np.fliplr(right)\n    # pad to equal widths if necessary\n    if left.shape[1] != right_flipped.shape[1]:\n        minw = min(left.shape[1], right_flipped.shape[1])\n        left = left[:, :minw]\n        right_flipped = right_flipped[:, :minw]\n    diff = np.abs(left - right_flipped)\n    # normalized by number of pixels\n    return float(np.mean(diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Balance of ink near main diagonal vs anti-diagonal: (main - anti) / total, positive means more main-diagonal ink (useful for diagonal orientation)'\n    import numpy as np\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    thr = (np.nanmin(gray) + np.nanmax(gray)) / 2.0\n    dark_count = np.count_nonzero(gray < thr)\n    ink = (gray < thr) if dark_count < gray.size / 2 else (gray > thr)\n    ink = np.asarray(ink, dtype=bool)\n    if not np.any(ink):\n        return 0.0\n    # distances to main diagonal (y ~= x scaled by aspect) and anti-diagonal (y ~= h-1-x)\n    ys, xs = np.nonzero(ink)\n    # scale x to y dimension to compare properly\n    xs_scaled = xs * (h / max(1.0, w))\n    main_dist = np.abs(ys - xs_scaled)\n    anti_dist = np.abs(ys - (h - 1 - xs_scaled))\n    tol = max(1.0, 0.05 * max(h, w))\n    near_main = np.count_nonzero(main_dist <= tol)\n    near_anti = np.count_nonzero(anti_dist <= tol)\n    total = near_main + near_anti\n    if total == 0:\n        return 0.0\n    return float(near_main - near_anti) / float(total)\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of significant horizontal projection peaks (rows with strong ink) normalized by image height'\n    import numpy as np\n    if image is None:\n        return 0.0\n    gray = np.array(image, dtype=float)\n    if gray.ndim == 3:\n        gray = np.mean(gray, axis=2)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    rng = mx - mn + 1e-9\n    gray = (gray - mn) / rng\n    h, w = gray.shape\n    thresh = np.mean(gray)\n    fg1 = gray < thresh\n    fg2 = gray > thresh\n    fg = fg1 if np.count_nonzero(fg1) <= np.count_nonzero(fg2) else fg2\n    row_sums = fg.sum(axis=1).astype(float)\n    if row_sums.size == 0 or row_sums.max() == 0:\n        return 0.0\n    # normalized projection\n    rs = row_sums / (row_sums.max() + 1e-9)\n    # count local maxima above 30% of peak\n    peaks = 0\n    for i in range(1, len(rs) - 1):\n        if rs[i] > rs[i-1] and rs[i] >= rs[i+1] and rs[i] > 0.3:\n            peaks += 1\n    return float(peaks / max(1, h))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fractional size of the largest internal hole (background region not touching border) relative to image area'\n    import numpy as np\n    eps = 1e-9\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    below = np.count_nonzero(gray < thresh)\n    above = np.count_nonzero(gray > thresh)\n    if below <= above:\n        ink = (gray < thresh)\n    else:\n        ink = (gray > thresh)\n    bg = ~ink\n    visited = np.zeros_like(bg, dtype=bool)\n    max_hole = 0\n    # flood fill background components\n    for r in range(h):\n        for c in range(w):\n            if not bg[r, c] or visited[r, c]:\n                continue\n            # new component\n            stack = [(r, c)]\n            visited[r, c] = True\n            comp_size = 0\n            touches_border = False\n            while stack:\n                y, x = stack.pop()\n                comp_size += 1\n                if y == 0 or x == 0 or y == h-1 or x == w-1:\n                    touches_border = True\n                # explore 4-neighbors for speed\n                for ny, nx in ((y-1, x), (y+1, x), (y, x-1), (y, x+1)):\n                    if 0 <= ny < h and 0 <= nx < w and (not visited[ny, nx]) and bg[ny, nx]:\n                        visited[ny, nx] = True\n                        stack.append((ny, nx))\n            if not touches_border:\n                if comp_size > max_hole:\n                    max_hole = comp_size\n    return float(max_hole / (h * w + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted centroid distance from geometric center normalized by diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return float(0.0)\n    weights = a - float(a.min())\n    S = float(weights.sum())\n    if S <= eps:\n        return float(0.0)\n    ys = np.arange(h, dtype=float)[:, None]\n    xs = np.arange(w, dtype=float)[None, :]\n    cy = float((weights * ys).sum()) / S\n    cx = float((weights * xs).sum()) / S\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = float(np.hypot(cx - center_x, cy - center_y))\n    norm = float(np.hypot(center_x, center_y)) + eps\n    result = dist / norm\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency energy fraction: average-pooled image energy divided by total energy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 1 or w < 1:\n        return 0.0\n    # 3x3 box blur via roll-sum\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    blur = s / 9.0\n    low_energy = float(np.sum(np.abs(blur)))\n    total_energy = float(np.sum(np.abs(a))) + eps\n    result = low_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant frequency radius: normalized distance of strongest FFT peak from DC (0..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(image.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(image.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        F = np.fft.fft2(a)\n    except Exception:\n        return 0.0\n    S = np.abs(np.fft.fftshift(F))\n    cy, cx = h // 2, w // 2\n    S[cy, cx] = 0.0  # remove DC\n    idx = np.argmax(S)\n    if S.size == 0 or S.flat[idx] == 0:\n        return 0.0\n    iy, ix = np.unravel_index(int(idx), S.shape)\n    dist = float(np.hypot(iy - cy, ix - cx))\n    maxd = float(np.hypot(cy, cx))\n    if maxd == 0:\n        return 0.0\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Absolute correlation with image rotated by 180 degrees (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    b = np.rot90(a, 2)\n    if a.size != b.size:\n        a = a.ravel()\n        b = b.ravel()\n    A = a.ravel().astype(float)\n    B = b.ravel().astype(float)\n    if A.size == 0:\n        return 0.0\n    Am = A.mean()\n    Bm = B.mean()\n    Az = A - Am\n    Bz = B - Bm\n    num = float((Az * Bz).sum())\n    den = float(np.sqrt((Az * Az).sum() * (Bz * Bz).sum()) + eps)\n    if den <= eps:\n        return 0.0\n    corr = num / den\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'L1 normalized vertical symmetry score: average absolute column difference between left and flipped right'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    # normalize to [0,1]\n    gray = (gray - gray.min()) / max(1e-8, (gray.max() - gray.min()))\n    left = gray[:, :w // 2]\n    right = np.fliplr(gray[:, (w + 1) // 2:]) if w % 2 else np.fliplr(gray[:, w // 2:])\n    # match shapes\n    minw = min(left.shape[1], right.shape[1]) if left.size and right.size else 0\n    if minw == 0:\n        # trivial case: no symmetry information\n        return 0.0\n    diff = np.abs(left[:, :minw] - right[:, :minw])\n    # normalized by pixel count and intensity range\n    return float(np.mean(diff))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation coherence (0..1): how aligned are edge directions'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = mag.sum() + eps\n    # unit vectors for angles weighted by magnitude\n    ux = (gx * (mag > 0)) / (mag + eps)\n    uy = (gy * (mag > 0)) / (mag + eps)\n    vx = (ux * mag).sum() / total\n    vy = (uy * mag).sum() / total\n    coherence = np.hypot(vx, vy)  # between 0 and 1\n    return float(np.clip(coherence, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted eccentricity from second moments (0..1), 0=circular, 1=elongated'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # shift coordinates to center\n    ys, xs = np.indices((h, w))\n    xs = xs.astype(float)\n    ys = ys.astype(float)\n    total = float(a.sum())\n    if total == 0.0:\n        return 0.0\n    mx = (a * xs).sum() / total\n    my = (a * ys).sum() / total\n    x = xs - mx\n    y = ys - my\n    # covariance elements\n    Cxx = float((a * (x * x)).sum()) / total\n    Cyy = float((a * (y * y)).sum()) / total\n    Cxy = float((a * (x * y)).sum()) / total\n    # eigenvalues of covariance matrix\n    trace = Cxx + Cyy\n    det = Cxx * Cyy - Cxy * Cxy\n    # numerical stability\n    disc = max(0.0, trace * trace / 4.0 - det)\n    l1 = trace / 2.0 + np.sqrt(disc)\n    l2 = trace / 2.0 - np.sqrt(disc)\n    # avoid division by zero\n    mxeig = max(l1, l2, eps)\n    mineig = min(l1, l2)\n    # eccentricity-like measure: 1 - (minor / major)\n    result = 1.0 - max(0.0, float(mineig) / float(mxeig))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border uniformity (0..1): higher means border pixels are more uniform'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    borders = []\n    # top and bottom rows\n    borders.append(a[0, :])\n    if h > 1:\n        borders.append(a[-1, :])\n    # left and right columns (excluding corners already added)\n    if w > 1:\n        if h > 2:\n            borders.append(a[1:-1, 0].ravel())\n            borders.append(a[1:-1, -1].ravel())\n        else:\n            borders.append(a[:, 0].ravel())\n            borders.append(a[:, -1].ravel())\n    border_pixels = np.concatenate([b.ravel() for b in borders]) if borders else np.array([])\n    if border_pixels.size == 0:\n        return 0.0\n    mean_abs = float(np.mean(np.abs(border_pixels)))\n    std = float(np.std(border_pixels))\n    # uniformity measure: mean_abs / (mean_abs + std) -> close to 1 if std small relative to mean\n    uniformity = mean_abs / (mean_abs + std + eps)\n    return float(np.clip(uniformity, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of very dark pixels (<5th percentile)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    thresh = np.percentile(arr, 5)\n    frac = float(np.count_nonzero(arr < thresh)) / float(arr.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gini coefficient of pixel intensities (measure of sparsity/inequality, 0..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    # Make non-negative by shifting if necessary\n    arr_min = arr.min()\n    if arr_min < 0:\n        arr = arr - arr_min\n    sum_x = arr.sum()\n    n = arr.size\n    if sum_x == 0 or n == 0:\n        return 0.0\n    arr_sorted = np.sort(arr)\n    idx = np.arange(1, n + 1)\n    gini = (2.0 * np.sum(idx * arr_sorted) / (n * sum_x)) - (n + 1.0) / n\n    gini = float(np.clip(gini, 0.0, 1.0))\n    return float(gini)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Central disk prominence: center mean vs surrounding annulus normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    rx = xs - cx\n    ry = ys - cy\n    r = np.hypot(rx, ry)\n    R = max(1.0, min(h, w) / 6.0)\n    inner = r <= R\n    outer = np.logical_and(r > R, r <= (2.0 * R))\n    if not np.any(inner) or not np.any(outer):\n        return 0.0\n    center_mean = float(a[inner].mean())\n    ann_mean = float(a[outer].mean())\n    gstd = float(a.std()) + eps\n    result = (center_mean - ann_mean) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Rim intensity bias: mean rim intensity minus interior mean normalized by std'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    rim = max(1, min(h, w) // 12)\n    rim_mask = np.zeros_like(a, dtype=bool)\n    rim_mask[:rim, :] = True\n    rim_mask[-rim:, :] = True\n    rim_mask[:, :rim] = True\n    rim_mask[:, -rim:] = True\n    rim_vals = a[rim_mask]\n    inner_vals = a[~rim_mask]\n    if rim_vals.size == 0 or inner_vals.size == 0:\n        return 0.0\n    diff = float(rim_vals.mean() - inner_vals.mean())\n    overall_std = float(a.std()) + eps\n    result = diff / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left vs right ink balance: normalized difference in ink pixel counts'\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    # adaptive binarization: determine if ink is darker\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    low_mean = np.mean(gray[gray <= p10]) if np.any(gray <= p10) else p10\n    high_mean = np.mean(gray[gray >= p90]) if np.any(gray >= p90) else p90\n    ink_dark = low_mean < high_mean\n    thr = np.percentile(gray, 50)\n    fg = (gray <= thr) if ink_dark else (gray >= thr)\n    left = float(np.count_nonzero(fg[:, :w//2]))\n    right = float(np.count_nonzero(fg[:, w//2:]))\n    denom = left + right + 1e-6\n    return float((left - right) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of strict local maxima (pixels greater than all 8 neighbors), normalized by image area'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # pad with -inf so edges are handled without wrap\n    pad = np.pad(a, pad_width=((1, 1), (1, 1)), mode='constant', constant_values=-np.inf)\n    center = pad[1:-1, 1:-1]\n    neighs = [\n        pad[0:-2, 0:-2], pad[0:-2, 1:-1], pad[0:-2, 2:],\n        pad[1:-1, 0:-2],                 pad[1:-1, 2:],\n        pad[2:, 0:-2],   pad[2:, 1:-1],   pad[2:, 2:]\n    ]\n    mask = np.ones_like(center, dtype=bool)\n    for n in neighs:\n        mask &= (center > n)\n    count = float(np.count_nonzero(mask))\n    denom = float(a.size)\n    return float(np.clip(count / (denom + 1e-12), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Prominence of the dominant intensity histogram peak: (max - second) / total_counts (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(arr.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    nbins = 32\n    hist, _ = np.histogram(vals, bins=nbins)\n    if hist.sum() <= 0:\n        return 0.0\n    sorted_counts = np.sort(hist)[::-1]\n    maxc = float(sorted_counts[0])\n    second = float(sorted_counts[1]) if sorted_counts.size > 1 else 0.0\n    total = float(hist.sum())\n    result = (maxc - second) / (total + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized displacement of bright-pixel centroid from image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    N = a.size\n    if N == 0:\n        return 0.0\n    # select top 10% brightest pixels\n    k = max(1, int(0.10 * N))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    thr = np.partition(flat, -k)[-k]\n    mask = a >= thr\n    if not np.any(mask):\n        return 0.0\n    # intensity-weighted centroid among masked pixels\n    weights = a * mask\n    total_w = weights.sum() + eps\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    cy = float((weights * ys).sum() / total_w)\n    cx = float((weights * xs).sum() / total_w)\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cy - center_y, cx - center_x)\n    max_dist = np.hypot(center_y, center_x) + eps\n    norm = dist / max_dist\n    return float(np.clip(norm, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized variance of mean intensities across concentric radial bins (ringiness)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = int(np.ceil(r.max()))\n    if maxr <= 0:\n        return 0.0\n    means = []\n    for rr in range(maxr + 1):\n        mask = (np.floor(r) == rr)\n        if np.any(mask):\n            means.append(float(a[mask].mean()))\n    means = np.array(means, dtype=float)\n    if means.size <= 1:\n        return 0.0\n    var_r = float(np.var(means))\n    global_var = float(np.var(a)) + eps\n    result = var_r / global_var\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of edge energy that is diagonal (detects slanted strokes like the 9 tail)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gray = gray.astype(float)\n    gx, gy = np.gradient(gray)\n    mag = np.sqrt(gx * gx + gy * gy)\n    total = mag.sum()\n    if total < 1e-9:\n        return 0.0\n    # diagonal if |abs(gx)-abs(gy)| is small relative to their sum\n    diag_mask = np.abs(np.abs(gx) - np.abs(gy)) <= 0.3 * (np.abs(gx) + np.abs(gy) + 1e-9)\n    diag_energy = mag[diag_mask].sum()\n    return float(diag_energy / (total + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of gradient (edge) energy in lower half to upper half (captures lower loops vs top strokes)'\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h < 2:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    grad = np.sqrt(gx * gx + gy * gy)\n    top = grad[:h//2, :]\n    bot = grad[h//2:, :]\n    top_sum = float(np.sum(top))\n    bot_sum = float(np.sum(bot))\n    return float(bot_sum) / (top_sum + 1e-9)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized average horizontal gradient magnitude in the top 25% rows (detects top bars)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    top_h = max(1, h // 4)\n    top = gray[:top_h, :]\n    _, gx_top = np.gradient(top.astype(float))\n    top_energy = np.mean(np.abs(gx_top))\n    # normalize by whole-image horizontal gradient\n    _, gx_all = np.gradient(gray.astype(float))\n    norm = np.mean(np.abs(gx_all)) + 1e-9\n    return float(top_energy / norm)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Laplacian energy: mean(|\u0394I|) / (mean(|I|)+eps)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, gyx = np.gradient(gy)\n        gxy, gxx = np.gradient(gx)\n        lap = gxx + gyy\n    except Exception:\n        return 0.0\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    mean_abs = float(np.mean(np.abs(a))) + eps\n    result = mean_abs_lap / mean_abs\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal edge strength in the middle third rows (mean abs vertical differences) normalized by global edge'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    if h < 3:\n        return 0.0\n    # compute vertical differences (abs of diff along rows gives horizontal edges)\n    vert_diff = np.abs(np.diff(gray, axis=0))\n    mid0 = h // 3\n    mid1 = 2 * h // 3\n    if vert_diff.size == 0:\n        return 0.0\n    mid_region = vert_diff[mid0:mid1, :]\n    global_mean = vert_diff.mean() + 1e-9\n    return float(mid_region.mean() / global_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical separation between two largest enclosed hole centroids normalized by image height (0 if fewer than 2 holes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.mean(gray))\n    cand = gray < thr\n    if np.sum(cand) > gray.size / 2:\n        ink = ~cand\n    else:\n        ink = cand\n    ink = ink.astype(bool)\n    # exterior fill\n    exterior = np.zeros_like(ink, dtype=bool)\n    from collections import deque\n    q = deque()\n    for i in range(h):\n        for j in (0, w-1):\n            if not ink[i, j] and not exterior[i, j]:\n                exterior[i, j] = True\n                q.append((i, j))\n    for j in range(w):\n        for i in (0, h-1):\n            if not ink[i, j] and not exterior[i, j]:\n                exterior[i, j] = True\n                q.append((i, j))\n    while q:\n        i, j = q.popleft()\n        for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n            ni, nj = i+di, j+dj\n            if 0 <= ni < h and 0 <= nj < w and (not ink[ni, nj]) and (not exterior[ni, nj]):\n                exterior[ni, nj] = True\n                q.append((ni, nj))\n    internal = (~ink) & (~exterior)\n    visited = np.zeros_like(internal, dtype=bool)\n    centroids = []\n    for i in range(h):\n        for j in range(w):\n            if internal[i, j] and not visited[i, j]:\n                # BFS\n                q = deque()\n                q.append((i, j))\n                visited[i, j] = True\n                pts = [(i, j)]\n                while q:\n                    ci, cj = q.popleft()\n                    for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ni, nj = ci+di, cj+dj\n                        if 0 <= ni < h and 0 <= nj < w and internal[ni, nj] and not visited[ni, nj]:\n                            visited[ni, nj] = True\n                            pts.append((ni, nj))\n                            q.append((ni, nj))\n                pts = np.array(pts)\n                centroids.append((float(np.mean(pts[:,0])), float(np.mean(pts[:,1])), pts.shape[0]))\n    if len(centroids) < 2:\n        return 0.0\n    # sort by area desc and take two largest\n    centroids.sort(key=lambda x: x[2], reverse=True)\n    y1 = centroids[0][0]\n    y2 = centroids[1][0]\n    return float(abs(y1 - y2) / max(1.0, h))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity moment of inertia normalized by max radius^2 (0=centered bright, 1=peripheral)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    r2 = (ys - cy)**2 + (xs - cx)**2\n    weight = img\n    total_weight = float(weight.sum())\n    if total_weight <= 0:\n        return 0.0\n    moi = float((weight * r2).sum() / (total_weight + eps))\n    max_r2 = float(r2.max()) if r2.size else 1.0\n    return float(np.clip(moi / (max_r2 + eps), 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute vertical edge strength (gx) in the center-right quadrant (detects vertical right strokes)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = gray.min(), gray.max()\n    norm = (gray - mn) / (mx - mn + 1e-9)\n    gy, gx = np.gradient(norm)\n    r0, c0 = h//4, w//2\n    region = gx[r0:3*h//4, c0:w]\n    if region.size == 0:\n        return 0.0\n    return float(np.mean(np.abs(region)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shape elongation measured by eigenvalue ratio of intensity-weighted coords (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    # use intensity as weight but shift to be non-negative\n    vals = a - a.min()\n    total = vals.sum()\n    if total <= 0:\n        # fall back to binary\n        mask = a > np.median(flat)\n        ys, xs = np.nonzero(mask)\n        if ys.size == 0:\n            return 0.0\n        vals_coords = np.ones_like(ys, dtype=float)\n    else:\n        ys, xs = np.indices(a.shape)\n        ys = ys.ravel()\n        xs = xs.ravel()\n        vals_coords = vals.ravel()\n    wsum = vals_coords.sum() + eps\n    mean_y = (ys * vals_coords).sum() / wsum\n    mean_x = (xs * vals_coords).sum() / wsum\n    dy = ys - mean_y\n    dx = xs - mean_x\n    Cxx = (vals_coords * (dx * dx)).sum() / wsum + eps\n    Cyy = (vals_coords * (dy * dy)).sum() / wsum + eps\n    Cxy = (vals_coords * (dx * dy)).sum() / wsum\n    # covariance matrix eigenvalues\n    tr = Cxx + Cyy\n    det = Cxx * Cyy - Cxy * Cxy\n    # numerical safe eigenvalues\n    disc = max(0.0, tr * tr / 4.0 - det)\n    l1 = tr / 2.0 + np.sqrt(disc)\n    l2 = tr / 2.0 - np.sqrt(disc)\n    if l1 <= 0:\n        return 0.0\n    ratio = l2 / (l1 + eps)\n    # elongation: 1 - (min/max) so 0 (round) to ~1 (very elongated)\n    elong = 1.0 - float(np.clip(ratio, 0.0, 1.0))\n    return float(np.clip(elong, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Peak diagonal projection: largest bin count when projecting ink onto i+j diagonal axis normalized by ink count'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    mask = gray < np.mean(gray)\n    rows, cols = np.nonzero(mask)\n    if rows.size == 0:\n        return 0.0\n    diag_idx = rows + cols\n    min_idx = diag_idx.min()\n    bins = np.bincount(diag_idx - min_idx)\n    peak = float(bins.max())\n    return float(peak / (np.sum(mask) + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized maximum radius of bright region: farthest bright pixel from center / image diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean() + 0.5 * a.std())\n    mask = (a > thr)\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    dists = np.hypot(ys - cy, xs - cx)\n    maxd = float(dists.max()) if dists.size else 0.0\n    diag = np.hypot(h, w) / 2.0 + eps\n    result = maxd / diag\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative ink mass in the lower central region (bottom half & central 60% width) compared to total ink'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape\n    vals = gray.ravel()\n    lowp, highp = np.percentile(vals, 10), np.percentile(vals, 90)\n    thresh = (lowp + highp) / 2.0\n    binary = gray < thresh\n    if np.count_nonzero(binary) == 0:\n        binary = gray > thresh\n    total = float(np.count_nonzero(binary))\n    if total == 0.0:\n        return 0.0\n    left = int(w * 0.2)\n    right = int(w * 0.8)\n    bottom_mask = np.zeros_like(binary, dtype=bool)\n    bottom_mask[h//2:, left:right] = True\n    bottom_count = float(np.count_nonzero(binary & bottom_mask))\n    return bottom_count / total\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Lower-right vs lower-left ink density difference: (lower-right - lower-left) normalized by total ink'\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    thresh = np.mean(gray)\n    bin_img = (gray < thresh).astype(np.float32)\n    if np.sum(bin_img) < 1:\n        bin_img = (gray > thresh).astype(np.float32)\n        if np.sum(bin_img) < 1:\n            return 0.0\n    half_h = h // 2\n    half_w = w // 2\n    lower = bin_img[half_h:, :]\n    lr = np.sum(lower[:, half_w:])\n    ll = np.sum(lower[:, :half_w])\n    total = np.sum(bin_img)\n    return float((lr - ll) / (total + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical gradient energy in the right half vs whole image (higher means stronger vertical strokes on the right side)'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        if image.ndim == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        # vertical gradients\n        vg = np.abs(np.diff(gray, axis=0))\n        total_vg = np.mean(vg) if vg.size>0 else 0.0\n        right_vg = np.mean(vg[:, w//2:]) if vg[:, w//2:].size>0 else 0.0\n        eps = 1e-6\n        return float(right_vg / (total_vg + eps))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean inward border gradient: average gradient magnitude from outer 1-pixel ring toward center normalized by total edge energy'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    # outer ring mask (1-pixel)\n    mask = np.zeros_like(a, dtype=bool)\n    mask[0, :] = True\n    mask[-1, :] = True\n    mask[:, 0] = True\n    mask[:, -1] = True\n    outer_mag = mag[mask]\n    total = float(mag.sum()) + eps\n    if outer_mag.size == 0:\n        return 0.0\n    result = float(outer_mag.mean()) / total\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of total ink pixels that lie within a narrow vertical strip centered at the image middle (vertical midline ink concentration)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink_candidate = gray < thresh\n    if np.count_nonzero(ink_candidate) > 0.9 * h * w:\n        ink = ~ink_candidate\n    else:\n        ink = ink_candidate\n    ink = ink.astype(bool)\n    total_ink = np.count_nonzero(ink)\n    if total_ink == 0:\n        return 0.0\n    band_width = max(1, w // 8)\n    center = w // 2\n    left = max(0, center - band_width // 2)\n    right = min(w, left + band_width)\n    mid_ink = np.count_nonzero(ink[:, left:right])\n    return float(mid_ink / total_ink)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global edge-orientation coherence (0..1): how aligned gradient directions are'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    # unit vectors weighted by magnitude -> resultant length normalized by total magnitude\n    sx = float((gx * mag).sum())\n    sy = float((gy * mag).sum())\n    # but above sums produce scale; better use unit orientation sum weighted by mag\n    ux = (gx / mag) * mag\n    uy = (gy / mag) * mag\n    Rx = float(ux.sum())\n    Ry = float(uy.sum())\n    resultant = np.hypot(Rx, Ry)\n    total = float(mag.sum()) + eps\n    result = resultant / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Degree of 180-degree rotational symmetry (0..1, 1 = identical under rotation)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    # rotate 180 degrees\n    rot = np.rot90(a, 2)\n    if a.shape != rot.shape:\n        return 0.0\n    a_flat = a.ravel()\n    r_flat = rot.ravel()\n    a_mean = a_flat.mean()\n    r_mean = r_flat.mean()\n    a_c = a_flat - a_mean\n    r_c = r_flat - r_mean\n    denom = np.sqrt((a_c ** 2).sum() * (r_c ** 2).sum()) + eps\n    corr = float((a_c * r_c).sum() / denom)\n    result = float(np.clip(abs(corr), 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global gradient coherence from structure tensor (0..1, higher = more coherent)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(img)\n    Sxx = float((gx * gx).sum())\n    Syy = float((gy * gy).sum())\n    Sxy = float((gx * gy).sum())\n    # structure tensor eigenvalues\n    trace = Sxx + Syy\n    det = Sxx * Syy - Sxy * Sxy\n    tmp = max(trace * trace / 4.0 - det, 0.0)\n    diff = float(np.sqrt(tmp))\n    lam1 = trace / 2.0 + diff\n    lam2 = trace / 2.0 - diff\n    if lam1 + lam2 <= eps:\n        return 0.0\n    coherence = (lam1 - lam2) / (lam1 + lam2 + eps)\n    return float(np.clip(coherence, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of a horizontal bar near the middle: mean vertical gradient magnitude in central horizontal band normalized by global'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gy, gx = np.gradient(gray)\n    vert_mag = np.abs(gy)\n    top = h // 3\n    bot = max(top + 1, (2 * h) // 3)\n    center_band = vert_mag[top:bot, :]\n    center_mean = np.mean(center_band) if center_band.size > 0 else 0.0\n    global_mean = np.mean(vert_mag) + 1e-9\n    return float(center_mean / global_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative edge energy in a narrow horizontal band around the image center vs whole image (8 often has stronger edges at the waist)'\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3 or w < 1:\n        return 0.0\n    gy, gx = np.gradient(gray.astype(float))\n    grad_mag = np.sqrt(gy * gy + gx * gx)\n    whole_mean = float(np.mean(grad_mag))\n    band_h = max(1, h // 10)\n    center = h // 2\n    band = grad_mag[max(0, center - band_h):min(h, center + band_h), :]\n    band_mean = float(np.mean(band))\n    if whole_mean <= 0:\n        return float(band_mean)\n    return float(band_mean / whole_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized aspect ratio (width/height) clipped to [0..5]'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    try:\n        h, w = img.shape[:2]\n    except Exception:\n        return 0.0\n    if h <= 0:\n        return 0.0\n    ar = float(w) / float(h)\n    result = float(np.clip(ar, 0.0, 5.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized aspect ratio of the bright-region bounding box (1.0 = square, 0.0 = very elongated)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    thr = img.mean() + 0.5 * img.std()\n    mask = img > thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    miny, maxy = ys.min(), ys.max()\n    minx, maxx = xs.min(), xs.max()\n    bbox_h = max(1, maxy - miny + 1)\n    bbox_w = max(1, maxx - minx + 1)\n    small = min(bbox_h, bbox_w)\n    large = max(bbox_h, bbox_w)\n    ratio = float(small) / float(large + eps)\n    return float(np.clip(ratio, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Eccentricity (major/minor axis ratio) of the largest foreground blob (clipped 0..10)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.median(a))\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    # label components to find largest (simple flood fill)\n    visited = np.zeros_like(mask, dtype=bool)\n    largest_coords = None\n    largest_size = 0\n    stack = []\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                coords = []\n                stack.append((y, x))\n                visited[y, x] = True\n                while stack:\n                    cy, cx = stack.pop()\n                    coords.append((cy, cx))\n                    if cy > 0 and mask[cy - 1, cx] and not visited[cy - 1, cx]:\n                        visited[cy - 1, cx] = True\n                        stack.append((cy - 1, cx))\n                    if cy + 1 < h and mask[cy + 1, cx] and not visited[cy + 1, cx]:\n                        visited[cy + 1, cx] = True\n                        stack.append((cy + 1, cx))\n                    if cx > 0 and mask[cy, cx - 1] and not visited[cy, cx - 1]:\n                        visited[cy, cx - 1] = True\n                        stack.append((cy, cx - 1))\n                    if cx + 1 < w and mask[cy, cx + 1] and not visited[cy, cx + 1]:\n                        visited[cy, cx + 1] = True\n                        stack.append((cy, cx + 1))\n                size = len(coords)\n                if size > largest_size:\n                    largest_size = size\n                    largest_coords = np.array(coords)\n    if largest_coords is None or largest_coords.shape[0] < 2:\n        return 0.0\n    ys = largest_coords[:, 0].astype(float)\n    xs = largest_coords[:, 1].astype(float)\n    # covariance matrix of coordinates\n    cx_m = xs.mean()\n    cy_m = ys.mean()\n    cov_xx = np.mean((xs - cx_m) ** 2)\n    cov_yy = np.mean((ys - cy_m) ** 2)\n    cov_xy = np.mean((xs - cx_m) * (ys - cy_m))\n    # eigenvalues\n    trace = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    diff = np.sqrt(max(0.0, (trace * trace) / 4.0 - det))\n    lam1 = trace / 2.0 + diff\n    lam2 = trace / 2.0 - diff\n    lam2 = max(lam2, eps)\n    ratio = lam1 / lam2\n    result = float(np.clip(ratio, 0.0, 10.0))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized aspect ratio w/(h+ w) in (0..1) (closer to 1 => wide)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        h, w = img.shape[0], img.shape[1]\n    else:\n        h, w = img.shape[0], img.shape[1]\n    if h <= 0 and w <= 0:\n        return 0.0\n    denom = float(h + w)\n    if denom <= 0:\n        return 0.0\n    result = float(w / denom)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border vs interior gradient contrast normalized by mean gradient (positive => borders stronger)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    bw = max(1, int(min(h, w) * 0.1))\n    mask_border = np.zeros_like(a, dtype=bool)\n    mask_border[:bw, :] = True\n    mask_border[-bw:, :] = True\n    mask_border[:, :bw] = True\n    mask_border[:, -bw:] = True\n    mask_interior = ~mask_border\n    border_mean = float(mag[mask_border].mean()) if mask_border.any() else 0.0\n    interior_mean = float(mag[mask_interior].mean()) if mask_interior.any() else 0.0\n    denom = float(mag.mean()) + eps\n    result = (border_mean - interior_mean) / denom\n    # clip to a reasonable symmetric range\n    return float(np.clip(result, -5.0, 5.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-vs-border contrast normalized by global std (positive => center brighter)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ch = max(1, h // 4)\n    cw = max(1, w // 4)\n    center = a[h//2 - ch//2:h//2 + (ch - ch//2), w//2 - cw//2:w//2 + (cw - cw//2)]\n    # border: outer ring excluding center area\n    border_mask = np.ones_like(a, dtype=bool)\n    br_top = max(0, h//2 - ch//2)\n    br_bot = min(h, h//2 + (ch - ch//2))\n    br_left = max(0, w//2 - cw//2)\n    br_right = min(w, w//2 + (cw - cw//2))\n    border_mask[br_top:br_bot, br_left:br_right] = False\n    border = a[border_mask]\n    if center.size == 0 or border.size == 0:\n        return 0.0\n    center_mean = float(center.mean())\n    border_mean = float(border.mean())\n    gstd = float(a.std()) + eps\n    result = (center_mean - border_mean) / gstd\n    # clip to reasonable range\n    return float(np.clip(result, -5.0, 5.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Centrosymmetry: normalized correlation with 180-degree rotated image (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    flipped = np.rot90(a, 2)\n    num = float(np.sum(a * flipped))\n    denom = np.sqrt(float(np.sum(a * a)) * float(np.sum(flipped * flipped))) + 1e-12\n    corr = num / denom\n    # map from [-1,1] to [0,1]\n    result = (corr + 1.0) / 2.0\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of mean intensities across the four image quadrants normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mid_h = h // 2\n    mid_w = w // 2\n    q1 = a[:mid_h, :mid_w]\n    q2 = a[:mid_h, mid_w:]\n    q3 = a[mid_h:, :mid_w]\n    q4 = a[mid_h:, mid_w:]\n    means = []\n    for q in (q1, q2, q3, q4):\n        means.append(float(np.mean(q)) if q.size else 0.0)\n    var_means = float(np.var(np.array(means)))\n    gstd = float(a.std()) + eps\n    result = var_means / gstd\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of edge density in center region to edge density in border (>=0)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(np.median(mag))\n    edges = mag > thr\n    # center region\n    r0, r1 = h // 4, 3 * (h // 4)\n    c0, c1 = w // 4, 3 * (w // 4)\n    # ensure at least 1 pixel\n    r1 = max(r1, r0 + 1)\n    c1 = max(c1, c0 + 1)\n    center_mask = np.zeros_like(edges, dtype=bool)\n    center_mask[r0:r1, c0:c1] = True\n    border_mask = ~center_mask\n    center_edges = float(np.count_nonzero(edges & center_mask))\n    border_edges = float(np.count_nonzero(edges & border_mask))\n    center_area = float(center_mask.sum()) + eps\n    border_area = float(border_mask.sum()) + eps\n    center_density = center_edges / center_area\n    border_density = border_edges / border_area\n    if border_density < eps:\n        result = center_density\n    else:\n        result = center_density / (border_density + eps)\n    return float(np.clip(result, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute center-symmetric intensity difference normalized by global std (asymmetry)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    flipped = np.flip(np.flip(a, 0), 1)\n    diff = np.abs(a - flipped)\n    mean_diff = float(np.mean(diff))\n    gstd = float(a.std()) + eps\n    result = mean_diff / gstd\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency dominance via 2x2 block smoothing: fraction of energy in low frequencies (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h0, w0 = a.shape\n    if h0 == 0 or w0 == 0:\n        return float(0.0)\n    # pad to even dimensions by reflecting last row/col if needed\n    pad_h = 0 if (h0 % 2 == 0) else 1\n    pad_w = 0 if (w0 % 2 == 0) else 1\n    if pad_h or pad_w:\n        a_pad = np.pad(a, ((0, pad_h), (0, pad_w)), mode='reflect')\n    else:\n        a_pad = a\n    h, w = a_pad.shape\n    # compute 2x2 block means\n    a_blocks = a_pad.reshape((h//2, 2, w//2, 2)).mean(axis=(1,3))\n    # upsample back to padded size\n    low = np.repeat(np.repeat(a_blocks, 2, axis=0), 2, axis=1)\n    low = low[:h0, :w0]\n    residual = a - low\n    low_energy = float(np.sum(np.abs(low)))\n    high_energy = float(np.sum(np.abs(residual)))\n    denom = low_energy + high_energy + eps\n    result = low_energy / denom\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density: proportion of pixels with strong gradient magnitude'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(np.mean(mag) + np.std(mag))\n    count = float(np.count_nonzero(mag > thr))\n    result = count / float(arr.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical edge strength in the lower half: mean absolute horizontal-gradient in bottom half divided by global mean gradient'\n    import numpy as np\n    if image is None:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    grayn = (gray - mn) / (mx - mn + 1e-8)\n    gy, gx = np.gradient(grayn)\n    lower_gy = gy[h//2:, :]\n    mean_lower = float(np.mean(np.abs(lower_gy)))\n    mean_global = float((np.mean(np.abs(gx)) + np.mean(np.abs(gy))) / 2.0 + 1e-10)\n    return float(mean_lower / mean_global)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with strong gradient magnitude relative to image stats'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    m = float(mag.mean())\n    s = float(mag.std())\n    thr = m + s  # strong edges\n    strong = (mag > thr).sum()\n    result = float(strong) / float(mag.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (Hasler-S\u00fcsstrunk); returns 0 for grayscale or flat images'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    img = np.nan_to_num(arr.astype(float))\n    R = img[:, :, 0]\n    G = img[:, :, 1]\n    B = img[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg * std_rg + std_yb * std_yb) + 0.3 * np.sqrt(mean_rg * mean_rg + mean_yb * mean_yb)\n    # normalize by dynamic range\n    dyn = float(max(1.0, img.max() - img.min()))\n    result = colorfulness / (dyn + eps)\n    return float(max(0.0, result))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of very dark pixels (below mean - 0.5*std), 0..1'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m - 0.5 * s\n    dark = np.count_nonzero(a < thr)\n    result = dark / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Adaptive foreground fraction: fraction of pixels above mean+0.5*std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    mu = float(np.mean(a))\n    sd = float(np.std(a))\n    thresh = mu + 0.5 * sd\n    frac = float(np.count_nonzero(a > thresh)) / (a.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal symmetry correlation: normalized correlation between image and its transpose (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 1.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    try:\n        t = a.T\n    except Exception:\n        return 0.0\n    if a.shape != t.shape:\n        # resize transpose to match original shape (fast, may repeat data)\n        t = np.resize(t, a.shape)\n    a_zero = a - a.mean()\n    t_zero = t - t.mean()\n    num = float((a_zero * t_zero).sum())\n    den = float(np.sqrt((a_zero ** 2).sum() * (t_zero ** 2).sum()) + eps)\n    corr = num / den\n    return float(np.clip(abs(corr), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between NW-SE and NE-SW diagonal gradient energy (positive -> NW-SE dominant)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # gradients\n    gy, gx = np.gradient(gray)\n    diag1 = gx + gy  # NW-SE\n    diag2 = gx - gy  # NE-SW\n    e1 = np.sum(np.abs(diag1))\n    e2 = np.sum(np.abs(diag2))\n    tot = e1 + e2 + 1e-6\n    return float((e1 - e2) / tot)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio in the 2D FFT (fraction of energy outside low-frequency disk)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute power spectrum\n    F = np.fft.fftshift(np.fft.fft2(a))\n    P = np.abs(F) ** 2\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    # low-frequency radius as 10% of diagonal\n    low_r = max(1.0, 0.1 * np.hypot(h, w))\n    low_mask = (r <= low_r)\n    total = P.sum() + eps\n    high = P[~low_mask].sum()\n    result = float(high / total)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant edge orientation as a fraction of 180deg (0..1) using gradient-weighted histogram'\n    import numpy as np\n    eps = 1e-12\n    bins = 8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= 0:\n        return 0.0\n    # orientation in [0,180)\n    ang = (np.degrees(np.arctan2(gy, gx)) + 180.0) % 180.0\n    # histogram\n    inds = np.floor(ang / (180.0 / bins)).astype(int)\n    inds = np.clip(inds, 0, bins - 1)\n    hist = np.zeros(bins, dtype=float)\n    for b in range(bins):\n        hist[b] = mag[inds == b].sum()\n    if hist.sum() <= 0:\n        return 0.0\n    dom = float(np.argmax(hist))\n    result = dom / float(bins - 1 + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of pixels above the 95th intensity percentile (highlight sparsity)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    thr = float(np.percentile(a, 95))\n    count = float((a > thr).sum())\n    result = count / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant edge orientation strength: fraction of edge magnitude falling into the most common orientation bin'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() == 0:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    # convert to 0..180 degrees (orientation ignoring sign)\n    ang_deg = np.degrees(np.abs(ang))\n    ang_deg = ang_deg % 180.0\n    bins = 8\n    hist, _ = np.histogram(ang_deg.ravel(), bins=bins, range=(0.0, 180.0), weights=mag.ravel())\n    total = hist.sum() + eps\n    dominant = hist.max()\n    result = float(dominant) / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of background holes that are centered in the lower half of the bounding box (float int)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    meanv = float(np.mean(gray))\n    if meanv > (mn + mx) / 2.0:\n        fg = (gray < meanv)\n    else:\n        fg = (gray > meanv)\n    fg = fg.astype(np.uint8)\n    coords = np.argwhere(fg)\n    if coords.size == 0:\n        return 0.0\n    r0, c0 = coords.min(axis=0)\n    r1, c1 = coords.max(axis=0)\n    sub = fg[r0:r1+1, c0:c1+1]\n    # background mask inside bbox\n    bg = (sub == 0).astype(np.uint8)\n    H, W = bg.shape\n    visited = np.zeros_like(bg, dtype=np.uint8)\n    holes_lower = 0\n    # 4-connectivity neighbors\n    for i in range(H):\n        for j in range(W):\n            if bg[i, j] and not visited[i, j]:\n                # flood fill\n                stack = [(i, j)]\n                visited[i, j] = 1\n                touches_border = False\n                sum_r = 0\n                count = 0\n                while stack:\n                    y, x = stack.pop()\n                    sum_r += y\n                    count += 1\n                    if y == 0 or x == 0 or y == H - 1 or x == W - 1:\n                        touches_border = True\n                    # neighbors\n                    if y > 0 and bg[y - 1, x] and not visited[y - 1, x]:\n                        visited[y - 1, x] = 1\n                        stack.append((y - 1, x))\n                    if y < H - 1 and bg[y + 1, x] and not visited[y + 1, x]:\n                        visited[y + 1, x] = 1\n                        stack.append((y + 1, x))\n                    if x > 0 and bg[y, x - 1] and not visited[y, x - 1]:\n                        visited[y, x - 1] = 1\n                        stack.append((y, x - 1))\n                    if x < W - 1 and bg[y, x + 1] and not visited[y, x + 1]:\n                        visited[y, x + 1] = 1\n                        stack.append((y, x + 1))\n                # if component does NOT touch bbox border -> it's a hole\n                if not touches_border and count > 0:\n                    centroid_r = float(sum_r) / float(count)\n                    # if centroid lies in lower half of the bbox region\n                    if centroid_r >= H / 2.0:\n                        holes_lower += 1\n    return float(holes_lower)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation concentration: fraction of gradient energy in the dominant orientation bin (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() == 0:\n        return 0.0\n    ang = np.arctan2(gy, gx)  # -pi..pi\n    nbins = 12\n    # map angles to [0, nbins)\n    bins = ((ang + np.pi) / (2 * np.pi) * nbins).astype(int) % nbins\n    energies = np.zeros(nbins, dtype=float)\n    for b in range(nbins):\n        energies[b] = mag[bins == b].sum()\n    max_frac = float(energies.max()) / (energies.sum() + 1e-12)\n    return float(np.clip(max_frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for grayscale), normalized by max intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    arr = np.nan_to_num(img.astype(float))\n    R = arr[:, :, 0]\n    G = arr[:, :, 1]\n    B = arr[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    raw = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    norm = float(np.nanmax(arr)) + eps\n    result = raw / norm\n    return float(np.clip(result, 0.0, 5.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-vs-ring brightness contrast: positive if center region is brighter than its surrounding ring (suggests a closed loop/hole)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 4 or w < 4:\n        return 0.0\n    # define center box and a slightly larger ring box\n    ch0, ch1 = h // 3, 2 * h // 3\n    cw0, cw1 = w // 3, 2 * w // 3\n    center = gray[ch0:ch1, cw0:cw1]\n    ring_outer = gray[h//4:3*h//4, w//4:3*w//4]\n    # ring region excluding center\n    if ring_outer.size == 0 or center.size == 0:\n        return 0.0\n    ring_mask = np.ones_like(ring_outer, dtype=bool)\n    inner_y0 = ch0 - (h//4)\n    inner_x0 = cw0 - (w//4)\n    inner_y1 = inner_y0 + center.shape[0]\n    inner_x1 = inner_x0 + center.shape[1]\n    # ensure indices safe\n    inner_y0 = max(0, inner_y0); inner_x0 = max(0, inner_x0)\n    inner_y1 = min(ring_outer.shape[0], inner_y1); inner_x1 = min(ring_outer.shape[1], inner_x1)\n    if inner_y1 > inner_y0 and inner_x1 > inner_x0:\n        ring_mask[inner_y0:inner_y1, inner_x0:inner_x1] = False\n    ring_pixels = ring_outer[ring_mask]\n    center_mean = float(np.mean(center)) if center.size > 0 else 0.0\n    ring_mean = float(np.mean(ring_pixels)) if ring_pixels.size > 0 else center_mean\n    overall = float(np.mean(gray)) + 1e-8\n    # positive when center is brighter (i.e., potential hole background inside ink)\n    return float((center_mean - ring_mean) / overall)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of ink \"endpoints\": ink pixels with only one ink neighbor (8-connected). Loops like 0/8 have few endpoints; open strokes like 5 have endpoints'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    if border_mean > np.median(gray):\n        thr = (border_mean + float(np.min(gray))) / 2.0\n        ink = (gray < thr).astype(np.uint8)\n    else:\n        thr = (border_mean + float(np.max(gray))) / 2.0\n        ink = (gray > thr).astype(np.uint8)\n    if np.sum(ink) == 0:\n        return 0.0\n    padded = np.pad(ink, pad_width=1, mode='constant', constant_values=0)\n    endpoints = 0\n    for r in range(1, h + 1):\n        row_slice = padded[r - 1:r + 2, :]\n        for c in range(1, w + 1):\n            if padded[r, c]:\n                neigh = row_slice[:, c - 1:c + 2].flatten()\n                neigh_count = int(np.sum(neigh)) - 1  # exclude center\n                if neigh_count == 1:\n                    endpoints += 1\n    return float(endpoints)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of vertical gradient energy located in the right half of the image (0..1)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # compute vertical gradient\n    gy, gx = np.gradient(gray)\n    energy = np.abs(gy)\n    left_energy = energy[:, :w // 2].sum()\n    right_energy = energy[:, w // 2:].sum()\n    total = left_energy + right_energy + 1e-9\n    return float(right_energy / total)\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio using local mean subtraction (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    # local 3x3 mean via roll (fast, periodic rolled edges but acceptable)\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    high = a - local_mean\n    hv = float(np.sum(np.abs(high)))\n    gv = float(np.sum(np.abs(a))) + eps\n    result = hv / gv\n    # clip to [0,1]\n    result = max(0.0, min(1.0, result))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ink perimeter (boundary pixels) divided by ink area (higher -> finer/thinner or more complex contours)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.mean(gray))\n    cand = gray < thr\n    if np.sum(cand) > gray.size / 2:\n        ink = ~cand\n    else:\n        ink = cand\n    ink = ink.astype(np.uint8)\n    # boundary pixels: ink pixel with at least one 4-neighbor background\n    neighbor_sum = np.zeros_like(ink, dtype=np.int32)\n    neighbor_sum[1:, :] += ink[:-1, :]\n    neighbor_sum[:-1, :] += ink[1:, :]\n    neighbor_sum[:, 1:] += ink[:, :-1]\n    neighbor_sum[:, :-1] += ink[:, 1:]\n    boundary = (ink == 1) & (neighbor_sum < 4)\n    perimeter = float(np.sum(boundary))\n    area = float(np.sum(ink))\n    if area <= 0.0:\n        return 0.0\n    return float(perimeter / area)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial decay correlation: negative Pearson correlation between ring mean intensity and radius (positive => brighter center)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    ys, xs = np.indices(a.shape)\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    R = np.hypot(xs - cx, ys - cy)\n    maxr = R.max()\n    if maxr <= 0:\n        return 0.0\n    nbins = min(12, max(2, int(maxr)))\n    bins = np.linspace(0.0, maxr + eps, nbins + 1)\n    idx = np.digitize(R.ravel(), bins) - 1\n    means = []\n    radii = []\n    for i in range(nbins):\n        mask = (idx == i)\n        if not np.any(mask):\n            continue\n        means.append(float(a.ravel()[mask].mean()))\n        radii.append(float((bins[i] + bins[i+1]) / 2.0))\n    means = np.array(means)\n    radii = np.array(radii)\n    if means.size < 2 or np.allclose(means, means[0]):\n        return 0.0\n    # correlation: positive when intensity increases with radius; we invert so positive => center brighter\n    try:\n        corr = np.corrcoef(radii, means)[0, 1]\n    except Exception:\n        corr = 0.0\n    result = float(-corr)\n    return float(np.clip(result, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation coherence (0..1), 1 = all gradients aligned'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    total_mag = float(mag.sum()) + eps\n    sx = float(gx.sum())\n    sy = float(gy.sum())\n    coherence = float(np.hypot(sx, sy) / (total_mag + eps))\n    return float(np.clip(coherence, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized mean absolute Laplacian (image sharpness) relative to intensity std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # discrete Laplacian: 4*center - neighbors\n    up = np.roll(a, 1, axis=0)\n    down = np.roll(a, -1, axis=0)\n    left = np.roll(a, 1, axis=1)\n    right = np.roll(a, -1, axis=1)\n    lap = (4.0 * a) - (up + down + left + right)\n    # zero out wrap-around artifacts by masking border\n    lap[0, :] = lap[0, :] * 1.0\n    lap[-1, :] = lap[-1, :] * 1.0\n    lap[:, 0] = lap[:, 0] * 1.0\n    lap[:, -1] = lap[:, -1] * 1.0\n    mad = float(np.mean(np.abs(lap)))\n    denom = float(np.std(a)) + eps\n    result = mad / denom\n    # clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between ink density in the right half and left half (positive = more ink on right)'\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    # robust binarization: assume ink is darker than background\n    med = np.median(gray)\n    bw = gray < med\n    if np.count_nonzero(bw) == 0:\n        bw = gray > med\n    left = np.count_nonzero(bw[:, :w//2])\n    right = np.count_nonzero(bw[:, w//2:])\n    total = left + right\n    if total == 0:\n        return 0.0\n    return float((right - left) / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in a central square region (middle half) to indicate center occlusion vs hole'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.mean(gray))\n    cand = gray < thr\n    if np.sum(cand) > gray.size / 2:\n        ink = ~cand\n    else:\n        ink = cand\n    ink = ink.astype(bool)\n    ch0, ch1 = h // 4, 3 * h // 4\n    cw0, cw1 = w // 4, 3 * w // 4\n    # ensure indices valid\n    ch0 = max(0, min(h, ch0)); ch1 = max(0, min(h, ch1))\n    cw0 = max(0, min(w, cw0)); cw1 = max(0, min(w, cw1))\n    center_region = ink[ch0:ch1, cw0:cw1]\n    center_ink = float(np.sum(center_region))\n    total_ink = float(np.sum(ink))\n    if total_ink <= 0.0:\n        return 0.0\n    return float(center_ink / total_ink)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy fraction: ratio of local high-pass energy to total energy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    # local 3x3 mean via rolling sum (fast, no convolution)\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    highpass = a - local_mean\n    hf_energy = float(np.sum(np.abs(highpass)))\n    total_energy = float(np.sum(np.abs(a - a.mean()))) + eps\n    result = hf_energy / total_energy\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    vals = arr.ravel()\n    if vals.size == 0:\n        return 0.0\n    # use fixed number of bins\n    bins = 32\n    hist, _ = np.histogram(vals, bins=bins, range=(vals.min(), vals.max()), density=False)\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0]\n    ent = -np.sum(p * np.log(p + eps))\n    # normalize by log(bins)\n    norm = ent / (np.log(bins) + eps)\n    return float(np.clip(norm, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Signed vertical offset between ink centroid and background-inside-bbox centroid (normalized by height)'\n    import numpy as np\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        if h == 0 or w == 0:\n            return 0.0\n        thresh = (np.min(gray) + np.max(gray)) / 2.0\n        ink_candidate = gray < thresh\n        ink_mask = ink_candidate if np.sum(ink_candidate) <= (h*w/2) else ~ink_candidate\n        if not np.any(ink_mask):\n            return 0.0\n        ys, xs = np.nonzero(ink_mask)\n        y_mean_ink = float(np.mean(ys))\n        x_min, x_max = np.min(xs), np.max(xs)\n        y_min, y_max = np.min(ys), np.max(ys)\n        # bounding box\n        bb = (slice(y_min, y_max+1), slice(x_min, x_max+1))\n        inner_bg = ~ink_mask[bb]\n        if not np.any(inner_bg):\n            return 0.0\n        bys, bxs = np.nonzero(inner_bg)\n        y_mean_hole = float(np.mean(bys)) + y_min\n        # signed: positive means ink centroid below hole centroid\n        return float((y_mean_ink - y_mean_hole) / float(h))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency energy fraction from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # zero-mean to focus on structural energy\n    a0 = a - a.mean()\n    # compute power spectrum\n    F = np.fft.fft2(a0)\n    P = np.abs(F) ** 2\n    Psum = float(P.sum()) + eps\n    # select central low-frequency square after fftshift\n    Pshift = np.fft.fftshift(P)\n    ch = max(1, int(max(1, round(0.1 * h))))\n    cw = max(1, int(max(1, round(0.1 * w))))\n    cy = h // 2\n    cx = w // 2\n    ly = slice(max(0, cy - ch), min(h, cy + ch + 1))\n    lx = slice(max(0, cx - cw), min(w, cx + cw + 1))\n    low_power = float(Pshift[ly, lx].sum())\n    frac = low_power / Psum\n    return float(np.clip(frac, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for non-RGB)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # use first three channels as R,G,B\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    result = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box compactness: (bbox area) / (region pixel count) for pixels > mean (>=1), 0 if none'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    thr = float(np.mean(a))\n    mask = a > thr\n    region_area = int(np.count_nonzero(mask))\n    if region_area == 0:\n        return 0.0\n    rows = np.where(mask.any(axis=1))[0]\n    cols = np.where(mask.any(axis=0))[0]\n    if rows.size == 0 or cols.size == 0:\n        return 0.0\n    h_bb = rows[-1] - rows[0] + 1\n    w_bb = cols[-1] - cols[0] + 1\n    bbox_area = float(h_bb * w_bb)\n    compactness = bbox_area / (float(region_area) + eps)\n    return float(np.clip(compactness, 1.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels classified as edges by local gradient (75th percentile threshold)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total = mag.size\n    if total == 0:\n        return 0.0\n    thr = float(np.percentile(mag.ravel(), 75))\n    cnt = int(np.count_nonzero(mag > thr))\n    result = float(cnt) / float(total + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative brightness concentration in a central circle (positive => center brighter)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    y = np.arange(h)[:, None]\n    x = np.arange(w)[None, :]\n    r = max(1.0, min(h, w) / 4.0)\n    mask = ((y - cy) ** 2 + (x - cx) ** 2) <= (r ** 2)\n    center = a[mask]\n    overall_mean = float(a.mean())\n    if center.size == 0:\n        return 0.0\n    center_mean = float(center.mean())\n    gstd = float(a.std()) + eps\n    result = (center_mean - overall_mean) / gstd\n    return float(np.clip(result, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Top horizontal stroke strength: difference between top-row ink density and center density'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    low_mean = np.mean(gray[gray <= p10]) if np.any(gray <= p10) else p10\n    high_mean = np.mean(gray[gray >= p90]) if np.any(gray >= p90) else p90\n    ink_dark = low_mean < high_mean\n    thr = np.percentile(gray, 50)\n    fg = (gray <= thr) if ink_dark else (gray >= thr)\n    top_h = max(1, h // 8)\n    top_density = np.mean(fg[:top_h, :]) if top_h > 0 else 0.0\n    ch = max(1, h // 4)\n    cw = max(1, w // 4)\n    center_density = np.mean(fg[h//2 - ch//2:h//2 + ch//2, w//2 - cw//2:w//2 + cw//2])\n    return float(top_density - center_density)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border noise ratio: border std divided by global mean intensity'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    bw = max(1, min(h, w) // 10)\n    top = a[:bw, :].ravel()\n    bot = a[-bw:, :].ravel()\n    left = a[:, :bw].ravel()\n    right = a[:, -bw:].ravel()\n    border = np.concatenate([top, bot, left, right])\n    if border.size == 0:\n        return 0.0\n    bstd = float(border.std())\n    mean_global = float(a.mean()) + eps\n    result = float(bstd / mean_global)\n    # clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of high-gradient pixels: proportion of pixels with gradient magnitude > mean+std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    count = float((mag > thr).sum())\n    total = float(mag.size) + eps\n    result = count / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box area fraction of very bright pixels (>95th percentile)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    flat = np.ravel(arr)\n    if flat.size == 0:\n        return 0.0\n    thresh = float(np.percentile(flat, 95))\n    mask = arr > thresh\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    h, w = arr.shape\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    bbox_area = (y1 - y0 + 1) * (x1 - x0 + 1)\n    frac = bbox_area / float(h * w)\n    return float(frac)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Right-to-left ink density ratio (sum of ink on right half divided by left half, >1 means more ink on right)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.count_nonzero(ink) > 0.9 * h * w:\n        ink = gray > thr\n    left_sum = float(np.count_nonzero(ink[:, :w//2]))\n    right_sum = float(np.count_nonzero(ink[:, w//2:]))\n    if left_sum + right_sum == 0:\n        return 1.0\n    ratio = right_sum / (left_sum + 1e-8)\n    return float(ratio)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of total intensity located in outer border band (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    bw = max(1, min(h, w) // 8)\n    top = a[:bw, :]\n    bottom = a[-bw:, :]\n    left = a[:, :bw]\n    right = a[:, -bw:]\n    border = np.concatenate([top.ravel(), bottom.ravel(), left.ravel(), right.ravel()])\n    total = float(a.sum()) + eps\n    border_sum = float(border.sum())\n    result = border_sum / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels much brighter than the image average (bright-spot coverage)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    m = float(np.mean(arr))\n    s = float(np.std(arr)) + eps\n    thr = m + s\n    count = float(np.count_nonzero(arr > thr))\n    result = count / float(arr.size)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized standard deviation of distances from centroid (radial spread normalized by half-min-dim)'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    thr = np.percentile(gray, 40)\n    ink = gray <= thr\n    if np.count_nonzero(ink) == 0:\n        thr = np.percentile(gray, 60); ink = gray <= thr\n    ys, xs = np.where(ink)\n    if xs.size == 0:\n        return 0.0\n    h, w = gray.shape[:2]\n    cx = xs.mean(); cy = ys.mean()\n    dx = (xs - cx) / (min(h, w) / 2.0 + 1e-6)\n    dy = (ys - cy) / (min(h, w) / 2.0 + 1e-6)\n    d = np.sqrt(dx * dx + dy * dy)\n    return float(np.std(d))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local variance (3x3) normalized by global variance (texture energy)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    pad = np.pad(a, 1, mode='reflect')\n    s = np.zeros_like(a, dtype=float)\n    s2 = np.zeros_like(a, dtype=float)\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            patch = pad[1 + dy:1 + dy + h, 1 + dx:1 + dx + w]\n            s += patch\n            s2 += patch * patch\n    mean_local = s / 9.0\n    mean_sq_local = s2 / 9.0\n    var_local = mean_sq_local - mean_local * mean_local\n    energy = float(np.mean(var_local))\n    global_var = float(a.var()) + eps\n    result = energy / global_var\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right brightness bias normalized by global std (positive => left brighter)'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left_mean = float(np.mean(arr[:, :mid])) if arr[:, :mid].size else 0.0\n    right_mean = float(np.mean(arr[:, -mid:])) if arr[:, -mid:].size else 0.0\n    gstd = float(arr.std()) + eps\n    result = (left_mean - right_mean) / gstd\n    return float(np.clip(result, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Lower-right vs upper-right ink density ratio (helps detect lower loop on right side)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    low_mean = np.mean(gray[gray <= p10]) if np.any(gray <= p10) else p10\n    high_mean = np.mean(gray[gray >= p90]) if np.any(gray >= p90) else p90\n    ink_dark = low_mean < high_mean\n    thr = np.percentile(gray, 50)\n    fg = (gray <= thr) if ink_dark else (gray >= thr)\n    mid_col = w // 2\n    mid_row = h // 2\n    upper_right = fg[:mid_row, mid_col:]\n    lower_right = fg[mid_row:, mid_col:]\n    ur = float(np.count_nonzero(upper_right))\n    lr = float(np.count_nonzero(lower_right))\n    denom = ur + 1e-6\n    return float(lr / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of significant horizontal-edge peaks across rows (useful to detect two-curved 3 vs single bars)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy = np.gradient(gray, axis=0)  # response to horizontal edges\n    row_strength = np.mean(np.abs(gy), axis=1)\n    # smooth with simple 3-point moving average\n    kernel = np.array([1., 1., 1.]) / 3.0\n    padded = np.r_[row_strength[0], row_strength, row_strength[-1]]\n    smooth = np.convolve(padded, kernel, mode='valid')\n    mean = smooth.mean()\n    std = smooth.std()\n    # peak threshold\n    thresh = mean + 0.5 * std\n    peaks = np.where(smooth > thresh)[0]\n    # compress counts by grouping neighboring indices as a single peak\n    if peaks.size == 0:\n        return 0.0\n    groups = 1 + np.sum(np.diff(peaks) > 1)\n    return float(groups)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal (main) symmetry score: mean absolute difference between center square and its transpose (0=perfect)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    s = min(h, w)\n    if s == 0:\n        return 0.0\n    r0 = (h - s) // 2\n    c0 = (w - s) // 2\n    square = gray[r0:r0+s, c0:c0+s]\n    # normalize by dynamic range\n    rng = float(np.max(square) - np.min(square))\n    if rng == 0:\n        return 0.0\n    diff = np.abs(square - square.T)\n    score = float(np.mean(diff) / rng)\n    return score\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for grayscale)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    # use first three channels as R,G,B\n    R = np.nan_to_num(arr[:, :, 0].astype(float))\n    G = np.nan_to_num(arr[:, :, 1].astype(float))\n    B = np.nan_to_num(arr[:, :, 2].astype(float))\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(np.abs(rg.mean()))\n    mean_yb = float(np.abs(yb.mean()))\n    # Hasler & Suesstrunk metric\n    score = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in top-right quadrant to bottom-left quadrant (helps detect 7-like top-right strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    minv = float(np.min(gray))\n    meanv = float(np.mean(gray))\n    if meanv == minv:\n        return 0.0\n    thresh = (minv + meanv) / 2.0\n    ink = (gray < thresh) if meanv > minv else (gray > thresh)\n    tr = np.sum(ink[0:h//2, w//2:w])\n    bl = np.sum(ink[h//2:h, 0:w//2])\n    return float((tr + 1e-6) / (bl + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest continuous horizontal ink run in the top quarter of the image, normalized by width'\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx > mn:\n        gray = (gray - mn) / (mx - mn)\n    else:\n        gray = gray * 0.0\n    thr = np.percentile(gray, 50.0)\n    ink = (gray < thr).astype(np.uint8)\n    if np.sum(ink) == 0:\n        ink = (gray > thr).astype(np.uint8)\n        if np.sum(ink) == 0:\n            return 0.0\n    top_band = ink[:max(1, h // 4), :]\n    max_run = 0\n    # For each row compute longest consecutive ones\n    for row in top_band:\n        # compute run lengths by diff trick\n        padded = np.concatenate(([0], row, [0]))\n        changes = np.diff(padded)\n        starts = np.nonzero(changes == 1)[0]\n        ends = np.nonzero(changes == -1)[0]\n        if starts.size and ends.size:\n            runs = ends - starts\n            max_run = max(int(np.max(runs)), max_run)\n    return float(max_run / max(1, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Strength of a middle horizontal bar: mean absolute horizontal gradient in central band normalized by overall gradient'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3:\n        return 0.0\n    gx, gy = np.gradient(gray)\n    abs_gx = np.abs(gx)\n    # central band - middle 20% of rows\n    start = max(0, h//2 - max(1, h//10))\n    end = min(h, h//2 + max(1, h//10))\n    band_mean = float(np.mean(abs_gx[start:end, :]))\n    total_mean = float(np.mean(abs_gx) + 1e-9)\n    return band_mean / total_mean\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest run of consecutive ink pixels along the central row normalized by image width (captures long horizontal bars)'\n    import numpy as np\n    h, w = image.shape[:2]\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    scaled = (gray - mn) / (mx - mn + 1e-9)\n    ink = (scaled < 0.5)\n    row = ink[h//2] if h > 0 else np.zeros(w, dtype=bool)\n    # find longest consecutive True run\n    if row.size == 0:\n        return 0.0\n    max_run = 0\n    cur = 0\n    for v in row:\n        if v:\n            cur += 1\n            if cur > max_run:\n                max_run = cur\n        else:\n            cur = 0\n    return float(max_run / max(1, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean log-gradient magnitude normalized by max log-gradient (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    g = np.hypot(gx, gy)\n    if g.size == 0:\n        return 0.0\n    logg = np.log1p(g)\n    maxlog = logg.max()\n    if maxlog <= eps:\n        return 0.0\n    meanlog = float(logg.mean())\n    result = meanlog / (maxlog + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Average row-wise edge complexity (normalized sign-change rate)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2 or h == 0:\n        return 0.0\n    diffs = np.abs(np.diff(a, axis=1))\n    # baseline threshold: median of diffs\n    med = float(np.median(diffs)) + eps\n    edge_bool = diffs > (med * 0.5)  # detect significant changes\n    # count transitions per row normalized by possible transitions\n    per_row = edge_bool.sum(axis=1) / float(max(1, edge_bool.shape[1]))\n    result = float(per_row.mean())\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average intensity of the central horizontal band (middle 20% of rows) normalized by overall mean \u2014 captures middle bar like in 5'\n    import numpy as np\n    eps = 1e-6\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    start = max(0, int(h * 0.4))\n    end = min(h, int(h * 0.6) + 1)\n    band = gray[start:end, :]\n    if band.size == 0:\n        return 0.0\n    return float((np.mean(band) + eps) / (np.mean(gray) + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical gradient energy in the right third (indicates strong vertical strokes on right side)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gy = np.abs(np.gradient(gray, axis=0))\n    total = gy.sum() + 1e-9\n    right = gy[:, max(0, w - w//3):].sum()\n    return float(right / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local 3x3 variance normalized by global variance (>=0)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        # fallback to global variance ratio (0 when flat)\n        glob_var = float(a.var()) + eps\n        return float(np.clip(glob_var / (glob_var + eps), 0.0, 1e6))\n    pad = np.pad(a, 1, mode='reflect')\n    s = np.zeros_like(a, dtype=float)\n    ss = np.zeros_like(a, dtype=float)\n    for dy in (0, 1, 2):\n        for dx in (0, 1, 2):\n            window = pad[dy:dy + h, dx:dx + w]\n            s += window\n            ss += window * window\n    mean_local = s / 9.0\n    mean_sq_local = ss / 9.0\n    var_local = mean_sq_local - mean_local * mean_local\n    avg_var = float(np.mean(var_local))\n    glob_var = float(a.var()) + eps\n    result = avg_var / (glob_var + eps)\n    return float(max(0.0, result))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Correlation between a square patch and its transpose as a main-diagonal symmetry score (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    m = min(h, w)\n    if m < 2:\n        return 0.0\n    # use top-left m x m square for a consistent region\n    sq = a[:m, :m]\n    sqT = sq.T\n    L = sq.ravel() - sq.mean()\n    R = sqT.ravel() - sqT.mean()\n    denom = (np.linalg.norm(L) * np.linalg.norm(R) + eps)\n    corr = float(np.dot(L, R) / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (Hasler-Suesstrunk style); returns 0 for grayscale'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    R = a[:, :, 0]\n    G = a[:, :, 1]\n    B = a[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    return float(max(0.0, colorfulness))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Percentile contrast: (90th-10th) divided by median intensity'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    p90 = float(np.percentile(a, 90))\n    p10 = float(np.percentile(a, 10))\n    med = float(np.percentile(a, 50)) + eps\n    result = (p90 - p10) / med\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Upper-left ink density: ink fraction contained in the upper-left quadrant'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        thr = np.percentile(gray, 85)\n        ink = (gray < thr).astype(np.uint8)\n        total = float(np.sum(ink))\n        if total <= 0:\n            return 0.0\n        ul = float(np.sum(ink[:h//2, :w//2]))\n        return ul / (total + 1e-12)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean normalized distance of bright pixels to image center (0..1, smaller=closer)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    mean = float(a.mean())\n    std = float(a.std())\n    thr = mean + 0.5 * std\n    mask = a > thr\n    if not mask.any():\n        # fallback to top 10% brightest pixels\n        flat = a.ravel()\n        k = max(1, int(0.1 * flat.size))\n        thr = float(np.partition(flat, -k)[-k])\n        mask = a >= thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    d = np.hypot(ys - cy, xs - cx)\n    maxd = np.hypot(cy, cx) + 1e-12\n    result = float(d.mean() / maxd)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity elongation: anisotropy of intensity distribution (0..1, higher => more elongated)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    flat = a.ravel()\n    if flat.sum() == 0:\n        return 0.0\n    # coordinates\n    ys, xs = np.indices(a.shape)\n    weight = flat.reshape(a.shape)\n    total = float(weight.sum()) + eps\n    cx = float((weight * xs).sum()) / total\n    cy = float((weight * ys).sum()) / total\n    dx = (xs - cx).ravel()\n    dy = (ys - cy).ravel()\n    wv = weight.ravel()\n    cov_xx = float((wv * (dx * dx)).sum()) / total\n    cov_yy = float((wv * (dy * dy)).sum()) / total\n    cov_xy = float((wv * (dx * dy)).sum()) / total\n    # covariance matrix eigenvalues\n    tr = cov_xx + cov_yy\n    det = cov_xx * cov_yy - cov_xy * cov_xy\n    tmp = np.sqrt(max(0.0, (tr * tr) / 4.0 - det))\n    l1 = max(0.0, tr / 2.0 + tmp)\n    l2 = max(0.0, tr / 2.0 - tmp)\n    # anisotropy: 1 - (l2 / l1) (clamped), if l1 ~ 0 then 0\n    if l1 < eps:\n        return 0.0\n    anis = 1.0 - (l2 / (l1 + eps))\n    return float(np.clip(anis, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the right-middle region (rows h/4..3h/4, cols w/2..w)'\n    # Robust grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float32)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    p40 = np.percentile(gray.flatten(), 40)\n    p60 = np.percentile(gray.flatten(), 60)\n    mask = gray <= p40\n    total = mask.sum()\n    if total == 0 or total > 0.9 * h * w:\n        mask = gray >= p60\n        total = mask.sum()\n    if total == 0:\n        # fallback: threshold by mean\n        mask = gray <= np.mean(gray)\n        total = mask.sum()\n        if total == 0:\n            return 0.0\n    r0, r1 = h // 4, 3 * h // 4\n    c0, c1 = w // 2, w\n    right_mid = mask[r0:r1, c0:c1]\n    right_mid_count = int(np.count_nonzero(right_mid))\n    return float(right_mid_count) / float(total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Topmost ink row normalized by image height (min row index of ink / height)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    mn, mx = float(gray.min()), float(gray.max())\n    if mx == mn:\n        return 0.0\n    grayn = (gray - mn) / (mx - mn)\n    thr = (grayn.mean() + np.median(grayn)) / 2.0\n    ink = ((grayn > thr) if np.sum(grayn > thr) < np.sum(grayn < thr) else (grayn < thr)).astype(np.uint8)\n    ys, _ = np.where(ink)\n    if ys.size == 0:\n        return 0.0\n    top = ys.min()\n    h = ink.shape[0]\n    return float(top) / float(h)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of medium-large bright blobs normalized (0..1), capped at 1.0'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = img.mean() + 0.5 * img.std()\n    mask = img > thr\n    if not mask.any():\n        return 0.0\n    visited = np.zeros(mask.shape, dtype=bool)\n    min_area = max(1, int(h * w * 0.005))  # ~0.5% of image\n    max_area = max(1, int(h * w * 0.5))    # avoid counting almost-full\n    count = 0\n    # simple flood fill\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                stack = [(y, x)]\n                visited[y, x] = True\n                area = 0\n                while stack:\n                    cy, cx = stack.pop()\n                    area += 1\n                    if cy > 0 and mask[cy-1, cx] and not visited[cy-1, cx]:\n                        visited[cy-1, cx] = True; stack.append((cy-1, cx))\n                    if cy+1 < h and mask[cy+1, cx] and not visited[cy+1, cx]:\n                        visited[cy+1, cx] = True; stack.append((cy+1, cx))\n                    if cx > 0 and mask[cy, cx-1] and not visited[cy, cx-1]:\n                        visited[cy, cx-1] = True; stack.append((cy, cx-1))\n                    if cx+1 < w and mask[cy, cx+1] and not visited[cy, cx+1]:\n                        visited[cy, cx+1] = True; stack.append((cy, cx+1))\n                if area >= min_area and area <= max_area:\n                    count += 1\n                # early stop if many\n                if count >= 20:\n                    break\n        if count >= 20:\n            break\n    result = float(min(count, 20) / 20.0)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Kurtosis of column-sum intensities (higher -> sharper vertical concentration)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    cols = img.sum(axis=0)\n    if cols.size == 0:\n        return 0.0\n    m = float(cols.mean())\n    s = float(cols.std()) + eps\n    kurt = float(np.mean(((cols - m) ** 4))) / (s ** 4 + eps)\n    # convert to excess kurtosis (0 for normal) for interpretability\n    excess = kurt - 3.0\n    # clamp to a reasonable range\n    return float(np.clip(excess, -50.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of connected ink components (large separate blobs) \u2014 some handwritten digits split into multiple disconnected strokes'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    visited = np.zeros_like(ink, dtype=bool)\n    from collections import deque\n    comp_count = 0\n    min_size = max(3, (h*w)//200)  # ignore tiny artifacts\n    for i in range(h):\n        for j in range(w):\n            if ink[i, j] and not visited[i, j]:\n                size = 0\n                q = deque([(i, j)])\n                visited[i, j] = True\n                while q:\n                    ci, cj = q.popleft()\n                    size += 1\n                    for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ni, nj = ci+di, cj+dj\n                        if 0 <= ni < h and 0 <= nj < w and ink[ni, nj] and not visited[ni, nj]:\n                            visited[ni, nj] = True\n                            q.append((ni, nj))\n                if size >= min_size:\n                    comp_count += 1\n    return float(comp_count)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of border pixels darker than the image median (border width 5% min 1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    bw = max(1, int(round(0.05 * min(h, w))))\n    mask = np.zeros_like(arr, dtype=bool)\n    mask[:bw, :] = True\n    mask[-bw:, :] = True\n    mask[:, :bw] = True\n    mask[:, -bw:] = True\n    border = arr[mask]\n    if border.size == 0:\n        return 0.0\n    med = float(np.median(arr))\n    frac = float(np.count_nonzero(border < med)) / float(border.size)\n    return float(frac)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted eccentricity (1=elongated, 0=circular) from second moments'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    yy, xx = np.indices((h, w))\n    total = float(a.sum())\n    if total <= 0:\n        return 0.0\n    cx = (a * xx).sum() / total\n    cy = (a * yy).sum() / total\n    x = xx - cx\n    y = yy - cy\n    # covariance entries\n    mu_xx = float((a * (x * x)).sum() / total)\n    mu_yy = float((a * (y * y)).sum() / total)\n    mu_xy = float((a * (x * y)).sum() / total)\n    # eigenvalues of covariance\n    trace = mu_xx + mu_yy\n    det = mu_xx * mu_yy - mu_xy * mu_xy\n    discr = max(trace * trace / 4.0 - det, 0.0)\n    eig1 = trace / 2.0 + np.sqrt(discr)\n    eig2 = trace / 2.0 - np.sqrt(discr)\n    if eig1 <= eps:\n        return 0.0\n    ecc = 1.0 - (eig2 / (eig1 + eps))\n    result = float(np.clip(ecc, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of edge orientations weighted by gradient magnitude (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    total_mag = float(mag.sum())\n    if total_mag <= 0.0:\n        return 0.0\n    theta = np.arctan2(gy, gx).ravel()\n    weights = mag.ravel()\n    bins = 36\n    hist, _ = np.histogram(theta, bins=bins, range=(-np.pi, np.pi), weights=weights)\n    p = hist / (hist.sum() + 1e-12)\n    p = p[p > 0.0]\n    entropy = -np.sum(p * np.log2(p))\n    max_entropy = np.log2(bins) if bins > 1 else 1.0\n    result = float(np.clip(entropy / max_entropy, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial profile variance: normalized variance of mean intensities over concentric rings (0..inf)'\n    import numpy as np\n    eps = 1e-12\n    rings = 6\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    dist = np.hypot(ys - cy, xs - cx)\n    maxd = float(dist.max()) + eps\n    # assign to ring indices 0..rings-1\n    idx = np.floor((dist / maxd) * rings).astype(int)\n    idx = np.clip(idx, 0, rings - 1)\n    means = []\n    for k in range(rings):\n        sel = (idx == k)\n        if np.any(sel):\n            means.append(float(a[sel].mean()))\n        else:\n            means.append(0.0)\n    means = np.array(means, dtype=float)\n    if not np.isfinite(means).any():\n        return 0.0\n    var = float(means.var())\n    norm = float(np.mean(means) + eps)\n    result = var / norm\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of negative-slope diagonal gradient energy to positive-slope diagonal gradient energy (high for strokes sloping down-left like in many 7s)'\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    # diag1 approximates gradient along top-right -> bottom-left (negative slope)\n    diag1 = gray[:-1, 1:] - gray[1:, :-1]\n    # diag2 approximates gradient along top-left -> bottom-right (positive slope)\n    diag2 = gray[:-1, :-1] - gray[1:, 1:]\n    e1 = float(np.sum(np.abs(diag1)))\n    e2 = float(np.sum(np.abs(diag2)))\n    eps = 1e-8\n    return e1 / (e2 + eps)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientations (0..1), higher = many directions'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    theta = np.arctan2(gy, gx).ravel()  # -pi..pi\n    bins = 36\n    hist, _ = np.histogram(theta, bins=bins, range=(-np.pi, np.pi), density=True)\n    prob = hist.clip(min=0.0)\n    prob_sum = prob.sum()\n    if prob_sum <= 0:\n        return 0.0\n    prob = prob / (prob_sum + eps)\n    ent = -np.sum(np.where(prob > 0, prob * np.log(prob), 0.0))\n    result = float(ent / (np.log(bins) + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute corner contrast: average absolute difference between corners and global mean, normalized'\n    import numpy as np\n    eps = 1e-12\n    COR = 0.1  # fraction of min dimension for corner patch size\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    bw = max(1, int(min(h, w) * COR))\n    patches = []\n    patches.append(img[:bw, :bw])         # top-left\n    patches.append(img[:bw, -bw:])        # top-right\n    patches.append(img[-bw:, :bw])        # bottom-left\n    patches.append(img[-bw:, -bw:])       # bottom-right\n    global_mean = float(img.mean())\n    diffs = [abs(p.mean() - global_mean) for p in patches if p.size]\n    if len(diffs) == 0:\n        return 0.0\n    avg_diff = float(np.mean(diffs))\n    overall_std = float(np.std(img)) + eps\n    result = avg_diff / overall_std\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal edge strength in the bottom quarter compared to full image (captures bottom bars)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.array(image, dtype=float)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray.astype(float))\n    horiz_edge = np.abs(gx)\n    bottom_start = max(0, (3*h)//4)\n    bottom = horiz_edge[bottom_start:, :]\n    bottom_mean = float(np.mean(bottom)) if bottom.size > 0 else 0.0\n    full_mean = float(np.mean(horiz_edge)) if horiz_edge.size > 0 else 1.0\n    return float(bottom_mean / (full_mean + 1e-12))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized top margin: row index of first ink pixel divided by image height (0 top, 1 bottom)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0:\n        return 0.0\n    gm = np.mean(gray)\n    corner = np.mean(gray[:max(1,h//10), :max(1,w//10)])\n    ink = gray < gm if corner > gm else gray > gm\n    ink = np.asarray(ink, dtype=bool)\n    ys = np.nonzero(ink)[0]\n    if ys.size == 0:\n        return 1.0\n    top_row = int(np.min(ys))\n    return float(top_row / max(1, h-1))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strong Laplacian responses: proportion of pixels with abs(laplacian) > mean+std (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) + np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    lap_abs = np.abs(lap)\n    thr = float(lap_abs.mean() + lap_abs.std())\n    count = int(np.count_nonzero(lap_abs > thr))\n    result = float(count) / float(lap_abs.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bias of extreme saturation: high_frac - low_frac in normalized intensity range (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    mn = float(a.min()); mx = float(a.max())\n    if mx <= mn + eps:\n        return 0.0\n    rng = mx - mn\n    low_thr = mn + 0.05 * rng\n    high_thr = mx - 0.05 * rng\n    low_frac = float(np.count_nonzero(a <= low_thr)) / (a.size + eps)\n    high_frac = float(np.count_nonzero(a >= high_thr)) / (a.size + eps)\n    result = high_frac - low_frac\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Concentration of edge orientations (0..1), 1 if all gradient vectors align'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    tot = mag.sum()\n    if tot <= eps:\n        return 0.0\n    ux = gx / (mag + eps)\n    uy = gy / (mag + eps)\n    sx = (ux * mag).sum()\n    sy = (uy * mag).sum()\n    resultant = np.hypot(sx, sy)\n    result = resultant / (tot + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity correlation: how intensity correlates with distance from center (-1..1, positive => intensity increases outward)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    yy = np.arange(h) - (h - 1) / 2.0\n    xx = np.arange(w) - (w - 1) / 2.0\n    ry = yy[:, None] ** 2\n    rx = xx[None, :] ** 2\n    dist = np.sqrt(ry + rx)\n    d = dist.ravel()\n    v = img.ravel()\n    if d.size == 0 or v.size == 0:\n        return 0.0\n    d = (d - d.mean()) / (d.std() + eps)\n    v = (v - v.mean()) / (v.std() + eps)\n    corr = float(np.sum(d * v) / (float(d.size) + eps))\n    # corr in roughly [-1,1], clamp\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized top-most ink row (min_row / height), lower values mean ink starts near top'\n    import numpy as np\n    if image is None:\n        return 1.0\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    if h == 0:\n        return 1.0\n    m = np.mean(gray)\n    dark_count = np.sum(gray < m)\n    bright_count = gray.size - dark_count\n    ink = (gray < m) if dark_count <= bright_count else (gray > m)\n    ys, _ = np.nonzero(ink)\n    if ys.size == 0:\n        return 1.0\n    minr = ys.min()\n    return float(minr) / float(max(1, h - 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal-edge energy concentrated in the top 20% rows (higher if a top bar exists)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    mag = np.hypot(gx, gy)\n    # angle in degrees (-180..180)\n    ang = np.degrees(np.arctan2(gy, gx))\n    # horizontal-edge means edge normal vertical -> angle near 90 or -90? We target edges that run horizontally,\n    # i.e., gradient pointing up or down (angle around 90/-90). But we want edges corresponding to horizontal strokes,\n    # so detect angles near +/-90 degrees (abs(abs(angle)-90) small). We'll call these horizontal-edge responses.\n    horiz_mask = (np.abs(np.abs(ang) - 90) <= 25)\n    top_h = max(1, h // 5)\n    top_mask = np.zeros_like(horiz_mask, dtype=bool)\n    top_mask[:top_h, :] = True\n    horiz_total = mag[horiz_mask].sum()\n    if horiz_total <= 0:\n        return 0.0\n    top_horiz = mag[np.logical_and(horiz_mask, top_mask)].sum()\n    return float(top_horiz / horiz_total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score (1.0 = perfectly symmetric, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 1.0\n    left = a[:, :w//2]\n    right = a[:, w - (w//2):][:, ::-1]\n    # match sizes\n    minw = min(left.shape[1], right.shape[1])\n    left = left[:, :minw]\n    right = right[:, :minw]\n    denom = float(np.mean(np.abs(a)) + a.std() + eps)\n    diff = float(np.mean(np.abs(left - right)))\n    score = 1.0 - (diff / denom)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal vs vertical edge energy in the top half of the image (hor / (ver + eps))'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    top = gray[0:h//2, :]\n    # gradients (axis 0 -> vertical change, axis 1 -> horizontal change)\n    gy, gx = np.gradient(top)\n    hor_energy = np.sum(np.abs(gx))\n    ver_energy = np.sum(np.abs(gy))\n    eps = 1e-6\n    return float(hor_energy / (ver_energy + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal gradient bias: (NE-SW - NW-SE) / (total diagonal energy)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute two diagonal differences\n    if gray.shape[0] < 2 or gray.shape[1] < 2:\n        return 0.0\n    d_ne_sw = np.abs(gray[:-1, :-1] - gray[1:, 1:]).sum()\n    d_nw_se = np.abs(gray[1:, :-1] - gray[:-1, 1:]).sum()\n    total = d_ne_sw + d_nw_se + 1e-8\n    return float((d_ne_sw - d_nw_se) / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center vs border contrast normalized by global std'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape if a.ndim == 2 else (0, 0)\n    if h == 0 or w == 0:\n        return 0.0\n    ch0, cw0 = h // 4, w // 4\n    center = a[ch0:3*ch0 or h, cw0:3*cw0 or w]\n    # border as rim of width at least 1\n    rim = max(1, min(h, w) // 10)\n    top = a[:rim, :]\n    bottom = a[-rim:, :]\n    left = a[rim:-rim if rim < h else None, :rim]\n    right = a[rim:-rim if rim < h else None, -rim:]\n    border_stack = [m for m in (top, bottom, left, right) if m.size]\n    if not border_stack or center.size == 0:\n        return 0.0\n    border = np.concatenate([m.ravel() for m in border_stack])\n    mean_center = float(np.mean(center))\n    mean_border = float(np.mean(border))\n    overall_std = float(np.std(a)) + eps\n    result = (mean_center - mean_border) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average vertical gradient magnitude in the central horizontal band (detects middle bars like in 5)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 3:\n        return 0.0\n    gx, gy = np.gradient(gray)\n    band_top = max(0, h//2 - h//8)\n    band_bottom = min(h, h//2 + h//8)\n    band = gy[band_top:band_bottom, :]\n    return float(np.mean(np.abs(band)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean horizontal-to-vertical gradient ratio in the bottom-right quadrant (detects diagonal/horizontal strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    br = gray[h//2:h, w//2:w]\n    if br.size == 0:\n        return 0.0\n    gy, gx = np.gradient(br.astype(float))\n    mean_ax = float(np.mean(np.abs(gx)))\n    mean_ay = float(np.mean(np.abs(gy)))\n    return float(mean_ax / (mean_ay + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean intensity of top 5% brightest pixels normalized by intensity range'\n    import numpy as np\n    eps = 1e-12\n    q = 95.0\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).ravel().astype(float))\n    else:\n        arr = np.nan_to_num(img.ravel().astype(float))\n    if arr.size == 0:\n        return 0.0\n    p = np.percentile(arr, q)\n    top = arr[arr >= p]\n    if top.size == 0:\n        return 0.0\n    mean_top = float(top.mean())\n    rng = float(arr.max() - arr.min()) + eps\n    result = (mean_top - float(arr.min())) / rng\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge orientation concentration (1 => edges mostly aligned, 0 => isotropic)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy) + eps\n    ux = gx / mag\n    uy = gy / mag\n    # magnitude-weighted mean direction vector\n    sum_mag = float(mag.sum())\n    if sum_mag <= eps:\n        return 0.0\n    mean_x = float((ux * mag).sum()) / sum_mag\n    mean_y = float((uy * mag).sum()) / sum_mag\n    resultant = np.hypot(mean_x, mean_y)\n    result = float(np.clip(resultant, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels in the upper-right quadrant (helps detect 7 which often has ink in top-right)'\n    try:\n        import numpy as np\n        # grayscale conversion\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        if gray.size == 0:\n            return 0.0\n        # normalize to ~0-1\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        # estimate background polarity from corners\n        corner = np.concatenate([\n            gray[:max(1, h//16), :max(1, w//16)].ravel(),\n            gray[-max(1, h//16):, :max(1, w//16)].ravel(),\n            gray[:max(1, h//16), -max(1, w//16):].ravel(),\n            gray[-max(1, h//16):, -max(1, w//16):].ravel()\n        ])\n        corner_mean = float(np.mean(corner)) if corner.size else 0.0\n        thresh = float(np.percentile(gray, 40))\n        if corner_mean > 0.5:\n            fg = gray < thresh\n        else:\n            fg = gray > thresh\n        # region: upper-right quadrant\n        ur = fg[:h//2, w//2:]\n        total_fg = float(np.count_nonzero(fg)) + 1e-8\n        return float(np.count_nonzero(ur) / total_fg)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum radial sharpness: largest adjacent-ring mean jump normalized by overall std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    dist = np.hypot(ys - cy, xs - cx)\n    maxd = float(dist.max()) if dist.size else 1.0\n    if maxd <= 0:\n        return 0.0\n    nbins = min(30, max(4, int(round(maxd))))\n    bins = np.linspace(0, maxd, nbins + 1)\n    ring_means = []\n    for i in range(nbins):\n        mask = (dist >= bins[i]) & (dist < bins[i + 1])\n        if np.any(mask):\n            ring_means.append(np.mean(img[mask]))\n    if len(ring_means) <= 1:\n        return 0.0\n    rm = np.array(ring_means)\n    diffs = np.abs(np.diff(rm))\n    maxjump = float(diffs.max())\n    overall_std = float(np.std(img)) + eps\n    result = maxjump / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute Laplacian normalized by global intensity std (higher => stronger fine details)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, gyx = np.gradient(gy)\n        gxy, gxx = np.gradient(gx)\n    except Exception:\n        return 0.0\n    lap = gxx + gyy\n    mean_abs = float(np.mean(np.abs(lap)))\n    gstd = float(a.std()) + eps\n    result = mean_abs / gstd\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of foreground pixels that lie within a narrow image border (object touches border)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    bw = max(1, int(round(0.05 * min(h, w))))\n    # define foreground as pixels greater than mean (robust enough)\n    mask = img > img.mean()\n    fg_count = float(np.count_nonzero(mask))\n    if fg_count <= 0:\n        return 0.0\n    top = mask[:bw, :].sum()\n    bottom = mask[-bw:, :].sum()\n    left = mask[:, :bw].sum()\n    right = mask[:, -bw:].sum()\n    border_cnt = float(top + bottom + left + right)\n    # pixels in corners counted twice; approximate is acceptable for efficiency\n    result = border_cnt / (fg_count + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground-background contrast: (mean of top 10% - mean of bottom 10%) normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    flat = arr.ravel()\n    if flat.size == 0:\n        return 0.0\n    p90 = float(np.percentile(flat, 90))\n    p10 = float(np.percentile(flat, 10))\n    top_mean = float(flat[flat >= p90].mean()) if np.any(flat >= p90) else float(flat.mean())\n    bot_mean = float(flat[flat <= p10].mean()) if np.any(flat <= p10) else float(flat.mean())\n    global_std = float(arr.std()) + eps\n    result = (top_mean - bot_mean) / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized largest vertical gap (background) in the central column region (helps detect separation between lobes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy()\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    corner = min(5, h//2, w//2)\n    if corner > 0:\n        bg = np.mean(np.concatenate([gray[:corner,:corner].ravel(),\n                                     gray[:corner,-corner:].ravel(),\n                                     gray[-corner:,:corner].ravel(),\n                                     gray[-corner:,-corner:].ravel()]))\n    else:\n        bg = np.mean(gray)\n    if bg >= np.mean(gray):\n        thr = (bg + np.min(gray)) / 2.0\n        bin_img = (gray < thr).astype(np.uint8)\n    else:\n        thr = (bg + np.max(gray)) / 2.0\n        bin_img = (gray > thr).astype(np.uint8)\n    # choose a narrow central band\n    center = w // 2\n    band = max(1, w // 10)\n    cols = slice(max(0, center - band), min(w, center + band + 1))\n    col_band = np.any(bin_img[:, cols], axis=1).astype(int)  # 1 if any ink in band, else 0\n    # we want longest run of zeros (background)\n    if col_band.size == 0:\n        return 0.0\n    padded = np.concatenate(([0], col_band, [0]))\n    diffs = np.diff(padded)\n    starts = np.where(diffs == 1)[0]\n    ends = np.where(diffs == -1)[0]\n    lengths = ends - starts\n    if lengths.size == 0:\n        # all background or all ink -> set accordingly\n        if np.all(col_band == 0):\n            return 1.0\n        else:\n            return 0.0\n    # background runs are where col_band == 0: compute from inverse\n    inv = 1 - col_band\n    padded_inv = np.concatenate(([0], inv, [0]))\n    diffs_inv = np.diff(padded_inv)\n    starts_inv = np.where(diffs_inv == 1)[0]\n    ends_inv = np.where(diffs_inv == -1)[0]\n    lengths_inv = ends_inv - starts_inv\n    max_gap = float(lengths_inv.max()) if lengths_inv.size else 0.0\n    return float(max_gap) / float(h)\n",
    "def feature(image: np.ndarray) -> float:\n    'Top-half to bottom-half foreground pixel mass ratio (top_mass / bottom_mass), clipped and normalized'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 1.0\n    thr = float(np.percentile(gray, 75))\n    mask = gray >= thr\n    if mask.sum() > 0.6 * (h * w):\n        mask = ~mask\n    mask = mask.astype(float)\n    top_mass = mask[:h // 2, :].sum()\n    bottom_mass = mask[h // 2:, :].sum()\n    # avoid division by zero\n    if bottom_mass <= 1e-6:\n        return float(min(10.0, top_mass + 0.0))\n    ratio = top_mass / bottom_mass\n    # clip to reasonable range and return\n    return float(max(0.0, min(10.0, ratio)))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Interquartile contrast: (90th-10th percentile) normalized by mean intensity'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    p90 = float(np.percentile(flat, 90))\n    p10 = float(np.percentile(flat, 10))\n    denom = float(np.mean(np.abs(flat))) + eps\n    result = (p90 - p10) / denom\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of area of the second-largest hole to the largest hole (0 if fewer than 2 holes)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    t = np.mean(gray)\n    mask1 = gray < t\n    mask2 = gray > t\n    ink = mask1 if np.count_nonzero(mask1) <= np.count_nonzero(mask2) else mask2\n    if np.count_nonzero(ink) == 0:\n        thr = np.percentile(gray, 40)\n        ink = gray < thr\n    visited = np.zeros((h, w), dtype=bool)\n    hole_areas = []\n    for r in range(h):\n        for c in range(w):\n            if visited[r, c] or ink[r, c]:\n                visited[r, c] = visited[r, c] or ink[r, c]\n                continue\n            stack = [(r, c)]\n            visited[r, c] = True\n            touches_border = False\n            area = 0\n            while stack:\n                y, x = stack.pop()\n                area += 1\n                if y == 0 or y == h-1 or x == 0 or x == w-1:\n                    touches_border = True\n                for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                    ny, nx = y+dy, x+dx\n                    if 0 <= ny < h and 0 <= nx < w and (not visited[ny, nx]) and (not ink[ny, nx]):\n                        visited[ny, nx] = True\n                        stack.append((ny, nx))\n            if not touches_border:\n                hole_areas.append(area)\n    if len(hole_areas) < 2:\n        return 0.0\n    hole_areas.sort(reverse=True)\n    largest, second = hole_areas[0], hole_areas[1]\n    return float(second / largest) if largest > 0 else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground bounding-box aspect bias: (w/h - 1) / (w/h + 1) in [-1,1], positive => wider than tall'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    flat = img.ravel()\n    if flat.size == 0:\n        return 0.0\n    try:\n        thr = float(np.percentile(flat, 50.0))\n    except Exception:\n        thr = float(np.mean(flat))\n    mask = img > thr\n    if not mask.any():\n        return 0.0\n    rows = np.any(mask, axis=1)\n    cols = np.any(mask, axis=0)\n    row_idx = np.where(rows)[0]\n    col_idx = np.where(cols)[0]\n    if row_idx.size == 0 or col_idx.size == 0:\n        return 0.0\n    h_box = int(row_idx[-1] - row_idx[0] + 1)\n    w_box = int(col_idx[-1] - col_idx[0] + 1)\n    if h_box <= 0:\n        return 0.0\n    ratio = float(w_box) / float(h_box)\n    result = (ratio - 1.0) / (ratio + 1.0 + 1e-12)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels with strong gradient (edge density), normalized 0..1'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + 0.5 * mag.std())\n    strong = np.count_nonzero(mag > thr)\n    result = strong / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of intensity histogram normalized to [0,1]'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size == 0:\n        return 0.0\n    # shift to positive range for histogram stability\n    amin = arr.min()\n    arr_shift = arr - amin\n    if arr_shift.max() <= 0:\n        return 0.0\n    hist, _ = np.histogram(arr_shift, bins=bins, range=(0.0, float(arr_shift.max())), density=False)\n    total = hist.sum()\n    if total <= 0:\n        return 0.0\n    p = hist.astype(float) / float(total)\n    ent = -np.sum(np.where(p > 0, p * np.log(p), 0.0))\n    norm = np.log(float(bins)) + eps\n    return float(np.clip(ent / norm, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Sharpness of brightest spot: (max - local mean)/global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    idx = int(np.argmax(a.ravel()))\n    h, w = a.shape\n    r, c = divmod(idx, w)\n    r0 = max(0, r - 1)\n    r1 = min(h, r + 2)\n    c0 = max(0, c - 1)\n    c1 = min(w, c + 2)\n    local = a[r0:r1, c0:c1]\n    max_val = float(a[r, c])\n    local_mean = float(np.mean(local)) if local.size else max_val\n    gstd = float(a.std()) + eps\n    result = (max_val - local_mean) / gstd\n    return float(np.clip(result, -10.0, 50.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with gradient magnitude above mean+std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    count = float(np.count_nonzero(mag > thr))\n    result = count / (float(h * w) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal-vs-vertical edge dominance ratio (-1..1), positive => horizontal stronger'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    magx = np.mean(np.abs(gx))\n    magy = np.mean(np.abs(gy))\n    denom = magx + magy + eps\n    ratio = (magx - magy) / denom\n    return float(np.clip(ratio, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (0 for grayscale), normalized by image range'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    img = np.nan_to_num(arr.astype(float))\n    R = img[:, :, 0]\n    G = img[:, :, 1]\n    B = img[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    raw = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    rng = float(np.max(img) - np.min(img)) + eps\n    result = raw / rng\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized horizontal edge strength in the central horizontal band (captures mid crossbar presence)'\n    import numpy as np\n    # convert to grayscale float\n    if image is None:\n        return 0.0\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    if h < 3 or w < 3:\n        return 0.0\n    # central band\n    r0, r1 = h // 3, (2 * h) // 3\n    band = gray[r0:r1, :]\n    # horizontal edges ~ gradient along columns (diff across columns)\n    gx = np.abs(np.diff(band, axis=1))\n    # normalize by band area and global dynamic range\n    denom = (np.ptp(gray) + 1e-6) * band.size\n    return float(np.sum(gx) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local contrast: average absolute difference to 4-neighbors normalized by mean intensity'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    # differences with four neighbors using shifts\n    up = np.abs(a - np.roll(a, 1, axis=0))\n    down = np.abs(a - np.roll(a, -1, axis=0))\n    left = np.abs(a - np.roll(a, 1, axis=1))\n    right = np.abs(a - np.roll(a, -1, axis=1))\n    # average of these (each pixel counted 4 times)\n    local = (up + down + left + right) / 4.0\n    mean_local = float(local.mean())\n    overall = float(np.mean(np.abs(a))) + eps\n    result = mean_local / overall\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio using 3x3 mean blur (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    # small images: if too small, just return 0\n    h, w = arr.shape\n    if h < 1 or w < 1:\n        return 0.0\n    pad = np.pad(arr, 1, mode='reflect')\n    # compute 3x3 mean efficiently\n    s = (pad[0:-2, 0:-2] + pad[0:-2, 1:-1] + pad[0:-2, 2:] +\n         pad[1:-1, 0:-2] + pad[1:-1, 1:-1] + pad[1:-1, 2:] +\n         pad[2:, 0:-2] + pad[2:, 1:-1] + pad[2:, 2:])\n    blur = s / 9.0\n    high = arr - blur\n    high_energy = float(np.sum(np.abs(high)))\n    total_energy = float(np.sum(np.abs(arr))) + eps\n    result = high_energy / (total_energy + eps)\n    result = float(np.clip(result, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean chroma (max-min per pixel) normalized by image dynamic range; 0 for non-color'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim < 3 or img.shape[2] < 3:\n        return 0.0\n    arr = np.nan_to_num(img.astype(float))\n    maxc = arr.max(axis=2)\n    minc = arr.min(axis=2)\n    chroma = maxc - minc\n    mean_chroma = float(np.mean(chroma))\n    dyn = float(arr.max() - arr.min()) + eps\n    result = mean_chroma / dyn\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between mid annulus and inner disk normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    mm = float(min(h, w))\n    r1 = mm / 8.0\n    r2 = mm / 3.0\n    inner_mask = r <= r1\n    ring_mask = (r > r1) & (r <= r2)\n    if not np.any(inner_mask) or not np.any(ring_mask):\n        return 0.0\n    inner_mean = float(a[inner_mask].mean())\n    ring_mean = float(a[ring_mask].mean())\n    gstd = float(a.std()) + eps\n    result = (ring_mean - inner_mean) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity centroid offset (0..1): distance between image center and intensity-weighted centroid'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    total = float(arr.sum())\n    if total <= eps or h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    x_cent = float((xs * arr).sum()) / total\n    y_cent = float((ys * arr).sum()) / total\n    dist = float(np.hypot(x_cent - cx, y_cent - cy))\n    diag = float(np.hypot(w, h)) + eps\n    result = dist / diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows with 4 or more binary transitions (proxy for loops/multiple segments)'\n    import numpy as np\n    img = image.astype(float)\n    h, w = img.shape[:2]\n    if img.max() > 1.0:\n        img = img / 255.0\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    thr = gray.mean()\n    cand1 = gray < thr\n    cand2 = gray > thr\n    mask = cand1 if cand1.sum() <= cand2.sum() else cand2\n    if w <= 1:\n        return 0.0\n    transitions = np.abs(mask[:, :-1].astype(int) - mask[:, 1:].astype(int)).sum(axis=1)\n    rows_with_many = (transitions >= 4).sum()\n    return float(rows_with_many / max(1.0, h))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of horizontal-edge energy (abs vertical gradient) in upper third to lower third (values >1 -> stronger upper horizontal structure)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.asarray(image).astype(float)\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr\n    h, w = gray.shape[:2]\n    if h < 3:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    abs_gy = np.abs(gy)\n    upper = abs_gy[:h//3, :]\n    lower = abs_gy[-h//3:, :]\n    upper_energy = upper.mean() if upper.size else 0.0\n    lower_energy = lower.mean() if lower.size else 0.0\n    return float((upper_energy + 1e-9) / (lower_energy + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1), higher => more diverse intensities'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    # use grayscale projection for color images\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    vals = a.ravel()\n    # choose number of bins but not more than unique values and at least 2\n    try:\n        uniq = np.unique(vals)\n        nb = min(256, max(2, uniq.size))\n    except Exception:\n        nb = 256\n    hist, _ = np.histogram(vals, bins=nb, range=(vals.min(), vals.max()))\n    probs = hist.astype(float) / (hist.sum() + 1e-12)\n    probs = probs[probs > 0]\n    if probs.size == 0:\n        return 0.0\n    ent = -np.sum(probs * np.log(probs))\n    max_ent = np.log(probs.size)\n    result = 0.0 if max_ent <= 0 else ent / max_ent\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted centroid offset from image center normalized to [0..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # make intensities non-negative to compute meaningful centroid\n    a_shift = a - float(a.min())\n    total = float(a_shift.sum())\n    if total <= eps:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = float((xs * a_shift).sum()) / total\n    cy = float((ys * a_shift).sum()) / total\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.sqrt((cx - center_x) ** 2 + (cy - center_y) ** 2)\n    max_dist = np.sqrt(center_x ** 2 + center_y ** 2) + eps\n    result = dist / max_dist\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference between SE and SW diagonal edge energies (positive -> SE dominant)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.shape[0] < 2 or gray.shape[1] < 2:\n        return 0.0\n    diff_se = np.sum(np.abs(gray[:-1, :-1] - gray[1:, 1:]))\n    diff_sw = np.sum(np.abs(gray[:-1, 1:] - gray[1:, :-1]))\n    denom = diff_se + diff_sw + 1e-6\n    return float((diff_se - diff_sw) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left vs right middle strip ink asymmetry: normalized difference (left - right) by total ink'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    mx = float(np.max(gray))\n    if mx > 0:\n        gray = gray / (mx + eps)\n    h, w = gray.shape[:2]\n    k = max(1, w // 8)\n    med = float(np.percentile(gray, 50))\n    corners = np.mean([gray[:k,:k].mean(), gray[:k,-k:].mean(), gray[-k:,:k].mean(), gray[-k:,-k:].mean()])\n    if corners > med:\n        ink = (gray < med).astype(np.uint8)\n    else:\n        ink = (gray > med).astype(np.uint8)\n    left_start = max(0, w // 8)\n    left_end = max(left_start + 1, w // 2)\n    right_start = min(w - 1, w // 2)\n    right_end = min(w, w * 7 // 8)\n    left_count = float(np.sum(ink[:, left_start:left_end]))\n    right_count = float(np.sum(ink[:, right_start:right_end]))\n    total = float(np.sum(ink)) + eps\n    return float((left_count - right_count) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical edge energy in the middle third of the image (vertical stroke prominence in mid-region)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray)\n    vert_edge = np.abs(gx)\n    r0 = h // 3\n    r1 = 2 * h // 3\n    mid_energy = np.mean(vert_edge[r0:r1, :]) if r1 > r0 else np.mean(vert_edge)\n    total_energy = np.mean(vert_edge) + 1e-9\n    return float(mid_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of image area occupied by the bounding box of bright foreground (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    vmin = float(a.min()); vmax = float(a.max())\n    if vmax <= vmin + eps:\n        return 0.0\n    thresh = float(a.mean()) + 0.25 * (vmax - vmin)\n    mask = a > thresh\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    y0 = ys.min(); y1 = ys.max()\n    x0 = xs.min(); x1 = xs.max()\n    bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1))\n    frac = bbox_area / float(h * w)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean vertical-edge energy (abs gradient along columns) in the left half, normalized by region area'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    left = gray[:, : max(1, w // 2)]\n    gy, gx = np.gradient(left)\n    energy = np.mean(np.abs(gx))  # gx corresponds to changes across columns -> vertical strokes\n    return float(energy)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average absolute symmetry correlation with horizontal and vertical flips (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    def norm_corr(u, v):\n        uf = u.ravel().astype(float)\n        vf = v.ravel().astype(float)\n        su = uf - uf.mean()\n        sv = vf - vf.mean()\n        nu = np.sqrt((su * su).sum())\n        nv = np.sqrt((sv * sv).sum())\n        denom = (nu * nv) + eps\n        return float(np.sum(su * sv) / denom)\n    corr_h = norm_corr(a, np.flipud(a))\n    corr_v = norm_corr(a, np.fliplr(a))\n    # take absolute correlation (symmetry magnitude) and average\n    result = (abs(corr_h) + abs(corr_v)) / 2.0\n    result = float(np.clip(result, 0.0, 1.0))\n    return result\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local variance normalized by global variance (>=0)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    # local mean and mean of squares via 3x3 box\n    s = np.zeros_like(a)\n    sq = a * a\n    ssq = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    ssq += sq\n    ssq += np.roll(sq, 1, axis=0)\n    ssq += np.roll(sq, -1, axis=0)\n    ssq += np.roll(sq, 1, axis=1)\n    ssq += np.roll(sq, -1, axis=1)\n    ssq += np.roll(np.roll(sq, 1, axis=0), 1, axis=1)\n    ssq += np.roll(np.roll(sq, 1, axis=0), -1, axis=1)\n    ssq += np.roll(np.roll(sq, -1, axis=0), 1, axis=1)\n    ssq += np.roll(np.roll(sq, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    local_sq_mean = ssq / 9.0\n    local_var = np.maximum(0.0, local_sq_mean - local_mean * local_mean)\n    mean_local_var = float(np.mean(local_var))\n    global_var = float(np.var(a)) + eps\n    result = mean_local_var / global_var\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Foreground fill ratio: fraction of pixels > mean + 0.5*std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    mean = float(a.mean())\n    std = float(a.std())\n    thresh = mean + 0.5 * std\n    result = float(np.count_nonzero(a > thresh)) / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant structure orientation (0..1) where 0=vertical-ish and 1=horizontal-ish (averaged from structure tensor)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    Jxx = (gx * gx).mean()\n    Jyy = (gy * gy).mean()\n    Jxy = (gx * gy).mean()\n    # orientation of dominant eigenvector: 0..pi -> map to 0..1\n    angle = 0.5 * np.arctan2(2.0 * Jxy, (Jxx - Jyy) + eps)\n    # angle in radians in [-pi/2, pi/2]; map to [0,1]\n    result = float(np.clip((angle + np.pi/2.0) / np.pi, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels in the right third of the image (right-side density)'\n    import numpy as np\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    # convert to grayscale\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img.astype(float)\n    # robust binarization: prefer sparser side for ink detection\n    med = np.median(gray)\n    prop = float(np.mean(gray < med))\n    thr = np.percentile(gray, 20) if prop > 0.5 else med\n    bw = (gray < thr).astype(np.uint8)\n    if bw.sum() == 0:\n        bw = (gray > thr).astype(np.uint8)\n    right = bw[:, (2*w)//3 : ].sum()\n    total = max(1.0, bw.sum())\n    return float(right / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized median absolute deviation (MAD) relative to intensity range'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    med = float(np.median(flat))\n    mad = float(np.median(np.abs(flat - med)))\n    rng = float(flat.max() - flat.min()) + eps\n    result = mad / rng\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of mean intensities across concentric rings normalized by global variance'\n    import numpy as np\n    eps = 1e-12\n    rings = 8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    maxr = float(r.max()) + eps\n    bins = np.linspace(0.0, maxr, rings + 1)\n    means = []\n    for i in range(rings):\n        mask = (r >= bins[i]) & (r < bins[i+1])\n        if np.any(mask):\n            means.append(float(a[mask].mean()))\n    if len(means) <= 1:\n        return 0.0\n    mean_arr = np.array(means, dtype=float)\n    var_rings = float(np.var(mean_arr))\n    global_var = float(np.var(a)) + eps\n    result = var_rings / global_var\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Median of non-overlapping block variances (coarseness), normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    blocks = max(1, min(h, w) // 8)\n    bh = max(1, h // blocks)\n    bw = max(1, w // blocks)\n    variances = []\n    for y in range(0, h, bh):\n        for x in range(0, w, bw):\n            block = arr[y:y+bh, x:x+bw]\n            if block.size:\n                variances.append(float(block.var()))\n    if not variances:\n        return 0.0\n    median_var = float(np.median(variances))\n    denom = float(np.std(arr)) + eps\n    result = median_var / denom\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (height / width) of the tight bounding box around the ink (1 is square, >1 is tall like 1, <1 is wide like 7)'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 1.0\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        h, w = gray.shape\n        corner = np.concatenate([\n            gray[:max(1, h//16), :max(1, w//16)].ravel(),\n            gray[-max(1, h//16):, :max(1, w//16)].ravel(),\n            gray[:max(1, h//16), -max(1, w//16):].ravel(),\n            gray[-max(1, h//16):, -max(1, w//16):].ravel()\n        ])\n        corner_mean = float(np.mean(corner)) if corner.size else 0.0\n        thresh = float(np.percentile(gray, 40))\n        if corner_mean > 0.5:\n            fg = gray < thresh\n        else:\n            fg = gray > thresh\n        ys, xs = np.where(fg)\n        if ys.size == 0:\n            return 1.0\n        bh = float(ys.max() - ys.min() + 1)\n        bw = float(xs.max() - xs.min() + 1)\n        if bw <= 0:\n            return 1.0\n        return float(bh / bw)\n    except Exception:\n        return 1.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of image energy in high-frequency residual after a 3x3 blur (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # simple 3x3 mean blur via shifts with edge padding\n    p = np.pad(a, pad_width=1, mode='edge')\n    s = np.zeros_like(a, dtype=float)\n    s += p[0:h, 0:w]\n    s += p[0:h, 1:w+1]\n    s += p[0:h, 2:w+2]\n    s += p[1:h+1, 0:w]\n    s += p[1:h+1, 1:w+1]\n    s += p[1:h+1, 2:w+2]\n    s += p[2:h+2, 0:w]\n    s += p[2:h+2, 1:w+1]\n    s += p[2:h+2, 2:w+2]\n    blur = s / 9.0\n    residual = a - blur\n    energy_res = float(np.sum(residual * residual))\n    total_var = float(np.sum((a - np.mean(a)) ** 2))\n    if total_var <= eps:\n        return 0.0\n    frac = energy_res / (total_var + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative top-quarter left vs right ink density: (right - left) / (total in top quarter)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    p40, p60 = np.percentile(gray, 40), np.percentile(gray, 60)\n    mask_dark = gray <= p40\n    mask_bright = gray >= p60\n    mask = mask_dark if mask_dark.sum() < mask_bright.sum() else mask_bright\n    top = slice(0, max(1, h//4))\n    left_count = mask[top, :w//2].sum()\n    right_count = mask[top, w//2:].sum()\n    total = left_count + right_count\n    if total == 0:\n        return 0.0\n    return float((right_count - left_count) / (total + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarse-to-fine energy ratio using 2x2 block averaging (higher => smoother)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # trim to even dimensions\n    he = h - (h % 2)\n    we = w - (w % 2)\n    a_trim = a[:he, :we]\n    if a_trim.size == 0:\n        return 0.0\n    # block mean 2x2\n    a_blocks = a_trim.reshape(he//2, 2, we//2, 2).mean(axis=(1, 3))\n    # upsample by repeating\n    coarse = np.repeat(np.repeat(a_blocks, 2, axis=0), 2, axis=1)\n    # pad if original had odd row/col\n    if he != h or we != w:\n        coarse_full = np.zeros_like(a)\n        coarse_full[:he, :we] = coarse\n        if he < h:\n            coarse_full[he:, :we] = np.mean(a[he:, :we])\n        if we < w:\n            coarse_full[:he, we:] = np.mean(a[:he, we:])\n        if he < h and we < w:\n            coarse_full[he:, we:] = np.mean(a[he:, we:])\n        coarse = coarse_full\n    fine = a - coarse\n    coarse_energy = float(np.sum(coarse * coarse))\n    fine_energy = float(np.sum(fine * fine)) + eps\n    result = coarse_energy / fine_energy\n    # compress scale to reasonable range\n    result = np.log1p(result)\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Multi-scale contrast: mean absolute difference between image and coarse block-averaged version normalized by global std'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    k = max(1, min(h, w) // 4)\n    bh = h // k\n    bw = w // k\n    if bh < 1 or bw < 1:\n        # fallback to simple local mean subtraction\n        coarse = np.full_like(img, img.mean())\n    else:\n        # crop to multiple of k\n        ch = bh * k\n        cw = bw * k\n        cropped = img[:ch, :cw]\n        # reshape to blocks and compute mean per block\n        blocks = cropped.reshape(bh, k, bw, k)\n        block_means = blocks.mean(axis=(1, 3))\n        # expand back\n        coarse = np.repeat(np.repeat(block_means, k, axis=0), k, axis=1)\n        # pad if needed to original size\n        if coarse.shape != img[:coarse.shape[0], :coarse.shape[1]].shape:\n            coarse = coarse[:img.shape[0], :img.shape[1]]\n        if coarse.shape != img.shape:\n            # pad with global mean\n            pad = np.full(img.shape, img.mean())\n            pad[:coarse.shape[0], :coarse.shape[1]] = coarse\n            coarse = pad\n    diff = np.abs(img - coarse)\n    gstd = float(img.std()) + 1e-12\n    result = float(diff.mean()) / gstd\n    # clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of the foreground bounding box (width/height), clipped and normalized to [0,1] \u2014 tall thin like \"1\" gives small values'\n    import numpy as np\n    arr = np.array(image, dtype=float)\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    fg = gray < th\n    if np.count_nonzero(fg) > gray.size / 2:\n        fg = ~fg\n    ys, xs = np.nonzero(fg)\n    if xs.size == 0:\n        return 0.5\n    x_min, x_max = int(xs.min()), int(xs.max())\n    y_min, y_max = int(ys.min()), int(ys.max())\n    bw = x_max - x_min + 1\n    bh = y_max - y_min + 1\n    if bh == 0:\n        return 0.0\n    ar = float(bw) / float(bh)\n    # normalize: expect ar in [0.25,4], clip then map to [0,1]\n    ar_clamped = max(0.25, min(4.0, ar))\n    return float((ar_clamped - 0.25) / (4.0 - 0.25))\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated number of enclosed holes (loops) in the digit stroke (9 and 8 tend to have loops)'\n    try:\n        import numpy as np\n        # grayscale + normalize\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 0.0\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        h, w = gray.shape\n        corner = np.concatenate([\n            gray[:max(1, h//16), :max(1, w//16)].ravel(),\n            gray[-max(1, h//16):, :max(1, w//16)].ravel(),\n            gray[:max(1, h//16), -max(1, w//16):].ravel(),\n            gray[-max(1, h//16):, -max(1, w//16):].ravel()\n        ])\n        corner_mean = float(np.mean(corner)) if corner.size else 0.0\n        thresh = float(np.percentile(gray, 40))\n        if corner_mean > 0.5:\n            fg = gray < thresh\n        else:\n            fg = gray > thresh\n        # bounding box around foreground\n        ys, xs = np.where(fg)\n        if ys.size == 0:\n            return 0.0\n        y0, y1 = ys.min(), ys.max()\n        x0, x1 = xs.min(), xs.max()\n        sub = ~fg[y0:y1+1, x0:x1+1]  # background inside bbox\n        # flood fill the background component that touches the border to exclude outer background\n        H, W = sub.shape\n        visited = np.zeros_like(sub, dtype=np.bool_)\n        from collections import deque\n        q = deque()\n        for i in range(H):\n            for j in (0, W-1):\n                if sub[i, j] and not visited[i, j]:\n                    visited[i, j] = True\n                    q.append((i, j))\n        for j in range(W):\n            for i in (0, H-1):\n                if sub[i, j] and not visited[i, j]:\n                    visited[i, j] = True\n                    q.append((i, j))\n        while q:\n            y, x = q.popleft()\n            for dy in (-1, 0, 1):\n                for dx in (-1, 0, 1):\n                    ny, nx = y+dy, x+dx\n                    if 0 <= ny < H and 0 <= nx < W and sub[ny, nx] and not visited[ny, nx]:\n                        visited[ny, nx] = True\n                        q.append((ny, nx))\n        # now count remaining background components (holes)\n        holes = 0\n        for i in range(H):\n            for j in range(W):\n                if sub[i, j] and not visited[i, j]:\n                    # new hole\n                    holes += 1\n                    # mark component\n                    stack = [(i, j)]\n                    visited[i, j] = True\n                    while stack:\n                        y, x = stack.pop()\n                        for dy in (-1, 0, 1):\n                            for dx in (-1, 0, 1):\n                                ny, nx = y+dy, x+dx\n                                if 0 <= ny < H and 0 <= nx < W and sub[ny, nx] and not visited[ny, nx]:\n                                    visited[ny, nx] = True\n                                    stack.append((ny, nx))\n        return float(holes)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels in the top-center band that are background (open-top indicator): top 20% rows, central 40% columns'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    r0 = 0\n    r1 = max(1, int(h * 0.2))\n    c0 = max(0, int(w * 0.3))\n    c1 = min(w, int(w * 0.7))\n    region = gray[r0:r1, c0:c1]\n    if region.size == 0:\n        return 0.0\n    fg_region = region < np.mean(gray)\n    bg_fraction = float(1.0 - (np.count_nonzero(fg_region) / region.size))\n    return bg_fraction\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge orientation entropy (0..1): entropy of gradient orientations normalized by log(bins)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    ori = np.arctan2(gy, gx)  # -pi..pi\n    # map to 0..pi to ignore direction (180-degree symmetry)\n    ori = np.mod(ori, np.pi)\n    bins = 16\n    hist, _ = np.histogram(ori.ravel(), bins=bins, range=(0.0, np.pi))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0]\n    ent = -np.sum(p * np.log(p + eps))\n    norm = ent / (np.log(bins) + eps)\n    return float(np.clip(norm, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference between ink proportion in top-left and top-right quadrants (positive => more ink in top-left)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy()\n    gray = np.asarray(gray, dtype=float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.mean(gray)\n    fg = gray < thr\n    if np.mean(fg) > 0.6:\n        fg = gray > thr\n    mid_y = h // 2\n    mid_x = w // 2\n    top_left = fg[:mid_y, :mid_x]\n    top_right = fg[:mid_y, mid_x:]\n    pl = float(np.mean(top_left)) if top_left.size > 0 else 0.0\n    pr = float(np.mean(top_right)) if top_right.size > 0 else 0.0\n    return float(pl - pr)\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of strong local maxima (bright peaks) normalized by image area'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # compare to 8 neighbors using rolls\n    neighs = []\n    neighs.append(np.roll(a, 1, axis=0))\n    neighs.append(np.roll(a, -1, axis=0))\n    neighs.append(np.roll(a, 1, axis=1))\n    neighs.append(np.roll(a, -1, axis=1))\n    neighs.append(np.roll(np.roll(a, 1, axis=0), 1, axis=1))\n    neighs.append(np.roll(np.roll(a, 1, axis=0), -1, axis=1))\n    neighs.append(np.roll(np.roll(a, -1, axis=0), 1, axis=1))\n    neighs.append(np.roll(np.roll(a, -1, axis=0), -1, axis=1))\n    greater = np.ones_like(a, dtype=bool)\n    for n in neighs:\n        greater &= (a > n)\n    # suppress borders because roll wraps\n    greater[0, :] = False\n    greater[-1, :] = False\n    greater[:, 0] = False\n    greater[:, -1] = False\n    thresh = np.percentile(a, 90.0)\n    peaks = greater & (a >= thresh)\n    count = float(peaks.sum())\n    area = float(h) * float(w) + eps\n    result = count / area\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Central mass offset: normalized distance between intensity centroid and image center (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # shift to non-negative mass\n    arr_pos = arr - float(np.min(arr))\n    total = arr_pos.sum()\n    if total <= 0:\n        return 0.0\n    ys = np.arange(h, dtype=float)[:, None]\n    xs = np.arange(w, dtype=float)[None, :]\n    y_mean = float((arr_pos * ys).sum() / total)\n    x_mean = float((arr_pos * xs).sum() / total)\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    dist = np.hypot(y_mean - cy, x_mean - cx)\n    diag = np.hypot(h, w) / 2.0 + 1e-12\n    result = dist / diag\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Primary stroke orientation: absolute angle of the first principal component normalized to [0,1] (0 = horizontal, 1 = vertical)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    thr = gray.mean()\n    mask = (gray > thr)\n    if mask.mean() > 0.6 or mask.mean() < 0.001:\n        p30, p70 = np.percentile(gray.flatten(), [30, 70])\n        thr2 = (p30 + p70) / 2.0\n        mask = (gray > thr2)\n        if mask.mean() > 0.6:\n            mask = (gray < thr2)\n    coords = np.column_stack(np.where(mask))\n    if coords.shape[0] < 2:\n        return 0.0\n    # rows -> y, cols -> x; convert to (x,y) for covariance\n    ys = coords[:, 0].astype(float)\n    xs = coords[:, 1].astype(float)\n    mx, my = xs.mean(), ys.mean()\n    cov_xx = np.mean((xs - mx) * (xs - mx))\n    cov_xy = np.mean((xs - mx) * (ys - my))\n    cov_yy = np.mean((ys - my) * (ys - my))\n    cov = np.array([[cov_xx, cov_xy], [cov_xy, cov_yy]])\n    try:\n        vals, vecs = np.linalg.eigh(cov)\n    except Exception:\n        return 0.0\n    # principal component is eigenvector of largest eigenvalue\n    idx = np.argmax(vals)\n    v = vecs[:, idx]\n    angle = float(np.abs(np.arctan2(v[1], v[0])))  # radians relative to x axis\n    # normalize to [0,1] where pi/2 maps to 1\n    return float(min(angle, np.pi/2) / (np.pi/2))\n\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry correlation (-1..1)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    rot = np.rot90(img, 2)\n    A = img.ravel()\n    B = rot.ravel()\n    A_mean = A.mean()\n    B_mean = B.mean()\n    num = np.sum((A - A_mean) * (B - B_mean))\n    den = np.sqrt(np.sum((A - A_mean)**2) * np.sum((B - B_mean)**2)) + eps\n    result = num / den\n    return float(np.clip(result, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Eccentricity of bright-region centroid (0=centered .. 1=corner) using top 10% pixels'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if a.size == 0:\n        return 0.0\n    thresh = np.percentile(a, 90)\n    mask = a >= thresh\n    if not mask.any():\n        return 0.0\n    weights = a * mask\n    s = float(weights.sum()) + eps\n    ys, xs = np.indices((h, w))\n    cx = float((weights * xs).sum()) / s\n    cy = float((weights * ys).sum()) / s\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dx = cx - center_x\n    dy = cy - center_y\n    dist = np.hypot(dx, dy)\n    maxdist = np.hypot(center_x, center_y) + eps\n    result = dist / maxdist\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness (Hasler-Susstrunk) for RGB images normalized by mean intensity (0..inf)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    # use first three channels as R,G,B\n    rgb = np.nan_to_num(arr[:, :, :3].astype(float))\n    R = rgb[:, :, 0]\n    G = rgb[:, :, 1]\n    B = rgb[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    colorfulness = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    mean_int = float(np.mean(rgb)) + eps\n    result = colorfulness / mean_int\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of local intensity peaks (distinct bright spots) per pixel'\n    import numpy as np\n    eps = 1e-12\n    arr_in = np.asarray(image)\n    if arr_in.size == 0:\n        return 0.0\n    if arr_in.ndim == 3:\n        a = np.nan_to_num(arr_in.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr_in.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    # compare each pixel to its 8 neighbors using shifted arrays (wrap avoided by masking border)\n    shifts = [(0,1),(0,-1),(1,0),(-1,0),(1,1),(1,-1),(-1,1),(-1,-1)]\n    center = a\n    greater = np.ones_like(a, dtype=bool)\n    for dy, dx in shifts:\n        neigh = np.roll(np.roll(a, dy, axis=0), dx, axis=1)\n        greater &= (center > neigh)\n    # remove border false positives due to roll wrap\n    greater[0,:] = False\n    greater[-1,:] = False\n    greater[:,0] = False\n    greater[:,-1] = False\n    # only count peaks that stand above local statistics\n    thr = float(a.mean() + 0.5 * a.std())\n    peaks = greater & (a > thr)\n    count = float(peaks.sum())\n    result = count / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram bimodality score (0..1); high when two distinct peaks separated across intensities'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    nbins = 64\n    amin, amax = float(flat.min()), float(flat.max())\n    if amax <= amin:\n        return 0.0\n    hist, edges = np.histogram(flat, bins=nbins, range=(amin, amax))\n    if hist.sum() == 0:\n        return 0.0\n    # find two highest peaks\n    idx = np.argsort(hist)\n    i1 = int(idx[-1])\n    i2 = int(idx[-2]) if hist.size >= 2 else int(idx[-1])\n    h1 = float(hist[i1])\n    h2 = float(hist[i2])\n    if h1 <= eps or h2 <= eps:\n        return 0.0\n    separation = abs(i1 - i2) / float(nbins - 1)\n    peak_balance = min(h1, h2) / (max(h1, h2) + eps)\n    score = separation * peak_balance\n    return float(np.clip(score, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score (0..1), 1 => perfectly symmetric'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    mid = w // 2\n    if mid == 0:\n        return 0.0\n    left = a[:, :mid]\n    right = a[:, -mid:]\n    right_flipped = np.fliplr(right)\n    if left.shape != right_flipped.shape:\n        # safety check, crop to smallest common shape\n        min_h = min(left.shape[0], right_flipped.shape[0])\n        min_w = min(left.shape[1], right_flipped.shape[1])\n        left = left[:min_h, :min_w]\n        right_flipped = right_flipped[:min_h, :min_w]\n    mean_abs_diff = float(np.mean(np.abs(left - right_flipped)))\n    mean_scale = float(np.mean((np.abs(left) + np.abs(right_flipped)) * 0.5)) + eps\n    score = 1.0 - (mean_abs_diff / mean_scale)\n    result = float(np.clip(score, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarse-to-fine gradient ratio (mean coarse gradient / mean fine gradient) -> >1 coarser texture'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy_f, gx_f = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag_f = np.hypot(gx_f, gy_f)\n    # coarse downsample by factor 2 (floor)\n    a_c = a[::2, ::2]\n    if a_c.size < 4:\n        # fallback: blur by simple local average (via slicing) then compute gradient\n        a_c = (a + np.roll(a, 1, axis=0) + np.roll(a, 1, axis=1) + np.roll(a, (1,1), axis=(0,1))) / 4.0\n    try:\n        gy_c, gx_c = np.gradient(a_c)\n    except Exception:\n        return 0.0\n    mag_c = np.hypot(gx_c, gy_c)\n    mean_f = float(mag_f.mean()) + eps\n    mean_c = float(mag_c.mean()) + eps\n    result = mean_c / mean_f\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical vs horizontal gradient energy in the right half (higher if there are strong vertical strokes on the right)'\n    try:\n        import numpy as np\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        g = (gray - np.min(gray)) / (np.max(gray) - np.min(gray) + 1e-9)\n        gy, gx = np.gradient(g)\n        h, w = g.shape\n        right = slice(w//2, w)\n        vert_energy = np.sum(np.abs(gy[:, right]))\n        horiz_energy = np.sum(np.abs(gx[:, right]))\n        return float(vert_energy / (horiz_energy + 1e-8))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Laplacian zero-crossing rate (fraction of pixels adjacent to a sign change)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n        gyy, gyx = np.gradient(gy)\n        gxy, gxx = np.gradient(gx)\n    except Exception:\n        return 0.0\n    lap = gxx + gyy\n    # detect sign changes between neighbors along rows and cols\n    prod_row = lap * np.roll(lap, 1, axis=0)\n    prod_col = lap * np.roll(lap, 1, axis=1)\n    zc = (prod_row < 0) | (prod_col < 0)\n    count = float(np.count_nonzero(zc))\n    h, w = lap.shape\n    result = count / float(h * w + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels significantly darker than image mean (shadow presence)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h * w == 0:\n        return 0.0\n    m = float(arr.mean())\n    s = float(arr.std())\n    thr = m - 0.5 * s\n    mask = arr < thr\n    frac = float(np.count_nonzero(mask)) / float(h * w)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized centroid offset: distance between intensity centroid and image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    total = arr.sum()\n    if total == 0:\n        return 0.0\n    cy = float((arr * ys).sum() / (total + eps))\n    cx = float((arr * xs).sum() / (total + eps))\n    center_y = (h - 1) / 2.0\n    center_x = (w - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    maxd = np.hypot(center_x, center_y) + eps\n    result = dist / maxd\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of radial inner energy to combined inner+outer energy (1=all energy inner)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    yy, xx = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(yy - cy, xx - cx)\n    rmax = r.max() if r.size else 0.0\n    if rmax <= 0:\n        return 0.0\n    inner_mask = r <= (0.33 * rmax)\n    outer_mask = r >= (0.66 * rmax)\n    energy = arr.astype(float) ** 2\n    inner = float(energy[inner_mask].sum())\n    outer = float(energy[outer_mask].sum())\n    denom = inner + outer + eps\n    result = inner / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center horizontal gap ratio: 1 - (ink in center row / max ink in any row) (higher => more central horizontal gap)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mean = np.mean(gray)\n    dark = (gray < mean).astype(np.uint8)\n    light = (gray > mean).astype(np.uint8)\n    if np.count_nonzero(dark) == 0 and np.count_nonzero(light) == 0:\n        return 0.0\n    binary = dark if np.count_nonzero(dark) <= np.count_nonzero(light) else light\n    row_counts = np.sum(binary, axis=1)\n    if row_counts.max() == 0:\n        return 0.0\n    center_row = h // 2\n    center_count = row_counts[center_row]\n    ratio = 1.0 - (center_count / (row_counts.max() + 1e-9))\n    return float(ratio)\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference between fraction of ink in the lower third and the middle third (lower_density - middle_density)'\n    # Robust grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # Binarize by choosing the polarity where ink is minority\n    meanv = gray.mean()\n    m1 = gray < meanv\n    m2 = gray > meanv\n    ink = m1 if np.count_nonzero(m1) <= np.count_nonzero(m2) else m2\n    total = float(np.count_nonzero(ink))\n    if total == 0:\n        return 0.0\n    lower = ink[2*h//3:h, :].sum() / total\n    middle = ink[h//3:2*h//3, :].sum() / total\n    return float(lower - middle)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Signed x-offset of the centroid of ink in the top third (normalized to [-0.5,0.5]); positive means centroid is to the right (useful to separate right-skewed 7)'\n    import numpy as np\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    gray = gray.astype(float)\n    thr = (np.nanmin(gray) + np.nanmax(gray)) / 2.0\n    dark_count = np.count_nonzero(gray < thr)\n    ink = (gray < thr) if dark_count < gray.size / 2 else (gray > thr)\n    top_rows = max(1, h // 3)\n    top = ink[:top_rows, :]\n    ys, xs = np.nonzero(top)\n    if xs.size == 0:\n        return 0.0\n    centroid_x = float(xs.mean()) / float(max(1, w))\n    # center is at 0.5, return signed offset in [-0.5,0.5]\n    return centroid_x - 0.5\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean radial gradient alignment: 1 outward, -1 inward, 0 random'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    rx = xs - cx\n    ry = ys - cy\n    rmag = np.hypot(rx, ry)\n    gmag = np.hypot(gx, gy)\n    dot = gx * rx + gy * ry\n    denom = (gmag * rmag) + eps\n    align = dot / denom\n    # consider only pixels with meaningful gradient\n    mask = gmag > np.median(gmag)\n    if not np.any(mask):\n        return 0.0\n    mean_align = float(np.mean(align[mask]))\n    return float(np.clip(mean_align, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variance of the discrete curvature (second differences) of the rightmost ink boundary (higher for more curved shapes like 3)'\n    import numpy as np\n    eps = 1e-6\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.copy()\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    thresh = np.percentile(gray, 40)\n    bin_img = (gray <= thresh).astype(np.uint8)\n    if bin_img.sum() > (h * w) * 0.6:\n        bin_img = 1 - bin_img\n    rightmost = []\n    for r in range(h):\n        cols = np.where(bin_img[r, :])[0]\n        if cols.size:\n            rightmost.append(cols[-1])\n    if len(rightmost) < 3:\n        return 0.0\n    rightmost = np.array(rightmost, dtype=float)\n    # second differences\n    second_diff = rightmost[2:] - 2 * rightmost[1:-1] + rightmost[:-2]\n    return float(np.var(second_diff) / (w**2 + eps))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect difference of bright-region bounding box (0..1), 0=circular/square, 1=very elongated'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    thr = float(a.mean() + a.std())\n    mask = a > thr\n    if np.count_nonzero(mask) < 3:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    w_box = int(xs.max() - xs.min() + 1)\n    h_box = int(ys.max() - ys.min() + 1)\n    denom = max(w_box, h_box, eps)\n    result = abs(w_box - h_box) / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Skewness of the vertical projection (column sums) indicating right-skew or left-skew of ink'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        if image.ndim == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n        thr = 0.5 * (np.percentile(gray, 10) + np.percentile(gray, 90))\n        lower_count = np.sum(gray < thr)\n        ink = (gray < thr) if lower_count < (gray.size - lower_count) else (gray >= thr)\n        col_sums = ink.sum(axis=0).astype(float)\n        if col_sums.sum() == 0:\n            return 0.0\n        p = col_sums / col_sums.sum()\n        xs = np.linspace(0.0, 1.0, num=w)\n        mean = (xs * p).sum()\n        std = np.sqrt(((xs - mean)**2 * p).sum())\n        if std <= 1e-6:\n            return 0.0\n        skew = (( (xs - mean)**3 * p).sum()) / (std**3)\n        return float(skew)\n    except Exception:\n        return 0.0\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of background pixels inside a small central circular region (higher for digits with centered hole like 0)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    fg = gray < thr\n    if np.count_nonzero(fg) > 0.6 * fg.size:\n        fg = ~fg\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = max(1, min(h, w) // 6)\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    mask = ((ys - cy) ** 2 + (xs - cx) ** 2) <= (r ** 2)\n    bg = ~fg\n    region = bg & mask\n    denom = float(np.count_nonzero(mask)) + 1e-6\n    return float(np.count_nonzero(region) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian sharpness proxy: mean absolute Laplacian normalized by mean absolute intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    center = 4.0 * a\n    up = np.roll(a, 1, axis=0)\n    down = np.roll(a, -1, axis=0)\n    left = np.roll(a, 1, axis=1)\n    right = np.roll(a, -1, axis=1)\n    lap = center - (up + down + left + right)\n    mean_abs_lap = float(np.mean(np.abs(lap)))\n    mean_abs_img = float(np.mean(np.abs(a))) + eps\n    result = mean_abs_lap / mean_abs_img\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated number of internal background pixels (holes) normalized by ink area using border flood fill'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    dark_mask = gray < thresh\n    ink = dark_mask if dark_mask.sum() <= (h * w) / 2 else ~dark_mask\n    bg = ~ink\n    # border-reachable background initialization\n    reachable = np.zeros_like(bg, dtype=bool)\n    reachable[0, :] = bg[0, :]\n    reachable[-1, :] = bg[-1, :]\n    reachable[:, 0] = reachable[:, 0] | bg[:, 0]\n    reachable[:, -1] = reachable[:, -1] | bg[:, -1]\n    # iterative expansion using 8-neighborhood until stable or iteration cap\n    pad = lambda arr: np.pad(arr, 1, mode='constant', constant_values=False)\n    hcap = h * w\n    for _ in range(min(1000, hcap)):\n        old = reachable.copy()\n        p = pad(reachable)\n        neigh = (\n            p[0:h, 0:w] | p[0:h, 1:w+1] | p[0:h, 2:w+2] |\n            p[1:h+1, 0:w] | p[1:h+1, 2:w+2] |\n            p[2:h+2, 0:w] | p[2:h+2, 1:w+1] | p[2:h+2, 2:w+2]\n        )\n        reachable = reachable | (bg & neigh)\n        if reachable.sum() == old.sum():\n            break\n    holes = bg & (~reachable)\n    hole_area = float(holes.sum())\n    ink_area = float(ink.sum())\n    if ink_area == 0:\n        return 0.0\n    return float(hole_area / (ink_area + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of intensity histogram (32 bins), higher for more complex textures'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    bins = 32\n    hist, _ = np.histogram(arr, bins=bins, density=False)\n    p = hist.astype(float) / (hist.sum() + 1e-12)\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -np.sum(p_nonzero * np.log2(p_nonzero))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of ink runs (background->ink transitions) per column in the central vertical third (captures vertical fragmentation)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 1:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    thresh = 0.5 * (mn + mx)\n    p = float(np.mean(gray < thresh))\n    ink = (gray < thresh) if p <= 0.5 else (gray > thresh)\n    c0, c1 = w // 3, max(w // 3 + 1, 2 * w // 3)\n    if c1 <= c0:\n        cols = ink\n    else:\n        cols = ink[:, c0:c1]\n    # compute transitions per column\n    diffs = np.diff(cols.astype(int), axis=0)\n    runs_per_col = np.sum(diffs == 1, axis=0)  # count background->ink transitions\n    if runs_per_col.size == 0:\n        return 0.0\n    avg_runs = np.mean(runs_per_col)\n    return float(avg_runs / max(1.0, h))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of very bright pixels (top 0.5 percentile) indicating sparse highlights'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(arr.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    try:\n        thr = float(np.percentile(vals, 99.5))\n    except Exception:\n        thr = float(vals.max())\n    count = float(np.count_nonzero(vals >= thr))\n    result = count / float(vals.size + eps)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels near the dominant intensity mode (background uniformity)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(img.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    bins = 64\n    try:\n        hist, edges = np.histogram(a, bins=bins, range=(float(a.min()), float(a.max())) if a.max() > a.min() else (0.0, 1.0))\n    except Exception:\n        return 0.0\n    if hist.sum() == 0:\n        return 0.0\n    idx = int(np.argmax(hist))\n    bin_low = edges[idx]\n    bin_high = edges[idx+1]\n    # include a small neighborhood around the bin\n    width = (bin_high - bin_low) + eps\n    low = bin_low - 0.5 * width\n    high = bin_high + 0.5 * width\n    count = float(np.count_nonzero((a >= low) & (a <= high)))\n    result = count / float(a.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Centroid offset: normalized distance between intensity centroid and image center (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices(a.shape)\n    total = float(a.sum())\n    if total == 0:\n        return 0.0\n    cx = float((a * xs).sum()) / total\n    cy = float((a * ys).sum()) / total\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    # normalize by image diagonal\n    diag = np.hypot(w, h) + eps\n    return float(np.clip(dist / diag, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity centroid offset normalized by image diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    total = float(arr.sum())\n    if total <= eps:\n        return 0.0\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    cy = float((h - 1) / 2.0)\n    cx = float((w - 1) / 2.0)\n    y_cent = float((arr * ys).sum() / total)\n    x_cent = float((arr * xs).sum() / total)\n    dist = float(np.hypot(y_cent - cy, x_cent - cx))\n    diag = float(np.hypot(cy, cx)) + eps\n    result = dist / diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal vs anti-diagonal gradient energy: sum|gx+gy| / (sum|gx-gy| + eps)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gx, gy = np.gradient(gray)\n    diag = np.sum(np.abs(gx + gy))\n    antidiag = np.sum(np.abs(gx - gy))\n    eps = 1e-6\n    return float(diag / (antidiag + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry: 1 - normalized L1 difference between left half and mirrored right half (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if w < 2 or arr.size == 0:\n        return 0.0\n    mid = w // 2\n    if w % 2 == 0:\n        left = arr[:, :mid]\n        right = arr[:, mid:]\n    else:\n        left = arr[:, :mid]\n        right = arr[:, mid+1:]\n    # mirror right\n    right_m = np.fliplr(right)\n    minw = min(left.shape[1], right_m.shape[1])\n    if minw == 0:\n        return 0.0\n    left_c = left[:, :minw]\n    right_c = right_m[:, :minw]\n    diff = np.abs(left_c - right_c).mean()\n    norm = (np.abs(arr).mean() + eps)\n    score = 1.0 - (diff / norm)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strict local maxima (8-neighborhood) normalized by image size'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    pad_min = float(a.min()) - 1.0\n    p = np.pad(a, 1, mode='constant', constant_values=pad_min)\n    center = p[1:-1, 1:-1]\n    greater = np.ones_like(center, dtype=bool)\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            if dy == 0 and dx == 0:\n                continue\n            neigh = p[1 + dy:1 + dy + h, 1 + dx:1 + dx + w]\n            greater &= (center > neigh)\n    count = float(np.count_nonzero(greater))\n    frac = count / (center.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local variance over 3x3 neighborhoods normalized by global variance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h * w == 0:\n        return 0.0\n    # use integral images to compute 3x3 sums efficiently\n    pad = np.pad(a, 1, mode='reflect').astype(float)\n    s = pad.cumsum(axis=0).cumsum(axis=1)\n    s2 = (pad * pad).cumsum(axis=0).cumsum(axis=1)\n    # window sum for each original pixel (3x3)\n    k = 3\n    total = (s[k:, k:] - s[:-k, k:] - s[k:, :-k] + s[:-k, :-k])\n    total2 = (s2[k:, k:] - s2[:-k, k:] - s2[k:, :-k] + s2[:-k, :-k])\n    area = float(k * k)\n    local_var = (total2 / area) - (total / area) ** 2\n    # ensure non-negative numerical\n    local_var = np.maximum(local_var, 0.0)\n    global_var = float(np.var(a)) + eps\n    mean_local_var = float(np.mean(local_var))\n    result = mean_local_var / global_var\n    # normalize to reasonable range and clip to [0,1]\n    return float(np.clip(result / (1.0 + result), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Correlation slope between row index and row-wise edge energy (signed, normalized)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    h, w = a.shape\n    if h < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    row_energy = np.sum(np.abs(gx) + np.abs(gy), axis=1)\n    y = np.arange(h).astype(float)\n    # slope via covariance\n    y_mean = y.mean()\n    r_mean = row_energy.mean()\n    cov = ((y - y_mean) * (row_energy - r_mean)).mean()\n    var_y = ((y - y_mean) ** 2).mean() + eps\n    slope = cov / var_y\n    # normalize by mean energy to keep scale reasonable\n    norm = float(max(eps, row_energy.mean()))\n    result = slope / norm\n    # clip to avoid extreme values\n    return float(np.clip(result, -5.0, 5.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Downsample stability: mean absolute difference to 2x down-up sample normalized by dynamic range'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    h2 = (h // 2) * 2\n    w2 = (w // 2) * 2\n    if h2 == 0 or w2 == 0:\n        return 0.0\n    ac = a[:h2, :w2]\n    # average 2x2 blocks\n    ac_rs = ac.reshape(h2 // 2, 2, w2 // 2, 2)\n    down = ac_rs.mean(axis=(1, 3))\n    # upsample by repeating\n    up = np.repeat(np.repeat(down, 2, axis=0), 2, axis=1)\n    diff = np.abs(ac - up)\n    denom = float(a.max() - a.min()) + eps\n    result = float(diff.mean()) / denom\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score in [0..1] (1 = perfect symmetry)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w < 2 or h == 0:\n        return 0.0\n    half = w // 2\n    left = a[:, :half]\n    right = a[:, -half:]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    right_flipped = np.fliplr(right)\n    # if widths differ (odd w), crop the larger to match\n    if left.shape[1] != right_flipped.shape[1]:\n        m = min(left.shape[1], right_flipped.shape[1])\n        left = left[:, :m]\n        right_flipped = right_flipped[:, :m]\n    diff = np.abs(left - right_flipped)\n    norm = float(np.mean(np.abs(a))) + eps\n    score = 1.0 - (float(np.mean(diff)) / norm)\n    return float(np.clip(score, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of strong edges located in central region (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + 0.5 * mag.std())\n    strong = mag > thr\n    if not np.any(strong):\n        return 0.0\n    ch1, ch2 = h // 4, 3 * h // 4\n    cw1, cw2 = w // 4, 3 * w // 4\n    center_mask = np.zeros_like(a, dtype=bool)\n    center_mask[ch1:ch2, cw1:cw2] = True\n    center_edges = float(np.sum(strong & center_mask))\n    total_edges = float(np.sum(strong)) + eps\n    result = center_edges / total_edges\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Circular variance of gradient orientations in the lower half (higher for loops/curves)'\n    # convert to grayscale float\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # compute gradients\n    gy, gx = np.gradient(gray)\n    orientation = np.arctan2(gy, gx)  # [-pi, pi]\n    # use lower half\n    lower = orientation[h//2:, :]\n    mag = np.hypot(gy[h//2:, :], gx[h//2:, :])\n    # mask by significant edge magnitude to avoid noise\n    thresh = np.percentile(mag, 50) if mag.size else 0.0\n    mask = mag > max(thresh * 0.3, 1e-6)\n    if not mask.any():\n        return 0.0\n    theta = lower[mask]\n    # orientation is axial (pi periodic), double angles for circular stats\n    doubled = 2.0 * theta\n    c = np.cos(doubled).mean()\n    s = np.sin(doubled).mean()\n    R = np.hypot(c, s)\n    circ_var = float(1.0 - R)\n    return circ_var\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute diagonal gradient along NW-SE vs NE-SW (detects dominant diagonal stroke direction)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gx, gy = np.gradient(gray)\n    # diagonal components\n    diag1 = (gx + gy) / np.sqrt(2.0)  # NW-SE\n    diag2 = (gx - gy) / np.sqrt(2.0)  # NE-SW\n    m1 = np.mean(np.abs(diag1))\n    m2 = np.mean(np.abs(diag2))\n    return float(m1 / (m2 + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate number of connected bright components (capped) after thresholding'\n    import numpy as np\n    eps = 1e-12\n    MAX_CC = 1000\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # choose threshold at 75th percentile to focus on bright components\n    thr = float(np.percentile(a.ravel(), 75))\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    visited = np.zeros_like(mask, dtype=bool)\n    cc = 0\n    # 4-connected neighbors\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                cc += 1\n                if cc >= MAX_CC:\n                    break\n                # iterative flood fill\n                stack = [(y, x)]\n                visited[y, x] = True\n                while stack:\n                    yy, xx = stack.pop()\n                    # neighbors\n                    if yy > 0 and mask[yy - 1, xx] and not visited[yy - 1, xx]:\n                        visited[yy - 1, xx] = True\n                        stack.append((yy - 1, xx))\n                    if yy + 1 < h and mask[yy + 1, xx] and not visited[yy + 1, xx]:\n                        visited[yy + 1, xx] = True\n                        stack.append((yy + 1, xx))\n                    if xx > 0 and mask[yy, xx - 1] and not visited[yy, xx - 1]:\n                        visited[yy, xx - 1] = True\n                        stack.append((yy, xx - 1))\n                    if xx + 1 < w and mask[yy, xx + 1] and not visited[yy, xx + 1]:\n                        visited[yy, xx + 1] = True\n                        stack.append((yy, xx + 1))\n                # continue scanning\n        if cc >= MAX_CC:\n            break\n    # normalize by image area\n    result = float(min(cc, MAX_CC)) / float(h * w + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute vertical gradient on right half to left half (right/left)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray.astype(float))\n    abs_v = np.abs(gy)\n    left_mean = abs_v[:, :w//2].mean() if w//2 > 0 else 0.0\n    right_mean = abs_v[:, w//2:].mean() if w - w//2 > 0 else 0.0\n    # avoid division by zero\n    return float((right_mean + 1e-8) / (left_mean + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of high-contrast patches in a 4x4 grid (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    gs = 4\n    ys = np.linspace(0, h, gs + 1, dtype=int)\n    xs = np.linspace(0, w, gs + 1, dtype=int)\n    global_std = float(a.std()) + eps\n    high_count = 0\n    total = 0\n    for i in range(gs):\n        for j in range(gs):\n            block = a[ys[i]:ys[i+1], xs[j]:xs[j+1]]\n            if block.size == 0:\n                continue\n            total += 1\n            if float(block.std()) > 1.5 * global_std:\n                high_count += 1\n    if total == 0:\n        return 0.0\n    result = float(high_count) / float(total)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Sparsity of very bright pixels: fraction above the 95th percentile'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    total = a.size\n    if total == 0:\n        return 0.0\n    try:\n        thr = float(np.percentile(a, 95))\n    except Exception:\n        thr = float(a.mean())\n    cnt = int(np.count_nonzero(a > thr))\n    return float(cnt) / float(total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energy to total gradient energy (higher when diagonal strokes present, e.g., \"4\")'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    try:\n        gy, gx = np.gradient(gray.astype(float))\n    except Exception:\n        return 0.0\n    # approximate diagonal gradients by rotated components\n    g45 = (gx + gy) / np.sqrt(2.0)\n    g135 = (gx - gy) / np.sqrt(2.0)\n    diag_energy = np.sum(np.abs(g45)) + np.sum(np.abs(g135))\n    total_energy = np.sum(np.abs(gx)) + np.sum(np.abs(gy)) + 1e-9\n    return float(diag_energy / float(total_energy))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientations weighted by magnitude (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 16\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # [-pi, pi]\n    # map to [0, 2*pi)\n    theta = (theta + 2.0 * np.pi) % (2.0 * np.pi)\n    # weighted histogram\n    hist, _ = np.histogram(theta.ravel(), bins=bins, range=(0.0, 2.0 * np.pi), weights=mag.ravel())\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0.0]\n    ent = -float((p * np.log(p)).sum())\n    norm = np.log(float(bins) + eps)\n    result = ent / (norm + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical ink span in upper half to vertical span in lower half (helps separate top-loop digits like 9)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    dark_mask = gray < thresh\n    ink = dark_mask if dark_mask.sum() <= (h * w) / 2 else ~dark_mask\n    if ink.sum() == 0:\n        return 0.0\n    mid = h // 2\n    upper = ink[:mid, :]\n    lower = ink[mid:, :]\n    def vert_span(arr):\n        cols = np.any(arr, axis=0)\n        if not cols.any():\n            return 0.0\n        ys = np.any(arr, axis=1)\n        if not ys.any():\n            return 0.0\n        return float(ys.nonzero()[0].max() - ys.nonzero()[0].min() + 1)\n    upper_span = vert_span(upper)\n    lower_span = vert_span(lower)\n    if lower_span == 0.0:\n        return float(upper_span)\n    return float(upper_span / (lower_span + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized horizontal centroid of ink mass (0=left, 1=right)'\n    import numpy as np\n    # convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # simple threshold between min and mean to find ink (robust for dark-on-light)\n    minv = float(np.min(gray))\n    meanv = float(np.mean(gray))\n    if meanv == minv:\n        return 0.0\n    thresh = (minv + meanv) / 2.0\n    ink = gray < thresh if meanv > minv else gray > thresh\n    ys, xs = np.nonzero(ink)\n    if xs.size == 0:\n        return 0.0\n    cx = float(np.mean(xs)) / float(w)\n    return float(cx)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Global contrast: (max-min) normalized by global std'\n    import numpy as np\n    eps = 1e-8\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    vmin = float(a.min())\n    vmax = float(a.max())\n    gstd = float(a.std()) + eps\n    result = (vmax - vmin) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical-edge centeredness (0..1), 1 => vertical edges concentrated at image center'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    gx_mag = np.abs(gx)\n    col_energy = gx_mag.sum(axis=0)\n    total = col_energy.sum()\n    if total <= eps:\n        return 0.0\n    xs = np.arange(w, dtype=float)\n    centroid = float((col_energy * xs).sum() / (total + eps))\n    center_x = (w - 1) / 2.0\n    dist = abs(centroid - center_x)\n    maxd = center_x if center_x > 0 else eps\n    dist_norm = dist / maxd\n    result = 1.0 - np.clip(dist_norm, 0.0, 1.0)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant gradient orientation concentration (0=uniform, 1=all aligned)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(img)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= 0:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # range [-pi, pi]\n    cx = np.sum(mag * np.cos(theta))\n    cy = np.sum(mag * np.sin(theta))\n    R = np.hypot(cx, cy) / (mag.sum() + eps)\n    return float(np.clip(R, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fill ratio of the bright region in its bounding box (1 = fully filled)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    mean = float(a.mean())\n    std = float(a.std())\n    thresh = mean + 0.5 * std\n    ys, xs = np.nonzero(a > thresh)\n    if ys.size == 0:\n        return 0.0\n    y0, y1 = int(ys.min()), int(ys.max())\n    x0, x1 = int(xs.min()), int(xs.max())\n    bbox_area = max(1, (y1 - y0 + 1) * (x1 - x0 + 1))\n    filled = float(ys.size)\n    result = filled / float(bbox_area + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of strict local peaks (pixel > all 8 neighbors), robust to borders'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h < 1 or w < 1:\n        return 0.0\n    pad = np.pad(arr, 1, mode='edge')\n    center = pad[1:-1, 1:-1]\n    neighbors = [\n        pad[0:-2, 0:-2], pad[0:-2, 1:-1], pad[0:-2, 2:],\n        pad[1:-1, 0:-2],               pad[1:-1, 2:],\n        pad[2:, 0:-2], pad[2:, 1:-1], pad[2:, 2:]\n    ]\n    comp = np.ones_like(center, dtype=bool)\n    for nb in neighbors:\n        comp &= (center > nb)\n    total = float(center.size) + eps\n    peaks = float(np.count_nonzero(comp))\n    result = peaks / total\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Absolute horizontal centroid difference between top third and bottom third normalized by width (detects twisting)'\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn < 1e-8:\n        return 0.0\n    g = (gray - mn) / (mx - mn)\n    mask = (g < 0.5 if np.sum(g < 0.5) <= np.sum(g > 0.5) else g > 0.5).astype(np.uint8)\n    h, w = mask.shape\n    if h < 3 or w == 0:\n        return 0.0\n    t_end = max(1, h // 3)\n    b_start = h - t_end\n    top = mask[:t_end, :]\n    bot = mask[b_start:, :]\n    def centroid_x(m):\n        ink = np.sum(m)\n        if ink == 0:\n            return w / 2.0\n        xs = np.arange(w).reshape((1, w))\n        return float(np.sum(xs * m)) / float(ink)\n    cx_top = centroid_x(top)\n    cx_bot = centroid_x(bot)\n    return float(abs(cx_top - cx_bot)) / float(max(1, w-1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness measure for RGB images (0 for grayscale) normalized by max intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    imgf = np.nan_to_num(img.astype(float))\n    R = imgf[..., 0]\n    G = imgf[..., 1]\n    B = imgf[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(np.std(rg))\n    std_yb = float(np.std(yb))\n    mean_rg = float(np.mean(rg))\n    mean_yb = float(np.mean(yb))\n    # Has commonly used form\n    colorfulness = np.hypot(std_rg, std_yb) + 0.3 * np.hypot(mean_rg, mean_yb)\n    # normalize by typical max intensity (use 1/255 scaling if image appears in 0..255)\n    maxv = float(np.nanmax(imgf)) + eps\n    result = colorfulness / (maxv + eps)\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels that are near-zero intensity (sparsity), scale-invariant'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 1.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 1.0\n    mn = float(flat.min())\n    mx = float(flat.max())\n    dr = mx - mn\n    if dr <= eps:\n        # constant image: consider it 'near-zero' if value near 0\n        return 1.0 if abs(mn) <= 1e-6 else 0.0\n    scaled = (flat - mn) / dr\n    thresh = 0.05\n    near_zero = float(np.count_nonzero(scaled <= thresh))\n    result = near_zero / float(flat.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Texture coarseness: mean local standard deviation over blocks normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    bs = max(1, min(h, w) // 8)\n    local_stds = []\n    for y in range(0, h, bs):\n        for x in range(0, w, bs):\n            block = arr[y:y + bs, x:x + bs]\n            if block.size:\n                local_stds.append(float(block.std()))\n    if not local_stds:\n        return 0.0\n    mean_local = float(np.mean(local_stds))\n    global_std = float(arr.std()) + eps\n    result = mean_local / global_std\n    # coarseness >1 possible; compress to (0..1) via ratio/(1+ratio)\n    result = result / (1.0 + result)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of strong local maxima (strictly greater than 8 neighbors, normalized by image area)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center = a[1:-1, 1:-1]\n    neighbors = [\n        a[:-2, :-2], a[:-2, 1:-1], a[:-2, 2:],\n        a[1:-1, :-2],              a[1:-1, 2:],\n        a[2:, :-2],  a[2:, 1:-1],  a[2:, 2:]\n    ]\n    cond = np.ones_like(center, dtype=bool)\n    for nb in neighbors:\n        cond &= (center > nb)\n    # only count maxima that are above a threshold (median + std) to ignore noise\n    thr = float(np.median(a)) + float(np.std(a))\n    cond &= (center > thr)\n    count = float(np.count_nonzero(cond))\n    area = float(h * w) + eps\n    result = count / area\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean diagonal-gradient (\\\\ direction) to the other diagonal-gradient (/ direction) magnitudes (detects diagonal stroke bias)'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        if h == 0 or w == 0:\n            return 0.0\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        gy, gx = np.gradient(gray)\n        diag1 = np.mean(np.abs(gx + gy))\n        diag2 = np.mean(np.abs(gx - gy))\n        return float((diag1 + 1e-9) / (diag2 + 1e-9))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright-region circularity: 4*pi*area / perimeter^2 for bright mask (0..1), higher => more circular'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    thr = float(np.mean(flat) + np.std(flat))\n    mask = a > thr\n    area = int(np.count_nonzero(mask))\n    if area == 0:\n        return 0.0\n    # perimeter: mask pixels with at least one neighbor False\n    neigh = np.zeros_like(mask, dtype=int)\n    neigh += np.roll(mask, 1, axis=0)\n    neigh += np.roll(mask, -1, axis=0)\n    neigh += np.roll(mask, 1, axis=1)\n    neigh += np.roll(mask, -1, axis=1)\n    neigh += np.roll(np.roll(mask, 1, axis=0), 1, axis=1)\n    neigh += np.roll(np.roll(mask, 1, axis=0), -1, axis=1)\n    neigh += np.roll(np.roll(mask, -1, axis=0), 1, axis=1)\n    neigh += np.roll(np.roll(mask, -1, axis=0), -1, axis=1)\n    perimeter = int(np.count_nonzero(mask & (neigh < 8)))\n    if perimeter <= 0:\n        return 0.0\n    circ = 4.0 * np.pi * float(area) / (float(perimeter) * float(perimeter) + eps)\n    return float(np.clip(circ, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity skewness (third standardized moment), indicating asymmetry of brightness'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    mu = arr.mean()\n    sigma = arr.std()\n    if sigma <= 0:\n        return 0.0\n    skew = np.mean(((arr - mu) / (sigma + eps)) ** 3)\n    return float(np.clip(skew, -10.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of nonzero/binary bounding box (width/height), returns 0.0 if undefined'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    # threshold at mean to find content\n    thr = a.mean()\n    mask = a > thr\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    minr, maxr = int(ys.min()), int(ys.max())\n    minc, maxc = int(xs.min()), int(xs.max())\n    height = maxr - minr + 1\n    width = maxc - minc + 1\n    if height <= 0:\n        return 0.0\n    result = float(width) / float(height)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of ink mass located in the top-right quadrant (helps detect digits with right-side strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float64)\n    else:\n        gray = image.astype(np.float64)\n    mx = gray.max() if gray.size else 1.0\n    if mx > 1.1:\n        gray = gray / mx\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[:3, :].ravel(), gray[-3:, :].ravel(), gray[:, :3].ravel(), gray[:, -3:].ravel()]) if h>=3 and w>=3 else gray.ravel()\n    center = gray[h//4:3*h//4, w//4:3*w//4] if h>=4 and w>=4 else gray\n    border_mean = float(border.mean()) if border.size else 0.0\n    thresh = float(np.percentile(gray, 50)) if gray.size else 0.5\n    ink = (gray < thresh) if border_mean > (center.mean() if center.size else 0.0) else (gray > thresh)\n    ink = ink.astype(np.float64)\n    if ink.sum() <= 1e-9:\n        return 0.0\n    top = slice(0, h//2)\n    right = slice(w//2, w)\n    top_right = ink[top, right].sum()\n    return float(top_right / (ink.sum() + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels in the largest intensity histogram bin (background dominance)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size == 0:\n        return 0.0\n    mn = float(arr.min())\n    mx = float(arr.max())\n    if mx <= mn:\n        return 1.0\n    bins = 32\n    hist, _ = np.histogram(arr, bins=bins, range=(mn, mx))\n    maxcount = float(hist.max()) if hist.size else 0.0\n    result = maxcount / float(arr.size)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Strength of vertical banding: std of column means normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    col_means = a.mean(axis=0)\n    gstd = float(a.std()) + eps\n    result = float(col_means.std()) / gstd\n    # clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative vertical stroke strength: mean absolute vertical gradient in right third divided by left third'\n    try:\n        h, w = image.shape[:2]\n    except Exception:\n        return 0.0\n    if h < 2 or w < 2:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    gy, gx = np.gradient(gray.astype(float))\n    right = slice(max(0, w - w // 3), w)\n    left = slice(0, max(1, w // 3))\n    right_strength = np.mean(np.abs(gy[:, right])) if np.size(gy[:, right]) > 0 else 0.0\n    left_strength = np.mean(np.abs(gy[:, left])) if np.size(gy[:, left]) > 0 else 0.0\n    if left_strength == 0:\n        return float(right_strength)\n    return float(right_strength / (left_strength + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0 = constant, 1 = maximum entropy over bins)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    bins = 64\n    try:\n        hist, _ = np.histogram(flat, bins=bins, range=(float(flat.min()), float(flat.max())) if flat.max() > flat.min() else (0.0, 1.0))\n    except Exception:\n        return 0.0\n    total = float(hist.sum())\n    if total <= 0:\n        return 0.0\n    p = hist.astype(float) / total\n    p_nonzero = p[p > 0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -float((p_nonzero * np.log2(p_nonzero)).sum())\n    # normalize by log2(bins)\n    max_ent = np.log2(bins)\n    result = entropy / (max_ent + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of intensity bounding box (min_dim / max_dim, 0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    mask = a != 0\n    if not np.any(mask):\n        # fallback: use pixels above tiny threshold\n        mask = a > (a.max() * 0.01)\n    if not np.any(mask):\n        return 0.0\n    ys, xs = np.where(mask)\n    y0, y1 = ys.min(), ys.max()\n    x0, x1 = xs.min(), xs.max()\n    hh = float(y1 - y0 + 1)\n    ww = float(x1 - x0 + 1)\n    if hh <= eps or ww <= eps:\n        return 0.0\n    mn = min(hh, ww)\n    mx = max(hh, ww)\n    result = float(mn / (mx + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of border pixels within a small tolerance of the border median (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    rim = max(1, min(h, w) // 12)\n    parts = []\n    parts.append(a[:rim, :].ravel())\n    parts.append(a[-rim:, :].ravel())\n    if h > 2 * rim:\n        parts.append(a[rim:-rim, :rim].ravel())\n        parts.append(a[rim:-rim, -rim:].ravel())\n    border = np.concatenate([p for p in parts if p.size])\n    if border.size == 0:\n        return 0.0\n    med = float(np.median(border))\n    std = float(border.std())\n    vmin = float(a.min()); vmax = float(a.max())\n    range_tol = max(0.02 * (vmax - vmin), 0.25 * std, eps)\n    consistent = np.abs(border - med) <= range_tol\n    frac = float(np.count_nonzero(consistent)) / float(border.size)\n    return float(np.clip(frac, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram tail asymmetry: normalized difference between upper and lower tail masses (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        vals = np.nan_to_num(img.mean(axis=2).ravel().astype(float))\n    else:\n        vals = np.nan_to_num(img.ravel().astype(float))\n    if vals.size == 0:\n        return 0.0\n    p25 = float(np.percentile(vals, 25.0))\n    p75 = float(np.percentile(vals, 75.0))\n    lower = np.count_nonzero(vals < p25)\n    upper = np.count_nonzero(vals > p75)\n    total = float(vals.size) + eps\n    result = (upper - lower) / total\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Lower-left darkness fraction relative to lower-right (helps detect 4 which often has darker lower-left stem area)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    img = np.array(image, dtype=float)\n    h, w = img.shape[:2]\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    dark = (np.max(gray) - gray)\n    # lower half split left/right\n    lower = dark[h // 2 :, :] if h // 2 < h else dark[-1:, :]\n    midc = w // 2\n    left = np.sum(lower[:, :midc]) if midc > 0 else 0.0\n    right = np.sum(lower[:, midc:]) if midc < w else 0.0\n    denom = (left + right + 1e-6)\n    return float(left / denom)\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio in Fourier domain (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    power = np.abs(F) ** 2\n    cy = h // 2\n    cx = w // 2\n    ys, xs = np.ogrid[:h, :w]\n    r = np.hypot(ys - cy, xs - cx)\n    # define low-frequency radius as min dimension / 8\n    r0 = max(1.0, min(h, w) / 8.0)\n    low_mask = r <= r0\n    low_energy = float(power[low_mask].sum())\n    total_energy = float(power.sum()) + eps\n    high_energy = total_energy - low_energy\n    result = float(high_energy / total_energy)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute horizontal gradient to mean absolute vertical gradient restricted to the right half (captures right-side curvature)'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        # smooth-ish by simple local mean to reduce noise\n        # compute gradients\n        gx, gy = np.gradient(gray.astype(float))\n        right_gx = gx[:, w//2:]\n        right_gy = gy[:, w//2:]\n        mag_x = np.mean(np.abs(right_gx)) if right_gx.size > 0 else 0.0\n        mag_y = np.mean(np.abs(right_gy)) if right_gy.size > 0 else 0.0\n        if mag_y == 0:\n            return float(mag_x)\n        return float(mag_x) / float(mag_y)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Orientation-preferring edge coherence: +1=>horizontal, -1=>vertical, magnitude accounts for coherence'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # [-pi, pi]\n    # use doubled angle to treat theta and theta+pi as same orientation\n    cos2 = np.cos(2.0 * theta) * mag\n    sin2 = np.sin(2.0 * theta) * mag\n    cos_sum = float(cos2.sum())\n    sin_sum = float(sin2.sum())\n    mag_sum = float(mag.sum()) + eps\n    # orientation preference in [-1,1]; positive => horizontal-dominant, negative => vertical-dominant\n    result = cos_sum / mag_sum\n    return float(np.clip(result, -1.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-contrast fraction: fraction of pixels within 5% of dynamic range around median'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.ravel(np.nan_to_num(arr.mean(axis=2).astype(float)))\n    else:\n        vals = np.ravel(np.nan_to_num(arr.astype(float)))\n    if vals.size == 0:\n        return 0.0\n    vmin = float(vals.min())\n    vmax = float(vals.max())\n    dr = vmax - vmin\n    if dr <= 0:\n        return 1.0\n    med = float(np.median(vals))\n    tol = 0.05 * dr\n    frac = float(np.count_nonzero((vals >= med - tol) & (vals <= med + tol))) / float(vals.size)\n    return float(frac)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant histogram bin ratio: fraction of pixels in the largest intensity bin (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    bins = 16\n    hist, _ = np.histogram(vals, bins=bins, range=(vals.min(), vals.max() if vals.max() > vals.min() else vals.min()+1.0))\n    top = float(hist.max())\n    total = float(hist.sum()) + 1e-12\n    result = top / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal gradient strength in the right half: mean|dx| / (mean|dy| + eps) on right half'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    dy, dx = np.gradient(gray)\n    right_dx = np.abs(dx[:, w//2:])\n    right_dy = np.abs(dy[:, w//2:])\n    mean_dx = float(np.mean(right_dx))\n    mean_dy = float(np.mean(right_dy))\n    result = float(mean_dx / (mean_dy + 1e-9))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance of the brightest pixel to image center (0..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = img.mean(axis=2).astype(float)\n    else:\n        a = img.astype(float)\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    idx = int(np.argmax(a))\n    y, x = np.unravel_index(idx, a.shape)\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    dist = float(np.hypot(x - cx, y - cy))\n    maxdist = float(np.hypot(cx, cy))\n    if maxdist <= 0.0:\n        return 0.0\n    result = float(np.clip(dist / maxdist, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Color channel mean divergence: std of channel means normalized by overall mean'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 2:\n        return 0.0\n    channels = img.shape[2]\n    try:\n        means = img.mean(axis=(0, 1)).astype(float)\n    except Exception:\n        means = np.array([float(np.mean(img[..., c])) for c in range(channels)])\n    mean_of_means = float(means.mean())\n    std_of_means = float(means.std())\n    result = std_of_means / (abs(mean_of_means) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bottom horizontal gradient strength: mean absolute horizontal gradient in bottom strip (detect bottom bar)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    low_mean = np.mean(gray[gray <= p10]) if np.any(gray <= p10) else p10\n    high_mean = np.mean(gray[gray >= p90]) if np.any(gray >= p90) else p90\n    ink_dark = low_mean < high_mean\n    thr = np.percentile(gray, 50)\n    fg = (gray <= thr) if ink_dark else (gray >= thr)\n    gy, gx = np.gradient(gray.astype(np.float64))\n    horiz_abs = np.abs(gx)\n    bottom_h = max(1, h // 5)\n    region = horiz_abs[h - bottom_h:, :]\n    fg_region = fg[h - bottom_h:, :]\n    # weight by foreground presence to emphasize strokes\n    weighted = region * (fg_region.astype(np.float64))\n    mean_val = weighted.mean() if weighted.size else 0.0\n    return float(mean_val)\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized Shannon entropy of intensity histogram (0..1, higher => more complex)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    bins = 32\n    hist, _ = np.histogram(a.ravel(), bins=bins, range=(float(a.min()), float(a.max()) + eps))\n    hist = hist.astype(float)\n    total = hist.sum() + eps\n    p = hist / total\n    p_nonzero = p[p > 0]\n    H = -np.sum(p_nonzero * np.log(p_nonzero + eps))\n    # normalize by log(bins)\n    result = H / (np.log(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal edge energy ratio: (sum of absolute diagonal gradients) divided by total gradient energy (0..1)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute diagonal gradients using shifts\n    g1 = np.zeros_like(gray)\n    g2 = np.zeros_like(gray)\n    # shift down-right minus original\n    g1[:-1, :-1] = gray[1:, 1:] - gray[:-1, :-1]\n    # shift down-left minus original\n    g2[:-1, 1:] = gray[1:, :-1] - gray[:-1, 1:]\n    diag_energy = np.sum(np.abs(g1)) + np.sum(np.abs(g2))\n    # horizontal and vertical gradients\n    gx = np.zeros_like(gray)\n    gy = np.zeros_like(gray)\n    gx[:, :-1] = gray[:, 1:] - gray[:, :-1]\n    gy[:-1, :] = gray[1:, :] - gray[:-1, :]\n    total = diag_energy + np.sum(np.abs(gx)) + np.sum(np.abs(gy))\n    if total <= 0:\n        return 0.0\n    return float(diag_energy / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of connected ink components (after simple threshold) as a float'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thr = np.mean(gray) - 0.25 * np.std(gray)\n    mask = (gray < thr).astype(np.uint8)\n    if mask.sum() == 0:\n        return 0.0\n    visited = np.zeros_like(mask, dtype=bool)\n    comp_count = 0\n    # stack-based flood fill\n    for i in range(h):\n        for j in range(w):\n            if mask[i, j] and not visited[i, j]:\n                comp_count += 1\n                stack = [(i, j)]\n                visited[i, j] = True\n                while stack:\n                    y, x = stack.pop()\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = y + dy, x + dx\n                            if 0 <= ny < h and 0 <= nx < w and not visited[ny, nx] and mask[ny, nx]:\n                                visited[ny, nx] = True\n                                stack.append((ny, nx))\n    return float(comp_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of intensity histogram normalized to [0,1]'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    bins = 32\n    try:\n        hist, _ = np.histogram(flat, bins=bins, range=(flat.min(), flat.max()))\n    except Exception:\n        hist, _ = np.histogram(flat, bins=bins)\n    p = hist.astype(float)\n    s = p.sum()\n    if s <= 0:\n        return 0.0\n    p = p / s\n    p = p[p > 0]\n    ent = -np.sum(p * np.log2(p))\n    max_ent = np.log2(bins) if bins > 1 else 1.0\n    return float(np.clip(ent / (max_ent + 1e-12), 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean absolute horizontal offset of enclosed hole centroids from image center, normalized by width (0 if no holes)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.mean(gray))\n    cand = gray < thr\n    if np.sum(cand) > gray.size / 2:\n        ink = ~cand\n    else:\n        ink = cand\n    ink = ink.astype(bool)\n    # exterior fill\n    exterior = np.zeros_like(ink, dtype=bool)\n    from collections import deque\n    q = deque()\n    for i in range(h):\n        for j in (0, w-1):\n            if not ink[i, j] and not exterior[i, j]:\n                exterior[i, j] = True\n                q.append((i, j))\n    for j in range(w):\n        for i in (0, h-1):\n            if not ink[i, j] and not exterior[i, j]:\n                exterior[i, j] = True\n                q.append((i, j))\n    while q:\n        i, j = q.popleft()\n        for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n            ni, nj = i+di, j+dj\n            if 0 <= ni < h and 0 <= nj < w and (not ink[ni, nj]) and (not exterior[ni, nj]):\n                exterior[ni, nj] = True\n                q.append((ni, nj))\n    internal = (~ink) & (~exterior)\n    visited = np.zeros_like(internal, dtype=bool)\n    offsets = []\n    for i in range(h):\n        for j in range(w):\n            if internal[i, j] and not visited[i, j]:\n                # BFS\n                pts = []\n                q = deque()\n                q.append((i, j))\n                visited[i, j] = True\n                pts.append((i, j))\n                while q:\n                    ci, cj = q.popleft()\n                    for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ni, nj = ci+di, cj+dj\n                        if 0 <= ni < h and 0 <= nj < w and internal[ni, nj] and not visited[ni, nj]:\n                            visited[ni, nj] = True\n                            pts.append((ni, nj))\n                            q.append((ni, nj))\n                pts = np.array(pts)\n                cx = float(np.mean(pts[:,1]))\n                offsets.append(abs(cx - (w-1)/2.0))\n    if len(offsets) == 0:\n        return 0.0\n    return float(np.mean(offsets) / max(1.0, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Strength ratio of NW-SE diagonal gradient to NE-SW diagonal gradient (useful for slanted tails)'\n    import numpy as np\n    if image is None:\n        return 1.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    # diag1 approximates differences along top-left to bottom-right\n    if gray.shape[0] < 2 or gray.shape[1] < 2:\n        return 1.0\n    diag1 = gray[:-1, :-1] - gray[1:, 1:]\n    diag2 = gray[1:, :-1] - gray[:-1, 1:]\n    s1 = np.sum(np.abs(diag1))\n    s2 = np.sum(np.abs(diag2))\n    eps = 1e-6\n    return float(s1 / (s2 + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal gradient strength: mean|dx-dy| / (mean|dx+dy| + eps). Emphasizes TR->BL vs TL->BR diagonals'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray)  # gy = d/dy, gx = d/dx\n    a = np.mean(np.abs(gx - gy))\n    b = np.mean(np.abs(gx + gy))\n    return float(a / (b + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity slope from center (positive => brighter toward edge)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    y, x = np.indices((h, w))\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    r = np.hypot(y - cy, x - cx)\n    maxr = float(r.max()) + eps\n    nbins = min(12, max(3, int(maxr)))\n    bins = np.linspace(0.0, maxr, nbins + 1)\n    inds = np.digitize(r.ravel(), bins) - 1\n    bin_centers = (bins[:-1] + bins[1:]) / 2.0\n    means = []\n    centers = []\n    for i in range(nbins):\n        mask = inds == i\n        if not np.any(mask):\n            continue\n        means.append(float(a.ravel()[mask].mean()))\n        centers.append(bin_centers[i])\n    if len(means) < 2:\n        return 0.0\n    try:\n        slope = float(np.polyfit(centers, means, 1)[0])\n    except Exception:\n        return 0.0\n    intensity_range = float(a.max() - a.min()) + eps\n    # normalize by range and max radius to make comparable across sizes\n    result = slope / (intensity_range * maxr + eps)\n    return float(np.clip(result, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized vertical centroid of the ink (y-coordinate of center of mass, 0=top, 1=bottom)'\n    import numpy as np\n    # Normalize to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # Determine ink mask (assume ink is the minority of pixels)\n    thresh = np.mean(gray)\n    dark_mask = gray < thresh\n    if dark_mask.sum() <= (h * w) / 2:\n        ink = dark_mask\n    else:\n        ink = ~dark_mask\n    ink_count = float(ink.sum())\n    if ink_count == 0:\n        return 0.0\n    ys, xs = np.nonzero(ink)\n    centroid_y = ys.mean() / max(1.0, h - 1)\n    return float(centroid_y)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative high-frequency energy via absolute Laplacian normalized by total absolute intensity'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    # discrete Laplacian (4-neighbor)\n    up = np.roll(a, -1, axis=0)\n    down = np.roll(a, 1, axis=0)\n    left = np.roll(a, -1, axis=1)\n    right = np.roll(a, 1, axis=1)\n    lap = (up + down + left + right) - 4.0 * a\n    energy = float(np.sum(np.abs(lap)))\n    denom = float(np.sum(np.abs(a))) + 1e-12\n    result = energy / denom\n    # clip to a reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) computed from 16-bin histogram'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    # convert to single-channel intensity\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    arr = a.ravel()\n    if arr.size == 0:\n        return 0.0\n    # histogram\n    bins = 16\n    mn, mx = float(arr.min()), float(arr.max())\n    if mx <= mn:\n        return 0.0\n    hist, _ = np.histogram(arr, bins=bins, range=(mn, mx))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0.0]\n    if p.size == 0:\n        return 0.0\n    entropy = -float((p * np.log(p + eps)).sum())\n    max_entropy = float(np.log(bins))\n    result = entropy / (max_entropy + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of edge orientation histogram (0..1 where 1 = maximal orientation disorder)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    ang = np.arctan2(gy, gx)  # [-pi, pi]\n    # map orientation to [0, pi) since opposite directions equivalent for orientation\n    ang = np.mod(ang, np.pi)\n    nbins = 36\n    flat = ang.ravel()\n    hist, _ = np.histogram(flat, bins=nbins, range=(0.0, np.pi))\n    total = float(hist.sum()) + eps\n    probs = hist.astype(float) / total\n    probs = probs[probs > 0]\n    ent = -float(np.sum(probs * np.log2(probs + eps)))\n    max_ent = float(np.log2(nbins))\n    score = ent / (max_ent + eps)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean normalized radial distance of pixels above median (0=centered, 1=at periphery)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    med = float(np.median(arr))\n    mask = arr > med\n    if not np.any(mask):\n        return 0.0\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    dist = np.hypot(ys - cy, xs - cx)\n    maxd = float(dist.max()) + eps\n    mean_dist = float(np.mean(dist[mask]))\n    result = mean_dist / maxd\n    result = float(np.clip(result, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of extreme pixels near min/max (useful for clipping/overexposure detection)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        flat = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(arr.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    p_low = float(np.percentile(flat, 1))\n    p_high = float(np.percentile(flat, 99))\n    count_low = float(np.count_nonzero(flat <= p_low))\n    count_high = float(np.count_nonzero(flat >= p_high))\n    frac = (count_low + count_high) / (flat.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels brighter than mean + 0.5*std (simple foreground ratio)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        vals = np.nan_to_num(arr.astype(float))\n    thr = float(vals.mean() + 0.5 * vals.std())\n    mask = vals > thr\n    n_total = float(vals.size) + eps\n    result = float(np.count_nonzero(mask)) / n_total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal gradient energies (NE-SW over NW-SE) to detect slanted strokes like in 7 or skewed 5/6'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    gy, gx = np.gradient(gray.astype(float))\n    diag_ne_sw = gx - gy   # one diagonal orientation\n    diag_nw_se = gx + gy   # the other diagonal orientation\n    e1 = np.sum(np.abs(diag_ne_sw))\n    e2 = np.sum(np.abs(diag_nw_se))\n    return float((e1 + 1e-8) / (e2 + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute horizontal gradient in upper half to that in lower half (indicates horizontal stroke concentration up/down)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    gy, gx = np.gradient(gray)\n    abs_gx = np.abs(gx)\n    h = gray.shape[0]\n    upper = abs_gx[:h//2, :]\n    lower = abs_gx[h//2:, :]\n    mu_upper = float(np.mean(upper)) if upper.size else 0.0\n    mu_lower = float(np.mean(lower)) if lower.size else 0.0\n    if mu_lower == 0.0:\n        return float(mu_upper)\n    return float(mu_upper / mu_lower)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Perimeter-to-area ratio of largest mean-thresholded component (higher => more complex)'\n    import numpy as np\n    from collections import deque\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        gray = np.nan_to_num(img.astype(float))\n    h, w = gray.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = gray.mean()\n    mask = gray > thr\n    if not mask.any():\n        return 0.0\n    visited = np.zeros_like(mask, dtype=bool)\n    max_area = 0\n    max_perim = 0\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                area = 0\n                perim = 0\n                dq = deque()\n                dq.append((y, x))\n                visited[y, x] = True\n                while dq:\n                    cy, cx = dq.popleft()\n                    area += 1\n                    # check 4-neighbors\n                    for ny, nx in ((cy-1, cx), (cy+1, cx), (cy, cx-1), (cy, cx+1)):\n                        if ny < 0 or ny >= h or nx < 0 or nx >= w or not mask[ny, nx]:\n                            perim += 1\n                        elif not visited[ny, nx]:\n                            visited[ny, nx] = True\n                            dq.append((ny, nx))\n                if area > max_area:\n                    max_area = area\n                    max_perim = perim\n    if max_area == 0:\n        return 0.0\n    ratio = float(max_perim) / (float(max_area) + eps)\n    return float(ratio)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean number of ink/background transitions per horizontal scanline (rows) - closed loops produce ~2 transitions'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = (gray > thr).astype(np.uint8)\n    if h == 0:\n        return 0.0\n    # For each row count transitions 0->1 or 1->0\n    transitions = np.count_nonzero(ink[:, :-1] != ink[:, 1:], axis=1)\n    # Return average transitions per row (float)\n    return float(np.mean(transitions))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric normalized by dynamic range (0..1); returns 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    imgf = np.nan_to_num(img.astype(float))\n    R = imgf[:, :, 0]\n    G = imgf[:, :, 1]\n    B = imgf[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    dyn = float(max(imgf.max() - imgf.min(), eps))\n    result = float(np.clip(colorfulness / dyn, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical edge density: fraction of pixels with strong vertical gradient (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag_v = np.abs(gx)\n    mean = float(mag_v.mean())\n    std = float(mag_v.std())\n    thresh = mean + std\n    count = float((mag_v > thresh).sum())\n    total = float(mag_v.size) + eps\n    result = float(np.clip(count / total, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized global intensity entropy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    vals = a.ravel()\n    # choose moderate number of bins\n    bins = 32\n    try:\n        hist, _ = np.histogram(vals, bins=bins)\n    except Exception:\n        return 0.0\n    hist = hist.astype(float) + eps\n    p = hist / hist.sum()\n    entropy = -np.sum(p * np.log(p + eps))\n    # normalize by log(bins)\n    norm = entropy / (np.log(bins) + eps)\n    return float(np.clip(norm, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of columns that contain a continuous vertical ink run longer than 50% of image height, normalized by width'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    low = gray[gray <= thresh]\n    high = gray[gray > thresh]\n    if low.size == 0 or high.size == 0:\n        ink = gray <= thresh\n    else:\n        ink = gray <= thresh if (low.mean() < high.mean()) else (gray >= thresh)\n    count_cols = 0\n    min_len = max(1, h // 2)\n    for j in range(w):\n        col = ink[:, j]\n        # find longest contiguous True run\n        max_run = 0\n        run = 0\n        for val in col:\n            if val:\n                run += 1\n                if run > max_run:\n                    max_run = run\n            else:\n                run = 0\n        if max_run >= min_len:\n            count_cols += 1\n    return float(count_cols / float(max(1, w)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    '90-10 percentile contrast normalized by mean intensity'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    p90 = float(np.percentile(a, 90))\n    p10 = float(np.percentile(a, 10))\n    mean = float(a.mean())\n    eps = 1e-8\n    result = (p90 - p10) / (abs(mean) + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'RGB channel contrast: (max channel mean - min channel mean) normalized by gray std (0 if not RGB)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # use first three channels\n    ch_means = a[..., :3].mean(axis=(0, 1))\n    diff = float(np.max(ch_means) - np.min(ch_means))\n    gray = a[..., :3].mean(axis=2)\n    gstd = float(np.std(gray)) + eps\n    result = diff / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0 for grayscale)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    arr = np.nan_to_num(img.astype(float))\n    R = arr[:, :, 0]\n    G = arr[:, :, 1]\n    B = arr[:, :, 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    # Hasler and S\u00fcsstrunk colorfulness\n    result = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    return float(max(0.0, result + 0.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Angle of principal component of ink pixels relative to vertical (0..1 where 1 ~= 90 degrees)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    rng = np.max(gray) - np.min(gray)\n    thr = np.mean(gray) - 0.15 * (rng if rng > 0 else 1.0)\n    ink = gray < thr\n    if np.count_nonzero(ink) < 4:\n        ink = gray > thr\n    coords = np.argwhere(ink)\n    if coords.shape[0] < 3:\n        return 0.0\n    # center coords\n    pts = coords.astype(float)\n    pts -= pts.mean(axis=0)\n    cov = np.cov(pts, rowvar=False)\n    # eigen decomposition (2x2)\n    try:\n        vals, vecs = np.linalg.eigh(cov)\n    except Exception:\n        return 0.0\n    # principal eigenvector corresponds to largest eigenvalue\n    idx = np.argmax(vals)\n    vx, vy = vecs[:, idx]\n    # vector points in (row, col) coordinates; angle relative to vertical axis:\n    # vertical axis is (1,0) in row,col space. Compute angle between (vx,vy) and vertical.\n    dot = vx * 1.0 + vy * 0.0\n    mag = max(1e-9, np.hypot(vx, vy))\n    cos_theta = np.clip(dot / mag, -1.0, 1.0)\n    angle_rad = np.arccos(cos_theta)  # 0 = aligned with vertical, pi/2 = horizontal\n    angle_deg = angle_rad * (180.0 / np.pi)\n    return float(angle_deg / 90.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean signed horizontal balance of edge strength in the upper half (captures asymmetry of top curve orientations)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    upper = gray[0:h // 2, :]\n    # approximate gradients\n    gx = np.abs(np.gradient(upper, axis=1))\n    gy = np.abs(np.gradient(upper, axis=0))\n    # signed measure: positive when horizontal edges stronger, negative when vertical stronger\n    diff = gx - gy\n    # weight right side a bit more to emphasize curvature on the right\n    weights = np.linspace(0.5, 1.5, upper.shape[1])[None, :]\n    weighted = diff * weights\n    result = float(np.mean(weighted)) / (np.mean(np.abs(diff)) + 1e-8)\n    return result\n",
    "def feature(image: np.ndarray) -> float:\n    'Perimeter-to-area ratio: boundary pixel count divided by ink pixel count (higher = more perimeter relative to area)'\n    try:\n        if len(image.shape) == 3:\n            gray = image.mean(axis=2)\n        else:\n            gray = image.astype(float)\n        g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n        border = np.concatenate([g[0:1, :].ravel(), g[-1:, :].ravel(), g[:, 0:1].ravel(), g[:, -1:].ravel()])\n        border_mean = float(np.mean(border)) if border.size else 0.5\n        if border_mean > 0.5:\n            ink = g < max(0.0, border_mean - 0.15)\n        else:\n            ink = g > min(1.0, border_mean + 0.15)\n        h, w = ink.shape\n        if np.count_nonzero(ink) == 0:\n            return 0.0\n        pad = np.pad(ink, pad_width=1, mode='constant', constant_values=False)\n        eroded = np.ones_like(ink, dtype=bool)\n        for dy, dx in ((0,0),(1,0),(-1,0),(0,1),(0,-1)):\n            eroded &= pad[1+dy : 1+dy+h, 1+dx : 1+dx+w]\n        boundary = ink & (~eroded)\n        perim = float(np.count_nonzero(boundary))\n        area = float(np.count_nonzero(ink))\n        return float(perim / max(1e-9, area))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative right-edge strength: mean vertical gradient magnitude in right third divided by left third ( >1 => stronger edges on right )'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    grayf = gray.astype(float)\n    h, w = grayf.shape[:2]\n    # compute vertical gradient (abs difference along columns)\n    gy = np.abs(np.gradient(grayf, axis=0))\n    gx = np.abs(np.gradient(grayf, axis=1))\n    mag = gx + gy\n    third = max(1, w // 3)\n    left_mean = np.mean(mag[:, :third]) if third > 0 else 0.0\n    right_mean = np.mean(mag[:, -third:]) if third > 0 else 0.0\n    if left_mean == 0:\n        return float(right_mean)\n    return float(right_mean / left_mean)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of ink pixels falling inside the central 50% x 50% box (detects central loops like in 9)'\n    try:\n        h, w = image.shape[:2]\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        p40 = np.percentile(gray, 40)\n        p60 = np.percentile(gray, 60)\n        mask_dark = gray < p40\n        mask_light = gray > p60\n        mask = mask_dark if mask_dark.sum() <= mask_light.sum() and mask_dark.sum() > 0 else (mask_light if mask_light.sum() > 0 else (gray < gray.mean()))\n        ch0, ch1 = h//4, w//4\n        center_block = mask[ch0:h-ch0, ch1:w-ch1]\n        total = float(np.count_nonzero(mask))\n        if total == 0:\n            return 0.0\n        return float(np.count_nonzero(center_block)) / total\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Saturation fraction: fraction of pixels near data range extremes (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    if a.ndim == 3 and a.shape[2] >= 1:\n        mins = a.min(axis=(0, 1))\n        maxs = a.max(axis=(0, 1))\n        ranges = maxs - mins\n        small = ranges < eps\n        ranges[small] = eps\n        low_thr = mins + 0.01 * ranges\n        high_thr = maxs - 0.01 * ranges\n        # pixel is saturated if any channel near low or high\n        low_mask = (a <= low_thr[None, None, :]).any(axis=2)\n        high_mask = (a >= high_thr[None, None, :]).any(axis=2)\n        mask = low_mask | high_mask\n        total = float(a.shape[0] * a.shape[1])\n    else:\n        # grayscale\n        mins = a.min()\n        maxs = a.max()\n        if maxs - mins < eps:\n            return 0.0\n        low_thr = mins + 0.01 * (maxs - mins)\n        high_thr = maxs - 0.01 * (maxs - mins)\n        mask = (a <= low_thr) | (a >= high_thr)\n        total = float(a.size)\n    count = float(np.count_nonzero(mask))\n    result = count / (total + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Interquartile contrast: (75th-25th percentile) relative to mean intensity'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    p75 = np.percentile(a, 75)\n    p25 = np.percentile(a, 25)\n    meanv = float(np.mean(a)) + eps\n    result = (float(p75) - float(p25)) / meanv\n    return float(np.clip(result, 0.0, 10.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity profile variance normalized by global variance (higher => rings or radial structure)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    ys, xs = np.indices(a.shape)\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = int(np.floor(r.max()))\n    if maxr <= 0:\n        return 0.0\n    radial_means = []\n    for rad in range(maxr + 1):\n        mask = (np.floor(r) == rad)\n        if np.any(mask):\n            radial_means.append(float(a[mask].mean()))\n    radial_means = np.array(radial_means)\n    if radial_means.size < 2:\n        return 0.0\n    var_radial = float(radial_means.var())\n    global_var = float(a.var()) + eps\n    result = var_radial / global_var\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean gradient magnitude on the right half minus left half (positive if right half has stronger edges)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray)\n    mag = np.sqrt(gx*gx + gy*gy)\n    left_mag = np.mean(mag[:, :w//2]) if w//2 > 0 else 0.0\n    right_mag = np.mean(mag[:, w//2:]) if w - w//2 > 0 else 0.0\n    return float(right_mag - left_mag)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between a central small region and its surrounding annulus (helps detect holes/loops)'\n    # Robust grayscale conversion\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h < 4 or w < 4:\n        return 0.0\n    # define radii\n    r = max(1, min(h, w) // 12)\n    cy, cx = h // 2, w // 2\n    yy, xx = np.ogrid[:h, :w]\n    dist = np.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n    center_mask = dist <= r\n    annulus_mask = (dist > r) & (dist <= 2 * r)\n    # compute means; if annulus empty, fallback to surrounding square\n    center_mean = float(np.mean(gray[center_mask])) if np.any(center_mask) else 0.0\n    if np.any(annulus_mask):\n        annulus_mean = float(np.mean(gray[annulus_mask]))\n    else:\n        pad = max(1, r)\n        y0, y1 = max(0, cy - 2 * pad), min(h, cy + 2 * pad)\n        x0, x1 = max(0, cx - 2 * pad), min(w, cx + 2 * pad)\n        ring = gray[y0:y1, x0:x1].copy()\n        annulus_mean = float(np.mean(ring)) if ring.size else center_mean\n    # For typical images ink is darker (lower values); a hole gives annulus darker than center\n    return float(annulus_mean - center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    '180-degree rotational symmetry (1 = perfect symmetry, 0 = very different)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    try:\n        rot = np.rot90(arr, 2)\n    except Exception:\n        return 0.0\n    denom = float(np.mean(np.abs(arr))) + eps\n    diff = np.abs(arr - rot)\n    mean_diff = float(np.mean(diff))\n    result = 1.0 - (mean_diff / denom)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized horizontal edge strength in the top band (captures a top bar) as top_horizontal / total_horizontal'\n    try:\n        import numpy as np\n        h, w = image.shape[:2]\n        if h < 2:\n            return 0.0\n        gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n        gy, gx = np.gradient(gray)\n        horiz = np.abs(gx)\n        top_band = horiz[:max(1, h//4), :]\n        total = np.sum(horiz)\n        top_sum = np.sum(top_band)\n        if total <= 0:\n            return 0.0\n        return float(top_sum / (total + 1e-12))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average vertical position (0..1) of hole centroids; 0 if no hole (0=top,1=bottom)'\n    try:\n        if len(image.shape) == 3:\n            gray = image.mean(axis=2)\n        else:\n            gray = image.astype(float)\n        g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n        border = np.concatenate([g[0:1, :].ravel(), g[-1:, :].ravel(), g[:, 0:1].ravel(), g[:, -1:].ravel()])\n        border_mean = float(np.mean(border)) if border.size else 0.5\n        if border_mean > 0.5:\n            ink = g < max(0.0, border_mean - 0.15)\n        else:\n            ink = g > min(1.0, border_mean + 0.15)\n        h, w = ink.shape\n        bg = ~ink\n        ext = np.zeros_like(bg, dtype=bool)\n        stack = []\n        for i in range(h):\n            for j in (0, w-1):\n                if bg[i, j] and not ext[i, j]:\n                    stack.append((i, j)); ext[i, j] = True\n        for j in range(w):\n            for i in (0, h-1):\n                if bg[i, j] and not ext[i, j]:\n                    stack.append((i, j)); ext[i, j] = True\n        while stack:\n            y, x = stack.pop()\n            for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                ny, nx = y+dy, x+dx\n                if 0 <= ny < h and 0 <= nx < w and bg[ny, nx] and not ext[ny, nx]:\n                    ext[ny, nx] = True\n                    stack.append((ny, nx))\n        enclosed = bg & (~ext)\n        visited = np.zeros_like(enclosed, dtype=bool)\n        centroids = []\n        for i in range(h):\n            for j in range(w):\n                if enclosed[i, j] and not visited[i, j]:\n                    area = 0\n                    sumy = 0.0\n                    q = [(i, j)]\n                    visited[i, j] = True\n                    while q:\n                        y, x = q.pop()\n                        area += 1\n                        sumy += y\n                        for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                            ny, nx = y+dy, x+dx\n                            if 0 <= ny < h and 0 <= nx < w and enclosed[ny, nx] and not visited[ny, nx]:\n                                visited[ny, nx] = True\n                                q.append((ny, nx))\n                    if area > 0:\n                        centroids.append((sumy / area))\n        if len(centroids) == 0:\n            return 0.0\n        avg_y = float(np.mean(centroids))\n        return float(avg_y / max(1.0, h))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized spectral centroid (0=low-frequency, 1=high-frequency)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    img = img - img.mean()\n    try:\n        F = np.fft.fftshift(np.fft.fft2(img))\n    except Exception:\n        return 0.0\n    M = np.abs(F)\n    if M.sum() <= 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(ys - cy, xs - cx)\n    maxr = float(r.max()) + 1e-12\n    centroid = float((M * r).sum()) / float(M.sum())\n    result = centroid / maxr\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarseness: mean local variance over medium-size blocks normalized by overall variance'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    overall_var = arr.var()\n    if overall_var <= 0:\n        return 0.0\n    # choose block size based on smaller dimension\n    block = max(1, min(h, w) // 8)\n    bh = block\n    bw = block\n    # pad to multiple of block\n    pad_h = (-h) % bh\n    pad_w = (-w) % bw\n    if pad_h or pad_w:\n        arr_p = np.pad(arr, ((0, pad_h), (0, pad_w)), mode='reflect')\n    else:\n        arr_p = arr\n    H, W = arr_p.shape\n    arr_blocks = arr_p.reshape(H // bh, bh, W // bw, bw)\n    # compute variance within each block\n    block_vars = arr_blocks.transpose(0,2,1,3).reshape(-1, bh*bw).var(axis=1)\n    mean_block_var = float(np.mean(block_vars)) if block_vars.size else 0.0\n    result = mean_block_var / (overall_var + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1) using 64 bins'\n    import numpy as np\n    eps = 1e-12\n    bins = 64\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    flat = img.ravel()\n    if flat.size == 0:\n        return 0.0\n    mn = float(flat.min())\n    mx = float(flat.max())\n    if mx <= mn:\n        return 0.0\n    scaled = np.floor((flat - mn) / (mx - mn) * (bins - 1)).astype(int)\n    hist = np.bincount(scaled, minlength=bins).astype(float)\n    p = hist / (hist.sum() + eps)\n    entropy = -float(np.sum(np.where(p > 0, p * np.log(p + eps), 0.0)))\n    max_ent = float(np.log(bins))\n    result = entropy / (max_ent + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels with gradient magnitude above mean+std (edge density)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(img)\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    mask = mag > thr\n    result = float(np.count_nonzero(mask)) / float(h * w + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity centroid offset normalized by image diagonal (0=centered, 1=corner)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    total = float(a.sum())\n    if total <= eps:\n        return 0.0\n    cx = float((xs * a).sum()) / total\n    cy = float((ys * a).sum()) / total\n    midx = (w - 1) / 2.0\n    midy = (h - 1) / 2.0\n    dist = np.hypot(cx - midx, cy - midy)\n    max_dist = np.hypot(midx, midy)\n    result = float(dist / (max_dist + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels that lie within a border band (border ink density / total ink)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    minv = float(np.min(gray))\n    meanv = float(np.mean(gray))\n    if meanv == minv:\n        return 0.0\n    thresh = (minv + meanv) / 2.0\n    ink = (gray < thresh) if meanv > minv else (gray > thresh)\n    bw = max(1, min(h, w) // 10)\n    border_mask = np.zeros_like(ink, dtype=bool)\n    border_mask[:bw, :] = True\n    border_mask[-bw:, :] = True\n    border_mask[:, :bw] = True\n    border_mask[:, -bw:] = True\n    total = float(np.sum(ink))\n    if total == 0:\n        return 0.0\n    border = float(np.sum(ink & border_mask))\n    return float(border / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized difference of hole area between upper and lower halves of bounding box (top - bottom)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.percentile(gray, 50)\n    mask = gray < thr\n    if mask.sum() < max(5, int(0.005 * h * w)):\n        mask = gray > thr\n    if mask.sum() == 0:\n        return 0.0\n    ys, xs = np.nonzero(mask)\n    r0, r1 = ys.min(), ys.max()\n    c0, c1 = xs.min(), xs.max()\n    sub = mask[r0:r1+1, c0:c1+1]\n    inv = ~sub\n    H, W = inv.shape\n    # mark outer background\n    visited = np.zeros_like(inv, dtype=bool)\n    stack = []\n    for i in range(H):\n        for j in (0, W-1):\n            if inv[i, j] and not visited[i, j]:\n                stack.append((i, j)); visited[i, j] = True\n                while stack:\n                    y, x = stack.pop()\n                    for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                        ny, nx = y+dy, x+dx\n                        if 0 <= ny < H and 0 <= nx < W and inv[ny, nx] and not visited[ny, nx]:\n                            visited[ny, nx] = True; stack.append((ny, nx))\n    # count hole pixels in top half and bottom half\n    top_hole = 0\n    bottom_hole = 0\n    for i in range(H):\n        for j in range(W):\n            if inv[i, j] and not visited[i, j]:\n                # part of hole\n                if i < H // 2:\n                    top_hole += 1\n                else:\n                    bottom_hole += 1\n    denom = float(top_hole + bottom_hole) + 1e-8\n    return float((top_hole - bottom_hole) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of transitions (background<->ink) along the central horizontal row'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = np.mean(gray)\n    fg = gray < thresh\n    if np.count_nonzero(fg) > 0.5 * h * w:\n        fg = ~fg\n    mid = h // 2\n    row = fg[mid, :].astype(int)\n    transitions = np.count_nonzero(np.diff(row) != 0)\n    return float(transitions) / float(w)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest continuous vertical ink run in the right third of the image, normalized by image height'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.percentile(gray, 50)\n    ink_dark = np.mean(gray.flatten()[:max(1, int(0.05*h*w))]) < np.mean(gray.flatten()[-max(1, int(0.05*h*w)):])\n    if ink_dark:\n        ink = gray < thresh\n    else:\n        ink = gray > thresh\n    start_col = max(0, 2*w // 3)\n    region = ink[:, start_col:w]\n    # compute longest vertical run per column, take max\n    longest = 0\n    for c in range(region.shape[1]):\n        col = region[:, c]\n        cur = 0\n        maxc = 0\n        for v in col:\n            if v:\n                cur += 1\n                if cur > maxc: maxc = cur\n            else:\n                cur = 0\n        if maxc > longest: longest = maxc\n    return float(longest / (h + 1e-8))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average of the longest horizontal ink run per row in the central band (measures mid-line continuity like the middle bar of 5)'\n    import numpy as np\n    h, w = image.shape[:2]\n    r0 = h // 3\n    r1 = min(h, 2 * h // 3)\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    band = gray[r0:r1, :]\n    if band.size == 0:\n        return 0.0\n    thr = np.mean(band) - 0.5 * np.std(band)\n    mask = band < thr\n    if mask.sum() == 0:\n        thr = np.percentile(band, 50)\n        mask = band < thr\n    runs = []\n    for row in mask.astype(np.uint8):\n        if row.sum() == 0:\n            runs.append(0)\n            continue\n        dif = np.diff(np.concatenate(([0], row, [0])))\n        starts = np.where(dif == 1)[0]\n        ends = np.where(dif == -1)[0]\n        if starts.size and ends.size:\n            runs.append((ends - starts).max())\n        else:\n            runs.append(0)\n    avg_longest = float(np.mean(runs)) / float(w + 1e-9)\n    return avg_longest\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of radial distances of foreground pixels from centroid (normalized) \u2014 \"0\" tends to have larger circular spread'\n    import numpy as np\n    arr = np.array(image, dtype=float)\n    if arr.ndim == 3:\n        gray = np.mean(arr, axis=2)\n    else:\n        gray = arr\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    th = np.mean(gray)\n    fg = gray < th\n    if np.count_nonzero(fg) > gray.size / 2:\n        fg = ~fg\n    ys, xs = np.nonzero(fg)\n    if xs.size == 0:\n        return 0.0\n    cx, cy = np.mean(xs), np.mean(ys)\n    dists = np.sqrt((xs - cx) ** 2 + (ys - cy) ** 2)\n    std = np.std(dists)\n    # normalize by image diagonal\n    diag = np.sqrt(w * w + h * h)\n    return float(std / (diag + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of intensity distribution (normalized to [0..1])'\n    import numpy as np\n    eps = 1e-12\n    bins = 16\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    flat = img.ravel()\n    if flat.size == 0:\n        return 0.0\n    hist, _ = np.histogram(flat, bins=bins, range=(flat.min(), flat.max()))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0]\n    if p.size == 0:\n        return 0.0\n    entropy = -float((p * np.log(p + eps)).sum())\n    # normalize by max possible entropy log(bins)\n    result = entropy / (np.log(bins) + eps)\n    result = float(np.clip(result, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Asymmetry between a narrow band around the main diagonal and the anti-diagonal: (main - anti) / (main + anti + eps)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img.astype(float)\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = np.mean(border) if border.size else np.mean(gray)\n    thresh = (border_mean + np.mean(gray)) / 2.0\n    fg = gray < thresh if border_mean > np.mean(gray) else gray > thresh\n    # create coordinate grid\n    ys = np.arange(h)[:, None]\n    xs = np.arange(w)[None, :]\n    # compute distance to main diagonal (y-x) and anti-diagonal (y-(w-1-x))\n    band_width = max(1, int(min(h, w) * 0.08))\n    main_dist = np.abs(ys - xs)\n    anti_dist = np.abs(ys - (w-1 - xs))\n    main_band = main_dist <= band_width\n    anti_band = anti_dist <= band_width\n    main_sum = float(np.count_nonzero(fg & main_band))\n    anti_sum = float(np.count_nonzero(fg & anti_band))\n    eps = 1e-6\n    return float((main_sum - anti_sum) / (main_sum + anti_sum + eps))\n",
    "def feature(image: np.ndarray) -> float:\n    'Checkerboardness: fraction of 2x2 blocks with alternating sign around block mean'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = img.mean(axis=2).astype(float)\n    else:\n        a = img.astype(float)\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    a00 = a[:-1, :-1]; a01 = a[:-1, 1:]; a10 = a[1:, :-1]; a11 = a[1:, 1:]\n    bmean = (a00 + a01 + a10 + a11) / 4.0\n    v00 = a00 - bmean; v01 = a01 - bmean; v10 = a10 - bmean; v11 = a11 - bmean\n    pos_pattern = (v00 > 0) & (v11 > 0) & (v01 < 0) & (v10 < 0)\n    neg_pattern = (v00 < 0) & (v11 < 0) & (v01 > 0) & (v10 > 0)\n    mask = pos_pattern | neg_pattern\n    total = mask.size\n    if total == 0:\n        return 0.0\n    frac = float(np.count_nonzero(mask)) / float(total)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding box aspect ratio of the foreground (height/width); returns 0 if no foreground'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    thr = float(np.mean(gray)) if np.mean(gray) != np.min(gray) else (float(np.min(gray)) + 1.0)\n    fg_idx = np.argwhere(gray > thr)\n    if fg_idx.size == 0:\n        return 0.0\n    rows = fg_idx[:, 0]\n    cols = fg_idx[:, 1]\n    h = float(rows.max() - rows.min() + 1)\n    w = float(cols.max() - cols.min() + 1)\n    if w == 0.0:\n        return float(h)\n    return float(h / w)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean stroke thickness in the central vertical band to the average of top and bottom thirds (lower for pinched/8)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    img = np.array(image, dtype=float)\n    gray = np.mean(img, axis=2) if img.ndim == 3 else img\n    h, w = gray.shape[:2]\n    if h < 3 or w < 3:\n        return 0.0\n    rng = float(gray.max() - gray.min())\n    thr = float(np.mean(gray) - 0.15 * rng)\n    mask = gray < thr\n    if mask.sum() < 5 or mask.sum() > 0.95 * gray.size:\n        thr = float(np.median(gray))\n        mask = gray < thr\n    if mask.sum() > 0 and np.mean(gray[mask]) > np.mean(gray[~mask]):\n        mask = ~mask\n    # thickness per row = number of contiguous ink pixels in that row (we use sum across row as proxy)\n    row_sums = mask.sum(axis=1).astype(float)\n    top_mean = np.mean(row_sums[:max(1, h//3)])\n    bottom_mean = np.mean(row_sums[max(2*h//3, h//3):])\n    center_slice = mask[max(h//3 - 1, 0):min(2*h//3 + 1, h), max(w//2 - max(1, w//10),0):min(w, w//2 + max(1, w//10))]\n    center_thickness = float(np.sum(center_slice) / max(1, center_slice.shape[0]))\n    denom = (top_mean + bottom_mean) / 2.0\n    if denom <= 0:\n        return float(center_thickness)\n    return float(center_thickness / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity skewness (third standardized moment) clipped to [-5,5]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    mean = float(a.mean())\n    std = float(a.std()) + eps\n    skew = float(np.mean(((a - mean) / std) ** 3))\n    return float(np.clip(skew, -5.0, 5.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge pixel density using gradient magnitude threshold (0..1)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    m = mag.mean()\n    s = mag.std()\n    thr = m + 0.5 * s\n    edges = (mag > thr)\n    result = float(edges.sum()) / float(a.size)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink pixels located in the bottom quarter of the image'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    eps = 1e-8\n    t = np.percentile(gray, 40)\n    ink = gray <= t\n    if np.count_nonzero(ink) == 0:\n        t2 = np.percentile(gray, 60)\n        ink = gray >= t2\n    if np.count_nonzero(ink) == 0:\n        return 0.0\n    bottom_start = int(3 * h / 4)\n    bottom_ink = ink[bottom_start:h, :].sum()\n    total_ink = ink.sum()\n    return float(bottom_ink / (total_ink + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of 8-connected ink components normalized by total pixels (higher if disjoint pieces exist)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    thresh = (float(np.min(gray)) + float(np.max(gray))) / 2.0\n    ink = (gray < thresh)\n    visited = np.zeros_like(ink, dtype=bool)\n    comps = 0\n    stack = []\n    for i in range(h):\n        for j in range(w):\n            if ink[i, j] and not visited[i, j]:\n                comps += 1\n                # flood fill (8-connected)\n                stack.append((i, j))\n                visited[i, j] = True\n                while stack:\n                    y, x = stack.pop()\n                    for dy in (-1, 0, 1):\n                        for dx in (-1, 0, 1):\n                            ny, nx = y + dy, x + dx\n                            if (0 <= ny < h) and (0 <= nx < w) and not visited[ny, nx] and ink[ny, nx]:\n                                visited[ny, nx] = True\n                                stack.append((ny, nx))\n    return float(comps / (h * w + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Structure-tensor anisotropy (0=isotropic, 1=strong single orientation)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    Sxx = float((gx * gx).mean())\n    Syy = float((gy * gy).mean())\n    Sxy = float((gx * gy).mean())\n    T = Sxx + Syy\n    # determinant\n    det = Sxx * Syy - Sxy * Sxy\n    disc = max(0.0, T * T - 4.0 * det)\n    sqrt_disc = np.sqrt(disc)\n    lam1 = 0.5 * (T + sqrt_disc)\n    lam2 = 0.5 * (T - sqrt_disc)\n    result = (lam1 - lam2) / (lam1 + lam2 + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative prevalence difference between descending and ascending diagonal gradients (-1..1); positive means more descending-diagonal structure'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    mag = np.hypot(gx, gy)\n    if mag.max() <= 0:\n        return 0.0\n    # threshold to ignore noise\n    thr = max(np.percentile(mag, 60), mag.max() * 0.1)\n    ang = np.degrees(np.arctan2(gy, gx))\n    # descending diagonal: angle around -45 degrees (top-right to bottom-left or vice versa depending on coordinate system)\n    desc_mask = (mag >= thr) & (ang >= -70) & (ang <= -20)\n    asc_mask = (mag >= thr) & (ang >= 20) & (ang <= 70)\n    desc = desc_mask.sum()\n    asc = asc_mask.sum()\n    denom = float(desc + asc + 1e-6)\n    return float((desc - asc) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean gradient magnitude normalized by mean absolute intensity (edge energy)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    denom = float(np.mean(np.abs(a))) + 1e-12\n    result = float(np.mean(mag)) / denom\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in the right half to ink in the left half (captures horizontal bias)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy()\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thresh = float(np.percentile(gray.flatten(), 35))\n    ink = (gray <= thresh)\n    left = float(np.count_nonzero(ink[:, :w//2]))\n    right = float(np.count_nonzero(ink[:, w//2:]))\n    # return ratio right / left (symmetric if left is zero)\n    return float((right + 1e-6) / (left + 1e-6))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of ink contained in a top-center circular region (detects upper loops typical of 9)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.percentile(gray.flatten(), 40)\n    mask = gray < thr\n    if np.count_nonzero(mask) == 0:\n        mask = gray < np.mean(gray)\n    cy = max(h // 6, 1)\n    cx = w // 2\n    rad = max(min(h, w) // 6, 2)\n    ys, xs = np.ogrid[:h, :w]\n    circle = (ys - cy) ** 2 + (xs - cx) ** 2 <= rad * rad\n    ink_in_circle = float(np.count_nonzero(np.logical_and(mask, circle)))\n    total_ink = float(np.count_nonzero(mask))\n    return float(ink_in_circle / (total_ink + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink density in right third to left third (helps detect 4 which often has heavier right-side vertical stroke)'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        flat = gray.flatten()\n        t1 = np.percentile(flat, 30)\n        t2 = np.percentile(flat, 70)\n        cand1 = gray < t1\n        cand2 = gray > t2\n        total = h * w\n        if 0 < cand1.sum() <= total // 2:\n            ink = cand1\n        elif 0 < cand2.sum() <= total // 2:\n            ink = cand2\n        else:\n            med = np.median(flat)\n            ink = gray < med\n        left = ink[:, :max(1, w // 3)].sum()\n        right = ink[:, max(1, 2 * w // 3):].sum()\n        return float(right / (left + 1e-12))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Junction density: fraction of ink pixels that have 4 or more ink neighbors (stroke intersections)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    lo30, hi70 = np.percentile(gray, 30), np.percentile(gray, 70)\n    bg_light = gray.mean() > (gray.max() + gray.min()) / 2.0\n    if bg_light:\n        ink = (gray < lo30).astype(np.uint8)\n    else:\n        ink = (gray > hi70).astype(np.uint8)\n    total_ink = float(ink.sum())\n    if total_ink == 0:\n        return 0.0\n    padded = np.pad(ink, 1, mode='constant', constant_values=0)\n    neighbor_sum = np.zeros_like(ink, dtype=np.int32)\n    for dr in (-1, 0, 1):\n        for dc in (-1, 0, 1):\n            if dr == 0 and dc == 0:\n                continue\n            neighbor_sum += padded[1+dr:h+1+dr, 1+dc:w+1+dc]\n    junctions = float(((ink == 1) & (neighbor_sum >= 4)).sum())\n    return float(junctions / (total_ink + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical symmetry score: normalized correlation between left and mirrored right halves'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, w - mid:w]\n    if left.size == 0 or right.size == 0:\n        return 0.0\n    right_flipped = np.fliplr(right)\n    L = left.ravel() - left.mean()\n    R = right_flipped.ravel() - right_flipped.mean()\n    denom = (np.linalg.norm(L) * np.linalg.norm(R) + eps)\n    corr = float(np.dot(L, R) / denom)\n    return float(np.clip(corr, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of long horizontal runs in the top third of the image (number of continuous ink segments wider than 40% of width)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.count_nonzero(ink) > 0.9 * h * w:\n        ink = gray > thr\n    top = ink[:max(1, h//3), :]\n    minlen = max(1, int(0.4 * w))\n    count = 0\n    for r in range(top.shape[0]):\n        row = top[r, :].astype(int)\n        # find run lengths\n        diffs = np.diff(np.concatenate(([0], row, [0])))\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        lengths = ends - starts\n        count += int(np.sum(lengths >= minlen))\n    return float(count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Kurtosis-based tailness of intensity distribution (tanh-compressed)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.astype(float).mean(axis=2)).ravel()\n    else:\n        arr = np.nan_to_num(img.astype(float)).ravel()\n    if arr.size < 4:\n        return 0.0\n    mu = float(arr.mean())\n    sd = float(arr.std())\n    if sd <= 0:\n        return 0.0\n    kurt = float(((arr - mu) ** 4).mean()) / (sd ** 4) - 3.0\n    # compress range to (-1,1) to be stable\n    result = float(np.tanh(kurt / 10.0))\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in top-right quadrant to ink in top-left quadrant (large values indicate right-top heavy shapes like a 9 loop)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(gray.min()), float(gray.max())\n    grayn = (gray - mn) / (mx - mn + 1e-9)\n    ink = (grayn < 0.5)\n    top = slice(0, h//2)\n    left = slice(0, w//2)\n    right = slice(w//2, w)\n    top_right = np.count_nonzero(ink[top, right])\n    top_left = np.count_nonzero(ink[top, left])\n    return float(top_right) / (float(top_left) + 1e-6)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference in number of holes in the upper half vs lower half (upper - lower)'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.mean(ink) > 0.75:\n        ink = ~ink\n    # compute reachable background from borders\n    visited = np.zeros((h, w), dtype=bool)\n    stack = []\n    for i in range(h):\n        for j in (0, w - 1):\n            if not ink[i, j] and not visited[i, j]:\n                visited[i, j] = True\n                stack.append((i, j))\n    for j in range(w):\n        for i in (0, h - 1):\n            if not ink[i, j] and not visited[i, j]:\n                visited[i, j] = True\n                stack.append((i, j))\n    while stack:\n        i, j = stack.pop()\n        for di in (-1, 0, 1):\n            ni = i + di\n            if ni < 0 or ni >= h:\n                continue\n            for dj in (-1, 0, 1):\n                nj = j + dj\n                if nj < 0 or nj >= w:\n                    continue\n                if not ink[ni, nj] and not visited[ni, nj]:\n                    visited[ni, nj] = True\n                    stack.append((ni, nj))\n    holes = (~visited) & (~ink)\n    # count hole components separately in upper and lower halves\n    visited_holes = np.zeros_like(holes, dtype=bool)\n    upper_count = 0\n    lower_count = 0\n    for i in range(h):\n        for j in range(w):\n            if holes[i, j] and not visited_holes[i, j]:\n                # flood fill this hole component\n                comp_stack = [(i, j)]\n                visited_holes[i, j] = True\n                ys = [i]\n                while comp_stack:\n                    x, y = comp_stack.pop()\n                    for di in (-1, 0, 1):\n                        nx = x + di\n                        if nx < 0 or nx >= h:\n                            continue\n                        for dj in (-1, 0, 1):\n                            ny = y + dj\n                            if ny < 0 or ny >= w:\n                                continue\n                            if holes[nx, ny] and not visited_holes[nx, ny]:\n                                visited_holes[nx, ny] = True\n                                comp_stack.append((nx, ny))\n                                ys.append(nx)\n                # assign component to half by majority of pixels' rows\n                mean_row = np.mean(ys)\n                if mean_row < h / 2.0:\n                    upper_count += 1\n                else:\n                    lower_count += 1\n    return float(upper_count - lower_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of gradient magnitude aligned with ~45\u00b0 diagonal (captures prominent slanted stroke)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gx, gy = np.gradient(gray.astype(float), axis=1), np.gradient(gray.astype(float), axis=0)\n    mag = np.hypot(gx, gy)\n    total_mag = np.sum(mag) + 1e-9\n    ang = np.arctan2(gy, gx)  # radians\n    deg = np.degrees(ang)\n    # consider angles around +45 and -135 (same orientation)\n    mask45 = (deg >= 25) & (deg <= 65)\n    mask135 = (deg <= -115) & (deg >= -155)\n    aligned = np.sum(mag * (mask45 | mask135))\n    return float(aligned / total_mag)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Inter-quadrant mean absolute difference normalized by overall mean (0..1+)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    hy = h // 2\n    wx = w // 2\n    q1 = img[:hy, :wx]\n    q2 = img[:hy, wx:]\n    q3 = img[hy:, :wx]\n    q4 = img[hy:, wx:]\n    means = []\n    for q in (q1, q2, q3, q4):\n        means.append(float(q.mean()) if q.size else 0.0)\n    means = np.array(means)\n    pairwise = np.abs(means[:, None] - means[None, :])\n    # average off-diagonal\n    avg_diff = float(pairwise.sum() - np.trace(pairwise)) / (12.0 + eps)\n    overall_mean = float(np.abs(img).mean()) + eps\n    result = avg_diff / overall_mean\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score (0..1) based on normalized correlation with mirror'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mirrored = a[:, ::-1]\n    a_mean = a.mean()\n    m_mean = mirrored.mean()\n    a_zero = a - a_mean\n    m_zero = mirrored - m_mean\n    num = float((a_zero * m_zero).sum())\n    den = float(np.sqrt((a_zero**2).sum() * (m_zero**2).sum())) + eps\n    corr = num / den\n    score = float(np.clip(abs(corr), 0.0, 1.0))\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Solidity-like measure: area of largest connected ink component divided by its bounding-box area (0..1)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    t = (np.percentile(gray, 30) + np.percentile(gray, 70)) / 2.0\n    lower_mean = gray[gray <= t].mean() if np.any(gray <= t) else t\n    upper_mean = gray[gray > t].mean() if np.any(gray > t) else t\n    if lower_mean < upper_mean:\n        ink = (gray <= t)\n    else:\n        ink = (gray >= t)\n    ink = ink.astype(np.uint8)\n    visited = np.zeros_like(ink, dtype=bool)\n    largest_area = 0\n    largest_bbox_area = 1\n    for i in range(h):\n        for j in range(w):\n            if ink[i, j] and not visited[i, j]:\n                area = 0\n                minr, maxr = i, i\n                minc, maxc = j, j\n                stack = [(i, j)]\n                visited[i, j] = True\n                while stack:\n                    r, c = stack.pop()\n                    area += 1\n                    if r < minr: minr = r\n                    if r > maxr: maxr = r\n                    if c < minc: minc = c\n                    if c > maxc: maxc = c\n                    for dr, dc in ((1,0),(-1,0),(0,1),(0,-1),(1,1),(1,-1),(-1,1),(-1,-1)):\n                        nr, nc = r+dr, c+dc\n                        if 0 <= nr < h and 0 <= nc < w and ink[nr, nc] and not visited[nr, nc]:\n                            visited[nr, nc] = True\n                            stack.append((nr, nc))\n                bbox_area = max(1, (maxr - minr + 1) * (maxc - minc + 1))\n                if area > largest_area:\n                    largest_area = area\n                    largest_bbox_area = bbox_area\n    if largest_area == 0:\n        return 0.0\n    return float(largest_area) / float(largest_bbox_area)\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimate hole area ratio: fraction of ink-area that surrounds enclosed background (holes). 8 has two holes, 0 has one, 5 typically none'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    # robust thresholding as above\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    if border_mean > np.median(gray):\n        thr = (border_mean + float(np.min(gray))) / 2.0\n        ink = (gray < thr)\n    else:\n        thr = (border_mean + float(np.max(gray))) / 2.0\n        ink = (gray > thr)\n    ink = ink.astype(np.bool_)\n    if h == 0 or w == 0:\n        return 0.0\n    # flood-fill to find background connected to borders\n    bg = np.zeros_like(ink, dtype=bool)\n    stack = []\n    # push border background pixels\n    for c in range(w):\n        if not ink[0, c]:\n            stack.append((0, c))\n            bg[0, c] = True\n        if not ink[h - 1, c]:\n            stack.append((h - 1, c))\n            bg[h - 1, c] = True\n    for r in range(h):\n        if not ink[r, 0]:\n            stack.append((r, 0))\n            bg[r, 0] = True\n        if not ink[r, w - 1]:\n            stack.append((r, w - 1))\n            bg[r, w - 1] = True\n    # 4-connected flood fill\n    while stack:\n        r, c = stack.pop()\n        for dr, dc in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n            rr, cc = r + dr, c + dc\n            if 0 <= rr < h and 0 <= cc < w and (not bg[rr, cc]) and (not ink[rr, cc]):\n                bg[rr, cc] = True\n                stack.append((rr, cc))\n    holes = (~ink) & (~bg)\n    hole_area = float(np.count_nonzero(holes))\n    ink_area = float(np.count_nonzero(ink))\n    if ink_area <= 0:\n        return 0.0\n    return float(hole_area) / ink_area\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in the upper-left quadrant to ink in the upper-right quadrant (top-left/top-right asymmetry)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = float(np.percentile(gray, 50))\n    mask_dark = gray < thr\n    if float(mask_dark.mean()) > 0.6 or float(mask_dark.mean()) < 0.01:\n        thr = float(np.mean(gray))\n        mask_dark = gray < thr\n    mask = (mask_dark if float(mask_dark.mean()) <= 0.6 else (~mask_dark)).astype(bool)\n    if mask.sum() == 0:\n        return 0.0\n    ul = mask[:h//2, :w//2].sum()\n    ur = mask[:h//2, w//2:].sum()\n    return float((ul + 1e-6) / (ur + 1e-6))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Texture coarseness ratio: mean local variance(7x7) / mean local variance(3x3)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h < 1 or w < 1:\n        return 0.0\n    def mean_local_var(a, k):\n        if k <= 0 or k > a.shape[0] or k > a.shape[1]:\n            return 0.0\n        # integral images\n        I = np.zeros((h + 1, w + 1), dtype=float)\n        I2 = np.zeros((h + 1, w + 1), dtype=float)\n        I[1:, 1:] = np.cumsum(np.cumsum(a, axis=0), axis=1)\n        I2[1:, 1:] = np.cumsum(np.cumsum(a * a, axis=0), axis=1)\n        s = I[k:, k:] - I[:-k, k:] - I[k:, :-k] + I[:-k, :-k]\n        s2 = I2[k:, k:] - I2[:-k, k:] - I2[k:, :-k] + I2[:-k, :-k]\n        n = float(k * k)\n        var = (s2 - (s * s) / n) / n\n        # numerical issues\n        var = np.maximum(var, 0.0)\n        return float(var.mean()) if var.size else 0.0\n    v3 = mean_local_var(arr, 3)\n    v7 = mean_local_var(arr, 7)\n    eps = 1e-12\n    result = v7 / (v3 + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized distance of the brightest pixel from image center (0=center, 1=corner)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    idx = np.argmax(img)\n    h, w = img.shape\n    y, x = divmod(int(idx), w)\n    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n    dist = np.hypot(y - cy, x - cx)\n    max_dist = np.hypot(max(cy, h - 1 - cy), max(cx, w - 1 - cx))\n    result = float(dist / (max_dist + eps))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Largest vertical background run in the center column within the top half normalized by image height'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink = (gray < thresh)\n    center_col = w // 2\n    col = ink[:h//2, center_col]  # top half center column\n    # find longest run of False (background) in this column slice\n    max_run = 0\n    cur = 0\n    for val in col:\n        if not val:\n            cur += 1\n            if cur > max_run:\n                max_run = cur\n        else:\n            cur = 0\n    return float(max_run / float(h + 1e-9))\n",
    "def feature(image: np.ndarray) -> float:\n    'Left vs right ink imbalance: (left - right) / total_ink (negative = right-heavy)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gmin, gmax = float(np.min(gray)), float(np.max(gray))\n    if gmax == gmin:\n        return 0.0\n    thr = (gmin + gmax) / 2.0\n    low_count = np.sum(gray < thr)\n    high_count = np.sum(gray > thr)\n    ink = (gray < thr) if low_count < high_count else (gray > thr)\n    total = float(np.count_nonzero(ink))\n    if total == 0.0:\n        return 0.0\n    left = float(np.count_nonzero(ink[:, :w // 2]))\n    right = float(np.count_nonzero(ink[:, w // 2:]))\n    return float((left - right) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of local intensity peaks above mean+std (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mu = float(a.mean())\n    sd = float(a.std())\n    thresh = mu + sd\n    padded = np.pad(a, pad_width=1, mode='constant', constant_values=-np.inf)\n    center = padded[1:-1, 1:-1]\n    local_max = np.ones_like(center, dtype=bool)\n    for dy in (-1, 0, 1):\n        for dx in (-1, 0, 1):\n            if dy == 0 and dx == 0:\n                continue\n            neigh = padded[1+dy:h+1+dy, 1+dx:w+1+dx]\n            local_max &= (center > neigh)\n    peaks = (local_max & (center > thresh))\n    count = int(np.count_nonzero(peaks))\n    result = float(count) / float(h * w + eps)\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Centroid offset magnitude: distance between intensity centroid and image center normalized by diagonal (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total = float(a.sum())\n    if total == 0.0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (xs * a).sum() / total\n    cy = (ys * a).sum() / total\n    center_x = (w - 1) / 2.0\n    center_y = (h - 1) / 2.0\n    dist = np.hypot(cx - center_x, cy - center_y)\n    diag = np.hypot(w, h) + 1e-12\n    result = float(dist / diag)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (width / height) of the ink bounding box (indicates round vs tall/diagonal shapes)'\n    import numpy as np\n    eps = 1e-9\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gmin, gmax = gray.min(), gray.max()\n    denom = (gmax - gmin) + eps\n    norm = (gray - gmin) / denom\n    low_count = int(np.count_nonzero(norm < 0.5))\n    high_count = h * w - low_count\n    if low_count <= high_count:\n        ink = norm < 0.5\n    else:\n        ink = norm >= 0.5\n    ys, xs = np.where(ink)\n    if ys.size == 0:\n        return 0.0\n    min_y, max_y = ys.min(), ys.max()\n    min_x, max_x = xs.min(), xs.max()\n    bw = float(max_x - min_x + 1)\n    bh = float(max_y - min_y + 1)\n    return float(bw / (bh + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial spectral centroid of 2D FFT (0 = low-frequency dominated, 1 = high-frequency dominated)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(a))\n    except Exception:\n        return 0.0\n    P = np.abs(F) ** 2\n    cy, cx = h // 2, w // 2\n    ys = np.arange(h)[:, None] - cy\n    xs = np.arange(w)[None, :] - cx\n    r = np.hypot(ys, xs)\n    total = P.sum() + eps\n    centroid = (r * P).sum() / total\n    rmax = float(np.hypot(max(cy, h - cy), max(cx, w - cx))) + eps\n    norm = centroid / rmax\n    return float(np.clip(norm, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Perimeter-to-area ratio of a median-thresholded mask (shape complexity proxy)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.median(a))\n    mask = a > thr\n    area = float(mask.sum())\n    if area <= 0.0:\n        return 0.0\n    # count neighbors that are also foreground\n    neigh_count = np.zeros_like(mask, dtype=int)\n    neigh_count += np.roll(mask, 1, axis=0)\n    neigh_count += np.roll(mask, -1, axis=0)\n    neigh_count += np.roll(mask, 1, axis=1)\n    neigh_count += np.roll(mask, -1, axis=1)\n    # a foreground pixel with any background neighbor contributes to perimeter\n    perimeter = float(np.count_nonzero(mask & (neigh_count < 4)))\n    result = (perimeter + eps) / (area + eps)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Correlation between row index and ink centroid x across rows (pearson r, between -1 and 1)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    h, w = gray.shape[:2]\n    thr = np.mean(gray) - 0.15 * np.std(gray)\n    mask = (gray < thr).astype(np.uint8)\n    cols = np.arange(w)\n    ys = []\n    xs = []\n    for r in range(h):\n        row = mask[r, :]\n        s = row.sum()\n        if s > 0:\n            ys.append(float(r))\n            xs.append(float((row * cols).sum() / s))\n    if len(xs) < 2:\n        return 0.0\n    xs = np.array(xs)\n    ys = np.array(ys)\n    xs_mean = xs.mean()\n    ys_mean = ys.mean()\n    cov = ((xs - xs_mean) * (ys - ys_mean)).sum()\n    xs_std = xs.std()\n    ys_std = ys.std()\n    denom = (xs_std * ys_std * len(xs))\n    if denom == 0:\n        return 0.0\n    rcoef = cov / denom\n    # clamp to [-1,1]\n    rcoef = max(-1.0, min(1.0, float(rcoef)))\n    return float(rcoef)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Local texture coarseness: mean 5x5 patch std normalized by global std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    # compute local mean and mean of squares over 5x5 using rolled sums\n    offsets = range(-2, 3)\n    sum1 = np.zeros_like(img, dtype=float)\n    sum2 = np.zeros_like(img, dtype=float)\n    for dy in offsets:\n        for dx in offsets:\n            shifted = np.roll(np.roll(img, dy, axis=0), dx, axis=1)\n            sum1 += shifted\n            sum2 += shifted * shifted\n    kernel_area = 25.0\n    local_mean = sum1 / kernel_area\n    local_mean_sq = sum2 / kernel_area\n    local_var = local_mean_sq - (local_mean ** 2)\n    local_var = np.where(local_var > 0, local_var, 0.0)\n    local_std = np.sqrt(local_var)\n    avg_local_std = float(local_std.mean())\n    global_std = float(img.std()) + eps\n    result = avg_local_std / global_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted bounding-box aspect ratio (min(width/height, height/width) in (0..1])'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    total = float(a.sum())\n    if total <= eps:\n        return 0.0\n    row_sums = a.sum(axis=1)\n    col_sums = a.sum(axis=0)\n    cumr = np.cumsum(row_sums)\n    cumc = np.cumsum(col_sums)\n    low_frac = 0.01\n    high_frac = 1.0 - low_frac\n    r0 = int(np.searchsorted(cumr, total * low_frac))\n    r1 = int(np.searchsorted(cumr, total * high_frac))\n    c0 = int(np.searchsorted(cumc, total * low_frac))\n    c1 = int(np.searchsorted(cumc, total * high_frac))\n    # clamp\n    r0 = max(0, min(r0, h - 1))\n    r1 = max(0, min(r1, h - 1))\n    c0 = max(0, min(c0, w - 1))\n    c1 = max(0, min(c1, w - 1))\n    height = max(1, r1 - r0 + 1)\n    width = max(1, c1 - c0 + 1)\n    ratio = min(width / float(height + eps), height / float(width + eps))\n    return float(np.clip(ratio, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical (left-right) normalized L1 symmetry: average absolute column difference between left and flipped right, normalized by image width'\n    # Convert to grayscale\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # Determine ink polarity robustly (ink should be sparse)\n    thr = np.mean(gray)\n    ink_mask = gray < thr\n    if np.count_nonzero(ink_mask) > 0.9 * h * w:\n        ink_mask = gray > thr\n    # Compute left-right symmetry on binary ink mask\n    left = ink_mask[:, :w//2].astype(float)\n    right = np.fliplr(ink_mask[:, (w - w//2):]).astype(float)\n    # Resize to same width if needed\n    if left.shape[1] != right.shape[1]:\n        minw = min(left.shape[1], right.shape[1])\n        left = left[:, :minw]\n        right = right[:, :minw]\n    # L1 normalized by number of compared pixels\n    denom = float(left.size) if left.size > 0 else 1.0\n    score = np.sum(np.abs(left - right)) / denom\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian energy normalized by mean intensity (higher => more fine texture or noise)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # compute discrete Laplacian via padded slices\n    pad = np.pad(a, pad_width=1, mode='edge').astype(float)\n    center = pad[1:-1, 1:-1]\n    up = pad[0:-2, 1:-1]\n    down = pad[2:, 1:-1]\n    left = pad[1:-1, 0:-2]\n    right = pad[1:-1, 2:]\n    lap = (up + down + left + right) - 4.0 * center\n    energy = float(np.mean(np.abs(lap)))\n    mean_int = float(np.mean(np.abs(a))) + eps\n    result = energy / mean_int\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Block coarseness: ratio of coarse-block mean variance to fine-block mean variance (higher => coarser texture)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 0.0\n    # coarse and fine scales\n    coarse_bs = max(2, min_dim // 8)\n    fine_bs = max(1, coarse_bs // 4)\n    def block_means(X, bs):\n        if bs <= 1:\n            return X.ravel()\n        H = (X.shape[0] // bs) * bs\n        W = (X.shape[1] // bs) * bs\n        if H == 0 or W == 0:\n            return X.ravel()\n        Xc = X[:H, :W].reshape((H//bs, bs, W//bs, bs))\n        bm = Xc.mean(axis=(1,3)).ravel()\n        return bm\n    bm_coarse = block_means(a, coarse_bs)\n    bm_fine = block_means(a, fine_bs)\n    var_coarse = float(bm_coarse.var())\n    var_fine = float(bm_fine.var()) + eps\n    result = var_coarse / var_fine\n    # clip to reasonable range\n    return float(np.clip(result, 0.0, 100.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio (width/height) of bounding box of bright region (>=0), 1.0 if none'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 1.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 1.0\n    thr = float(np.mean(a) + 0.5 * np.std(a))\n    mask = a > thr\n    if not np.any(mask):\n        return 1.0\n    rows = np.where(mask.any(axis=1))[0]\n    cols = np.where(mask.any(axis=0))[0]\n    if rows.size == 0 or cols.size == 0:\n        return 1.0\n    h_bb = float(rows[-1] - rows[0] + 1)\n    w_bb = float(cols[-1] - cols[0] + 1)\n    if h_bb <= 0:\n        return 1.0\n    ratio = w_bb / (h_bb + eps)\n    return float(np.clip(ratio, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of horizontal transitions per row in the central 30% band, normalized by width'\n    import numpy as np\n    h, w = image.shape[:2]\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    p30, p70 = np.percentile(gray, 30), np.percentile(gray, 70)\n    mask = (gray <= p30) if np.sum(gray <= p30) <= np.sum(gray >= p70) and np.sum(gray <= p30) > 0 else ((gray >= p70) if np.sum(gray >= p70) > 0 else (gray < gray.mean()))\n    M = mask.astype(np.uint8)\n    top = max(0, h//2 - max(1, h//6))\n    bottom = min(h, h//2 + max(1, h//6))\n    band = M[top:bottom, :] if bottom > top else M\n    if band.size == 0:\n        return 0.0\n    diffs = np.abs(np.diff(band, axis=1))\n    transitions_per_row = diffs.sum(axis=1)\n    avg_trans = transitions_per_row.mean() / (w + 1e-9)\n    return float(avg_trans)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized x-component of vector from global centroid to top-quarter centroid (tail direction score)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(float), axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    meanv = float(np.mean(gray))\n    if meanv > (mn + mx) / 2.0:\n        fg = (gray < meanv)\n    else:\n        fg = (gray > meanv)\n    coords = np.argwhere(fg)\n    if coords.size == 0:\n        return 0.0\n    # overall centroid (x,y)\n    overall = np.array([coords[:, 1].mean(), coords[:, 0].mean()], dtype=float)\n    # top quarter region\n    top_lim = max(1, h // 4)\n    top_coords = coords[coords[:, 0] < top_lim]\n    if top_coords.shape[0] < 3:\n        # if not enough top pixels, try upper-middle quarter\n        top_coords = coords[(coords[:, 0] >= h//4) & (coords[:, 0] < h//2)]\n        if top_coords.shape[0] < 3:\n            return 0.0\n    top_centroid = np.array([top_coords[:, 1].mean(), top_coords[:, 0].mean()], dtype=float)\n    vec = top_centroid - overall\n    norm = np.sqrt(vec[0] * vec[0] + vec[1] * vec[1]) + 1e-8\n    # return normalized x component in range [-1,1]\n    return float(vec[0] / norm)\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of columns that contain a long vertical ink run (indicates strong vertical strokes like \"1\")'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    minv = float(np.min(gray))\n    meanv = float(np.mean(gray))\n    if meanv == minv or h == 0 or w == 0:\n        return 0.0\n    thresh = (minv + meanv) / 2.0\n    ink = (gray < thresh) if meanv > minv else (gray > thresh)\n    count = 0\n    for col in range(w):\n        colarr = ink[:, col].astype(int)\n        maxrun = 0\n        cur = 0\n        for v in colarr:\n            if v:\n                cur += 1\n                if cur > maxrun:\n                    maxrun = cur\n            else:\n                cur = 0\n        if maxrun >= max(1, int(0.4 * h)):\n            count += 1\n    return float(count / max(1.0, float(w)))\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized vertical center of mass (y coordinate of ink centroid divided by height) \u2014 >0.5 means ink bottom-heavy'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.count_nonzero(ink) > 0.9 * h * w:\n        ink = gray > thr\n    ys, xs = np.nonzero(ink)\n    if ys.size == 0:\n        return 0.0\n    cy = float(np.mean(ys)) / float(max(1, h - 1))\n    return float(cy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized imbalance of quadrant means (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    mh = h // 2\n    mw = w // 2\n    q1 = a[:mh, :mw]\n    q2 = a[:mh, mw:]\n    q3 = a[mh:, :mw]\n    q4 = a[mh:, mw:]\n    quads = np.array([q.mean() if q.size else 0.0 for q in (q1, q2, q3, q4)], dtype=float)\n    global_std = float(a.std()) + eps\n    quad_std = float(quads.std())\n    result = quad_std / global_std\n    # reasonable cap\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of ink bounding box (width / height). Returns 0.0 if no ink present.'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = gray.min(), gray.max()\n    if mx - mn < 1e-8:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    bw = (norm > 0.5).astype(np.uint8)\n    ys, xs = np.where(bw)\n    if ys.size == 0:\n        return 0.0\n    miny, maxy = ys.min(), ys.max()\n    minx, maxx = xs.min(), xs.max()\n    width = maxx - minx + 1\n    height = maxy - miny + 1\n    if height == 0:\n        return float(width)\n    return float(width / height)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink density in top-right quadrant to bottom-left quadrant (helps find top-right loops)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 1.0\n    thr = 0.5 * (mn + mx)\n    foreground_is_dark = float(np.mean(gray)) < thr\n    if foreground_is_dark:\n        ink = gray < thr\n    else:\n        ink = gray > thr\n    tr = ink[:h//2, w//2:]\n    bl = ink[h//2:, :w//2]\n    tr_density = float(np.count_nonzero(tr)) / max(1, tr.size)\n    bl_density = float(np.count_nonzero(bl)) / max(1, bl.size)\n    return float((tr_density + 1e-9) / (bl_density + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box fill ratio: fraction of the bounding box area that is ink (low values indicate holes or thin strokes)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    thr = gray.mean()\n    mask = (gray > thr)\n    if mask.mean() > 0.6 or mask.mean() < 0.001:\n        p30, p70 = np.percentile(gray.flatten(), [30, 70])\n        thr2 = (p30 + p70) / 2.0\n        mask = (gray > thr2)\n        if mask.mean() > 0.6:\n            mask = (gray < thr2)\n    mask = mask.astype(np.uint8)\n    rows = np.any(mask, axis=1)\n    cols = np.any(mask, axis=0)\n    if not rows.any() or not cols.any():\n        return 0.0\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    bh = rmax - rmin + 1\n    bw = cmax - cmin + 1\n    bbox_area = max(1, bh * bw)\n    ink = mask.sum()\n    return float(ink / bbox_area)\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of the image intensity histogram (higher => more complexity)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    vmin = float(a.min())\n    vmax = float(a.max())\n    if vmax <= vmin + eps:\n        return 0.0\n    hist, _ = np.histogram(a.ravel(), bins=256, range=(vmin, vmax))\n    prob = hist.astype(float) / (hist.sum() + eps)\n    prob = prob[prob > 0]\n    ent = -np.sum(prob * np.log2(prob + eps))\n    return float(ent)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Density of local intensity peaks (local maxima stronger than neighbors and > mean+0.5*std)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    padded = np.pad(arr, ((1, 1), (1, 1)), mode='constant', constant_values=-np.inf)\n    C = padded[1:-1, 1:-1]\n    N = padded[:-2, 1:-1]\n    S = padded[2:, 1:-1]\n    W = padded[1:-1, :-2]\n    E = padded[1:-1, 2:]\n    NW = padded[:-2, :-2]\n    NE = padded[:-2, 2:]\n    SW = padded[2:, :-2]\n    SE = padded[2:, 2:]\n    is_peak = (C > N) & (C > S) & (C > W) & (C > E) & (C > NW) & (C > NE) & (C > SW) & (C > SE)\n    mean = float(np.mean(arr))\n    std = float(np.std(arr))\n    thr = mean + 0.5 * std\n    mask = is_peak & (C > thr)\n    count = int(np.count_nonzero(mask))\n    area = float(h * w)\n    result = count / (area + 1e-12)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Corner variance ratio: mean corner variance divided by global variance (>=0)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return float(0.0)\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return float(0.0)\n    cs = max(1, min(h, w) // 8)\n    corners = []\n    corners.append(a[:cs, :cs])\n    corners.append(a[:cs, -cs:])\n    corners.append(a[-cs:, :cs])\n    corners.append(a[-cs:, -cs:])\n    corner_vars = []\n    for c in corners:\n        if c.size:\n            corner_vars.append(float(c.var()))\n        else:\n            corner_vars.append(0.0)\n    mean_corner_var = float(np.mean(corner_vars))\n    global_var = float(a.var()) + eps\n    result = mean_corner_var / global_var\n    return float(max(result, 0.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative strength of horizontal gradients in the top third (fraction of total horizontal gradient energy)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    # compute gradients: np.gradient returns [gy, gx]\n    gy, gx = np.gradient(gray.astype(float))\n    horiz_energy = np.abs(gx)\n    total = np.sum(horiz_energy) + 1e-9\n    top_region = slice(0, max(1, h // 3))\n    top_energy = np.sum(horiz_energy[top_region, :])\n    return float(top_energy / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized contrast between top 10% and bottom 10% intensity pixels (higher => stronger contrast)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    p90 = np.percentile(vals, 90)\n    p10 = np.percentile(vals, 10)\n    top = vals[vals >= p90]\n    bot = vals[vals <= p10]\n    if top.size == 0 or bot.size == 0:\n        return 0.0\n    mean_top = float(top.mean())\n    mean_bot = float(bot.mean())\n    overall_std = float(vals.std()) + eps\n    result = (mean_top - mean_bot) / overall_std\n    # clip to reasonable range\n    return float(np.clip(result, -10.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Average number of ink/background transitions per column (columns with many transitions indicate loops/complex shapes like 3)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w == 0:\n        return 0.0\n    mx = gray.max()\n    if mx > 1e-9:\n        gray = gray / float(mx)\n    thr = np.mean(gray)\n    ink = (gray < thr).astype(np.int8)\n    # transitions along each column: sum of abs differences between adjacent rows\n    transitions_per_col = np.sum(np.abs(np.diff(ink, axis=0)), axis=0)\n    # average transitions per column\n    avg_trans = float(np.mean(transitions_per_col))\n    # normalized by possible maximum (h-1)\n    return float(avg_trans / max(1.0, h - 1))\n",
    "def feature(image: np.ndarray) -> float:\n    'Block-wise spatial entropy (0..1): entropy of 4x4 block mean distribution normalized by max entropy'\n    import numpy as np\n    eps = 1e-12\n    bins = 16\n    blocks_y = 4\n    blocks_x = 4\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # compute approximate block means by splitting ranges\n    ys = np.linspace(0, h, blocks_y + 1, dtype=int)\n    xs = np.linspace(0, w, blocks_x + 1, dtype=int)\n    block_means = []\n    for i in range(blocks_y):\n        for j in range(blocks_x):\n            r0, r1 = ys[i], ys[i + 1]\n            c0, c1 = xs[j], xs[j + 1]\n            blk = a[r0:r1, c0:c1]\n            if blk.size:\n                block_means.append(float(blk.mean()))\n            else:\n                block_means.append(0.0)\n    block_means = np.array(block_means, dtype=float)\n    if block_means.size == 0:\n        return 0.0\n    try:\n        hist, _ = np.histogram(block_means, bins=bins, range=(block_means.min(), block_means.max()))\n    except Exception:\n        return 0.0\n    p = hist.astype(float)\n    s = p.sum()\n    if s <= 0:\n        return 0.0\n    p = p / s\n    p_nonzero = p[p > 0]\n    ent = -float((p_nonzero * np.log2(p_nonzero)).sum())\n    max_ent = float(np.log2(bins))\n    result = ent / (max_ent + eps)\n    return float(result)\n",
    "def feature(image: np.ndarray) -> float:\n    'Texture anisotropy: normalized difference between average row-variance and column-variance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    row_var = float(np.mean(np.var(arr, axis=1)))\n    col_var = float(np.mean(np.var(arr, axis=0)))\n    diff = abs(row_var - col_var)\n    denom = row_var + col_var + eps\n    anis = diff / denom\n    return float(np.clip(anis, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Aspect ratio of bounding box of bright region (>= mean), mapped to 0..1'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(a.mean())\n    mask = a >= thr\n    if not mask.any():\n        return 0.0\n    ys, xs = np.where(mask)\n    ymin, ymax = ys.min(), ys.max()\n    xmin, xmax = xs.min(), xs.max()\n    bh = float(max(1, ymax - ymin + 1))\n    bw = float(max(1, xmax - xmin + 1))\n    ratio = bw / bh\n    # compress to (0..1) via ratio/(1+ratio)\n    val = ratio / (1.0 + ratio + eps)\n    return float(np.clip(val, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels considerably darker than global mean (captures dark regions)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    mu = float(a.mean())\n    sd = float(a.std()) + eps\n    thr = mu - 0.5 * sd\n    count = float(np.count_nonzero(a < thr))\n    result = count / float(a.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative darkness of the upper-left quadrant compared to the whole image (positive => upper-left is darker)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    whole_mean = float(np.mean(gray))\n    ul = gray[0:max(1, h//2), 0:max(1, w//2)]\n    ul_mean = float(np.mean(ul)) if ul.size else whole_mean\n    return float(whole_mean - ul_mean)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal spread (std of x) of ink in the lower quarter normalized by half-width (higher = wider bottom spread)'\n    import numpy as np\n    eps = 1e-8\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(np.float32)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    low = np.percentile(gray, 10)\n    high = np.percentile(gray, 90)\n    if high - low < eps:\n        return 0.0\n    mid = 0.5 * (low + high)\n    ink = (gray < mid) if (low < mid) else (gray > mid)\n    ys, xs = np.nonzero(ink)\n    if ys.size == 0:\n        return 0.0\n    bottom_thr = int(h * 0.75)\n    mask = ys >= bottom_thr\n    if not np.any(mask):\n        mask = ys >= int(h * 0.6)\n    if not np.any(mask):\n        return 0.0\n    std_x = float(np.std(xs[mask]))\n    return float(std_x / (w / 2.0 + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Signed density difference between upper-right and lower-right quadrants (positive means more ink in upper-right)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    gray_n = (gray - mn) / (mx - mn + 1e-9)\n    median = np.median(gray_n)\n    bottom10 = np.percentile(gray_n.flatten(), 10)\n    top10 = np.percentile(gray_n.flatten(), 90)\n    if bottom10 < top10:\n        ink = (gray_n <= median).astype(float)\n    else:\n        ink = (gray_n >= median).astype(float)\n    rx0 = int(w * 2 / 3)\n    ur = ink[0:h//2, rx0:w].sum() / ( (h//2) * max(1, w - rx0) )\n    lr = ink[h//2:h, rx0:w].sum() / ( (h - h//2) * max(1, w - rx0) )\n    denom = ur + lr + 1e-9\n    return float((ur - lr) / denom)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation entropy (0..1) measuring directional complexity'\n    import numpy as np\n    eps = 1e-12\n    bins = 16\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # histogram weighted by magnitude\n    hist, _ = np.histogram(theta, bins=bins, range=(-np.pi, np.pi), weights=mag)\n    p = hist / (hist.sum() + eps)\n    # entropy normalized by log(bins)\n    ent = -np.sum(np.where(p > 0, p * np.log(p), 0.0))\n    result = ent / (np.log(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1), measures complexity of brightness distribution'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        # convert to luminance-like by averaging channels\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    a_flat = a.ravel()\n    # choose a modest number of bins for efficiency\n    bins = 32\n    if a_flat.size == 0:\n        return 0.0\n    lo = float(a_flat.min())\n    hi = float(a_flat.max())\n    if hi <= lo:\n        return 0.0\n    hist, _ = np.histogram(a_flat, bins=bins, range=(lo, hi), density=False)\n    probs = hist.astype(float) / (hist.sum() + 1e-12)\n    probs = probs[probs > 0]\n    if probs.size == 0:\n        return 0.0\n    entropy = -np.sum(probs * np.log(probs + 1e-12))\n    # normalize by log(bins) to keep in [0,1]\n    result = entropy / (np.log(bins) + 1e-12)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Diagonal orientation of ink: Pearson correlation between x and y coordinates of ink pixels'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image\n    p10, p90 = np.percentile(gray, 10), np.percentile(gray, 90)\n    low_mean = np.mean(gray[gray <= p10]) if np.any(gray <= p10) else p10\n    high_mean = np.mean(gray[gray >= p90]) if np.any(gray >= p90) else p90\n    ink_dark = low_mean < high_mean\n    thr = np.percentile(gray, 50)\n    fg = (gray <= thr) if ink_dark else (gray >= thr)\n    ys, xs = np.where(fg)\n    if ys.size < 2:\n        return 0.0\n    xs_f = xs.astype(np.float64)\n    ys_f = ys.astype(np.float64)\n    xs_c = xs_f - xs_f.mean()\n    ys_c = ys_f - ys_f.mean()\n    cov = np.mean(xs_c * ys_c)\n    sx = xs_c.std()\n    sy = ys_c.std()\n    if sx * sy < 1e-8:\n        return 0.0\n    corr = cov / (sx * sy)\n    return float(corr)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score (1.0 = perfectly symmetric, 0.0 = very asymmetric)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    half = w // 2\n    left = a[:, :half]\n    right = a[:, -half:]\n    right_flipped = np.fliplr(right)\n    minw = min(left.shape[1], right_flipped.shape[1])\n    if minw == 0:\n        return 0.0\n    diff = np.abs(left[:, :minw] - right_flipped[:, :minw])\n    denom = float(np.mean(np.abs(a)) + eps)\n    normalized = float(np.mean(diff)) / denom\n    score = 1.0 - np.clip(normalized, 0.0, 1.0)\n    return float(score)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant orientation (aggregated) encoded in [-1..1] using sin(2*theta) from intensity PCA'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    weight = a\n    total = float(weight.sum())\n    if total <= eps:\n        return 0.0\n    mean_y = float((weight * ys).sum() / (total + eps))\n    mean_x = float((weight * xs).sum() / (total + eps))\n    dy = (ys - mean_y)\n    dx = (xs - mean_x)\n    cov_xx = float((weight * (dx ** 2)).sum() / (total + eps))\n    cov_yy = float((weight * (dy ** 2)).sum() / (total + eps))\n    cov_xy = float((weight * (dx * dy)).sum() / (total + eps))\n    cov = np.array([[cov_xx, cov_xy], [cov_xy, cov_yy]])\n    try:\n        vals, vecs = np.linalg.eigh(cov)\n    except Exception:\n        return 0.0\n    # largest eigenvector\n    idx = int(np.argmax(vals))\n    vx, vy = vecs[:, idx]\n    angle = float(np.arctan2(vy, vx))\n    # use sin(2*angle) to make orientation periodic by pi and map to [-1,1]\n    result = float(np.sin(2.0 * angle))\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean vertical gradient magnitude (average absolute d/dy) normalized by intensity range'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    minv = float(np.min(gray))\n    maxv = float(np.max(gray))\n    if maxv > minv:\n        gray = (gray - minv) / (maxv - minv)\n    else:\n        gray = gray * 0.0\n    gy, gx = np.gradient(gray)\n    mag = np.abs(gy)\n    return float(np.mean(mag))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency energy ratio via 2x2 block averaging (0..inf)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h < 2 or w < 2:\n        return 0.0\n    h2 = (h // 2) * 2\n    w2 = (w // 2) * 2\n    crop = img[:h2, :w2]\n    try:\n        blocks = crop.reshape(h2//2, 2, w2//2, 2)\n        low = blocks.mean(axis=(1,3))\n    except Exception:\n        # fallback to simple downsample by slicing\n        low = img[::2, ::2]\n    low_energy = float(np.mean(np.abs(low)))\n    high_energy = float(np.mean(np.abs(img))) + eps\n    result = low_energy / high_energy\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Maximum continuous horizontal ink run length in the central third rows (normalized by width)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    img = np.asarray(image)\n    h, w = img.shape[:2]\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img.astype(float)\n    # robust binarization using border heuristic\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = np.mean(border) if border.size else np.mean(gray)\n    if border_mean > np.mean(gray):\n        thresh = np.percentile(gray, 40)\n        ink = gray < thresh\n    else:\n        thresh = np.percentile(gray, 60)\n        ink = gray > thresh\n    # central third rows and full width\n    r0, r1 = h // 3, (2 * h) // 3\n    center_region = ink[r0:r1, :]\n    if center_region.size == 0:\n        return 0.0\n    max_run = 0\n    # compute longest contiguous True in each center row\n    for row in center_region:\n        # find runs\n        # pad to handle edges\n        padded = np.concatenate([[0], row.astype(int), [0]])\n        diff = np.diff(padded)\n        starts = np.where(diff == 1)[0]\n        ends = np.where(diff == -1)[0]\n        if starts.size and ends.size:\n            runs = ends - starts\n            max_run = max(max_run, int(np.max(runs)))\n    return float(max_run / max(1, w))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of enclosed background regions (holes) inside ink strokes (helps detect two loops like in \"8\")'\n    import numpy as np\n    # Robust grayscale conversion\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    eps = 1e-8\n    # normalize to 0..1\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx - mn > eps:\n        g = (gray - mn) / (mx - mn)\n    else:\n        g = np.zeros_like(gray, dtype=float)\n    # infer ink polarity from border brightness\n    border = np.concatenate([g[0, :], g[-1, :], g[:, 0], g[:, -1]])\n    border_mean = float(np.mean(border)) if border.size else 1.0\n    if border_mean > 0.5:\n        ink = g < 0.5\n    else:\n        ink = g > 0.5\n    back = ~ink\n    visited = np.zeros_like(back, dtype=bool)\n    holes = 0\n    # Flood-fill background components and count those not touching border -> holes\n    for r in range(h):\n        for c in range(w):\n            if back[r, c] and not visited[r, c]:\n                stack = [(r, c)]\n                touch_border = False\n                while stack:\n                    rr, cc = stack.pop()\n                    if visited[rr, cc]:\n                        continue\n                    visited[rr, cc] = True\n                    if rr == 0 or rr == h - 1 or cc == 0 or cc == w - 1:\n                        touch_border = True\n                    # 4-neighborhood\n                    if rr > 0 and back[rr - 1, cc] and not visited[rr - 1, cc]:\n                        stack.append((rr - 1, cc))\n                    if rr < h - 1 and back[rr + 1, cc] and not visited[rr + 1, cc]:\n                        stack.append((rr + 1, cc))\n                    if cc > 0 and back[rr, cc - 1] and not visited[rr, cc - 1]:\n                        stack.append((rr, cc - 1))\n                    if cc < w - 1 and back[rr, cc + 1] and not visited[rr, cc + 1]:\n                        stack.append((rr, cc + 1))\n                if not touch_border:\n                    holes += 1\n    return float(holes)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of low-frequency Fourier energy in central band (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fft2(a)\n        F = np.fft.fftshift(F)\n        mag = np.abs(F)\n    except Exception:\n        return 0.0\n    cy, cx = h // 2, w // 2\n    radius = max(1, min(h, w) // 8)\n    yy, xx = np.ogrid[:h, :w]\n    mask = (yy - cy) ** 2 + (xx - cx) ** 2 <= radius * radius\n    total = float(mag.sum()) + 1e-12\n    low = float(mag[mask].sum())\n    result = low / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation coherence: magnitude of vector-sum of gradients (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    sum_gx = float(gx.sum())\n    sum_gy = float(gy.sum())\n    num = np.hypot(sum_gx, sum_gy)\n    denom = float(np.hypot(gx, gy).sum()) + eps\n    result = num / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized count of stroke endpoints (ink pixels with <=1 ink neighbor) (0..1)'\n    try:\n        if len(image.shape) == 3:\n            gray = image.mean(axis=2)\n        else:\n            gray = image.astype(float)\n        g = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n        border = np.concatenate([g[0:1, :].ravel(), g[-1:, :].ravel(), g[:, 0:1].ravel(), g[:, -1:].ravel()])\n        border_mean = float(np.mean(border)) if border.size else 0.5\n        if border_mean > 0.5:\n            ink = g < max(0.0, border_mean - 0.15)\n        else:\n            ink = g > min(1.0, border_mean + 0.15)\n        h, w = ink.shape\n        if np.count_nonzero(ink) == 0:\n            return 0.0\n        pad = np.pad(ink, pad_width=1, mode='constant', constant_values=False)\n        neighbor_count = np.zeros_like(ink, dtype=int)\n        for dy in (-1, 0, 1):\n            for dx in (-1, 0, 1):\n                if dy == 0 and dx == 0:\n                    continue\n                neighbor_count += pad[1+dy : 1+dy+h, 1+dx : 1+dx+w]\n        endpoints = ink & (neighbor_count <= 1)\n        return float(np.count_nonzero(endpoints)) / float(np.count_nonzero(ink))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0=constant, 1=max for chosen bins)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    vals = a.ravel()\n    # use a moderate number of bins\n    bins = 64\n    try:\n        hist, _ = np.histogram(vals, bins=bins, density=False)\n    except Exception:\n        return 0.0\n    total = float(hist.sum())\n    if total <= 0.0:\n        return 0.0\n    p = hist / total\n    p = p[p > 0.0]\n    entropy = -np.sum(p * np.log2(p))\n    max_entropy = np.log2(bins) if bins > 1 else 1.0\n    result = float(np.clip(entropy / max_entropy, 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bottom-center loop density: fraction of ink located in the lower central third of the image (useful to detect closed loops at the bottom like in 9)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape\n    thr = gray.mean()\n    mask = (gray > thr)\n    if mask.mean() > 0.6 or mask.mean() < 0.001:\n        p30, p70 = np.percentile(gray.flatten(), [30, 70])\n        thr2 = (p30 + p70) / 2.0\n        mask = (gray > thr2)\n        if mask.mean() > 0.6:\n            mask = (gray < thr2)\n    mask = mask.astype(np.uint8)\n    ink_total = mask.sum()\n    if ink_total == 0:\n        return 0.0\n    r0 = (2 * h) // 3\n    c0 = w // 4\n    c1 = 3 * w // 4\n    bottom_center = mask[r0:h, c0:c1]\n    return float(bottom_center.sum() / (ink_total + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of horizontal gradient energy in the upper half of the image (0..1)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image.astype(np.float32), axis=2)\n    else:\n        gray = image.astype(np.float32)\n    if gray.size == 0:\n        return 0.0\n    if gray.max() > 1.5:\n        gray = gray / 255.0\n    gy, gx = np.gradient(gray.astype(np.float32))\n    abs_gx = np.abs(gx)\n    h = gray.shape[0]\n    mid = max(1, h // 2)\n    upper_energy = np.sum(abs_gx[:mid, :])\n    total_energy = np.sum(abs_gx) + 1e-9\n    return float(upper_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity skewness normalized to [-1..1] using tanh compression'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        flat = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(img.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    m = float(flat.mean())\n    s = float(flat.std()) + eps\n    skew = float(np.mean(((flat - m) / s) ** 3))\n    # compress to [-1,1]\n    result = float(np.tanh(skew / 5.0))\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized intensity entropy (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    bins = 32\n    hist, _ = np.histogram(vals, bins=bins, density=False)\n    total = float(hist.sum()) + eps\n    p = hist / total\n    p_nonzero = p[p > 0]\n    ent = -float((p_nonzero * np.log(p_nonzero)).sum())\n    max_ent = float(np.log(bins) + eps)\n    return float(np.clip(ent / max_ent, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative radial spread of ink: std(distance to centroid) / (mean distance + eps)'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        h, w = gray.shape[:2]\n        thresh = np.percentile(gray, 50.0)\n        mask = (gray <= thresh)\n        ys, xs = np.where(mask)\n        if ys.size == 0:\n            return 0.0\n        cy, cx = ys.mean(), xs.mean()\n        dists = np.sqrt((ys - cy) ** 2 + (xs - cx) ** 2)\n        mean_d = dists.mean()\n        std_d = dists.std()\n        eps = 1e-6\n        return float(std_d / (mean_d + eps))\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of high-frequency energy to total energy from 2D FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    img = np.nan_to_num(img.astype(float))\n    h, w = img.shape\n    try:\n        F = np.fft.fftshift(np.fft.fft2(img))\n        mag = np.abs(F)\n    except Exception:\n        return 0.0\n    cy, cx = h // 2, w // 2\n    # low-pass radius: 10% of max radius, at least 1\n    maxr = np.hypot(cy, cx) or 1.0\n    r0 = max(1.0, 0.1 * maxr)\n    ys = np.arange(h)[:, None] - cy\n    xs = np.arange(w)[None, :] - cx\n    dist = np.hypot(ys, xs)\n    low_mask = dist <= r0\n    total = mag.sum() + eps\n    high = mag[~low_mask].sum()\n    return float(high / total)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0..1), 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    # use first three channels as R,G,B\n    img = np.nan_to_num(arr.astype(float))\n    R = img[:, :, 0].ravel()\n    G = img[:, :, 1].ravel()\n    B = img[:, :, 2].ravel()\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = np.std(rg)\n    std_yb = np.std(yb)\n    mean_rg = np.mean(rg)\n    mean_yb = np.mean(yb)\n    colorfulness = np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n    # normalize by typical intensity range\n    max_val = max(1.0, np.max(img) - np.min(img), eps)\n    norm = colorfulness / max_val\n    return float(np.clip(norm, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels with high gradient magnitude (above 90th percentile)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    if a.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy).ravel()\n    if mag.size == 0:\n        return 0.0\n    thresh = float(np.percentile(mag, 90))\n    high = float((mag > thresh).sum())\n    frac = high / float(mag.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Border smoothness: std of outer border normalized by global std (low = smooth border)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    bw = max(1, min(h, w) // 8)\n    top = a[:bw, :]\n    bottom = a[-bw:, :]\n    left = a[:, :bw]\n    right = a[:, -bw:]\n    # combine border regions without duplicating corners excessively by concatenation\n    border = np.concatenate([top.ravel(), bottom.ravel(), left.ravel(), right.ravel()])\n    if border.size == 0:\n        return 0.0\n    border_std = float(np.std(border))\n    global_std = float(a.std()) + eps\n    result = border_std / global_std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative diagonal edge energy: sum of absolute diagonal differences over vertical+horizontal gradient energy'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0 or np.std(gray) < 1e-9:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    horver = np.sum(np.abs(gx)) + np.sum(np.abs(gy))\n    # diagonal differences\n    d1 = np.abs(gray[1:, 1:] - gray[:-1, :-1])\n    d2 = np.abs(gray[1:, :-1] - gray[:-1, 1:])\n    diag = np.sum(d1) + np.sum(d2)\n    eps = 1e-9\n    return float(diag) / float(horver + eps)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative concentration of ink in the inner upper-right quadrant vs its border (indicates small top-right loops)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.copy()\n    h, w = gray.shape[:2]\n    meanv = np.mean(gray)\n    ink = gray < meanv\n    if np.count_nonzero(ink) > 0.5 * h * w:\n        ink = gray > meanv\n    # define upper-right quadrant\n    mid_h = h // 2\n    mid_w = w // 2\n    ur = ink[0:mid_h, mid_w:w]\n    if ur.size == 0:\n        return 0.0\n    # inner region (center of that quadrant)\n    ih = max(1, ur.shape[0] // 2)\n    iw = max(1, ur.shape[1] // 2)\n    inner = ur[ih//2:ih//2 + ih, iw//2:iw//2 + iw]\n    border_mask = np.ones_like(ur, dtype=bool)\n    # carve out inner area\n    inner_r0 = ih//2; inner_c0 = iw//2\n    inner_r1 = inner_r0 + ih; inner_c1 = inner_c0 + iw\n    inner_r1 = min(inner_r1, ur.shape[0]); inner_c1 = min(inner_c1, ur.shape[1])\n    border_mask[inner_r0:inner_r1, inner_c0:inner_c1] = False\n    inner_count = inner.sum() if inner.size > 0 else 0\n    border_count = ur[border_mask].sum() if border_mask.sum() > 0 else 0\n    eps = 1e-8\n    return float(inner_count / (border_count + eps))\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized image aspect difference (0=square, 1=extreme aspect)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    # shape may be (h,w,...) or (h,w)\n    if arr.ndim >= 2:\n        h, w = int(arr.shape[0]), int(arr.shape[1])\n    else:\n        return 0.0\n    if h <= 0 or w <= 0:\n        return 0.0\n    result = abs(h - w) / float(max(h, w))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows that contain a contiguous ink run longer than 60% of the image width'\n    import numpy as np\n    if image is None:\n        return 0.0\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image.astype(float), axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.0\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    p10, p90 = np.percentile(gray, (10, 90))\n    low_mean = float(np.mean(gray[gray <= p10])) if np.any(gray <= p10) else p10\n    high_mean = float(np.mean(gray[gray >= p90])) if np.any(gray >= p90) else p90\n    median = np.median(gray)\n    if low_mean < high_mean:\n        ink = (gray <= median).astype(np.uint8)\n    else:\n        ink = (gray >= median).astype(np.uint8)\n    threshold_len = max(1, int(0.6 * w))\n    long_row_count = 0\n    for i in range(h):\n        row = ink[i, :]\n        # find longest run of 1s in row\n        max_run = 0\n        run = 0\n        for val in row:\n            if val:\n                run += 1\n                if run > max_run:\n                    max_run = run\n            else:\n                run = 0\n        if max_run >= threshold_len:\n            long_row_count += 1\n    return float(long_row_count) / float(h)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels in the top 10% intensity percentile (bright-spot sparsity)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        flat = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        flat = np.nan_to_num(img.astype(float)).ravel()\n    if flat.size == 0:\n        return 0.0\n    thr = float(np.percentile(flat, 90))\n    count = float(np.count_nonzero(flat > thr))\n    result = count / float(flat.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Central cross edge strength: mean gradient magnitude on middle row and column normalized by global mean'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    mid_r = h // 2\n    mid_c = w // 2\n    # take a 3-pixel wide cross if possible\n    r_inds = slice(max(0, mid_r - 1), min(h, mid_r + 2))\n    c_inds = slice(max(0, mid_c - 1), min(w, mid_c + 2))\n    cross_mask = np.zeros_like(mag, dtype=bool)\n    cross_mask[r_inds, :] = True\n    cross_mask[:, c_inds] = True\n    cross_mean = float(np.mean(mag[cross_mask])) if np.any(cross_mask) else 0.0\n    global_mean = float(np.mean(mag)) + eps\n    result = cross_mean / global_mean\n    # typical range might exceed 1; clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram peakiness: largest histogram bin fraction using 16 bins (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 16\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    mn = float(vals.min())\n    mx = float(vals.max())\n    if mx <= mn:\n        return 1.0\n    hist, _ = np.histogram(vals, bins=bins, range=(mn, mx))\n    total = hist.sum() + eps\n    peak = float(hist.max()) / total\n    return float(np.clip(peak, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Radial intensity variation: variance of ring means normalized by overall variance (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cx = (w - 1) / 2.0\n    cy = (h - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    maxr = float(r.max()) + eps\n    bins = max(4, int(min(h, w) // 4))\n    edges = np.linspace(0.0, maxr, bins + 1)\n    means = []\n    for i in range(bins):\n        mask = (r >= edges[i]) & (r < edges[i+1])\n        if np.any(mask):\n            means.append(float(a[mask].mean()))\n    if len(means) < 2:\n        return 0.0\n    means = np.array(means)\n    var_means = float(means.var())\n    overall_var = float(a.var()) + eps\n    result = var_means / overall_var\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from 2D FFT (0..1)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        F = np.fft.fftshift(np.fft.fft2(img))\n        power = np.abs(F) ** 2\n    except Exception:\n        return 0.0\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    radius = max(1.0, min(h, w) * 0.1)\n    high_mask = r > radius\n    total = float(power.sum()) + 1e-12\n    high = float((power * high_mask).sum())\n    result = high / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Standard deviation of row-wise mean gradient magnitude in the middle band (captures how many distinct horizontal edges/bars are present)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    eps = 1e-8\n    mn, mx = np.min(gray), np.max(gray)\n    if mx - mn < eps:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    gy, gx = np.gradient(norm)\n    grad_mag = np.sqrt(gx**2 + gy**2)\n    mid_start = h//3\n    mid_end = 2*h//3\n    band = grad_mag[mid_start:mid_end, :]\n    if band.size == 0:\n        return 0.0\n    row_means = np.mean(band, axis=1)\n    return float(np.std(row_means) / (np.mean(row_means) + eps))\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient orientation concentration (0..1), 1 => most gradients align to one direction'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    mag_sum = mag.sum()\n    if mag_sum == 0:\n        return 0.0\n    ang = np.arctan2(gy, gx)\n    # mean resultant length weighted by magnitude\n    cx = np.cos(ang)\n    sx = np.sin(ang)\n    rcx = (mag * cx).sum() / (mag_sum + 1e-12)\n    rsx = (mag * sx).sum() / (mag_sum + 1e-12)\n    R = np.hypot(rcx, rsx)\n    result = float(np.clip(R, 0.0, 1.0))\n    return result\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of junction pixels (8-neighbor ink neighbors >= 3) indicating intersections like in \"4\"'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    thr = np.mean(gray)\n    ink = (gray < thr).astype(np.uint8)\n    # handle degenerate\n    if ink.sum() == 0:\n        return 0.0\n    # compute neighbor counts by shifted sums\n    neighbors = np.zeros_like(ink, dtype=np.int32)\n    shifts = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n    for dy, dx in shifts:\n        ys = slice(max(0, dy), None if dy >= 0 else dy)\n        xs = slice(max(0, dx), None if dx >= 0 else dx)\n        target_ys = slice(max(0, -dy), None if dy <= 0 else h - dy)\n        target_xs = slice(max(0, -dx), None if dx <= 0 else w - dx)\n        neighbors[target_ys, target_xs] += ink[ys, xs]\n    junctions = np.logical_and(ink == 1, neighbors >= 3)\n    return float(int(np.count_nonzero(junctions)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of local gradient peaks (simple corner-like peaks) normalized by image area'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 3 or w < 3:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(mag.mean() + mag.std())\n    # local maxima mask: greater than 8 neighbors\n    center = mag\n    neigh_max = np.maximum.reduce([\n        np.roll(np.roll(center, 1, 0), 1, 1),\n        np.roll(np.roll(center, 1, 0), -1, 1),\n        np.roll(np.roll(center, -1, 0), 1, 1),\n        np.roll(np.roll(center, -1, 0), -1, 1),\n        np.roll(center, 1, 0),\n        np.roll(center, -1, 0),\n        np.roll(center, 1, 1),\n        np.roll(center, -1, 1)\n    ])\n    peaks = (center > neigh_max) & (center > thr)\n    count = int(np.count_nonzero(peaks))\n    area = float(h * w) + eps\n    return float(count / area)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness index (Hasler & Suesstrunk style), normalized by mean intensity (0 for grayscale)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    # use first three channels\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(abs(rg.mean()))\n    mean_yb = float(abs(yb.mean()))\n    colorfulness = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    overall_mean = float(a.mean()) + eps\n    result = colorfulness / overall_mean\n    return float(np.clip(result, 0.0, 10.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'Horizontal vs vertical edge dominance: (H - V) / (H + V) in [-1..1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(image.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(image.astype(float))\n    if arr.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    hor = float(np.sum(np.abs(gx)))\n    ver = float(np.sum(np.abs(gy)))\n    denom = hor + ver + eps\n    score = (hor - ver) / denom\n    return float(np.clip(score, -1.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels within 0.1*std of the mean (flatness 0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    m = float(arr.mean())\n    s = float(arr.std()) + eps\n    thresh = 0.1 * s\n    count = float(np.count_nonzero(np.abs(arr - m) <= thresh))\n    result = count / (float(arr.size) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between bright and dark tails: (mean90 - mean10)/std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(arr.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    p90 = np.percentile(a, 90)\n    p10 = np.percentile(a, 10)\n    bright = a[a >= p90]\n    dark = a[a <= p10]\n    if bright.size == 0 or dark.size == 0:\n        return 0.0\n    mean90 = float(bright.mean())\n    mean10 = float(dark.mean())\n    std = float(a.std()) + eps\n    result = (mean90 - mean10) / std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Number of connected ink components in the right half (separate right-side blobs), returns component count'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(np.float32)\n        else:\n            gray = image.astype(np.float32)\n        if gray.size == 0:\n            return 0.0\n        if gray.max() > 1.5:\n            gray = gray / 255.0\n        h, w = gray.shape[:2]\n        thr = np.percentile(gray, 40)\n        bg_bright = np.mean(gray) > 0.5\n        mask = ((gray < thr) if bg_bright else (gray > thr)).astype(np.uint8)\n        region = mask[:, w//2:]\n        H, W = region.shape\n        if region.sum() == 0:\n            return 0.0\n        visited = np.zeros_like(region, dtype=bool)\n        comps = 0\n        # simple flood-fill (4-connectivity)\n        for i in range(H):\n            for j in range(W):\n                if region[i, j] and not visited[i, j]:\n                    comps += 1\n                    stack = [(i, j)]\n                    visited[i, j] = True\n                    while stack:\n                        y, x = stack.pop()\n                        for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                            ny, nx = y+dy, x+dx\n                            if 0 <= ny < H and 0 <= nx < W and region[ny, nx] and not visited[ny, nx]:\n                                visited[ny, nx] = True\n                                stack.append((ny, nx))\n        return float(comps)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of ink pixels located in the top quarter of the image (top density ratio)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    ink_mask_candidate = gray < thresh\n    if np.count_nonzero(ink_mask_candidate) > (h * w / 2):\n        ink = (~ink_mask_candidate).astype(float)\n    else:\n        ink = ink_mask_candidate.astype(float)\n    top_rows = max(1, h // 4)\n    top_ink = np.sum(ink[:top_rows, :])\n    total_ink = np.sum(ink)\n    if total_ink == 0:\n        return 0.0\n    return float(top_ink / total_ink)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Vertical center of mass of ink normalized to [0,1] (0 top, 1 bottom): 5 tends to have lower center than 0/8'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2)\n        else:\n            gray = image.astype(float)\n    except Exception:\n        return 0.5\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = float(np.mean(border)) if border.size > 0 else float(np.mean(gray))\n    if border_mean > np.median(gray):\n        thr = (border_mean + float(np.min(gray))) / 2.0\n        ink = (gray < thr).astype(float)\n    else:\n        thr = (border_mean + float(np.max(gray))) / 2.0\n        ink = (gray > thr).astype(float)\n    ink_sum = np.sum(ink)\n    if ink_sum <= 0:\n        return 0.5\n    rows = np.arange(h).reshape(h, 1)\n    com_y = float(np.sum(rows * np.sum(ink, axis=1).reshape(h, 1)) / np.sum(ink))\n    # normalize to 0..1\n    return float(com_y / max(1.0, h - 1))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Row-wise line prevalence: fraction of rows with a contiguous bright run (detects horizontal strokes)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = arr.mean() + arr.std()\n    k = max(1, w // 10)\n    rows_with_run = 0\n    for r in range(h):\n        row = arr[r, :] > thr\n        if not np.any(row):\n            continue\n        # compute max run length\n        dif = np.diff(np.concatenate(([0], row.view(np.int8), [0])))\n        starts = np.where(dif == 1)[0]\n        ends = np.where(dif == -1)[0]\n        if starts.size and ends.size:\n            maxrun = int((ends - starts).max())\n        else:\n            maxrun = 0\n        if maxrun >= k:\n            rows_with_run += 1\n    result = rows_with_run / float(h + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Corner consistency: normalized std of the four small corner patch means (lower => uniform background)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ch = max(1, h // 8)\n    cw = max(1, w // 8)\n    c1 = a[:ch, :cw]\n    c2 = a[:ch, -cw:]\n    c3 = a[-ch:, :cw]\n    c4 = a[-ch:, -cw:]\n    means = np.array([float(x.mean()) if x.size else 0.0 for x in (c1, c2, c3, c4)])\n    overall_std = float(a.std()) + eps\n    result = float(means.std()) / overall_std\n    return float(np.clip(result, 0.0, 10.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity entropy normalized to [0,1] (Shannon entropy of intensity histogram)'\n    import numpy as np\n    eps = 1e-12\n    bins = 256\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.nan_to_num(arr.mean(axis=2).astype(float)).ravel()\n    else:\n        vals = np.nan_to_num(arr.astype(float)).ravel()\n    if vals.size == 0:\n        return 0.0\n    vmin = float(vals.min())\n    vmax = float(vals.max())\n    if vmax <= vmin:\n        return 0.0\n    hist, _ = np.histogram(vals, bins=bins, range=(vmin, vmax))\n    p = hist.astype(float) / (hist.sum() + eps)\n    ppos = p[p > 0]\n    ent = -float((ppos * np.log2(ppos)).sum())\n    norm = np.log2(bins)\n    result = ent / (norm + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean color saturation for RGB images (0..1), 0 for non-RGB'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0 or img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(img.astype(float))\n    rgb = a[:, :, :3]\n    mx = rgb.max(axis=2)\n    mn = rgb.min(axis=2)\n    v = mx\n    s = np.zeros_like(v, dtype=float)\n    valid = v > eps\n    s[valid] = (v[valid] - mn[valid]) / (v[valid] + eps)\n    result = float(s.mean())\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest vertical run of foreground pixels in the right third of the image, normalized by height (detects vertical strokes on the right)'\n    import numpy as np\n    eps = 1e-6\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.mean(gray)\n    bw = (gray > thr).astype(np.uint8)\n    start_col = max(0, w * 2 // 3)\n    sub = bw[:, start_col:]\n    if sub.size == 0:\n        return 0.0\n    # compute longest run in each column\n    longest = 0\n    for c in range(sub.shape[1]):\n        col = sub[:, c]\n        # find consecutive ones runs\n        run = 0\n        max_run = 0\n        for val in col:\n            if val:\n                run += 1\n            else:\n                if run > max_run:\n                    max_run = run\n                run = 0\n        if run > max_run:\n            max_run = run\n        if max_run > longest:\n            longest = max_run\n    return float(longest / (h + eps))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score (1.0 = perfect symmetry, 0 = very asymmetric)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 1.0 if a.size == 0 else 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:] if mid > 0 else np.zeros_like(left)\n    right_flipped = np.fliplr(right)\n    # ensure same width\n    minw = min(left.shape[1], right_flipped.shape[1])\n    if minw == 0:\n        return 0.0\n    left_s = left[:, :minw]\n    right_s = right_flipped[:, :minw]\n    diff = np.mean(np.abs(left_s - right_s))\n    norm = np.mean(np.abs(a)) + eps\n    score = 1.0 - (diff / norm)\n    return float(np.clip(score, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Count of connected components in a median-thresholded binary image (4-connectivity), capped at 100'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    thr = float(np.median(a))\n    mask = a > thr\n    visited = np.zeros_like(mask, dtype=bool)\n    comps = 0\n    stack = []\n    for y in range(h):\n        for x in range(w):\n            if mask[y, x] and not visited[y, x]:\n                comps += 1\n                if comps >= 100:\n                    return float(100.0)\n                # flood fill (4-connectivity)\n                stack.append((y, x))\n                visited[y, x] = True\n                while stack:\n                    cy, cx = stack.pop()\n                    if cy > 0 and mask[cy - 1, cx] and not visited[cy - 1, cx]:\n                        visited[cy - 1, cx] = True\n                        stack.append((cy - 1, cx))\n                    if cy + 1 < h and mask[cy + 1, cx] and not visited[cy + 1, cx]:\n                        visited[cy + 1, cx] = True\n                        stack.append((cy + 1, cx))\n                    if cx > 0 and mask[cy, cx - 1] and not visited[cy, cx - 1]:\n                        visited[cy, cx - 1] = True\n                        stack.append((cy, cx - 1))\n                    if cx + 1 < w and mask[cy, cx + 1] and not visited[cy, cx + 1]:\n                        visited[cy, cx + 1] = True\n                        stack.append((cy, cx + 1))\n    return float(comps)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of sparse bright pixels above mean+1*std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    n = a.size\n    if n == 0:\n        return 0.0\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m + 1.0 * s\n    count = float(np.count_nonzero(a > thr))\n    result = count / (float(n) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of dark pixels (intensity < mean - std), 0..1'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    mean = float(arr.mean())\n    std = float(arr.std())\n    thr = mean - std\n    if arr.size == 0:\n        return 0.0\n    count = float((arr.ravel() < thr).sum())\n    result = count / (arr.size + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for RGB images (0..1), 0 for grayscale inputs'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim < 3 or img.shape[2] < 3:\n        return 0.0\n    # use first three channels as R,G,B\n    arr = np.nan_to_num(img.astype(float))\n    R = arr[..., 0]\n    G = arr[..., 1]\n    B = arr[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    # normalize by typical 8-bit range if possible\n    vmax = float(max(arr.max(), 1.0))\n    result = colorfulness / (vmax + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Difference of radial spread between lower-half and upper-half foreground pixels normalized by overall radial std'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(np.float32)\n    h, w = gray.shape[:2]\n    thr = np.mean(gray)\n    fg = gray < thr\n    if np.count_nonzero(fg) > 0.6 * fg.size:\n        fg = ~fg\n    ys, xs = np.where(fg)\n    if xs.size == 0:\n        return 0.0\n    cy = np.mean(ys)\n    cx = np.mean(xs)\n    dists = np.sqrt((ys - cy) ** 2 + (xs - cx) ** 2)\n    upper_mask = ys < cy\n    lower_mask = ~upper_mask\n    if np.count_nonzero(upper_mask) < 2 or np.count_nonzero(lower_mask) < 2:\n        return 0.0\n    upper_std = float(np.std(dists[upper_mask]))\n    lower_std = float(np.std(dists[lower_mask]))\n    overall_std = float(np.std(dists)) + 1e-6\n    return float((lower_std - upper_std) / overall_std)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Estimated local curvature: mean absolute second difference along a right-side vertical slice normalized by first-derivative magnitude'\n    import numpy as np\n    if image is None:\n        return 0.0\n    arr = np.asarray(image).astype(float)\n    gray = np.mean(arr, axis=2) if arr.ndim == 3 else arr\n    h, w = gray.shape[:2]\n    if h < 3 or w < 4:\n        return 0.0\n    x = min(w - 1, max(0, (3 * w) // 4))\n    profile = gray[:, x]\n    first = np.abs(np.diff(profile))\n    second = np.abs(np.diff(profile, n=2))\n    mean_second = second.mean() if second.size else 0.0\n    mean_first = first.mean() if first.size else 1e-9\n    return float(mean_second / (mean_first + 1e-9))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of gradient magnitude oriented near-vertical (proportion of gradient vectors whose absolute angle from vertical < 15 degrees)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    # compute gradients\n    gy, gx = np.gradient(gray.astype(float))\n    # orientation relative to vertical: angle = arctan2(|dx|, |dy|)\n    # if dx small relative to dy -> near vertical edge\n    ang = np.arctan2(np.abs(gx), np.abs(gy) + 1e-9)  # 0 => vertical, pi/2 => horizontal\n    # count where angle < 15 degrees in radians\n    thresh = np.deg2rad(15)\n    strong_mask = (ang < thresh) & (np.hypot(gx, gy) > (np.percentile(np.hypot(gx, gy), 50) * 0.1 + 1e-9))\n    frac = float(np.count_nonzero(strong_mask)) / float(gx.size)\n    return float(frac)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric (Hasler-Suesstrunk) for RGB images; returns 0 for non-RGB'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(arr.astype(float))\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg ** 2 + std_yb ** 2) + 0.3 * np.sqrt(mean_rg ** 2 + mean_yb ** 2)\n    return float(max(0.0, colorfulness))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Laplacian energy normalized by mean absolute intensity (texture measure)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    lap = (np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) +\n           np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1) - 4.0 * a)\n    energy = float(np.mean(np.abs(lap)))\n    denom = float(np.mean(np.abs(a))) + eps\n    result = energy / denom\n    return float(np.clip(result, 0.0, 100.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels above the 90th percentile intensity (bright pixel fraction)'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        img = img.mean(axis=2)\n    arr = np.ravel(np.nan_to_num(img.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    thresh = float(np.percentile(arr, 90))\n    frac = float(np.count_nonzero(arr > thresh)) / float(arr.size)\n    return float(frac)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels brighter than mean+0.5*std (foreground fraction)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    m = float(a.mean())\n    s = float(a.std())\n    thr = m + 0.5 * s\n    if a.size == 0:\n        return 0.0\n    frac = float(np.count_nonzero(a > thr)) / (a.size + eps)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity-weighted centroid offset from image center normalized by diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    ys = np.arange(h)[:, None].astype(float)\n    xs = np.arange(w)[None, :].astype(float)\n    weights = np.maximum(arr, 0.0)\n    total = weights.sum()\n    if total <= eps:\n        # fallback to unweighted centroid (uniform)\n        cy = (h - 1) / 2.0\n        cx = (w - 1) / 2.0\n    else:\n        cy = float((weights * ys).sum() / (total + eps))\n        cx = float((weights * xs).sum() / (total + eps))\n    cy_center = (h - 1) / 2.0\n    cx_center = (w - 1) / 2.0\n    dist = np.hypot(cx - cx_center, cy - cy_center)\n    diag_half = 0.5 * np.hypot(h, w) + eps\n    result = dist / diag_half\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-vs-border contrast normalized by overall std (positive => center brighter)'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = arr.mean(axis=2)\n    a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    ch0, ch1 = h // 4, 3 * h // 4\n    cw0, cw1 = w // 4, 3 * w // 4\n    if ch1 <= ch0 or cw1 <= cw0:\n        return 0.0\n    center = a[ch0:ch1, cw0:cw1]\n    if center.size == 0:\n        return 0.0\n    border_mask = np.ones_like(a, dtype=bool)\n    border_mask[ch0:ch1, cw0:cw1] = False\n    border = a[border_mask]\n    if border.size == 0:\n        return 0.0\n    center_mean = float(center.mean())\n    border_mean = float(border.mean())\n    overall_std = float(a.std()) + eps\n    result = (center_mean - border_mean) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Inter-percentile contrast: (90th - 10th percentile) normalized by median'\n    import numpy as np\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = img.mean(axis=2)\n    else:\n        arr = img\n    arr = np.ravel(np.nan_to_num(arr.astype(float)))\n    if arr.size == 0:\n        return 0.0\n    p90 = float(np.percentile(arr, 90))\n    p10 = float(np.percentile(arr, 10))\n    p50 = float(np.percentile(arr, 50))\n    result = (p90 - p10) / (abs(p50) + 1e-12)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Max continuous horizontal ink run length in the top third normalized by image width (detects top bar)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    thr = np.mean(gray)\n    border_mean = np.mean(np.concatenate([gray[0,:], gray[-1,:], gray[:,0], gray[:,-1]]))\n    ink_dark = border_mean > thr\n    if ink_dark:\n        ink = (gray < thr)\n    else:\n        ink = (gray > thr)\n    top_band = ink[:max(1, h//3), :]\n    max_run = 0\n    for row in top_band:\n        # find longest run of True in row\n        length = 0\n        best = 0\n        for val in row:\n            if val:\n                length += 1\n            else:\n                if length > best:\n                    best = length\n                length = 0\n        if length > best:\n            best = length\n        if best > max_run:\n            max_run = best\n    return float(max_run / float(w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean color saturation for RGB images (0..1), 0 for grayscale'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim != 3 or arr.shape[2] < 3:\n        return 0.0\n    rgb = np.nan_to_num(arr[:, :, :3].astype(float))\n    mx = np.max(rgb, axis=2)\n    mn = np.min(rgb, axis=2)\n    # saturation per pixel = (max - min) / (max + eps)\n    sat = (mx - mn) / (mx + eps)\n    mean_sat = float(np.mean(sat))\n    return float(np.clip(mean_sat, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientation histogram (magnitude-weighted), normalized to [0,1]'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    try:\n        gy, gx = np.gradient(a)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    if np.sum(mag) <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # map to orientation in [0, pi) (ignore direction)\n    orient = np.mod(theta, np.pi)\n    nbins = 16\n    hist, _ = np.histogram(orient.ravel(), bins=nbins, range=(0.0, np.pi), weights=mag.ravel())\n    total = float(hist.sum()) + eps\n    p = hist / total\n    # entropy normalized by log(nbins)\n    ent = -float(np.sum(np.where(p > 0, p * np.log(p), 0.0)))\n    norm = np.log(float(nbins))\n    result = float(ent / (norm + eps))\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Dominant average gradient angle in the top-right quadrant in degrees (negative/positive slope of strokes there can distinguish 7s or slanted parts of 4)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    tr = gray[: max(1, h // 3), max(0, 2 * w // 3):]\n    if tr.size == 0:\n        return 0.0\n    gy, gx = np.gradient(tr)\n    # average gradients\n    mean_gx = np.mean(gx)\n    mean_gy = np.mean(gy)\n    angle = np.arctan2(mean_gy, mean_gx)  # radians\n    # convert to degrees and normalize to [-180,180]\n    deg = np.degrees(angle)\n    return float(deg)\n",
    "def feature(image: np.ndarray) -> float:\n    'Longest vertical consecutive ink run within the left-third of the image, normalized by image height'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    gray = np.mean(image, axis=2) if len(image.shape) == 3 else image.astype(float)\n    gray = np.array(gray, dtype=float)\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.sum(ink) > gray.size / 2:\n        ink = ~ink\n    left_w = max(1, w // 3)\n    region = ink[:, 0:left_w]\n    max_run = 0\n    # compute vertical runs per column\n    for c in range(region.shape[1]):\n        col = region[:, c].astype(int)\n        # compute run lengths\n        if col.sum() == 0:\n            continue\n        # diff trick to get runs\n        diff = np.diff(np.concatenate(([0], col, [0])))\n        starts = np.where(diff == 1)[0]\n        ends = np.where(diff == -1)[0]\n        if starts.size and ends.size:\n            runs = ends - starts\n            max_run = max(max_run, np.max(runs))\n    return float(max_run / max(h, 1))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Coarseness estimate: fraction of energy in low-frequency (box-smoothed) component'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # 3x3 box blur via rolling sum (efficient, boundary-wrap okay)\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    low = s / 9.0\n    high = a - low\n    e_low = float((low * low).mean())\n    e_high = float((high * high).mean())\n    result = e_low / (e_low + e_high + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Variability of local contrast across a 4x4 grid (higher => more uneven texture)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    gs = 4\n    ys = np.linspace(0, h, gs + 1, dtype=int)\n    xs = np.linspace(0, w, gs + 1, dtype=int)\n    local_stds = []\n    for i in range(gs):\n        for j in range(gs):\n            block = a[ys[i]:ys[i+1], xs[j]:xs[j+1]]\n            if block.size:\n                local_stds.append(float(block.std()))\n    if len(local_stds) == 0:\n        return 0.0\n    local_stds = np.array(local_stds)\n    global_std = float(a.std()) + eps\n    # variability normalized\n    result = float(np.var(local_stds) / (global_std ** 2 + eps))\n    # clip to reasonable range\n    return float(np.clip(result, 0.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Shannon entropy of intensity histogram (0..1 normalized)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    # use fixed number of bins\n    bins = 64\n    hist, _ = np.histogram(flat, bins=bins, density=True)\n    p = hist.astype(float)\n    p = p[p > 0]\n    if p.size == 0:\n        return 0.0\n    ent = -float(np.sum(p * np.log(p + eps)))\n    # normalize by log(bins)\n    result = ent / (np.log(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Excess kurtosis of intensity distribution (Fisher, can be negative)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    vals = arr.ravel()\n    if vals.size < 4:\n        return 0.0\n    mean = vals.mean()\n    sd = vals.std()\n    if sd <= 0:\n        return 0.0\n    m4 = np.mean((vals - mean) ** 4)\n    kurt = m4 / (sd ** 4) - 3.0\n    # clip to a reasonable range\n    return float(np.clip(kurt, -10.0, 10.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized largest consecutive ink run length on the central row (0..1)'\n    img = np.array(image)\n    if img.size == 0:\n        return 0.0\n    if len(img.shape) == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img.astype(float)\n    h, w = gray.shape[:2]\n    mid = h // 2\n    thr = np.mean(gray)\n    ink = gray < thr\n    if np.count_nonzero(ink) / (h * w) > 0.6:\n        ink = gray > thr\n    row = ink[mid, :]\n    if w == 0:\n        return 0.0\n    max_run = 0\n    cur = 0\n    for v in row:\n        if v:\n            cur += 1\n            if cur > max_run:\n                max_run = cur\n        else:\n            cur = 0\n    return float(max_run / max(1, w))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bounding-box aspect ratio of the largest ink component (height / width), returns 1.0 if no ink'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    thresh = np.mean(gray)\n    ink = gray < thresh\n    if np.mean(ink) > 0.75:\n        ink = ~ink\n    coords = np.column_stack(np.nonzero(ink))\n    if coords.size == 0:\n        return 1.0\n    minr = int(np.min(coords[:, 0])); maxr = int(np.max(coords[:, 0]))\n    minc = int(np.min(coords[:, 1])); maxc = int(np.max(coords[:, 1]))\n    bw = maxc - minc + 1\n    bh = maxr - minr + 1\n    if bw <= 0:\n        return 1.0\n    return float(bh / bw)\n",
    "def feature(image: np.ndarray) -> float:\n    'Left-right symmetry score: Pearson correlation between left and mirrored right (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if w < 2:\n        return 0.0\n    mid = w // 2\n    left = a[:, :mid]\n    right = a[:, -mid:] if mid > 0 else None\n    if right is None or left.size == 0 or right.size == 0:\n        return 0.0\n    # mirror right horizontally\n    right_mir = np.fliplr(right)\n    # crop to same shape if widths differ by one\n    min_w = min(left.shape[1], right_mir.shape[1])\n    left_crop = left[:, :min_w].ravel()\n    right_crop = right_mir[:, :min_w].ravel()\n    if left_crop.size == 0:\n        return 0.0\n    lx = left_crop - left_crop.mean()\n    rx = right_crop - right_crop.mean()\n    denom = (np.sqrt((lx ** 2).sum() * (rx ** 2).sum()) + eps)\n    corr = float((lx * rx).sum() / denom)\n    result = abs(corr)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of pixels significantly brighter than image mean (foreground presence)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h * w == 0:\n        return 0.0\n    m = float(arr.mean())\n    s = float(arr.std())\n    thr = m + 0.5 * s\n    mask = arr > thr\n    frac = float(np.count_nonzero(mask)) / float(h * w)\n    return float(np.clip(frac, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy fraction (0..1) using discrete Laplacian squared energy'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # discrete 4-neighbor Laplacian via rolls (no boundary loss)\n    up = np.roll(a, -1, axis=0)\n    down = np.roll(a, 1, axis=0)\n    left = np.roll(a, -1, axis=1)\n    right = np.roll(a, 1, axis=1)\n    lap = (4.0 * a) - (up + down + left + right)\n    lap_energy = float((lap ** 2).sum())\n    total_var = float(((a - a.mean()) ** 2).sum()) + eps\n    result = lap_energy / (total_var + eps)\n    # normalize to reasonable 0..1\n    result = float(np.clip(result / (1.0 + result), 0.0, 1.0))\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink in an outer frame (border) to ink in the central box (higher for ring-like zeros)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    h, w = image.shape[:2]\n    if image.ndim == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    overall_mean = np.mean(gray)\n    cs = max(1, min(h, w) // 10)\n    corners = np.concatenate([\n        gray[:cs, :cs].ravel(),\n        gray[:cs, -cs:].ravel(),\n        gray[-cs:, :cs].ravel(),\n        gray[-cs:, -cs:].ravel()\n    ])\n    corner_mean = np.mean(corners) if corners.size > 0 else overall_mean\n    thresh = (overall_mean + corner_mean) / 2.0\n    ink_darker = overall_mean < corner_mean\n    if ink_darker:\n        mask = (gray < thresh).astype(np.uint8)\n    else:\n        mask = (gray > thresh).astype(np.uint8)\n    total_ink = np.count_nonzero(mask)\n    if total_ink == 0:\n        return 0.0\n    # define border frame as 10% wide around edges\n    bw_h = max(1, h // 8)\n    bw_w = max(1, w // 8)\n    top = mask[:bw_h, :]\n    bottom = mask[-bw_h:, :]\n    left = mask[:, :bw_w]\n    right = mask[:, -bw_w:]\n    border_ink = (np.count_nonzero(top) + np.count_nonzero(bottom) +\n                  np.count_nonzero(left) + np.count_nonzero(right))\n    # center box\n    ch0, ch1 = h // 4, w // 4\n    center = mask[ch0:3*ch0 if 3*ch0>ch0 else h, ch1:3*ch1 if 3*ch1>ch1 else w]\n    center_ink = np.count_nonzero(center)\n    # avoid division by zero\n    denom = float(center_ink) if center_ink > 0 else float(total_ink)\n    return float(border_ink) / denom\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Edge density: fraction of pixels with strong gradient magnitude'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        arr = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(arr.astype(float))\n    h, w = arr.shape\n    if h == 0 or w == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    mag = np.hypot(gx, gy)\n    thr = float(np.mean(mag) + np.std(mag))\n    count = float(np.count_nonzero(mag > thr))\n    denom = float(mag.size) if mag.size else 1.0\n    result = count / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean vertical-edge magnitude on right half to left half (right/left vertical edge ratio)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(gray)\n    left = slice(0, w // 2)\n    right = slice(w // 2, w)\n    left_mean = np.mean(np.abs(gx[:, left])) + 1e-9\n    right_mean = np.mean(np.abs(gx[:, right])) + 1e-9\n    return float(right_mean / left_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of gradient energy in the dominant edge orientation bin (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    total = mag.sum()\n    if total <= eps:\n        return 0.0\n    ang = np.arctan2(gy, gx)\n    # orientation modulo pi (unsigned)\n    ang = np.mod(ang, np.pi)\n    bins = 12\n    hist, _ = np.histogram(ang, bins=bins, range=(0.0, np.pi), weights=mag)\n    max_bin = float(hist.max())\n    result = max_bin / (total + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency energy ratio via FFT (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    A = a - a.mean()\n    try:\n        F = np.fft.fft2(A)\n    except Exception:\n        return 0.0\n    P = np.abs(F) ** 2\n    # frequency coordinates\n    fy = np.fft.fftfreq(h)\n    fx = np.fft.fftfreq(w)\n    fy = fy[:, None]\n    fx = fx[None, :]\n    R = np.hypot(fy, fx)\n    cutoff = 0.125 * R.max() if R.max() > 0 else 0.0\n    low_mask = R <= cutoff\n    total_energy = P.sum() + eps\n    low_energy = P[low_mask].sum()\n    result = float(low_energy) / float(total_energy)\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Low-frequency FFT energy fraction (0..1) using central radius = min(h,w)/8'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # subtract mean to focus on variations\n    f = np.fft.fftshift(np.fft.fft2(a - a.mean()))\n    mag = np.abs(f)\n    cy, cx = h // 2, w // 2\n    ry = np.arange(h) - cy\n    rx = np.arange(w) - cx\n    Y, X = np.ogrid[:h, :w]\n    dist = np.hypot(Y - cy, X - cx)\n    radius = max(1.0, min(h, w) / 8.0)\n    mask = dist <= radius\n    low = float(mag[mask].sum())\n    total = float(mag.sum()) + eps\n    return float(np.clip(low / total, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Fraction of rows in the middle third that contain a long horizontal ink run (>40% width)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx == mn:\n        return 0.0\n    norm = (gray - mn) / (mx - mn)\n    mask = norm < 0.5\n    r0, r1 = h // 3, (2 * h) // 3\n    if r1 <= r0:\n        return 0.0\n    rows = mask[r0:r1, :]\n    long_thresh = max(1, int(0.4 * w))\n    count_rows_with_long = 0\n    for row in rows:\n        # find runs\n        if not np.any(row):\n            continue\n        # compute lengths of contiguous True segments\n        padded = np.concatenate([[0], row.astype(int), [0]])\n        diffs = np.diff(padded)\n        starts = np.nonzero(diffs == 1)[0]\n        ends = np.nonzero(diffs == -1)[0]\n        lengths = ends - starts\n        if np.any(lengths >= long_thresh):\n            count_rows_with_long += 1\n    total_rows = rows.shape[0]\n    if total_rows == 0:\n        return 0.0\n    return float(count_rows_with_long / float(total_rows))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Size of background region reachable from bottom-right corner of the bottom-right quadrant (normalized)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    rng = mx - mn + 1e-9\n    norm = (gray - mn) / rng\n    low = norm < 0.5\n    high = ~low\n    ink = low if low.sum() <= high.sum() else high\n    ink = ink.astype(np.uint8)\n    # bottom-right quadrant coordinates\n    r0, c0 = h // 2, w // 2\n    quadrant = ink[r0:h, c0:w]\n    # background mask in quadrant\n    bg = (quadrant == 0)\n    if bg.size == 0:\n        return 0.0\n    # flood fill from bottom-right corner of the quadrant\n    H, W = bg.shape\n    visited = np.zeros_like(bg, dtype=np.bool_)\n    stack = []\n    # starting point is lower-right pixel in original image -> (H-1, W-1)\n    if bg[H-1, W-1]:\n        stack.append((H-1, W-1))\n        visited[H-1, W-1] = True\n    count = 0\n    while stack:\n        r, c = stack.pop()\n        count += 1\n        # 4-neighbors\n        if r > 0 and bg[r-1, c] and not visited[r-1, c]:\n            visited[r-1, c] = True; stack.append((r-1, c))\n        if r + 1 < H and bg[r+1, c] and not visited[r+1, c]:\n            visited[r+1, c] = True; stack.append((r+1, c))\n        if c > 0 and bg[r, c-1] and not visited[r, c-1]:\n            visited[r, c-1] = True; stack.append((r, c-1))\n        if c + 1 < W and bg[r, c+1] and not visited[r, c+1]:\n            visited[r, c+1] = True; stack.append((r, c+1))\n    # normalize by quadrant area\n    return float(count / float(max(1, bg.size)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of ink density in upper quarter vs lower quarter (upper_density / (lower_density + eps))'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0:\n        return 0.0\n    gm = np.mean(gray)\n    corner = np.mean(gray[:max(1,h//10), :max(1,w//10)])\n    ink = gray < gm if corner > gm else gray > gm\n    ink = np.asarray(ink, dtype=bool)\n    q = max(1, h // 4)\n    upper = ink[:q, :].sum() / float(max(1, q * w))\n    lower = ink[-q:, :].sum() / float(max(1, q * w))\n    return float(upper / (lower + 1e-9))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative horizontal edge energy concentrated in the middle third of the image (captures mid horizontal cross in 4)'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    gy, gx = np.gradient(gray)\n    horiz_energy = np.abs(gy)\n    r0, r1 = h // 3, (2 * h) // 3\n    mid_energy = np.sum(horiz_energy[r0:r1, :])\n    total_energy = np.sum(horiz_energy) + 1e-9\n    return float(mid_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Center-to-corner brightness contrast normalized by image std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    ch0, cw0 = h // 4, w // 4\n    center = a[ch0:3*ch0 or h, cw0:3*cw0 or w]\n    # corners of same size as center (or as close as possible)\n    c_h = max(1, center.shape[0])\n    c_w = max(1, center.shape[1])\n    tl = a[0:c_h, 0:c_w]\n    tr = a[0:c_h, w-c_w:w]\n    bl = a[h-c_h:h, 0:c_w]\n    br = a[h-c_h:h, w-c_w:w]\n    center_mean = float(np.mean(center)) if center.size else 0.0\n    corners_mean = float(np.mean(np.concatenate([tl.ravel(), tr.ravel(), bl.ravel(), br.ravel()]))) if a.size else 0.0\n    overall_std = float(np.std(a)) + eps\n    result = (center_mean - corners_mean) / overall_std\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of mean absolute vertical gradient to horizontal gradient in the top-right quadrant (vertical/horizontal)'\n    import numpy as np\n    h, w = image.shape[:2]\n    gray = np.mean(image, axis=2) if image.ndim == 3 else image.astype(float)\n    r0, c0 = 0, w // 2\n    r1, c1 = max(1, h // 2), w\n    region = gray[r0:r1, c0:c1]\n    if region.size == 0:\n        return 0.0\n    gy, gx = np.gradient(region.astype(float))\n    mean_abs_gx = np.mean(np.abs(gx)) + 1e-9\n    mean_abs_gy = np.mean(np.abs(gy))\n    return float(mean_abs_gy / mean_abs_gx)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Normalized inter-percentile spread ( (p90-p10)/(p90+p10) ) in [0,1]'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.nan_to_num(img.astype(float)).ravel()\n    if a.size == 0:\n        return 0.0\n    p10 = float(np.percentile(a, 10))\n    p90 = float(np.percentile(a, 90))\n    denom = (abs(p90) + abs(p10) + eps)\n    result = (p90 - p10) / denom\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Gradient directionality strength: |mean gradient vector| / mean gradient magnitude (0..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        arr = np.nan_to_num(img.astype(float))\n    if arr.size == 0:\n        return 0.0\n    try:\n        gy, gx = np.gradient(arr)\n    except Exception:\n        return 0.0\n    gx = gx.astype(float)\n    gy = gy.astype(float)\n    mag = np.hypot(gx, gy)\n    mean_vec_x = float((gx * mag).sum()) / (mag.sum() + eps)\n    mean_vec_y = float((gy * mag).sum()) / (mag.sum() + eps)\n    mean_mag = float(mag.mean() + eps)\n    strength = np.hypot(mean_vec_x, mean_vec_y) / mean_mag\n    return float(np.clip(strength, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Histogram peakiness: fraction of histogram bins (16 bins) that are local maxima'\n    import numpy as np\n    bins = 16\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        vals = np.ravel(np.nan_to_num(arr.mean(axis=2).astype(float)))\n    else:\n        vals = np.ravel(np.nan_to_num(arr.astype(float)))\n    if vals.size == 0:\n        return 0.0\n    try:\n        hist, _ = np.histogram(vals, bins=bins, range=(vals.min(), vals.max()))\n    except Exception:\n        return 0.0\n    if hist.size < 3:\n        return 0.0\n    peaks = 0\n    for i in range(hist.size):\n        left = hist[i - 1] if i - 1 >= 0 else -1\n        right = hist[i + 1] if i + 1 < hist.size else -1\n        if hist[i] > left and hist[i] > right:\n            peaks += 1\n    result = float(peaks) / float(hist.size)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Colorfulness metric for color images (0 for grayscale), higher = more colorful'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim != 3 or img.shape[2] < 3:\n        return 0.0\n    a = np.nan_to_num(image.astype(float))\n    # ensure channels last\n    if a.shape[2] < 3:\n        return 0.0\n    R = a[..., 0]\n    G = a[..., 1]\n    B = a[..., 2]\n    rg = R - G\n    yb = 0.5 * (R + G) - B\n    std_rg = float(rg.std())\n    std_yb = float(yb.std())\n    mean_rg = float(rg.mean())\n    mean_yb = float(yb.mean())\n    colorfulness = np.sqrt(std_rg * std_rg + std_yb * std_yb) + 0.3 * np.sqrt(mean_rg * mean_rg + mean_yb * mean_yb)\n    return float(max(0.0, colorfulness))\n",
    "def feature(image: np.ndarray) -> float:\n    'Relative area of the largest inner hole to the bounding box area (useful: 9 often has one large loop, 8 has two moderate loops)'\n    try:\n        import numpy as np\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        if gray.size == 0:\n            return 0.0\n        maxv = gray.max() if gray.max() != 0 else 1.0\n        if maxv > 1.1:\n            gray = gray / 255.0\n        h, w = gray.shape\n        corner = np.concatenate([\n            gray[:max(1, h//16), :max(1, w//16)].ravel(),\n            gray[-max(1, h//16):, :max(1, w//16)].ravel(),\n            gray[:max(1, h//16), -max(1, w//16):].ravel(),\n            gray[-max(1, h//16):, -max(1, w//16):].ravel()\n        ])\n        corner_mean = float(np.mean(corner)) if corner.size else 0.0\n        thresh = float(np.percentile(gray, 40))\n        if corner_mean > 0.5:\n            fg = gray < thresh\n        else:\n            fg = gray > thresh\n        ys, xs = np.where(fg)\n        if ys.size == 0:\n            return 0.0\n        y0, y1 = ys.min(), ys.max()\n        x0, x1 = xs.min(), xs.max()\n        sub = ~fg[y0:y1+1, x0:x1+1]\n        H, W = sub.shape\n        if H <= 0 or W <= 0:\n            return 0.0\n        visited = np.zeros_like(sub, dtype=np.bool_)\n        from collections import deque\n        q = deque()\n        for i in range(H):\n            for j in (0, W-1):\n                if sub[i, j] and not visited[i, j]:\n                    visited[i, j] = True\n                    q.append((i, j))\n        for j in range(W):\n            for i in (0, H-1):\n                if sub[i, j] and not visited[i, j]:\n                    visited[i, j] = True\n                    q.append((i, j))\n        while q:\n            y, x = q.popleft()\n            for dy in (-1, 0, 1):\n                for dx in (-1, 0, 1):\n                    ny, nx = y+dy, x+dx\n                    if 0 <= ny < H and 0 <= nx < W and sub[ny, nx] and not visited[ny, nx]:\n                        visited[ny, nx] = True\n                        q.append((ny, nx))\n        # find hole components and record largest\n        largest = 0\n        for i in range(H):\n            for j in range(W):\n                if sub[i, j] and not visited[i, j]:\n                    # new hole\n                    size = 0\n                    stack = [(i, j)]\n                    visited[i, j] = True\n                    while stack:\n                        y, x = stack.pop()\n                        size += 1\n                        for dy in (-1, 0, 1):\n                            for dx in (-1, 0, 1):\n                                ny, nx = y+dy, x+dx\n                                if 0 <= ny < H and 0 <= nx < W and sub[ny, nx] and not visited[ny, nx]:\n                                    visited[ny, nx] = True\n                                    stack.append((ny, nx))\n                    if size > largest:\n                        largest = size\n        bbox_area = float((y1 - y0 + 1) * (x1 - x0 + 1)) + 1e-8\n        return float(largest / bbox_area)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'X-coordinate (normalized 0..1) of centroid of any enclosed hole (background component not touching border). Returns -1.0 if no holes'\n    import numpy as np\n    from collections import deque\n    if image is None:\n        return -1.0\n    img = np.asarray(image)\n    if img.size == 0:\n        return -1.0\n    if img.ndim == 3:\n        gray = np.mean(img, axis=2)\n    else:\n        gray = img.astype(float)\n    h, w = gray.shape[:2]\n    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n    border_mean = np.mean(border) if border.size else np.mean(gray)\n    thresh = (border_mean + np.mean(gray)) / 2.0\n    fg = gray < thresh if border_mean > np.mean(gray) else gray > thresh\n    bg = ~fg\n    visited = np.zeros_like(bg, dtype=bool)\n    hole_centroids_x = []\n    for y in range(h):\n        for x in range(w):\n            if not bg[y, x] or visited[y, x]:\n                continue\n            # BFS flood fill\n            q = deque()\n            q.append((y, x))\n            visited[y, x] = True\n            coords = []\n            touches_border = False\n            while q:\n                yy, xx = q.popleft()\n                coords.append((yy, xx))\n                if yy == 0 or yy == h-1 or xx == 0 or xx == w-1:\n                    touches_border = True\n                # 4-connectivity\n                for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n                    ny, nx = yy+dy, xx+dx\n                    if 0 <= ny < h and 0 <= nx < w and (not visited[ny, nx]) and bg[ny, nx]:\n                        visited[ny, nx] = True\n                        q.append((ny, nx))\n            if not touches_border:\n                coords = np.array(coords)\n                if coords.size:\n                    cx = coords[:,1].mean()\n                    hole_centroids_x.append(cx / max(1, w-1))\n    if not hole_centroids_x:\n        return -1.0\n    return float(np.mean(hole_centroids_x))\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of diagonal edge strength (45 and -45 deg) to the sum of vertical+horizontal edge strength'\n    try:\n        if len(image.shape) == 3:\n            gray = np.mean(image, axis=2).astype(float)\n        else:\n            gray = image.astype(float)\n        gy, gx = np.gradient(gray)\n        abs_gx = np.abs(gx)\n        abs_gy = np.abs(gy)\n        # diagonal proxies: |gx +/- gy|\n        diag1 = np.abs(gx + gy)\n        diag2 = np.abs(gx - gy)\n        diag_strength = np.sum(diag1) + np.sum(diag2)\n        vert_horiz = np.sum(abs_gx) + np.sum(abs_gy)\n        denom = vert_horiz + 1e-9\n        return float(diag_strength / denom)\n    except Exception:\n        return 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Bright local maxima fraction: fraction of pixels that are local 3x3 maxima above mean+std'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        img = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        img = np.nan_to_num(arr.astype(float))\n    h, w = img.shape\n    if h * w == 0:\n        return 0.0\n    # smooth with 3x3 average\n    offsets = (-1, 0, 1)\n    sm = np.zeros_like(img, dtype=float)\n    for dy in offsets:\n        for dx in offsets:\n            sm += np.roll(np.roll(img, dy, axis=0), dx, axis=1)\n    sm /= 9.0\n    # compare to 8 neighbors\n    is_max = np.ones_like(sm, dtype=bool)\n    for dy in offsets:\n        for dx in offsets:\n            if dy == 0 and dx == 0:\n                continue\n            neigh = np.roll(np.roll(sm, dy, axis=0), dx, axis=1)\n            is_max &= (sm > neigh)\n    thr = float(sm.mean() + sm.std())\n    peaks = is_max & (sm > thr)\n    count = float(np.count_nonzero(peaks))\n    result = count / float(img.size + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Robust percentile contrast: (P90 - P10) / (median + eps)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        flat = np.nan_to_num(img.mean(axis=2).ravel().astype(float))\n    else:\n        flat = np.nan_to_num(img.ravel().astype(float))\n    if flat.size == 0:\n        return 0.0\n    p90 = float(np.percentile(flat, 90))\n    p10 = float(np.percentile(flat, 10))\n    med = float(np.median(flat))\n    result = (p90 - p10) / (abs(med) + eps)\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Intensity histogram entropy (32 bins) normalized to [0..1]'\n    import numpy as np\n    eps = 1e-12\n    bins = 32\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        arr = np.nan_to_num(img.mean(axis=2).ravel().astype(float))\n    else:\n        arr = np.nan_to_num(img.ravel().astype(float))\n    if arr.size == 0:\n        return 0.0\n    vmin = float(arr.min())\n    vmax = float(arr.max())\n    if vmax <= vmin:\n        return 0.0\n    hist, _ = np.histogram(arr, bins=bins, range=(vmin, vmax))\n    p = hist.astype(float) / (hist.sum() + eps)\n    p_nonzero = p[p > 0.0]\n    if p_nonzero.size == 0:\n        return 0.0\n    entropy = -np.sum(p_nonzero * np.log2(p_nonzero))\n    result = entropy / (np.log2(bins) + eps)\n    return float(np.clip(result, 0.0, 1.0))\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio from 2D FFT (fraction of power outside low-frequency disk)'\n    import numpy as np\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    # FFT power\n    F = np.fft.fft2(a)\n    P = np.abs(np.fft.fftshift(F)) ** 2\n    ys, xs = np.indices((h, w))\n    cy = (h - 1) / 2.0\n    cx = (w - 1) / 2.0\n    r = np.hypot(xs - cx, ys - cy)\n    # define low-frequency radius as 1/8 of smaller dimension\n    r0 = max(1.0, min(h, w) / 8.0)\n    total = float(P.sum()) + 1e-12\n    high = float(P[r > r0].sum())\n    result = high / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Proportion of strong gradients whose orientation is near-vertical (useful to detect vertical strokes like 4)'\n    import numpy as np\n    if image is None:\n        return 0.0\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    if h == 0 or w == 0:\n        return 0.0\n    mx = gray.max()\n    if mx > 1e-9:\n        gray = gray / float(mx)\n    gy, gx = np.gradient(gray)\n    mag = np.hypot(gx, gy) + 1e-9\n    orientations = np.arctan2(gy, gx)  # -pi..pi\n    # angle difference to vertical (pi/2) and -pi/2\n    angle_to_vert = np.minimum(np.abs(orientations - np.pi / 2), np.abs(orientations + np.pi / 2))\n    mask_strong = mag > (np.median(mag) * 0.7 + 1e-9)\n    if np.count_nonzero(mask_strong) == 0:\n        return 0.0\n    near_vert = np.sum((angle_to_vert < (np.pi / 8)) & mask_strong)\n    return float(near_vert / np.count_nonzero(mask_strong))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Orientation bias: normalized difference between column-mean and row-mean variances (-1..1)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    if a.size == 0:\n        return 0.0\n    col_means = a.mean(axis=0)\n    row_means = a.mean(axis=1)\n    var_c = float(np.var(col_means))\n    var_r = float(np.var(row_means))\n    result = (var_c - var_r) / (var_c + var_r + eps)\n    return float(np.clip(result, -1.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Approximate circularity of ink regions: 4*pi*Area / (Perimeter^2); higher for round loops like 0'\n    import numpy as np\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    h, w = gray.shape[:2]\n    thresh = np.mean(gray)\n    dark_mask = gray < thresh\n    ink = dark_mask if dark_mask.sum() <= (h * w) / 2 else ~dark_mask\n    area = float(ink.sum())\n    if area == 0:\n        return 0.0\n    # approximate perimeter by gradient magnitude threshold\n    gy, gx = np.gradient(gray)\n    grad = np.hypot(gx, gy)\n    # emphasize edges by masking to ink boundaries: gradient on mean image masked by ink XOR eroded ink\n    padded = np.pad(ink.astype(np.uint8), 1, mode='constant', constant_values=0)\n    eroded = np.ones_like(ink, dtype=bool)\n    for dy, dx in [(-1,0),(1,0),(0,-1),(0,1)]:\n        eroded &= padded[1+dy:1+dy+h,1+dx:1+dx+w].astype(bool)\n    boundary = ink & (~eroded)\n    # perimeter approximation: count boundary pixels weighted by gradient\n    if np.any(boundary):\n        perim = float(boundary.sum())\n    else:\n        # fallback: use high-gradient pixels\n        thr = np.percentile(grad, 75) if grad.size > 0 else 0.0\n        perim = float(np.count_nonzero(grad > thr))\n    if perim <= 0.0:\n        return 0.0\n    circ = 4.0 * np.pi * area / (perim * perim + 1e-9)\n    return float(circ)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Ratio of vertical gradient energy on the right half to total vertical gradient energy (captures vertical edge concentration on the right)'\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    if gray.size == 0:\n        return 0.0\n    # compute vertical gradient on grayscale image\n    gy, gx = np.gradient(gray)\n    vmag = np.abs(gy)\n    h, w = gray.shape\n    right = vmag[:, w // 2:]\n    total_energy = vmag.sum()\n    if total_energy == 0:\n        return 0.0\n    right_energy = right.sum()\n    return float(right_energy / total_energy)\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean local contrast: mean |pixel - local3x3_mean| normalized by global std'\n    import numpy as np\n    eps = 1e-8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h == 0 or w == 0:\n        return 0.0\n    # 3x3 local mean via rolling sum\n    s = np.zeros_like(a)\n    s += a\n    s += np.roll(a, 1, axis=0)\n    s += np.roll(a, -1, axis=0)\n    s += np.roll(a, 1, axis=1)\n    s += np.roll(a, -1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, 1, axis=0), -1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), 1, axis=1)\n    s += np.roll(np.roll(a, -1, axis=0), -1, axis=1)\n    local_mean = s / 9.0\n    diff = np.abs(a - local_mean)\n    gstd = float(a.std()) + eps\n    result = float(np.mean(diff)) / gstd\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio using discrete Laplacian'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    # 4-neighbor Laplacian\n    lap = (-4.0 * a +\n           np.roll(a, 1, axis=0) + np.roll(a, -1, axis=0) +\n           np.roll(a, 1, axis=1) + np.roll(a, -1, axis=1))\n    hf = float(np.sum(np.abs(lap)))\n    base = float(np.sum(np.abs(a))) + eps\n    result = hf / base\n    return float(result)\n\n",
    "def feature(image: np.ndarray) -> float:\n    'High-frequency energy ratio in gradients (proportion of gradient energy in strong edges)'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(img.astype(float))\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.size == 0:\n        return 0.0\n    med = float(np.median(mag)) + eps\n    # count energy above a multiple of median (captures strong high-frequency content)\n    mask = mag > (2.0 * med)\n    hf_energy = float((mag * mask).sum())\n    total = float(mag.sum()) + eps\n    result = hf_energy / total\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Mean pairwise distance among top bright pixels normalized by half-diagonal (0..1)'\n    import numpy as np\n    eps = 1e-12\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    flat = a.ravel()\n    if flat.size == 0:\n        return 0.0\n    k = min(50, flat.size)\n    # pick top-k indices\n    idx = np.argpartition(-flat, k-1)[:k]\n    coords = np.vstack(np.unravel_index(idx, (h, w))).T.astype(float)\n    if coords.shape[0] < 2:\n        return 0.0\n    # pairwise distances\n    dif = coords[:, None, :] - coords[None, :, :]\n    d = np.hypot(dif[..., 0], dif[..., 1])\n    # take upper triangle without diagonal\n    i_upper = np.triu_indices(d.shape[0], k=1)\n    dvals = d[i_upper]\n    mean_d = float(dvals.mean()) if dvals.size else 0.0\n    half_diag = (np.hypot(h, w) / 2.0) + eps\n    result = mean_d / half_diag\n    return float(np.clip(result, 0.0, 1.0))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Contrast between top 10% brightest and bottom 10% darkest pixels normalized by overall std'\n    import numpy as np\n    eps = 1e-12\n    img = np.asarray(image)\n    if img.size == 0:\n        return 0.0\n    if img.ndim == 3:\n        a = np.nan_to_num(img.mean(axis=2).astype(float)).ravel()\n    else:\n        a = np.ravel(np.nan_to_num(img.astype(float)))\n    if a.size == 0:\n        return 0.0\n    p90 = np.percentile(a, 90)\n    p10 = np.percentile(a, 10)\n    top_mean = float(a[a >= p90].mean()) if np.any(a >= p90) else float(a.mean())\n    bot_mean = float(a[a <= p10].mean()) if np.any(a <= p10) else float(a.mean())\n    overall_std = float(a.std()) + eps\n    result = (top_mean - bot_mean) / overall_std\n    return float(result)\n\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Length of longest horizontal stroke in the middle third (useful to detect the cross-bar of a \"4\"), normalized by width'\n    h, w = image.shape[:2]\n    if len(image.shape) == 3:\n        gray = np.mean(image, axis=2).astype(float)\n    else:\n        gray = image.astype(float)\n    mn, mx = float(np.min(gray)), float(np.max(gray))\n    if mx > mn:\n        gray = (gray - mn) / (mx - mn)\n    else:\n        gray = gray * 0.0\n    thr = np.percentile(gray, 50.0)\n    ink = (gray < thr).astype(np.uint8)\n    if np.sum(ink) == 0:\n        ink = (gray > thr).astype(np.uint8)\n        if np.sum(ink) == 0:\n            return 0.0\n    r0 = h // 3\n    r1 = max(r0 + 1, (2 * h) // 3)\n    middle = ink[r0:r1, :]\n    max_run = 0\n    for row in middle:\n        padded = np.concatenate(([0], row, [0]))\n        changes = np.diff(padded)\n        starts = np.nonzero(changes == 1)[0]\n        ends = np.nonzero(changes == -1)[0]\n        if starts.size and ends.size:\n            runs = ends - starts\n            max_run = max(int(np.max(runs)), max_run)\n    return float(max_run / max(1, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    'Entropy of gradient orientation histogram (0..1)'\n    import numpy as np\n    eps = 1e-12\n    bins = 8\n    arr = np.asarray(image)\n    if arr.size == 0:\n        return 0.0\n    if arr.ndim == 3:\n        a = np.nan_to_num(arr.mean(axis=2).astype(float))\n    else:\n        a = np.nan_to_num(arr.astype(float))\n    h, w = a.shape\n    if h < 2 or w < 2:\n        return 0.0\n    gy, gx = np.gradient(a)\n    mag = np.hypot(gx, gy)\n    if mag.sum() <= eps:\n        return 0.0\n    theta = np.arctan2(gy, gx)  # -pi..pi\n    # bin orientations into [0..pi) so opposite directions count the same\n    theta = np.mod(theta, np.pi)\n    hist, _ = np.histogram(theta, bins=bins, range=(0.0, np.pi), weights=mag)\n    p = hist.astype(float) / (hist.sum() + eps)\n    p = p[p > 0]\n    entropy = -np.sum(p * np.log2(p + eps))\n    max_entropy = np.log2(bins)\n    result = entropy / (max_entropy + eps)\n    return float(np.clip(result, 0.0, 1.0))\n\n\n"
  ]
}