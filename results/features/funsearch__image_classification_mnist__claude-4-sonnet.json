{
  "used_features": [
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of bright pixels (above 75th percentile) to total pixels\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 75)\n    bright_pixels = np.count_nonzero(image > threshold)\n    return float(bright_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Contrast measure using standard deviation divided by mean intensity\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return 0.0\n    return float(np.std(image) / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Edge density using gradient magnitude\"\n    if image.size == 0:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    edge_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n    return float(np.mean(edge_magnitude))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Vertical symmetry score comparing left and right halves\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if w < 2:\n        return 1.0\n    left_half = image[:, :w//2]\n    right_half = np.fliplr(image[:, w//2:])\n    min_width = min(left_half.shape[1], right_half.shape[1])\n    left_crop = left_half[:, :min_width]\n    right_crop = right_half[:, :min_width]\n    diff = np.mean(np.abs(left_crop - right_crop))\n    max_val = max(np.max(image), 1)\n    return float(1.0 - diff / max_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity difference between center and border regions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.0\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    border = np.concatenate([image[:h//4, :].flatten(), \n                           image[3*h//4:, :].flatten(),\n                           image[h//4:3*h//4, :w//4].flatten(),\n                           image[h//4:3*h//4, 3*w//4:].flatten()])\n    if border.size == 0 or center.size == 0:\n        return 0.0\n    return float(np.mean(center) - np.mean(border))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy measure using intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=50)\n    hist = hist + 1e-10\n    hist = hist / np.sum(hist)\n    entropy = -np.sum(hist * np.log2(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Aspect ratio weighted by intensity variance\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h == 0:\n        return 0.0\n    aspect_ratio = w / h\n    variance = np.var(image)\n    return float(aspect_ratio * (1 + variance / 255))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent pixels horizontally\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h_diff = np.abs(image[:, 1:] - image[:, :-1])\n    return float(np.max(h_diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in top half versus bottom half average intensity\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 1.0\n    h, w = image.shape\n    top_half = np.mean(image[:h//2, :])\n    bottom_half = np.mean(image[h//2:, :])\n    if bottom_half == 0:\n        return float(top_half)\n    return float(top_half / bottom_half)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of row-wise intensity means\"\n    if image.size == 0:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    return float(np.std(row_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of pixels within one standard deviation of the mean\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    std_val = np.std(image)\n    if std_val == 0:\n        return 1.0\n    within_std = np.count_nonzero(np.abs(image - mean_val) <= std_val)\n    return float(within_std / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Diagonal symmetry score comparing main diagonal regions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 1.0\n    upper_tri = np.triu(image[:min_dim, :min_dim])\n    lower_tri = np.tril(image[:min_dim, :min_dim]).T\n    diff = np.mean(np.abs(upper_tri - lower_tri))\n    max_val = max(np.max(image), 1)\n    return float(1.0 - diff / max_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Range of column-wise intensity sums\"\n    if image.size == 0:\n        return 0.0\n    col_sums = np.sum(image, axis=0)\n    return float(np.max(col_sums) - np.min(col_sums))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation between pixel position and intensity values\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    positions = np.arange(image.size)\n    intensities = image.flatten()\n    if np.std(positions) == 0 or np.std(intensities) == 0:\n        return 0.0\n    correlation = np.corrcoef(positions, intensities)[0, 1]\n    return float(0.0 if np.isnan(correlation) else correlation)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum non-zero pixel values\"\n    if image.size == 0:\n        return 1.0\n    nonzero_pixels = image[image > 0]\n    if nonzero_pixels.size == 0:\n        return 1.0\n    min_nz = np.min(nonzero_pixels)\n    max_nz = np.max(nonzero_pixels)\n    if min_nz == 0:\n        return float(max_nz)\n    return float(max_nz / min_nz)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local contrast measured by variance of local means in 3x3 neighborhoods\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.var(image))\n    local_means = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            local_mean = np.mean(image[i-1:i+2, j-1:j+2])\n            local_means.append(local_mean)\n    return float(np.var(local_means)) if local_means else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Kurtosis of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    if len(flat) < 4:\n        return 0.0\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    centered = flat - mean_val\n    fourth_moment = np.mean(centered**4)\n    kurtosis = fourth_moment / (std_val**4) - 3\n    return float(kurtosis)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile to those below 25th percentile\"\n    if image.size == 0:\n        return 1.0\n    p25 = np.percentile(image, 25)\n    p75 = np.percentile(image, 75)\n    below_25 = np.count_nonzero(image <= p25)\n    above_75 = np.count_nonzero(image >= p75)\n    if below_25 == 0:\n        return float(above_75)\n    return float(above_75 / below_25)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Smoothness measure using inverse of variance plus one\"\n    if image.size == 0:\n        return 1.0\n    variance = np.var(image)\n    smoothness = 1.0 - (1.0 / (1.0 + variance))\n    return float(smoothness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Energy measure as sum of squared pixel intensities normalized by size\"\n    if image.size == 0:\n        return 0.0\n    energy = np.sum(image**2)\n    normalized_energy = energy / image.size\n    return float(normalized_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of corner pixels relative to center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.mean(image))\n    corners = [image[0,0], image[0,w-1], image[h-1,0], image[h-1,w-1]]\n    center_val = image[h//2, w//2]\n    corner_avg = np.mean(corners)\n    if center_val == 0:\n        return float(corner_avg)\n    return float(corner_avg / center_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity range spanned by middle 50% of pixels\"\n    if image.size == 0:\n        return 0.0\n    p25 = np.percentile(image, 25)\n    p75 = np.percentile(image, 75)\n    return float(p75 - p25)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent columns\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    col_diffs = np.abs(np.diff(col_means))\n    return float(np.max(col_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Concentration of high intensity pixels in center quadrant\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return float(np.mean(image > np.mean(image)))\n    center_quad = image[h//4:3*h//4, w//4:3*w//4]\n    threshold = np.percentile(image, 75)\n    center_high = np.sum(center_quad > threshold)\n    total_high = np.sum(image > threshold)\n    if total_high == 0:\n        return 0.0\n    return float(center_high / total_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Smoothness measure using second derivative magnitude\"\n    if image.size == 0:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    grad2_y, _ = np.gradient(grad_y)\n    _, grad2_x = np.gradient(grad_x)\n    second_deriv = np.sqrt(grad2_x**2 + grad2_y**2)\n    return float(np.mean(second_deriv))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of bright pixels in outer ring to total bright pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 0.5\n    threshold = np.percentile(image, 80)\n    outer_ring = np.zeros_like(image, dtype=bool)\n    outer_ring[:h//6, :] = True\n    outer_ring[5*h//6:, :] = True\n    outer_ring[:, :w//6] = True\n    outer_ring[:, 5*w//6:] = True\n    bright_pixels = image > threshold\n    outer_bright = np.sum(bright_pixels & outer_ring)\n    total_bright = np.sum(bright_pixels)\n    if total_bright == 0:\n        return 0.0\n    return float(outer_bright / total_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity weighted centroid distance from image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    total_intensity = np.sum(image)\n    if total_intensity == 0:\n        return 0.0\n    y_indices, x_indices = np.mgrid[0:h, 0:w]\n    centroid_y = np.sum(y_indices * image) / total_intensity\n    centroid_x = np.sum(x_indices * image) / total_intensity\n    center_y, center_x = h / 2, w / 2\n    return float(np.sqrt((centroid_y - center_y)**2 + (centroid_x - center_x)**2))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Frequency of intensity transitions exceeding median difference\"\n    if image.size == 0:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    all_gradients = np.concatenate([grad_y.flatten(), grad_x.flatten()])\n    median_grad = np.median(np.abs(all_gradients))\n    if median_grad == 0:\n        return 0.0\n    strong_transitions = np.sum(np.abs(all_gradients) > median_grad)\n    return float(strong_transitions / len(all_gradients))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry between left and right halves intensity distribution\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_mean = np.mean(left_half)\n    right_mean = np.mean(right_half)\n    combined_mean = np.mean(image)\n    if combined_mean == 0:\n        return 0.0\n    return float(abs(left_mean - right_mean) / combined_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy approximation using intensity histogram bins\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=16)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    probs = hist / np.sum(hist)\n    return float(-np.sum(probs * np.log2(probs)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Kurtosis of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    normalized = (flat - mean_val) / std_val\n    kurtosis = np.mean(normalized**4) - 3\n    return float(kurtosis)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Diagonal symmetry measure comparing top-left to bottom-right triangles\"\n    if image.size == 0 or image.shape[0] != image.shape[1]:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    square = image[:min_dim, :min_dim]\n    upper_tri = np.triu(square, k=1)\n    lower_tri = np.tril(square, k=-1).T\n    if np.sum(upper_tri) + np.sum(lower_tri) == 0:\n        return 1.0\n    return float(1.0 - np.mean(np.abs(upper_tri - lower_tri)) / (np.mean(square) + 1e-10))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local contrast variation using sliding window standard deviations\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_stds = []\n    for i in range(0, h-2, 2):\n        for j in range(0, w-2, 2):\n            window = image[i:i+3, j:j+3]\n            local_stds.append(np.std(window))\n    return float(np.std(local_stds) if local_stds else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in corner regions to center region\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_mean = np.mean(corners)\n    center_mean = np.mean(center)\n    if center_mean == 0:\n        return float(corner_mean)\n    return float(corner_mean / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Texture measure using coefficient of variation in local neighborhoods\"\n    if image.size == 0 or image.shape[0] < 5 or image.shape[1] < 5:\n        return 0.0\n    h, w = image.shape\n    cv_values = []\n    step = max(1, min(h//10, w//10))\n    for i in range(0, h-4, step):\n        for j in range(0, w-4, step):\n            patch = image[i:i+5, j:j+5]\n            mean_val = np.mean(patch)\n            if mean_val > 0:\n                cv_values.append(np.std(patch) / mean_val)\n    return float(np.mean(cv_values) if cv_values else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry between left and right halves measured by absolute difference\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if w < 2:\n        return 0.0\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    if right_half.shape[1] > left_half.shape[1]:\n        right_half = right_half[:, :left_half.shape[1]]\n    elif left_half.shape[1] > right_half.shape[1]:\n        left_half = left_half[:, :right_half.shape[1]]\n    return float(np.mean(np.abs(left_half - np.fliplr(right_half))))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of image occupied by connected high-intensity regions\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.mean(image) + np.std(image)\n    high_intensity_mask = image > threshold\n    return float(np.sum(high_intensity_mask) / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Energy concentration in diagonal directions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    main_diag = np.mean([image[i, i] for i in range(min(h, w))])\n    anti_diag = np.mean([image[i, w-1-i] for i in range(min(h, w))])\n    total_mean = np.mean(image)\n    if total_mean == 0:\n        return 0.0\n    return float((main_diag + anti_diag) / (2 * total_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local variance averaged across 3x3 neighborhoods\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.var(image))\n    local_vars = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            patch = image[i-1:i+2, j-1:j+2]\n            local_vars.append(np.var(patch))\n    return float(np.mean(local_vars))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum row sum to maximum column sum\"\n    if image.size == 0:\n        return 1.0\n    row_sums = np.sum(image, axis=1)\n    col_sums = np.sum(image, axis=0)\n    max_row = np.max(row_sums)\n    max_col = np.max(col_sums)\n    if max_col == 0:\n        return float(max_row)\n    return float(max_row / max_col)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Coefficient of variation for pixel intensities\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return 0.0\n    std_val = np.std(image)\n    return float(std_val / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Kurtosis of pixel intensity distribution measuring tail heaviness\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    normalized = (flat - mean_val) / std_val\n    kurtosis = np.mean(normalized**4) - 3\n    return float(kurtosis)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Contrast between corner regions and center region\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 0.0\n    corner_size = min(h//4, w//4)\n    corners = [\n        image[:corner_size, :corner_size],\n        image[:corner_size, -corner_size:],\n        image[-corner_size:, :corner_size],\n        image[-corner_size:, -corner_size:]\n    ]\n    corner_mean = np.mean([np.mean(corner) for corner in corners])\n    center = image[h//3:2*h//3, w//3:2*w//3]\n    center_mean = np.mean(center)\n    return float(abs(corner_mean - center_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local variance texture measure using sliding window\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.var(image))\n    variances = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            window = image[i-1:i+2, j-1:j+2]\n            variances.append(np.var(window))\n    return float(np.mean(variances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of horizontal to vertical gradient magnitudes\"\n    if image.size == 0:\n        return 1.0\n    grad_y, grad_x = np.gradient(image)\n    horizontal_grad = np.mean(np.abs(grad_x))\n    vertical_grad = np.mean(np.abs(grad_y))\n    if vertical_grad == 0:\n        return float(horizontal_grad)\n    return float(horizontal_grad / vertical_grad)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of intensity histogram measuring randomness\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=min(32, len(np.unique(image))))\n    hist = hist + 1e-10\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log2(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Variance of row-wise intensity means measuring vertical texture variation\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    return float(np.var(row_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner pixels to edge pixels intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.mean(image))\n    corners = image[0,0] + image[0,w-1] + image[h-1,0] + image[h-1,w-1]\n    edges = np.sum(image[0,:]) + np.sum(image[h-1,:]) + np.sum(image[:,0]) + np.sum(image[:,w-1])\n    if edges == 0:\n        return 0.0\n    return float(corners / edges)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Percentage of pixels above 90th percentile concentrated in left half\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 90)\n    high_pixels = image > threshold\n    total_high = np.sum(high_pixels)\n    if total_high == 0:\n        return 0.0\n    left_half_high = np.sum(high_pixels[:, :image.shape[1]//2])\n    return float(left_half_high / total_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of pixel intensities along main diagonal\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 0.0\n    diag_pixels = [image[i, i] for i in range(min_dim)]\n    return float(np.std(diag_pixels))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of bright pixels in center circle vs outer ring\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    radius = min(h, w) // 4\n    if radius < 1:\n        return float(np.mean(image))\n    y, x = np.ogrid[:h, :w]\n    center_mask = (y - center_y)**2 + (x - center_x)**2 <= radius**2\n    outer_mask = ~center_mask\n    threshold = np.mean(image)\n    center_bright = np.sum((image > threshold) & center_mask)\n    outer_bright = np.sum((image > threshold) & outer_mask)\n    if outer_bright == 0:\n        return float(center_bright)\n    return float(center_bright / outer_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum absolute difference between consecutive pixel values in flattened image\"\n    if image.size <= 1:\n        return 0.0\n    flat = image.flatten()\n    diffs = np.abs(np.diff(flat))\n    return float(np.max(diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure of intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=10, density=True)\n    hist = hist + 1e-10\n    entropy = -np.sum(hist * np.log(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Contrast between corner regions and center region\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 0.0\n    corner_size = min(h//4, w//4)\n    corners = [\n        image[:corner_size, :corner_size],\n        image[:corner_size, -corner_size:],\n        image[-corner_size:, :corner_size],\n        image[-corner_size:, -corner_size:]\n    ]\n    corner_mean = np.mean([np.mean(corner) for corner in corners])\n    center_mean = np.mean(image[h//4:3*h//4, w//4:3*w//4])\n    return float(abs(corner_mean - center_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Radial intensity gradient from center to edges\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    y, x = np.ogrid[:h, :w]\n    distances = np.sqrt((y - center_y)**2 + (x - center_x)**2)\n    max_dist = np.max(distances)\n    if max_dist == 0:\n        return 0.0\n    inner_mask = distances <= max_dist / 3\n    outer_mask = distances >= 2 * max_dist / 3\n    inner_mean = np.mean(image[inner_mask]) if np.any(inner_mask) else 0\n    outer_mean = np.mean(image[outer_mask]) if np.any(outer_mask) else 0\n    return float(abs(inner_mean - outer_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local maxima density across the image\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_maxima = 0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            center = image[i, j]\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            if center >= np.max(neighborhood):\n                local_maxima += 1\n    return float(local_maxima / ((h-2) * (w-2)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance between adjacent pixel intensities\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 and w < 2:\n        return 0.0\n    distances = []\n    if h > 1:\n        vertical_diff = np.abs(np.diff(image, axis=0))\n        distances.extend(vertical_diff.flatten())\n    if w > 1:\n        horizontal_diff = np.abs(np.diff(image, axis=1))\n        distances.extend(horizontal_diff.flatten())\n    return float(np.mean(distances)) if distances else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of standard deviation in horizontal bands to vertical bands\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    h_bands = np.array_split(image, 4, axis=0)\n    v_bands = np.array_split(image, 4, axis=1)\n    h_std = np.mean([np.std(band) for band in h_bands])\n    v_std = np.mean([np.std(band) for band in v_bands])\n    if v_std == 0:\n        return float(h_std)\n    return float(h_std / v_std)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum local variance in 3x3 neighborhoods\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.var(image))\n    max_var = 0.0\n    for i in range(h-2):\n        for j in range(w-2):\n            local_var = np.var(image[i:i+3, j:j+3])\n            max_var = max(max_var, local_var)\n    return float(max_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in edges vs interior\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    edge_mask = np.zeros_like(image, dtype=bool)\n    edge_mask[0, :] = True\n    edge_mask[-1, :] = True\n    edge_mask[:, 0] = True\n    edge_mask[:, -1] = True\n    interior_mask = ~edge_mask\n    edge_high = np.sum((image > threshold) & edge_mask)\n    interior_high = np.sum((image > threshold) & interior_mask)\n    if interior_high == 0:\n        return float(edge_high)\n    return float(edge_high / interior_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance from center of mass to image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    y_coords, x_coords = np.ogrid[:h, :w]\n    total_mass = np.sum(image)\n    if total_mass == 0:\n        return 0.0\n    cm_y = np.sum(y_coords * image) / total_mass\n    cm_x = np.sum(x_coords * image) / total_mass\n    center_y, center_x = h / 2, w / 2\n    distance = np.sqrt((cm_y - center_y)**2 + (cm_x - center_x)**2)\n    return float(distance / max(h, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of intensity histogram with 16 bins\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=16, density=True)\n    hist = hist + 1e-10\n    entropy = -np.sum(hist * np.log2(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of row-wise intensity means\"\n    if image.size == 0 or image.shape[0] == 0:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    return float(np.std(row_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in corners to center cross pattern\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    corners = np.sum(image[:h//4, :w//4]) + np.sum(image[:h//4, 3*w//4:]) + np.sum(image[3*h//4:, :w//4]) + np.sum(image[3*h//4:, 3*w//4:])\n    cross = np.sum(image[h//4:3*h//4, w//2-w//8:w//2+w//8]) + np.sum(image[h//2-h//8:h//2+h//8, w//4:3*w//4])\n    if cross == 0:\n        return float(corners)\n    return float(corners / cross)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum difference between adjacent quadrants\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    q1 = np.mean(image[:h//2, :w//2])\n    q2 = np.mean(image[:h//2, w//2:])\n    q3 = np.mean(image[h//2:, :w//2])\n    q4 = np.mean(image[h//2:, w//2:])\n    diffs = [abs(q1-q2), abs(q1-q3), abs(q1-q4), abs(q2-q3), abs(q2-q4), abs(q3-q4)]\n    return float(max(diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Variance of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] == 0:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.var(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above mean in checkerboard pattern\"\n    if image.size == 0:\n        return 0.5\n    h, w = image.shape\n    mean_val = np.mean(image)\n    y_idx, x_idx = np.mgrid[0:h, 0:w]\n    checkerboard = (y_idx + x_idx) % 2 == 0\n    checker_pixels = np.sum((image > mean_val) & checkerboard)\n    total_checker = np.sum(checkerboard)\n    if total_checker == 0:\n        return 0.5\n    return float(checker_pixels / total_checker)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Range of intensities in middle horizontal strip\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3:\n        strip = image\n    else:\n        strip = image[h//3:2*h//3, :]\n    if strip.size == 0:\n        return 0.0\n    return float(np.max(strip) - np.min(strip))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of variance in left half to variance in right half\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    w = image.shape[1]\n    left_var = np.var(image[:, :w//2])\n    right_var = np.var(image[:, w//2:])\n    if right_var == 0:\n        return float(left_var)\n    return float(left_var / right_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Percentage of pixels above 90th percentile in outer edge pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return float(np.mean(image > np.percentile(image, 90)))\n    edge_pixels = np.concatenate([image[0, :], image[-1, :], image[1:-1, 0], image[1:-1, -1]])\n    threshold = np.percentile(image, 90)\n    edge_high = np.sum(edge_pixels > threshold)\n    return float(edge_high / len(edge_pixels))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity weighted distance from image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_h, center_w = h / 2, w / 2\n    total_weight = 0.0\n    weighted_distance = 0.0\n    for i in range(h):\n        for j in range(w):\n            distance = np.sqrt((i - center_h)**2 + (j - center_w)**2)\n            weight = image[i, j]\n            weighted_distance += distance * weight\n            total_weight += weight\n    if total_weight == 0:\n        return 0.0\n    return float(weighted_distance / total_weight)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum row sum to maximum column sum\"\n    if image.size == 0:\n        return 1.0\n    row_sums = np.sum(image, axis=1)\n    col_sums = np.sum(image, axis=0)\n    max_row = np.max(row_sums)\n    max_col = np.max(col_sums)\n    if max_col == 0:\n        return float(max_row)\n    return float(max_row / max_col)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between pixels and their 4-neighbors\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    total_diff = 0.0\n    count = 0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            center = image[i, j]\n            neighbors = [image[i-1, j], image[i+1, j], image[i, j-1], image[i, j+1]]\n            total_diff += np.sum(np.abs(center - np.array(neighbors)))\n            count += 4\n    if count == 0:\n        return 0.0\n    return float(total_diff / count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent pixel pairs\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    horizontal_diff = np.mean(np.abs(image[:, 1:] - image[:, :-1]))\n    vertical_diff = np.mean(np.abs(image[1:, :] - image[:-1, :]))\n    return float((horizontal_diff + vertical_diff) / 2)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels above local neighborhood mean\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.5\n    count = 0\n    total = 0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            local_mean = np.mean(neighborhood)\n            if image[i, j] > local_mean:\n                count += 1\n            total += 1\n    return float(count / total) if total > 0 else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Coefficient of variation of row-wise mean intensities\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    mean_of_means = np.mean(row_means)\n    if mean_of_means == 0:\n        return 0.0\n    std_of_means = np.std(row_means)\n    return float(std_of_means / mean_of_means)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between center and four corner regions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.0\n    corner_size = min(h//4, w//4)\n    if corner_size == 0:\n        return 0.0\n    center = image[h//2-corner_size:h//2+corner_size, w//2-corner_size:w//2+corner_size]\n    tl = image[:corner_size, :corner_size]\n    tr = image[:corner_size, -corner_size:]\n    bl = image[-corner_size:, :corner_size]\n    br = image[-corner_size:, -corner_size:]\n    center_mean = np.mean(center)\n    corner_mean = np.mean([np.mean(tl), np.mean(tr), np.mean(bl), np.mean(br)])\n    return float(abs(center_mean - corner_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=16)\n    hist = hist + 1e-10\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum row variance\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 1.0\n    row_vars = np.var(image, axis=1)\n    max_var = np.max(row_vars)\n    min_var = np.min(row_vars)\n    if min_var == 0:\n        return float(max_var + 1.0)\n    return float(max_var / min_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry measure comparing left and right halves\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = np.fliplr(image[:, w//2:w//2+w//2])\n    if right_half.shape[1] != left_half.shape[1]:\n        min_w = min(left_half.shape[1], right_half.shape[1])\n        left_half = left_half[:, :min_w]\n        right_half = right_half[:, :min_w]\n    diff = np.mean(np.abs(left_half - right_half))\n    return float(diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Contrast measure using 90th minus 10th percentile\"\n    if image.size == 0:\n        return 0.0\n    p90 = np.percentile(image, 90)\n    p10 = np.percentile(image, 10)\n    return float(p90 - p10)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skew = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skew)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner pixels mean to center region mean\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    corner_size = min(h//6, w//6, 3)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center = image[h//3:2*h//3, w//3:2*w//3]\n    corner_mean = np.mean(corners)\n    center_mean = np.mean(center)\n    if center_mean == 0:\n        return float(corner_mean)\n    return float(corner_mean / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=16, density=True)\n    hist = hist + 1e-10\n    entropy = -np.sum(hist * np.log(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum local contrast in sliding 3x3 windows\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.max(image) - np.min(image))\n    max_contrast = 0.0\n    for i in range(h - 2):\n        for j in range(w - 2):\n            window = image[i:i+3, j:j+3]\n            contrast = np.max(window) - np.min(window)\n            max_contrast = max(max_contrast, contrast)\n    return float(max_contrast)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half intensity variance\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_var = np.var(left_half)\n    right_var = np.var(right_half)\n    if right_var == 0:\n        return float(left_var)\n    return float(left_var / right_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels that are local maxima\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.5\n    local_maxima = 0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            center = image[i, j]\n            neighbors = image[i-1:i+2, j-1:j+2]\n            if center >= np.max(neighbors):\n                local_maxima += 1\n    return float(local_maxima / ((h-2) * (w-2)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of variance in corners to variance in edges\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    corner_size = min(h//4, w//4, 2)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    edges = np.concatenate([\n        image[0, corner_size:-corner_size],\n        image[-1, corner_size:-corner_size],\n        image[corner_size:-corner_size, 0],\n        image[corner_size:-corner_size, -1]\n    ])\n    corner_var = np.var(corners)\n    edge_var = np.var(edges)\n    if edge_var == 0:\n        return float(corner_var)\n    return float(corner_var / edge_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels above the median in checkerboard pattern\"\n    if image.size == 0:\n        return 0.5\n    h, w = image.shape\n    median_val = np.median(image)\n    y_indices, x_indices = np.ogrid[:h, :w]\n    checkerboard = (y_indices + x_indices) % 2 == 0\n    above_median = image > median_val\n    checkerboard_above = np.sum(above_median & checkerboard)\n    total_checkerboard = np.sum(checkerboard)\n    if total_checkerboard == 0:\n        return 0.5\n    return float(checkerboard_above / total_checkerboard)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of 90th percentile to 10th percentile intensity\"\n    if image.size == 0:\n        return 1.0\n    p90 = np.percentile(image, 90)\n    p10 = np.percentile(image, 10)\n    if p10 == 0:\n        return float(p90)\n    return float(p90 / p10)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of pixels along the image borders\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h == 1 and w == 1:\n        return float(image[0, 0])\n    border_pixels = []\n    if h > 1:\n        border_pixels.extend([image[0, :].flatten(), image[-1, :].flatten()])\n    if w > 1:\n        border_pixels.extend([image[:, 0].flatten(), image[:, -1].flatten()])\n    all_border = np.concatenate(border_pixels)\n    return float(np.mean(all_border))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation between row index and row mean intensity\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    row_indices = np.arange(len(row_means))\n    if np.std(row_means) == 0 or np.std(row_indices) == 0:\n        return 0.0\n    correlation = np.corrcoef(row_indices, row_means)[0, 1]\n    return float(correlation if not np.isnan(correlation) else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=256, range=(0, 256))\n    hist = hist + 1e-10\n    prob = hist / np.sum(hist)\n    entropy = -np.sum(prob * np.log2(prob))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation between column index and column mean intensity\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    col_indices = np.arange(len(col_means))\n    if np.std(col_means) == 0 or np.std(col_indices) == 0:\n        return 0.0\n    correlation = np.corrcoef(col_indices, col_means)[0, 1]\n    return float(correlation if not np.isnan(correlation) else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of edge pixels to total pixels using Sobel operator\"\n    if image.size == 0:\n        return 0.0\n    if image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    edge_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n    threshold = np.mean(edge_magnitude) + np.std(edge_magnitude)\n    edge_pixels = np.sum(edge_magnitude > threshold)\n    return float(edge_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of diagonal pixel values\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    diagonal_values = np.array([image[i, i] for i in range(min_dim)])\n    return float(np.std(diagonal_values))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Energy measure as sum of squared pixel values normalized\"\n    if image.size == 0:\n        return 0.0\n    energy = np.sum(image.astype(np.float64) ** 2)\n    normalized_energy = energy / (image.size * 255.0 * 255.0)\n    return float(normalized_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Compactness of bright regions using moments\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 75)\n    bright_mask = image > threshold\n    if np.sum(bright_mask) == 0:\n        return 0.0\n    bright_area = np.sum(bright_mask)\n    y_coords, x_coords = np.where(bright_mask)\n    if len(y_coords) < 2:\n        return 0.0\n    perimeter_approx = np.sqrt(np.var(y_coords) + np.var(x_coords)) * 4\n    if perimeter_approx == 0:\n        return 0.0\n    compactness = bright_area / (perimeter_approx ** 2)\n    return float(compactness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    max_diff = 0.0\n    for i in range(h-1):\n        for j in range(w-1):\n            diff1 = abs(float(image[i+1, j]) - float(image[i, j]))\n            diff2 = abs(float(image[i, j+1]) - float(image[i, j]))\n            max_diff = max(max_diff, diff1, diff2)\n    return max_diff\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of mean intensity in border pixels to interior pixels\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 1.0\n    border_mask = np.zeros((h, w), dtype=bool)\n    border_mask[0, :] = True\n    border_mask[-1, :] = True\n    border_mask[:, 0] = True\n    border_mask[:, -1] = True\n    border_mean = np.mean(image[border_mask])\n    interior_mean = np.mean(image[~border_mask])\n    if interior_mean == 0:\n        return float(border_mean)\n    return float(border_mean / interior_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size < 3:\n        return 0.0\n    pixels = image.flatten()\n    mean_val = np.mean(pixels)\n    std_val = np.std(pixels)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((pixels - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels that are local maxima in 3x3 neighborhoods\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    local_max_count = 0\n    total_count = 0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            center = image[i, j]\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            if center >= np.max(neighborhood):\n                local_max_count += 1\n            total_count += 1\n    return float(local_max_count / total_count) if total_count > 0 else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of pixels from image centroid weighted by intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    total_intensity = np.sum(image)\n    if total_intensity == 0:\n        return float(min(h, w) / 2)\n    centroid_y = np.sum(np.sum(image, axis=1) * np.arange(h)) / total_intensity\n    centroid_x = np.sum(np.sum(image, axis=0) * np.arange(w)) / total_intensity\n    distances = []\n    for i in range(h):\n        for j in range(w):\n            if image[i, j] > 0:\n                dist = np.sqrt((i - centroid_y)**2 + (j - centroid_x)**2)\n                distances.append(dist)\n    return float(np.mean(distances)) if distances else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry in radial intensity distribution from center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    y, x = np.ogrid[:h, :w]\n    distances = np.sqrt((y - center_y)**2 + (x - center_x)**2)\n    max_dist = np.max(distances)\n    if max_dist == 0:\n        return 0.0\n    normalized_dist = distances / max_dist\n    inner_mask = normalized_dist < 0.5\n    outer_mask = normalized_dist >= 0.5\n    inner_mean = np.mean(image[inner_mask]) if np.any(inner_mask) else 0\n    outer_mean = np.mean(image[outer_mask]) if np.any(outer_mask) else 0\n    if inner_mean + outer_mean == 0:\n        return 0.0\n    return float(abs(inner_mean - outer_mean) / (inner_mean + outer_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Texture roughness based on local variance\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 5 or w < 5:\n        return float(np.var(image))\n    local_variances = []\n    for i in range(0, h-4, 2):\n        for j in range(0, w-4, 2):\n            patch = image[i:i+5, j:j+5]\n            local_variances.append(np.var(patch))\n    return float(np.mean(local_variances)) if local_variances else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity clustering tendency using nearest neighbor distances\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    sorted_intensities = np.sort(flat_image)\n    if len(sorted_intensities) < 2:\n        return 0.0\n    differences = np.diff(sorted_intensities)\n    mean_diff = np.mean(differences)\n    std_diff = np.std(differences)\n    if mean_diff == 0:\n        return 0.0\n    return float(std_diff / mean_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum column-wise standard deviations\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    col_stds = np.std(image, axis=0)\n    min_std = np.min(col_stds)\n    max_std = np.max(col_stds)\n    if min_std == 0:\n        return float(max_std)\n    return float(max_std / min_std)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity weighted centroid distance from image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    y_indices, x_indices = np.ogrid[:h, :w]\n    total_intensity = np.sum(image)\n    if total_intensity == 0:\n        return 0.0\n    centroid_y = np.sum(y_indices * image) / total_intensity\n    centroid_x = np.sum(x_indices * image) / total_intensity\n    center_y, center_x = h / 2, w / 2\n    distance = np.sqrt((centroid_y - center_y)**2 + (centroid_x - center_x)**2)\n    return float(distance / max(h, w))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels below 25th percentile in left vs right half\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    threshold = np.percentile(image, 25)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_low = np.sum(left_half < threshold)\n    right_low = np.sum(right_half < threshold)\n    if right_low == 0:\n        return float(left_low)\n    return float(left_low / right_low)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average absolute difference between consecutive row means\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    consecutive_diffs = np.abs(np.diff(row_means))\n    return float(np.mean(consecutive_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Circular symmetry measure using angular intensity sampling\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    radius = min(h, w) // 4\n    if radius < 2:\n        return 0.0\n    angles = np.linspace(0, 2*np.pi, 16, endpoint=False)\n    intensities = []\n    for angle in angles:\n        y = int(center_y + radius * np.sin(angle))\n        x = int(center_x + radius * np.cos(angle))\n        if 0 <= y < h and 0 <= x < w:\n            intensities.append(image[y, x])\n    if len(intensities) < 8:\n        return 0.0\n    return float(1.0 - np.std(intensities) / (np.mean(intensities) + 1e-10))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum difference between adjacent pixels in the image\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    horizontal_diffs = np.abs(np.diff(image, axis=1))\n    vertical_diffs = np.abs(np.diff(image, axis=0))\n    max_h_diff = np.max(horizontal_diffs) if horizontal_diffs.size > 0 else 0.0\n    max_v_diff = np.max(vertical_diffs) if vertical_diffs.size > 0 else 0.0\n    return float(max(max_h_diff, max_v_diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner pixel intensities to center pixel intensities\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 1.0\n    corners = [image[0, 0], image[0, -1], image[-1, 0], image[-1, -1]]\n    corner_mean = np.mean(corners)\n    center_mean = np.mean(image[h//4:3*h//4, w//4:3*w//4])\n    if center_mean == 0:\n        return float(corner_mean)\n    return float(corner_mean / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of pixels from image center weighted by intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h / 2, w / 2\n    y_coords, x_coords = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n    distances = np.sqrt((y_coords - center_y)**2 + (x_coords - center_x)**2)\n    weights = image / (np.sum(image) + 1e-10)\n    weighted_distance = np.sum(distances * weights)\n    return float(weighted_distance)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    pixels = image.flatten()\n    if len(pixels) < 3:\n        return 0.0\n    mean_val = np.mean(pixels)\n    std_val = np.std(pixels)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((pixels - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile in left vs right half\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if w < 2:\n        return 1.0\n    threshold = np.percentile(image, 90)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_high = np.sum(left_half > threshold)\n    right_high = np.sum(right_half > threshold)\n    if right_high == 0:\n        return float(left_high)\n    return float(left_high / right_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of pixel intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=32, range=(image.min(), image.max()))\n    hist = hist + 1e-8\n    prob = hist / np.sum(hist)\n    entropy = -np.sum(prob * np.log2(prob))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Diagonal symmetry score comparing main diagonal regions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 0.0\n    upper_tri = image[:min_dim, :min_dim][np.triu_indices(min_dim, k=1)]\n    lower_tri = image[:min_dim, :min_dim][np.tril_indices(min_dim, k=-1)]\n    if len(upper_tri) == 0 or len(lower_tri) == 0:\n        return 0.0\n    correlation = np.corrcoef(upper_tri, lower_tri)[0, 1]\n    return float(correlation if not np.isnan(correlation) else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Peak-to-peak intensity range normalized by mean\"\n    if image.size == 0:\n        return 0.0\n    peak_range = np.max(image) - np.min(image)\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return float(peak_range)\n    return float(peak_range / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Energy concentration in central quarter of image\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    energy = np.sum(image ** 2)\n    if energy == 0:\n        return 0.0\n    center_h, center_w = h // 4, w // 4\n    center_region = image[center_h:3*center_h, center_w:3*center_w]\n    center_energy = np.sum(center_region ** 2)\n    return float(center_energy / energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in edges vs interior\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    edge_mask = np.zeros_like(image, dtype=bool)\n    edge_mask[0, :] = True\n    edge_mask[-1, :] = True\n    edge_mask[:, 0] = True\n    edge_mask[:, -1] = True\n    interior_mask = ~edge_mask\n    edge_bright = np.sum((image > threshold) & edge_mask)\n    interior_bright = np.sum((image > threshold) & interior_mask)\n    if interior_bright == 0:\n        return float(edge_bright)\n    return float(edge_bright / interior_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of pixel intensities in diagonal bands\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    diag1 = np.array([image[i, i] for i in range(min(h, w))])\n    diag2 = np.array([image[i, w-1-i] for i in range(min(h, w))])\n    combined_diag = np.concatenate([diag1, diag2])\n    return float(np.std(combined_diag))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy measure based on pixel intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=50)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    prob = hist / np.sum(hist)\n    entropy = -np.sum(prob * np.log2(prob))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Texture measure using local binary pattern approximation\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    pattern_count = 0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            center = image[i, j]\n            neighbors = [image[i-1,j-1], image[i-1,j], image[i-1,j+1],\n                        image[i,j+1], image[i+1,j+1], image[i+1,j], \n                        image[i+1,j-1], image[i,j-1]]\n            binary_pattern = sum(1 for n in neighbors if n >= center)\n            pattern_count += binary_pattern\n    return float(pattern_count / ((h-2) * (w-2)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner region intensity to center region intensity\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    corner_size = min(h//6, w//6, 5)\n    if corner_size < 1:\n        return 1.0\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center_h, center_w = h//4, w//4\n    center_region = image[center_h:3*center_h, center_w:3*center_w]\n    corner_mean = np.mean(corners)\n    center_mean = np.mean(center_region)\n    if center_mean == 0:\n        return float(corner_mean)\n    return float(corner_mean / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in left half versus right half\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if w < 2:\n        return 1.0\n    median_val = np.median(image)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_above = np.sum(left_half > median_val)\n    right_above = np.sum(right_half > median_val)\n    if right_above == 0:\n        return float(left_above)\n    return float(left_above / right_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels within one standard deviation of mean\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    std_val = np.std(image)\n    within_one_std = np.sum(np.abs(image - mean_val) <= std_val)\n    return float(within_one_std / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between corner regions and center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.0\n    corner_size = min(h//4, w//4)\n    corners = [\n        image[:corner_size, :corner_size],\n        image[:corner_size, -corner_size:],\n        image[-corner_size:, :corner_size],\n        image[-corner_size:, -corner_size:]\n    ]\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_mean = np.mean([np.mean(corner) for corner in corners])\n    center_mean = np.mean(center)\n    return float(abs(corner_mean - center_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness approximation using mean minus median\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    median_val = np.median(image)\n    std_val = np.std(image)\n    if std_val == 0:\n        return 0.0\n    return float((mean_val - median_val) / std_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in diagonal bands to total pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    diagonal_mask = np.zeros((h, w), dtype=bool)\n    for i in range(h):\n        for j in range(w):\n            if abs(i - j * h / w) < min(h, w) * 0.1:\n                diagonal_mask[i, j] = True\n            if abs(i - (w - 1 - j) * h / w) < min(h, w) * 0.1:\n                diagonal_mask[i, j] = True\n    return float(np.sum(diagonal_mask) / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between corner pixels and center pixel\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center = image[h//2, w//2]\n    corners = [image[0, 0], image[0, w-1], image[h-1, 0], image[h-1, w-1]]\n    corner_mean = np.mean(corners)\n    return float(abs(corner_mean - center))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in left half vs right half\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if w < 2:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_bright = np.sum(left_half > threshold)\n    right_bright = np.sum(right_half > threshold)\n    if right_bright == 0:\n        return float(left_bright)\n    return float(left_bright / right_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    max_diff = 0.0\n    if h > 1:\n        vertical_diffs = np.abs(np.diff(image, axis=0))\n        max_diff = max(max_diff, np.max(vertical_diffs))\n    if w > 1:\n        horizontal_diffs = np.abs(np.diff(image, axis=1))\n        max_diff = max(max_diff, np.max(horizontal_diffs))\n    return float(max_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in central cross pattern vs outer regions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 1.0\n    cross_mask = np.zeros_like(image, dtype=bool)\n    cross_mask[h//2, :] = True\n    cross_mask[:, w//2] = True\n    cross_pixels = np.sum(image[cross_mask])\n    outer_pixels = np.sum(image[~cross_mask])\n    if outer_pixels == 0:\n        return float(cross_pixels)\n    return float(cross_pixels / outer_pixels)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of diagonal pixel values from top-left to bottom-right\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 0.0\n    diagonal_values = [image[i, i] for i in range(min_dim)]\n    return float(np.std(diagonal_values))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels that are exactly equal to the median value\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    equal_to_median = np.sum(image == median_val)\n    return float(equal_to_median / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent pixels in the central cross pattern\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center_h, center_w = h // 2, w // 2\n    horizontal_line = image[center_h, :]\n    vertical_line = image[:, center_w]\n    h_diffs = np.abs(np.diff(horizontal_line))\n    v_diffs = np.abs(np.diff(vertical_line))\n    all_diffs = np.concatenate([h_diffs, v_diffs])\n    return float(np.mean(all_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum local variance to global variance\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    global_var = np.var(image)\n    if global_var == 0:\n        return 1.0\n    block_size = min(h // 4, w // 4, 10)\n    max_local_var = 0.0\n    for i in range(0, h - block_size, block_size):\n        for j in range(0, w - block_size, block_size):\n            block = image[i:i+block_size, j:j+block_size]\n            local_var = np.var(block)\n            max_local_var = max(max_local_var, local_var)\n    return float(max_local_var / global_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average magnitude of second-order differences in rows\"\n    if image.size == 0 or image.shape[1] < 3:\n        return 0.0\n    second_diffs = []\n    for row in image:\n        if len(row) >= 3:\n            first_diff = np.diff(row)\n            second_diff = np.diff(first_diff)\n            second_diffs.extend(np.abs(second_diff))\n    if len(second_diffs) == 0:\n        return 0.0\n    return float(np.mean(second_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of pixels that are local maxima in 3x3 neighborhoods\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    local_maxima_count = 0\n    total_pixels = 0\n    for i in range(1, h - 1):\n        for j in range(1, w - 1):\n            center = image[i, j]\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            if center == np.max(neighborhood):\n                local_maxima_count += 1\n            total_pixels += 1\n    if total_pixels == 0:\n        return 0.0\n    return float(local_maxima_count / total_pixels)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Energy ratio between high and low frequency components using gradient differences\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n    high_freq = np.sum(grad_mag > np.percentile(grad_mag, 70))\n    low_freq = np.sum(grad_mag <= np.percentile(grad_mag, 30))\n    if low_freq == 0:\n        return float(high_freq)\n    return float(high_freq / low_freq)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry measure between left and right halves of image\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = np.fliplr(image[:, w//2:])\n    min_width = min(left_half.shape[1], right_half.shape[1])\n    left_crop = left_half[:, :min_width]\n    right_crop = right_half[:, :min_width]\n    diff = np.mean(np.abs(left_crop - right_crop))\n    avg_intensity = np.mean(image)\n    if avg_intensity == 0:\n        return 0.0\n    return float(diff / avg_intensity)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Concentration of dark pixels in center versus periphery\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 0.5\n    threshold = np.percentile(image, 20)\n    center_h, center_w = h//3, w//3\n    center = image[center_h:2*center_h, center_w:2*center_w]\n    periphery = np.ones_like(image, dtype=bool)\n    periphery[center_h:2*center_h, center_w:2*center_w] = False\n    dark_center = np.sum(center <= threshold)\n    dark_periphery = np.sum(image[periphery] <= threshold)\n    total_dark = dark_center + dark_periphery\n    if total_dark == 0:\n        return 0.0\n    return float(dark_center / total_dark)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between any two adjacent pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 and w < 2:\n        return 0.0\n    max_diff = 0.0\n    if h > 1:\n        vertical_diffs = np.abs(np.diff(image, axis=0))\n        max_diff = max(max_diff, np.max(vertical_diffs))\n    if w > 1:\n        horizontal_diffs = np.abs(np.diff(image, axis=1))\n        max_diff = max(max_diff, np.max(horizontal_diffs))\n    return float(max_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of center 25% region mean to full image mean\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    full_mean = np.mean(image)\n    if full_mean == 0:\n        return 1.0\n    center_h_start, center_w_start = int(h * 0.375), int(w * 0.375)\n    center_h_end, center_w_end = int(h * 0.625), int(w * 0.625)\n    if center_h_end <= center_h_start or center_w_end <= center_w_start:\n        return 1.0\n    center_region = image[center_h_start:center_h_end, center_w_start:center_w_end]\n    center_mean = np.mean(center_region)\n    return float(center_mean / full_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of pixel intensity distribution using histogram bins\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=min(256, image.size))\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    prob = hist / np.sum(hist)\n    entropy = -np.sum(prob * np.log2(prob))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile to pixels below 10th percentile\"\n    if image.size == 0:\n        return 1.0\n    p10 = np.percentile(image, 10)\n    p90 = np.percentile(image, 90)\n    low_count = np.sum(image <= p10)\n    high_count = np.sum(image >= p90)\n    if low_count == 0:\n        return float(high_count)\n    return float(high_count / low_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of pixels from image center weighted by intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h / 2, w / 2\n    total_weighted_distance = 0.0\n    total_weight = 0.0\n    for i in range(h):\n        for j in range(w):\n            distance = np.sqrt((i - center_y)**2 + (j - center_x)**2)\n            weight = image[i, j]\n            total_weighted_distance += distance * weight\n            total_weight += weight\n    if total_weight == 0:\n        return 0.0\n    return float(total_weighted_distance / total_weight)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of diagonal pixel intensities from top-left to bottom-right\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h == 0 or w == 0:\n        return 0.0\n    min_dim = min(h, w)\n    diagonal = np.array([image[i, i] for i in range(min_dim)])\n    return float(np.std(diagonal))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in left half vs right half\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if w < 2:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_count = np.sum(left_half > threshold)\n    right_count = np.sum(right_half > threshold)\n    if right_count == 0:\n        return float(left_count)\n    return float(left_count / right_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average magnitude of second-order horizontal differences\"\n    if image.size == 0 or image.shape[1] < 3:\n        return 0.0\n    first_diff = np.diff(image, axis=1)\n    second_diff = np.diff(first_diff, axis=1)\n    return float(np.mean(np.abs(second_diff)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Weighted center of mass distance from image center in x-direction\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if w == 0:\n        return 0.0\n    total_intensity = np.sum(image)\n    if total_intensity == 0:\n        return 0.0\n    x_coords = np.arange(w)\n    weighted_x = np.sum(np.sum(image, axis=0) * x_coords) / total_intensity\n    center_x = w / 2.0\n    return float(abs(weighted_x - center_x))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum row-wise standard deviations\"\n    if image.size == 0 or image.shape[0] == 0:\n        return 1.0\n    row_stds = np.std(image, axis=1)\n    max_std = np.max(row_stds)\n    min_std = np.min(row_stds)\n    if min_std == 0:\n        return float(max_std)\n    return float(max_std / min_std)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation coefficient between pixel values and their distance from center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h / 2.0, w / 2.0\n    y_coords, x_coords = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n    distances = np.sqrt((y_coords - center_y)**2 + (x_coords - center_x)**2)\n    flat_image = image.flatten()\n    flat_distances = distances.flatten()\n    if np.std(flat_distances) == 0 or np.std(flat_image) == 0:\n        return 0.0\n    correlation_matrix = np.corrcoef(flat_image, flat_distances)\n    return float(correlation_matrix[0, 1])\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    horizontal_diffs = np.abs(np.diff(image, axis=1))\n    vertical_diffs = np.abs(np.diff(image, axis=0))\n    max_h_diff = np.max(horizontal_diffs) if horizontal_diffs.size > 0 else 0.0\n    max_v_diff = np.max(vertical_diffs) if vertical_diffs.size > 0 else 0.0\n    return float(max(max_h_diff, max_v_diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in center vs corners\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 1.0\n    median_val = np.median(image)\n    center = image[h//3:2*h//3, w//3:2*w//3]\n    corner_size = min(h//6, w//6, 5)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center_above = np.sum(center > median_val)\n    corners_above = np.sum(corners > median_val)\n    if corners_above == 0:\n        return float(center_above)\n    return float(center_above / corners_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity weighted by distance from center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_h, center_w = h // 2, w // 2\n    y_coords, x_coords = np.ogrid[:h, :w]\n    distances = np.sqrt((y_coords - center_h)**2 + (x_coords - center_w)**2)\n    max_dist = np.max(distances)\n    if max_dist == 0:\n        return float(np.mean(image))\n    weights = distances / max_dist\n    weighted_intensities = image * weights\n    return float(np.sum(weighted_intensities) / np.sum(weights))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels that are local minima\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    local_minima_count = 0\n    total_interior = (h - 2) * (w - 2)\n    for i in range(1, h - 1):\n        for j in range(1, w - 1):\n            center = image[i, j]\n            neighbors = image[i-1:i+2, j-1:j+2]\n            if center <= np.min(neighbors):\n                local_minima_count += 1\n    return float(local_minima_count / total_interior) if total_interior > 0 else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise intensity ranges\"\n    if image.size == 0 or image.shape[1] < 1:\n        return 0.0\n    col_ranges = []\n    for j in range(image.shape[1]):\n        col = image[:, j]\n        col_ranges.append(np.max(col) - np.min(col))\n    return float(np.std(col_ranges))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Concentration of high-intensity pixels in corner regions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return float(np.mean(image))\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    threshold = np.percentile(image, 75)\n    corner_bright = np.sum(corners > threshold)\n    total_corner_pixels = len(corners)\n    return float(corner_bright / total_corner_pixels if total_corner_pixels > 0 else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on intensity histogram distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=16, range=(image.min(), image.max()))\n    hist = hist + 1e-10\n    probabilities = hist / np.sum(hist)\n    entropy = -np.sum(probabilities * np.log(probabilities))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent columns\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_diffs = np.abs(np.diff(image, axis=1))\n    return float(np.mean(col_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile in center versus edges\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 1.0\n    threshold = np.percentile(image, 90)\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    edge_mask = np.ones_like(image, dtype=bool)\n    edge_mask[h//4:3*h//4, w//4:3*w//4] = False\n    edge_region = image[edge_mask]\n    center_bright = np.sum(center_region > threshold)\n    edge_bright = np.sum(edge_region > threshold)\n    if edge_bright == 0:\n        return float(center_bright)\n    return float(center_bright / edge_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile in center versus corners\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    threshold = np.percentile(image, 90)\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center_high = np.sum(center > threshold)\n    corner_high = np.sum(corners > threshold)\n    if corner_high == 0:\n        return float(center_high + 1.0)\n    return float(center_high / corner_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    pixels = image.flatten()\n    mean_val = np.mean(pixels)\n    std_val = np.std(pixels)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((pixels - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of bright pixels from image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h / 2, w / 2\n    threshold = np.percentile(image, 75)\n    bright_y, bright_x = np.where(image > threshold)\n    if len(bright_y) == 0:\n        return 0.0\n    distances = np.sqrt((bright_y - center_y)**2 + (bright_x - center_x)**2)\n    return float(np.mean(distances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of local maxima to local minima count\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 1.0\n    interior = image[1:-1, 1:-1]\n    neighbors = np.stack([\n        image[:-2, :-2], image[:-2, 1:-1], image[:-2, 2:],\n        image[1:-1, :-2], image[1:-1, 2:],\n        image[2:, :-2], image[2:, 1:-1], image[2:, 2:]\n    ])\n    max_neighbors = np.max(neighbors, axis=0)\n    min_neighbors = np.min(neighbors, axis=0)\n    local_maxima = np.sum(interior > max_neighbors)\n    local_minima = np.sum(interior < min_neighbors)\n    if local_minima == 0:\n        return float(local_maxima + 1.0)\n    return float(local_maxima / local_minima)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    return float(np.std(col_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in corners vs center\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    corner_size_h, corner_size_w = h // 4, w // 4\n    corners = np.concatenate([\n        image[:corner_size_h, :corner_size_w].flatten(),\n        image[:corner_size_h, -corner_size_w:].flatten(),\n        image[-corner_size_h:, :corner_size_w].flatten(),\n        image[-corner_size_h:, -corner_size_w:].flatten()\n    ])\n    center = image[corner_size_h:-corner_size_h, corner_size_w:-corner_size_w]\n    corner_bright = np.sum(corners > threshold)\n    center_bright = np.sum(center > threshold)\n    if center_bright == 0:\n        return float(corner_bright + 1)\n    return float(corner_bright / center_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent columns\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    col_diffs = np.abs(np.diff(col_means))\n    return float(np.mean(col_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels in middle horizontal band\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3:\n        return 1.0\n    band_start, band_end = h // 3, 2 * h // 3\n    band_pixels = (band_end - band_start) * w\n    return float(band_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness measure using percentile differences\"\n    if image.size == 0:\n        return 0.0\n    p25, p50, p75 = np.percentile(image, [25, 50, 75])\n    if p75 - p25 == 0:\n        return 0.0\n    return float((p75 + p25 - 2 * p50) / (p75 - p25))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum row mean to minimum row mean\"\n    if image.size == 0 or image.shape[0] < 1:\n        return 1.0\n    row_means = np.mean(image, axis=1)\n    max_row = np.max(row_means)\n    min_row = np.min(row_means)\n    if min_row == 0:\n        return float(max_row + 1)\n    return float(max_row / min_row)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels within one standard deviation of mean\"\n    if image.size == 0:\n        return 1.0\n    mean_val = np.mean(image)\n    std_val = np.std(image)\n    if std_val == 0:\n        return 1.0\n    within_std = np.sum(np.abs(image - mean_val) <= std_val)\n    return float(within_std / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Difference between maximum and minimum column-wise standard deviations\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_stds = np.std(image, axis=0)\n    return float(np.max(col_stds) - np.min(col_stds))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of center quarter mean to outer border mean intensity\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return float(np.mean(image))\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    border = np.concatenate([image[0,:], image[-1,:], image[:,0], image[:,-1]])\n    border_mean = np.mean(border)\n    if border_mean == 0:\n        return float(np.mean(center))\n    return float(np.mean(center) / border_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of diagonal pixel intensities from top-left to bottom-right\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h == 0 or w == 0:\n        return 0.0\n    min_dim = min(h, w)\n    diagonal = np.array([image[i, i] for i in range(min_dim)])\n    return float(np.std(diagonal))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels above median intensity in left half versus right half\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.5\n    h, w = image.shape\n    median_val = np.median(image)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_above = np.sum(left_half > median_val) / left_half.size\n    right_above = np.sum(right_half > median_val) / right_half.size\n    if (left_above + right_above) == 0:\n        return 0.0\n    return float(left_above / (left_above + right_above))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent pixels horizontally\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    horizontal_diffs = np.abs(np.diff(image, axis=1))\n    return float(np.mean(horizontal_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in quadrants: (top-left + bottom-right) vs (top-right + bottom-left)\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 1.0\n    tl = np.mean(image[:h//2, :w//2])\n    tr = np.mean(image[:h//2, w//2:])\n    bl = np.mean(image[h//2:, :w//2])\n    br = np.mean(image[h//2:, w//2:])\n    diag1 = tl + br\n    diag2 = tr + bl\n    if diag2 == 0:\n        return float(diag1)\n    return float(diag1 / diag2)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between center and corner regions\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.0\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    return float(np.mean(center) - np.mean(corners))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum row variance\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 1.0\n    row_vars = np.var(image, axis=1)\n    min_var = np.min(row_vars)\n    max_var = np.max(row_vars)\n    if min_var == 0:\n        return float(max_var)\n    return float(max_var / min_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels below 25th percentile in left half of image\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if w < 2:\n        return 0.5\n    left_half = image[:, :w//2]\n    threshold = np.percentile(image, 25)\n    below_threshold = np.sum(left_half < threshold)\n    return float(below_threshold / left_half.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of bright pixels in image center to image edges\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 1.0\n    threshold = np.percentile(image, 70)\n    center_region = image[h//3:2*h//3, w//3:2*w//3]\n    edge_region = np.concatenate([\n        image[0, :], image[-1, :], \n        image[1:-1, 0], image[1:-1, -1]\n    ])\n    center_bright = np.sum(center_region > threshold)\n    edge_bright = np.sum(edge_region > threshold)\n    if edge_bright == 0:\n        return float(center_bright)\n    return float(center_bright / center_region.size) / float(edge_bright / edge_region.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average magnitude of diagonal gradient differences\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    main_diag = np.array([image[i, i] for i in range(min(h, w))])\n    anti_diag = np.array([image[i, w-1-i] for i in range(min(h, w))])\n    if len(main_diag) < 2:\n        return 0.0\n    main_diff = np.mean(np.abs(np.diff(main_diag)))\n    anti_diff = np.mean(np.abs(np.diff(anti_diag)))\n    return float((main_diff + anti_diff) / 2)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of standard deviation to mean intensity (coefficient of variation)\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return 0.0\n    return float(np.std(image) / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels above 90th percentile concentrated in center quarter\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    threshold = np.percentile(image, 90)\n    high_pixels = image > threshold\n    center_h_start, center_w_start = 3*h//8, 3*w//8\n    center_h_end, center_w_end = 5*h//8, 5*w//8\n    center_high = np.sum(high_pixels[center_h_start:center_h_end, center_w_start:center_w_end])\n    total_high = np.sum(high_pixels)\n    if total_high == 0:\n        return 0.0\n    return float(center_high / total_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Left-right asymmetry measured as absolute difference in mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    return float(abs(left_half - right_half))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=32, range=(0, 255))\n    hist = hist.astype(np.float64)\n    hist = hist / np.sum(hist)\n    hist = hist[hist > 0]\n    entropy = -np.sum(hist * np.log2(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of pixels along the main diagonal\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    diagonal_pixels = np.array([image[i, i] for i in range(min_dim)])\n    return float(np.mean(diagonal_pixels))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of edge pixels to total pixels using simple edge detection\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    edge_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n    edge_threshold = np.percentile(edge_magnitude, 75)\n    edge_pixels = np.sum(edge_magnitude > edge_threshold)\n    return float(edge_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum local contrast in sliding 3x3 windows\"\n    if image.size == 0 or min(image.shape) < 3:\n        return 0.0\n    h, w = image.shape\n    max_contrast = 0.0\n    for i in range(h-2):\n        for j in range(w-2):\n            window = image[i:i+3, j:j+3]\n            contrast = np.max(window) - np.min(window)\n            max_contrast = max(max_contrast, contrast)\n    return float(max_contrast)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Diagonal symmetry measure between top-left and bottom-right triangles\"\n    if image.size == 0 or min(image.shape) < 2:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    upper_tri = np.triu(image[:min_dim, :min_dim])\n    lower_tri = np.tril(image[:min_dim, :min_dim]).T\n    mask = np.triu(np.ones((min_dim, min_dim)), 1)\n    if np.sum(mask) == 0:\n        return 0.0\n    diff = np.abs(upper_tri - lower_tri)[mask == 1]\n    return float(np.mean(diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner pixels sum to total image sum\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.sum(image) / max(1, np.sum(image)))\n    corner_size = min(h//4, w//4, 3)\n    corners_sum = (np.sum(image[:corner_size, :corner_size]) +\n                   np.sum(image[:corner_size, -corner_size:]) +\n                   np.sum(image[-corner_size:, :corner_size]) +\n                   np.sum(image[-corner_size:, -corner_size:]))\n    total_sum = np.sum(image)\n    if total_sum == 0:\n        return 0.0\n    return float(corners_sum / total_sum)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in center versus edges\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    median_val = np.median(image)\n    above_median = image > median_val\n    if h < 6 or w < 6:\n        return float(np.mean(above_median))\n    center_region = above_median[h//4:3*h//4, w//4:3*w//4]\n    edge_region = above_median.copy()\n    edge_region[h//4:3*h//4, w//4:3*w//4] = False\n    center_ratio = np.mean(center_region)\n    edge_ratio = np.mean(edge_region)\n    if edge_ratio == 0:\n        return float(center_ratio)\n    return float(center_ratio / edge_ratio)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy measure based on pixel intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=32, range=(image.min(), image.max() + 1e-8))\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log2(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Variance of column-wise standard deviations\"\n    if image.size == 0:\n        return 0.0\n    if image.shape[1] < 2:\n        return 0.0\n    col_stds = np.std(image, axis=0)\n    return float(np.var(col_stds))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance from each pixel to the image centroid weighted by intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    total_intensity = np.sum(image)\n    if total_intensity == 0:\n        return 0.0\n    y_indices, x_indices = np.meshgrid(range(h), range(w), indexing='ij')\n    centroid_y = np.sum(y_indices * image) / total_intensity\n    centroid_x = np.sum(x_indices * image) / total_intensity\n    distances = np.sqrt((y_indices - centroid_y)**2 + (x_indices - centroid_x)**2)\n    weighted_avg_distance = np.sum(distances * image) / total_intensity\n    return float(weighted_avg_distance)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in left half vs right half\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if w < 2:\n        return 1.0\n    median_val = np.median(image)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_above_median = np.sum(left_half > median_val)\n    right_above_median = np.sum(right_half > median_val)\n    if right_above_median == 0:\n        return float(left_above_median)\n    return float(left_above_median / right_above_median)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum difference between adjacent 2x2 block means\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    max_diff = 0.0\n    for i in range(h - 1):\n        for j in range(w - 1):\n            current_mean = np.mean(image[i:i+2, j:j+2])\n            if i > 0:\n                above_mean = np.mean(image[i-1:i+1, j:j+2])\n                max_diff = max(max_diff, abs(current_mean - above_mean))\n            if j > 0:\n                left_mean = np.mean(image[i:i+2, j-1:j+1])\n                max_diff = max(max_diff, abs(current_mean - left_mean))\n    return float(max_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    return float(np.std(col_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in left half vs right half\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if w < 2:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_bright = np.sum(left_half > threshold)\n    right_bright = np.sum(right_half > threshold)\n    if right_bright == 0:\n        return float(left_bright)\n    return float(left_bright / right_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation between pixel intensity and distance from center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h / 2, w / 2\n    y, x = np.ogrid[:h, :w]\n    distances = np.sqrt((y - center_y)**2 + (x - center_x)**2)\n    if np.std(distances) == 0 or np.std(image) == 0:\n        return 0.0\n    correlation = np.corrcoef(image.flatten(), distances.flatten())[0, 1]\n    return float(correlation if not np.isnan(correlation) else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent rows\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    max_diff = np.max(np.abs(np.diff(row_means)))\n    return float(max_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in corners vs center cross pattern\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return float(np.mean(image))\n    corner_size = min(h, w) // 4\n    corners = np.zeros_like(image, dtype=bool)\n    corners[:corner_size, :corner_size] = True\n    corners[:corner_size, -corner_size:] = True\n    corners[-corner_size:, :corner_size] = True\n    corners[-corner_size:, -corner_size:] = True\n    center_cross = np.zeros_like(image, dtype=bool)\n    center_cross[h//2-corner_size:h//2+corner_size, :] = True\n    center_cross[:, w//2-corner_size:w//2+corner_size] = True\n    corner_mean = np.mean(image[corners])\n    cross_mean = np.mean(image[center_cross])\n    if cross_mean == 0:\n        return float(corner_mean)\n    return float(corner_mean / cross_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in corners versus center\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_bright = np.sum(corners > threshold)\n    center_bright = np.sum(center > threshold)\n    if center_bright == 0:\n        return float(corner_bright)\n    return float(corner_bright / center_bright)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Kurtosis of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    pixels = image.flatten()\n    if len(pixels) < 4:\n        return 0.0\n    mean_val = np.mean(pixels)\n    std_val = np.std(pixels)\n    if std_val == 0:\n        return 0.0\n    normalized = (pixels - mean_val) / std_val\n    kurtosis = np.mean(normalized ** 4) - 3\n    return float(kurtosis)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum column-wise variance\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    col_vars = np.var(image, axis=0)\n    max_var = np.max(col_vars)\n    min_var = np.min(col_vars)\n    if min_var == 0:\n        return float(max_var)\n    return float(max_var / min_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of pixels in concentric rings weighted by ring distance\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    max_radius = min(center_y, center_x)\n    if max_radius == 0:\n        return float(np.mean(image))\n    weighted_sum = 0.0\n    total_weight = 0.0\n    for i in range(h):\n        for j in range(w):\n            distance = np.sqrt((i - center_y)**2 + (j - center_x)**2)\n            ring_weight = min(distance / max_radius, 1.0) + 0.1\n            weighted_sum += image[i, j] * ring_weight\n            total_weight += ring_weight\n    return float(weighted_sum / total_weight) if total_weight > 0 else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum row variance\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 1.0\n    row_variances = np.var(image, axis=1)\n    min_var = np.min(row_variances)\n    max_var = np.max(row_variances)\n    if min_var == 0:\n        return float(max_var)\n    return float(max_var / min_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels within one standard deviation of mean\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    std_val = np.std(image)\n    if std_val == 0:\n        return 1.0\n    within_std = np.sum(np.abs(image - mean_val) <= std_val)\n    return float(within_std / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent columns\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    consecutive_diffs = np.abs(np.diff(col_means))\n    return float(np.mean(consecutive_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of diagonal variance to anti-diagonal variance\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 1.0\n    main_diag = np.array([image[i, i] for i in range(min_dim)])\n    anti_diag = np.array([image[i, min_dim-1-i] for i in range(min_dim)])\n    main_var = np.var(main_diag)\n    anti_var = np.var(anti_diag)\n    if anti_var == 0:\n        return float(main_var)\n    return float(main_var / anti_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local contrast measured as standard deviation of 2x2 block means\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    block_means = []\n    for i in range(0, h-1, 2):\n        for j in range(0, w-1, 2):\n            block = image[i:i+2, j:j+2]\n            block_means.append(np.mean(block))\n    if len(block_means) == 0:\n        return 0.0\n    return float(np.std(block_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry measure between left and right halves of image\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = np.fliplr(image[:, w//2:w//2 + left_half.shape[1]])\n    return float(np.mean(np.abs(left_half - right_half)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in center versus corners\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    median_val = np.median(image)\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center_above = np.sum(center > median_val) / center.size if center.size > 0 else 0\n    corners_above = np.sum(corners > median_val) / corners.size if corners.size > 0 else 0\n    if corners_above == 0:\n        return float(center_above * 10)\n    return float(center_above / corners_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Variance of distances from each pixel to image centroid\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    total_intensity = np.sum(image)\n    if total_intensity == 0:\n        return 0.0\n    y_coords, x_coords = np.mgrid[0:h, 0:w]\n    centroid_y = np.sum(y_coords * image) / total_intensity\n    centroid_x = np.sum(x_coords * image) / total_intensity\n    distances = np.sqrt((y_coords - centroid_y)**2 + (x_coords - centroid_x)**2)\n    weighted_distances = distances * image / total_intensity\n    return float(np.var(weighted_distances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Smoothness measure using second-order derivatives\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    grad2_y, _ = np.gradient(grad_y)\n    _, grad2_x = np.gradient(grad_x)\n    second_order = np.abs(grad2_y) + np.abs(grad2_x)\n    return float(np.mean(second_order))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure using intensity histogram distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=32, density=True)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    entropy = -np.sum(hist * np.log(hist + 1e-10))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum intensity to mean intensity\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return 0.0\n    return float(np.max(image) / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between center and corners\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.0\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    center_mean = np.mean(center_region)\n    corner_size = min(h//4, w//4)\n    corners = [image[:corner_size, :corner_size], \n               image[:corner_size, -corner_size:],\n               image[-corner_size:, :corner_size], \n               image[-corner_size:, -corner_size:]]\n    corner_mean = np.mean([np.mean(corner) for corner in corners])\n    return float(abs(center_mean - corner_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels above 90th percentile\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 90)\n    high_pixels = np.sum(image > threshold)\n    return float(high_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Diagonal symmetry measure comparing top-left to bottom-right\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 1.0\n    top_left = image[:min_dim//2, :min_dim//2]\n    bottom_right = image[-min_dim//2:, -min_dim//2:]\n    diff = np.mean(np.abs(top_left - np.flip(np.flip(bottom_right, 0), 1)))\n    return float(diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Range of intensities normalized by mean\"\n    if image.size == 0:\n        return 0.0\n    intensity_range = np.max(image) - np.min(image)\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return float(intensity_range)\n    return float(intensity_range / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of diagonal pixel values\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    main_diag = np.array([image[i, i] for i in range(min_dim)])\n    anti_diag = np.array([image[i, min_dim-1-i] for i in range(min_dim)])\n    all_diag = np.concatenate([main_diag, anti_diag])\n    return float(np.std(all_diag))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half mean intensity\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    if right_half == 0:\n        return float(left_half)\n    return float(left_half / right_half)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in corners vs center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    threshold = np.percentile(image, 75)\n    corner_h, corner_w = h // 4, w // 4\n    corners = np.concatenate([\n        image[:corner_h, :corner_w].flatten(),\n        image[:corner_h, -corner_w:].flatten(),\n        image[-corner_h:, :corner_w].flatten(),\n        image[-corner_h:, -corner_w:].flatten()\n    ])\n    center = image[corner_h:3*corner_h, corner_w:3*corner_w]\n    corner_high = np.sum(corners > threshold)\n    center_high = np.sum(center > threshold)\n    if center_high == 0:\n        return float(corner_high)\n    return float(corner_high / center_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average magnitude of second-order differences along rows\"\n    if image.size == 0 or image.shape[1] < 3:\n        return 0.0\n    second_diffs = []\n    for row in image:\n        if len(row) >= 3:\n            first_diff = np.diff(row)\n            second_diff = np.diff(first_diff)\n            second_diffs.extend(np.abs(second_diff))\n    if not second_diffs:\n        return 0.0\n    return float(np.mean(second_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of unique pixel values to total pixels\"\n    if image.size == 0:\n        return 0.0\n    unique_count = len(np.unique(image))\n    return float(unique_count / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry between left and right halves mean absolute difference\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    right_flipped = np.fliplr(right_half)\n    min_width = min(left_half.shape[1], right_flipped.shape[1])\n    left_crop = left_half[:, :min_width]\n    right_crop = right_flipped[:, :min_width]\n    return float(np.mean(np.abs(left_crop - right_crop)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Proportion of pixels within one standard deviation of median\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    std_val = np.std(image)\n    lower_bound = median_val - std_val\n    upper_bound = median_val + std_val\n    within_range = np.sum((image >= lower_bound) & (image <= upper_bound))\n    return float(within_range / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] == 0:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels below 25th percentile in left half versus right half\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    threshold = np.percentile(image, 25)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_low = np.sum(left_half < threshold)\n    right_low = np.sum(right_half < threshold)\n    if right_low == 0:\n        return float(left_low)\n    return float(left_low / right_low)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of variance in outer border to inner region variance\"\n    if image.size == 0 or image.shape[0] < 6 or image.shape[1] < 6:\n        return 1.0\n    h, w = image.shape\n    border_thickness = min(h//8, w//8, 3)\n    if border_thickness < 1:\n        return 1.0\n    border_mask = np.ones_like(image, dtype=bool)\n    border_mask[border_thickness:-border_thickness, border_thickness:-border_thickness] = False\n    inner_region = image[border_thickness:-border_thickness, border_thickness:-border_thickness]\n    border_var = np.var(image[border_mask])\n    inner_var = np.var(inner_region)\n    if inner_var == 0:\n        return float(border_var)\n    return float(border_var / inner_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Mean absolute deviation from median intensity\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    mad = np.mean(np.abs(image - median_val))\n    return float(mad)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum row sum to minimum row sum\"\n    if image.size == 0 or image.shape[0] == 0:\n        return 1.0\n    row_sums = np.sum(image, axis=1)\n    max_sum = np.max(row_sums)\n    min_sum = np.min(row_sums)\n    if min_sum == 0:\n        return float(max_sum)\n    return float(max_sum / min_sum)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between center and edge pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    edges = np.concatenate([image[0,:], image[-1,:], image[:,0], image[:,-1]])\n    center_mean = np.mean(center) if center.size > 0 else 0.0\n    edge_mean = np.mean(edges) if edges.size > 0 else 0.0\n    return float(abs(center_mean - edge_mean))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels below 25th percentile to those above 75th percentile\"\n    if image.size == 0:\n        return 1.0\n    p25 = np.percentile(image, 25)\n    p75 = np.percentile(image, 75)\n    low_count = np.sum(image <= p25)\n    high_count = np.sum(image >= p75)\n    if high_count == 0:\n        return float(low_count)\n    return float(low_count / high_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average absolute deviation from median intensity\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    mad = np.mean(np.abs(image - median_val))\n    return float(mad)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of range in first quarter rows to last quarter rows\"\n    if image.size == 0 or image.shape[0] < 4:\n        return 1.0\n    h = image.shape[0]\n    first_quarter = image[:h//4, :]\n    last_quarter = image[3*h//4:, :]\n    first_range = np.max(first_quarter) - np.min(first_quarter)\n    last_range = np.max(last_quarter) - np.min(last_quarter)\n    if last_range == 0:\n        return float(first_range)\n    return float(first_range / last_range)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum intensity to median intensity\"\n    if image.size == 0:\n        return 1.0\n    max_val = np.max(image)\n    median_val = np.median(image)\n    if median_val == 0:\n        return float(max_val)\n    return float(max_val / median_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Contrast between left and right halves of image\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    return float(abs(left_half - right_half))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=32)\n    hist = hist + 1e-10\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log2(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Diagonal intensity gradient magnitude\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    diag1 = np.mean([image[i, i] for i in range(min(h, w))])\n    diag2 = np.mean([image[i, w-1-i] for i in range(min(h, w))])\n    return float(abs(diag1 - diag2))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile in quadrants\"\n    if image.size == 0:\n        return 0.25\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.25\n    threshold = np.percentile(image, 90)\n    q1 = np.sum(image[:h//2, :w//2] > threshold)\n    q2 = np.sum(image[:h//2, w//2:] > threshold)\n    q3 = np.sum(image[h//2:, :w//2] > threshold)\n    q4 = np.sum(image[h//2:, w//2:] > threshold)\n    total = q1 + q2 + q3 + q4\n    if total == 0:\n        return 0.0\n    return float(max(q1, q2, q3, q4) / total)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry measure between left and right halves using absolute difference\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:2*(w//2)]\n    if left_half.shape != right_half.shape:\n        min_w = min(left_half.shape[1], right_half.shape[1])\n        left_half = left_half[:, :min_w]\n        right_half = right_half[:, :min_w]\n    diff = np.mean(np.abs(left_half - np.fliplr(right_half)))\n    return float(diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on intensity histogram distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=16, range=(image.min(), image.max() + 1e-8))\n    hist = hist.astype(float)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    hist_norm = hist / np.sum(hist)\n    entropy = -np.sum(hist_norm * np.log2(hist_norm))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of 90th percentile to 10th percentile pixel intensities\"\n    if image.size == 0:\n        return 1.0\n    p10 = np.percentile(image, 10)\n    p90 = np.percentile(image, 90)\n    if p10 == 0:\n        return float(p90)\n    return float(p90 / (p10 + 1e-8))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of bright pixels from image centroid\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    threshold = np.percentile(image, 75)\n    bright_mask = image > threshold\n    if not np.any(bright_mask):\n        return float(min(h, w) / 2)\n    y_coords, x_coords = np.where(bright_mask)\n    centroid_y, centroid_x = np.mean(y_coords), np.mean(x_coords)\n    distances = np.sqrt((y_coords - centroid_y)**2 + (x_coords - centroid_x)**2)\n    return float(np.mean(distances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local contrast measure using standard deviation in overlapping windows\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    window_size = min(h//4, w//4, 5)\n    if window_size < 2:\n        return float(np.std(image))\n    local_stds = []\n    for i in range(0, h - window_size + 1, window_size//2):\n        for j in range(0, w - window_size + 1, window_size//2):\n            window = image[i:i+window_size, j:j+window_size]\n            local_stds.append(np.std(window))\n    return float(np.mean(local_stds))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent pixels in the image\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    max_diff = 0.0\n    for i in range(h-1):\n        row_diff = np.max(np.abs(image[i+1, :] - image[i, :]))\n        max_diff = max(max_diff, row_diff)\n    for j in range(w-1):\n        col_diff = np.max(np.abs(image[:, j+1] - image[:, j]))\n        max_diff = max(max_diff, col_diff)\n    return float(max_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile to pixels below 25th percentile\"\n    if image.size == 0:\n        return 1.0\n    p25 = np.percentile(image, 25)\n    p75 = np.percentile(image, 75)\n    high_count = np.sum(image > p75)\n    low_count = np.sum(image < p25)\n    if low_count == 0:\n        return float(high_count)\n    return float(high_count / low_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of diagonal pixels from top-left to bottom-right\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    diagonal_sum = 0.0\n    for i in range(min_dim):\n        diagonal_sum += image[i, i]\n    return float(diagonal_sum / min_dim)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of mean intensities in 2x2 non-overlapping blocks\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    block_means = []\n    for i in range(0, h-1, 2):\n        for j in range(0, w-1, 2):\n            block = image[i:i+2, j:j+2]\n            block_means.append(np.mean(block))\n    if len(block_means) == 0:\n        return 0.0\n    return float(np.std(block_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum row sum to minimum row sum\"\n    if image.size == 0 or image.shape[0] == 0:\n        return 1.0\n    row_sums = np.sum(image, axis=1)\n    max_sum = np.max(row_sums)\n    min_sum = np.min(row_sums)\n    if min_sum == 0:\n        return float(max_sum)\n    return float(max_sum / min_sum)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local variance in sliding window patches across the image\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    window_size = min(h//5, w//5, 3)\n    if window_size < 2:\n        return float(np.var(image))\n    variances = []\n    for i in range(0, h-window_size+1, window_size):\n        for j in range(0, w-window_size+1, window_size):\n            patch = image[i:i+window_size, j:j+window_size]\n            variances.append(np.var(patch))\n    return float(np.mean(variances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy measure of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=32, density=True)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    entropy = -np.sum(hist * np.log2(hist + 1e-10))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    if right_half == 0:\n        return float(left_half)\n    return float(left_half / right_half)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Coefficient of variation of column-wise mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    mean_of_means = np.mean(col_means)\n    if mean_of_means == 0:\n        return 0.0\n    std_of_means = np.std(col_means)\n    return float(std_of_means / mean_of_means)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of pixels above the 75th percentile\"\n    if image.size == 0:\n        return 0.0\n    p75 = np.percentile(image, 75)\n    above_p75 = np.sum(image > p75)\n    return float(above_p75 / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Gradient magnitude concentration in center versus edges\"\n    if image.size == 0:\n        return 1.0\n    grad_y, grad_x = np.gradient(image)\n    grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n    h, w = grad_mag.shape\n    if h < 4 or w < 4:\n        return float(np.mean(grad_mag))\n    center = grad_mag[h//4:3*h//4, w//4:3*w//4]\n    edge_mean = np.mean(grad_mag) - np.mean(center) * (center.size / grad_mag.size)\n    if edge_mean == 0:\n        return float(np.mean(center))\n    return float(np.mean(center) / edge_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of mean intensity in left third to right third\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if w < 3:\n        return 1.0\n    left_third = np.mean(image[:, :w//3])\n    right_third = np.mean(image[:, -w//3:])\n    if right_third == 0:\n        return float(left_third)\n    return float(left_third / right_third)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum absolute difference between diagonal elements\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 0.0\n    main_diag = np.array([image[i, i] for i in range(min_dim)])\n    anti_diag = np.array([image[i, min_dim-1-i] for i in range(min_dim)])\n    main_diff = np.max(np.abs(np.diff(main_diag))) if len(main_diag) > 1 else 0.0\n    anti_diff = np.max(np.abs(np.diff(anti_diag))) if len(anti_diag) > 1 else 0.0\n    return float(max(main_diff, anti_diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Coefficient of variation of pixel intensities\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return 0.0\n    std_val = np.std(image)\n    return float(std_val / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in top-left quadrant to bottom-right quadrant\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 1.0\n    median_val = np.median(image)\n    top_left = image[:h//2, :w//2]\n    bottom_right = image[h//2:, w//2:]\n    tl_above = np.sum(top_left > median_val)\n    br_above = np.sum(bottom_right > median_val)\n    if br_above == 0:\n        return float(tl_above)\n    return float(tl_above / br_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Mean absolute deviation from center pixel value\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_val = image[h//2, w//2]\n    deviations = np.abs(image - center_val)\n    return float(np.mean(deviations))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of range in first row to range in last row\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 1.0\n    first_row_range = np.max(image[0, :]) - np.min(image[0, :])\n    last_row_range = np.max(image[-1, :]) - np.min(image[-1, :])\n    if last_row_range == 0:\n        return float(first_row_range)\n    return float(first_row_range / last_row_range)\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum difference between adjacent columns\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    adjacent_diffs = np.abs(np.diff(col_means))\n    return float(np.max(adjacent_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity concentration in central quarter region\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    if center_region.size == 0:\n        return float(np.mean(image))\n    center_sum = np.sum(center_region)\n    total_sum = np.sum(image)\n    if total_sum == 0:\n        return 0.0\n    return float(center_sum / total_sum)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Diagonal intensity difference from top-left to bottom-right\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    diagonal = np.array([image[i, i] for i in range(min_dim)])\n    if len(diagonal) < 2:\n        return 0.0\n    return float(np.std(diagonal))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Percentage of pixels above 75th percentile\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 75)\n    above_threshold = np.sum(image > threshold)\n    return float(above_threshold / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Smoothness measure as inverse of variance plus one\"\n    if image.size == 0:\n        return 1.0\n    variance = np.var(image)\n    smoothness = 1.0 / (1.0 + variance)\n    return float(smoothness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Corner intensity sum normalized by image mean\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return float(np.mean(image))\n    corner_size = max(1, min(h//8, w//8))\n    corners_sum = (np.sum(image[:corner_size, :corner_size]) + \n                   np.sum(image[:corner_size, -corner_size:]) + \n                   np.sum(image[-corner_size:, :corner_size]) + \n                   np.sum(image[-corner_size:, -corner_size:]))\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return float(corners_sum)\n    return float(corners_sum / (4 * corner_size * corner_size * mean_val))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local contrast as difference between max and min in 3x3 neighborhoods\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_contrasts = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            local_contrast = np.max(neighborhood) - np.min(neighborhood)\n            local_contrasts.append(local_contrast)\n    return float(np.mean(local_contrasts))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry measure between left and right halves of the image\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if w < 2:\n        return 0.0\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    if right_half.shape[1] != left_half.shape[1]:\n        right_half = image[:, -(left_half.shape[1]):]\n    right_flipped = np.fliplr(right_half)\n    diff = np.abs(left_half - right_flipped)\n    return float(np.mean(diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Percentage of pixels below 25th percentile in image corners\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.5\n    corner_size = min(h//6, w//6, 5)\n    if corner_size < 1:\n        return 0.5\n    threshold = np.percentile(image, 25)\n    corners_mask = np.zeros_like(image, dtype=bool)\n    corners_mask[:corner_size, :corner_size] = True\n    corners_mask[:corner_size, -corner_size:] = True\n    corners_mask[-corner_size:, :corner_size] = True\n    corners_mask[-corner_size:, -corner_size:] = True\n    corner_pixels = image[corners_mask]\n    if corner_pixels.size == 0:\n        return 0.0\n    return float(np.mean(corner_pixels < threshold))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between any two adjacent rows\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    row_diffs = np.abs(np.diff(row_means))\n    return float(np.max(row_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of diagonal gradient magnitude to horizontal plus vertical gradients\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    diag1 = np.abs(grad_x + grad_y)\n    diag2 = np.abs(grad_x - grad_y)\n    diagonal_grad = np.mean(diag1) + np.mean(diag2)\n    orthogonal_grad = np.mean(np.abs(grad_x)) + np.mean(np.abs(grad_y))\n    if orthogonal_grad == 0:\n        return float(diagonal_grad)\n    return float(diagonal_grad / orthogonal_grad)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of intensities along the main diagonal\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim < 2:\n        return 0.0\n    diagonal_values = np.array([image[i, i] for i in range(min_dim)])\n    return float(np.std(diagonal_values))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in left half vs right half\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    median_val = np.median(image)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_above = np.sum(left_half > median_val)\n    right_above = np.sum(right_half > median_val)\n    if right_above == 0:\n        return float(left_above)\n    return float(left_above / right_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Mean absolute deviation from center pixel value\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_val = image[h//2, w//2]\n    mad = np.mean(np.abs(image - center_val))\n    return float(mad)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of 90th percentile to 10th percentile pixel intensity\"\n    if image.size == 0:\n        return 1.0\n    p90 = np.percentile(image, 90)\n    p10 = np.percentile(image, 10)\n    if p10 == 0:\n        return float(p90)\n    return float(p90 / p10)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation between row indices and row mean intensities\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    row_indices = np.arange(len(row_means))\n    correlation = np.corrcoef(row_indices, row_means)[0, 1]\n    return float(correlation if not np.isnan(correlation) else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=50, density=True)\n    hist = hist + 1e-10\n    hist = hist / np.sum(hist)\n    entropy = -np.sum(hist * np.log2(hist + 1e-10))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of corner region intensities\"\n    if image.size == 0 or image.shape[0] < 4 or image.shape[1] < 4:\n        return 0.0\n    h, w = image.shape\n    corner_size = min(h//8, w//8, 5)\n    if corner_size < 1:\n        return float(np.std(image))\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    return float(np.std(corners))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    return float(np.std(col_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half average intensity\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    if right_half == 0:\n        return float(left_half)\n    return float(left_half / right_half)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of pixels from image center weighted by intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_h, center_w = h / 2, w / 2\n    y_coords, x_coords = np.ogrid[:h, :w]\n    distances = np.sqrt((y_coords - center_h)**2 + (x_coords - center_w)**2)\n    weights = image / (np.sum(image) + 1e-8)\n    return float(np.sum(distances * weights))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of diagonal gradient variance to horizontal-vertical gradient variance\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 1.0\n    grad_y, grad_x = np.gradient(image)\n    hv_var = np.var(grad_x) + np.var(grad_y)\n    diag1 = image[1:, 1:] - image[:-1, :-1]\n    diag2 = image[1:, :-1] - image[:-1, 1:]\n    diag_var = np.var(diag1) + np.var(diag2)\n    if hv_var == 0:\n        return float(diag_var)\n    return float(diag_var / hv_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner region intensity to center region intensity\"\n    if image.size == 0 or image.shape[0] < 4 or image.shape[1] < 4:\n        return 1.0\n    h, w = image.shape\n    corner_size_h, corner_size_w = h // 4, w // 4\n    corners = np.concatenate([\n        image[:corner_size_h, :corner_size_w].flatten(),\n        image[:corner_size_h, -corner_size_w:].flatten(),\n        image[-corner_size_h:, :corner_size_w].flatten(),\n        image[-corner_size_h:, -corner_size_w:].flatten()\n    ])\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    center_mean = np.mean(center)\n    if center_mean == 0:\n        return float(np.mean(corners))\n    return float(np.mean(corners) / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent pixels in the image\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 and w < 2:\n        return 0.0\n    max_diff = 0.0\n    if h > 1:\n        vertical_diffs = np.abs(np.diff(image, axis=0))\n        max_diff = max(max_diff, np.max(vertical_diffs))\n    if w > 1:\n        horizontal_diffs = np.abs(np.diff(image, axis=1))\n        max_diff = max(max_diff, np.max(horizontal_diffs))\n    return float(max_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of mean intensity in diagonal quadrants versus anti-diagonal quadrants\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 1.0\n    top_left = np.mean(image[:h//2, :w//2])\n    bottom_right = np.mean(image[h//2:, w//2:])\n    top_right = np.mean(image[:h//2, w//2:])\n    bottom_left = np.mean(image[h//2:, :w//2])\n    diagonal_mean = (top_left + bottom_right) / 2\n    anti_diagonal_mean = (top_right + bottom_left) / 2\n    if anti_diagonal_mean == 0:\n        return float(diagonal_mean)\n    return float(diagonal_mean / anti_diagonal_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Percentage of pixels that are local maxima in their 3x3 neighborhood\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.0\n    local_maxima_count = 0\n    interior_pixels = (h - 2) * (w - 2)\n    for i in range(1, h - 1):\n        for j in range(1, w - 1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            if image[i, j] >= np.max(neighborhood):\n                local_maxima_count += 1\n    return float(local_maxima_count / max(1, interior_pixels))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of the pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum intensity in each quadrant, averaged\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 1.0\n    quadrants = [\n        image[:h//2, :w//2],\n        image[:h//2, w//2:],\n        image[h//2:, :w//2],\n        image[h//2:, w//2:]\n    ]\n    ratios = []\n    for quad in quadrants:\n        if quad.size == 0:\n            continue\n        min_val = np.min(quad)\n        max_val = np.max(quad)\n        if min_val == 0:\n            ratios.append(max_val)\n        else:\n            ratios.append(max_val / min_val)\n    return float(np.mean(ratios)) if ratios else 1.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skew = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skew)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of diagonal gradient magnitudes (main diagonal vs anti-diagonal)\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    main_diag = np.diag(image) if h == w else image.diagonal()\n    anti_diag = np.diag(np.fliplr(image)) if h == w else np.fliplr(image).diagonal()\n    if main_diag.size < 2 or anti_diag.size < 2:\n        return 1.0\n    main_grad = np.mean(np.abs(np.diff(main_diag)))\n    anti_grad = np.mean(np.abs(np.diff(anti_diag)))\n    if anti_grad == 0:\n        return float(main_grad)\n    return float(main_grad / anti_grad)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of pixels along image perimeter\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return float(np.mean(image))\n    perimeter = np.concatenate([\n        image[0, :],\n        image[-1, :],\n        image[1:-1, 0],\n        image[1:-1, -1]\n    ])\n    return float(np.mean(perimeter))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation coefficient between column indices and column mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    col_indices = np.arange(len(col_means))\n    if np.std(col_means) == 0 or np.std(col_indices) == 0:\n        return 0.0\n    correlation = np.corrcoef(col_indices, col_means)[0, 1]\n    return float(correlation) if not np.isnan(correlation) else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between diagonal quadrants\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    top_left = np.mean(image[:h//2, :w//2])\n    bottom_right = np.mean(image[h//2:, w//2:])\n    top_right = np.mean(image[:h//2, w//2:])\n    bottom_left = np.mean(image[h//2:, :w//2])\n    diag_diff = abs((top_left + bottom_right) - (top_right + bottom_left)) / 2\n    return float(diag_diff)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of edge pixels to total pixels using simple threshold\"\n    if image.size == 0:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n    threshold = np.mean(gradient_magnitude) + np.std(gradient_magnitude)\n    edge_pixels = np.count_nonzero(gradient_magnitude > threshold)\n    return float(edge_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] == 0:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Concentration index of high intensity pixels in center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    threshold = np.percentile(image, 75)\n    high_intensity_mask = image > threshold\n    center_h_start, center_h_end = h//4, 3*h//4\n    center_w_start, center_w_end = w//4, 3*w//4\n    center_high = np.sum(high_intensity_mask[center_h_start:center_h_end, center_w_start:center_w_end])\n    total_high = np.sum(high_intensity_mask)\n    if total_high == 0:\n        return 0.0\n    return float(center_high / total_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average difference between adjacent pixel pairs horizontally\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    horizontal_diffs = np.abs(np.diff(image, axis=1))\n    return float(np.mean(horizontal_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of minimum to maximum row variance\"\n    if image.size == 0 or image.shape[0] == 0:\n        return 1.0\n    row_variances = np.var(image, axis=1)\n    min_var = np.min(row_variances)\n    max_var = np.max(row_variances)\n    if max_var == 0:\n        return 1.0\n    return float(min_var / max_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skew = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skew)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half average intensity\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    if right_half == 0:\n        return float(left_half)\n    return float(left_half / right_half)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of pixels above the 90th percentile\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 90)\n    high_pixels = np.sum(image > threshold)\n    return float(high_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    return float(np.std(col_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of diagonal sum to anti-diagonal sum\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 1.0\n    diag_sum = np.sum([image[i, i] for i in range(min_dim)])\n    anti_diag_sum = np.sum([image[i, min_dim-1-i] for i in range(min_dim)])\n    if anti_diag_sum == 0:\n        return float(diag_sum)\n    return float(diag_sum / anti_diag_sum)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Range of intensities normalized by mean intensity\"\n    if image.size == 0:\n        return 0.0\n    intensity_range = image.max() - image.min()\n    mean_intensity = np.mean(image)\n    if mean_intensity == 0:\n        return float(intensity_range)\n    return float(intensity_range / mean_intensity)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=256, range=(0, 256))\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log2(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of diagonal pixel intensities\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    main_diag = np.array([image[i, i] for i in range(min_dim)])\n    anti_diag = np.array([image[i, w-1-i] for i in range(min_dim) if w-1-i >= 0])\n    all_diag = np.concatenate([main_diag, anti_diag])\n    return float(np.std(all_diag))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels in corners to center region average intensity\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_mean = np.mean(corners)\n    center_mean = np.mean(center)\n    if center_mean == 0:\n        return float(corner_mean)\n    return float(corner_mean / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    if len(flat) < 2:\n        return 0.0\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Variance of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] == 0:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.var(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half variance\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_var = np.var(left_half)\n    right_var = np.var(right_half)\n    if right_var == 0:\n        return float(left_var)\n    return float(left_var / right_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy measure of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=32, range=(0, 256))\n    hist = hist + 1e-10\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log2(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference in 3x3 neighborhoods\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    max_diffs = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            max_diff = np.max(neighborhood) - np.min(neighborhood)\n            max_diffs.append(max_diff)\n    return float(np.mean(max_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation between pixel values and their distances from center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    y_coords, x_coords = np.meshgrid(range(h), range(w), indexing='ij')\n    distances = np.sqrt((y_coords - center_y)**2 + (x_coords - center_x)**2)\n    flat_image = image.flatten()\n    flat_distances = distances.flatten()\n    if np.std(flat_distances) == 0 or np.std(flat_image) == 0:\n        return 0.0\n    correlation = np.corrcoef(flat_image, flat_distances)[0, 1]\n    return float(correlation if not np.isnan(correlation) else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of variance in corner quadrants to center quadrant variance\"\n    if image.size == 0 or image.shape[0] < 4 or image.shape[1] < 4:\n        return 1.0\n    h, w = image.shape\n    half_h, half_w = h // 2, w // 2\n    corners = [\n        image[:half_h, :half_w], image[:half_h, half_w:],\n        image[half_h:, :half_w], image[half_h:, half_w:]\n    ]\n    corner_vars = [np.var(corner) for corner in corners]\n    avg_corner_var = np.mean(corner_vars)\n    quarter_h, quarter_w = h // 4, w // 4\n    center_region = image[quarter_h:3*quarter_h, quarter_w:3*quarter_w]\n    center_var = np.var(center_region)\n    if center_var == 0:\n        return float(avg_corner_var)\n    return float(avg_corner_var / center_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Mean absolute deviation from median pixel intensity\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    median_val = np.median(flat_image)\n    mad = np.mean(np.abs(flat_image - median_val))\n    return float(mad)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile to pixels below 10th percentile\"\n    if image.size == 0:\n        return 1.0\n    p10, p90 = np.percentile(image, [10, 90])\n    high_pixels = np.sum(image >= p90)\n    low_pixels = np.sum(image <= p10)\n    if low_pixels == 0:\n        return float(high_pixels)\n    return float(high_pixels / low_pixels)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of pixel intensities along main diagonal\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    diagonal = np.array([image[i, i] for i in range(min_dim)])\n    return float(np.std(diagonal))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of image area occupied by connected components above median\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    above_median = image > median_val\n    return float(np.sum(above_median) / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of mean intensity in quadrant with highest mean to lowest mean\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    mid_h, mid_w = h//2, w//2\n    q1 = np.mean(image[:mid_h, :mid_w])\n    q2 = np.mean(image[:mid_h, mid_w:])\n    q3 = np.mean(image[mid_h:, :mid_w])\n    q4 = np.mean(image[mid_h:, mid_w:])\n    quad_means = [q1, q2, q3, q4]\n    max_mean = max(quad_means)\n    min_mean = min(quad_means)\n    if min_mean == 0:\n        return float(max_mean)\n    return float(max_mean / min_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile to pixels below 10th percentile\"\n    if image.size == 0:\n        return 1.0\n    p90 = np.percentile(image, 90)\n    p10 = np.percentile(image, 10)\n    high_pixels = np.sum(image >= p90)\n    low_pixels = np.sum(image <= p10)\n    if low_pixels == 0:\n        return float(high_pixels)\n    return float(high_pixels / low_pixels)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of pixel intensities along the main diagonal\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    diag_values = np.array([image[i, int(i * w / h)] for i in range(h) if int(i * w / h) < w])\n    if len(diag_values) < 2:\n        return 0.0\n    return float(np.std(diag_values))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation between row indices and row mean intensities\"\n    if image.size == 0 or image.shape[0] < 3:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    row_indices = np.arange(len(row_means))\n    if np.std(row_means) == 0:\n        return 0.0\n    corr_matrix = np.corrcoef(row_indices, row_means)\n    return float(corr_matrix[0, 1]) if not np.isnan(corr_matrix[0, 1]) else 0.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum local variance to global variance in 3x3 neighborhoods\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 1.0\n    global_var = np.var(image)\n    if global_var == 0:\n        return 0.0\n    h, w = image.shape\n    max_local_var = 0.0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            local_patch = image[i-1:i+2, j-1:j+2]\n            local_var = np.var(local_patch)\n            max_local_var = max(max_local_var, local_var)\n    return float(max_local_var / global_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of intensity distribution measured by third moment\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    std_val = np.std(image)\n    if std_val == 0:\n        return 0.0\n    centered = image - mean_val\n    third_moment = np.mean(centered ** 3)\n    skewness = third_moment / (std_val ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum pixel intensity to mean pixel intensity\"\n    if image.size == 0:\n        return 1.0\n    mean_val = np.mean(image)\n    max_val = np.max(image)\n    if mean_val == 0:\n        return float(max_val)\n    return float(max_val / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    return float(np.std(col_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of pixels above the 75th percentile\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 75)\n    above_threshold = np.sum(image > threshold)\n    return float(above_threshold / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average absolute difference between left and right half intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    w = image.shape[1]\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    return float(abs(left_half - right_half))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of non-zero pixels to total pixels\"\n    if image.size == 0:\n        return 0.0\n    non_zero_count = np.count_nonzero(image)\n    return float(non_zero_count / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Range of pixel intensities normalized by mean intensity\"\n    if image.size == 0:\n        return 0.0\n    pixel_range = np.max(image) - np.min(image)\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return float(pixel_range)\n    return float(pixel_range / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of pixels in the outermost border ring\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return float(np.mean(image))\n    border_pixels = np.concatenate([\n        image[0, :], image[-1, :], image[1:-1, 0], image[1:-1, -1]\n    ])\n    return float(np.mean(border_pixels))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Coefficient of variation of all pixel intensities\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return 0.0\n    std_val = np.std(image)\n    return float(std_val / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Sum of absolute differences between adjacent pixels horizontally\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    horizontal_diffs = np.abs(np.diff(image, axis=1))\n    return float(np.sum(horizontal_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=50, density=True)\n    hist = hist + 1e-10\n    entropy = -np.sum(hist * np.log(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local binary pattern variance across 3x3 neighborhoods\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    patterns = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            center = image[i, j]\n            neighbors = [image[i-1,j-1], image[i-1,j], image[i-1,j+1],\n                        image[i,j+1], image[i+1,j+1], image[i+1,j],\n                        image[i+1,j-1], image[i,j-1]]\n            binary = sum(2**k for k, n in enumerate(neighbors) if n > center)\n            patterns.append(binary)\n    return float(np.var(patterns))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in left half versus right half\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    median_val = np.median(image)\n    left_half = image[:, :w//2]\n    right_half = image[:, w//2:]\n    left_above = np.sum(left_half > median_val)\n    right_above = np.sum(right_half > median_val)\n    if right_above == 0:\n        return float(left_above + 1.0)\n    return float(left_above / right_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Energy concentration in center quadrant relative to total image energy\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    center_energy = np.sum(center_region ** 2)\n    total_energy = np.sum(image ** 2)\n    if total_energy == 0:\n        return 0.0\n    return float(center_energy / total_energy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile to pixels below 10th percentile\"\n    if image.size == 0:\n        return 1.0\n    p10 = np.percentile(image, 10)\n    p90 = np.percentile(image, 90)\n    high_count = np.sum(image >= p90)\n    low_count = np.sum(image <= p10)\n    if low_count == 0:\n        return float(high_count)\n    return float(high_count / low_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between corners and center point\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    center_val = image[h//2, w//2]\n    corner_sum = image[0, 0] + image[0, w-1] + image[h-1, 0] + image[h-1, w-1]\n    corner_avg = corner_sum / 4\n    return float(abs(corner_avg - center_val))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Weighted sum of distances from intensity centroid to image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    total_intensity = np.sum(image)\n    if total_intensity == 0:\n        return 0.0\n    y_coords, x_coords = np.mgrid[0:h, 0:w]\n    centroid_y = np.sum(y_coords * image) / total_intensity\n    centroid_x = np.sum(x_coords * image) / total_intensity\n    center_y, center_x = h / 2, w / 2\n    distance = np.sqrt((centroid_y - center_y)**2 + (centroid_x - center_x)**2)\n    return float(distance)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local contrast measured as standard deviation of 3x3 neighborhood means\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_means = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            local_means.append(np.mean(neighborhood))\n    return float(np.std(local_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum row variance to maximum column variance\"\n    if image.size == 0 or image.shape[0] < 2 or image.shape[1] < 2:\n        return 1.0\n    row_variances = np.var(image, axis=1)\n    col_variances = np.var(image, axis=0)\n    max_row_var = np.max(row_variances)\n    max_col_var = np.max(col_variances)\n    if max_col_var == 0:\n        return float(max_row_var)\n    return float(max_row_var / max_col_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skew = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skew)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median in left half versus right half\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    median_val = np.median(image)\n    left_above = np.sum(image[:, :w//2] > median_val)\n    right_above = np.sum(image[:, w//2:] > median_val)\n    if right_above == 0:\n        return float(left_above)\n    return float(left_above / right_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance from center pixel to all other pixels weighted by intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_r, center_c = h // 2, w // 2\n    total_weight = 0.0\n    weighted_distance = 0.0\n    for r in range(h):\n        for c in range(w):\n            weight = image[r, c]\n            distance = np.sqrt((r - center_r)**2 + (c - center_c)**2)\n            weighted_distance += weight * distance\n            total_weight += weight\n    if total_weight == 0:\n        return 0.0\n    return float(weighted_distance / total_weight)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of pixel intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=16, range=(image.min(), image.max() + 1e-10))\n    hist = hist / np.sum(hist)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    entropy = -np.sum(hist * np.log2(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of second moment to first moment of intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    first_moment = np.mean(flat)\n    second_moment = np.mean(flat**2)\n    if first_moment == 0:\n        return float(second_moment)\n    return float(second_moment / first_moment)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum consecutive pixels above 75th percentile in any row\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 75)\n    max_consecutive = 0\n    for row in image:\n        current_consecutive = 0\n        for pixel in row:\n            if pixel > threshold:\n                current_consecutive += 1\n                max_consecutive = max(max_consecutive, current_consecutive)\n            else:\n                current_consecutive = 0\n    return float(max_consecutive)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between any two corner pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    corners = [image[0, 0], image[0, w-1], image[h-1, 0], image[h-1, w-1]]\n    return float(np.max(corners) - np.min(corners))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of intensity distribution using histogram bins\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=32, density=True)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    return float(-np.sum(hist * np.log2(hist + 1e-10)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above median to total pixels\"\n    if image.size == 0:\n        return 0.5\n    median_val = np.median(image)\n    above_median = np.sum(image > median_val)\n    return float(above_median / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of pixel intensities from diagonal pattern\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    y_coords, x_coords = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n    expected_diag = (y_coords + x_coords) / (h + w - 2) * (np.max(image) - np.min(image)) + np.min(image)\n    return float(np.mean(np.abs(image - expected_diag)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of 90th percentile to 10th percentile intensity\"\n    if image.size == 0:\n        return 1.0\n    p90 = np.percentile(image, 90)\n    p10 = np.percentile(image, 10)\n    if p10 == 0:\n        return float(p90)\n    return float(p90 / p10)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average absolute curvature of intensity along main diagonal\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    diag_len = min(h, w)\n    if diag_len < 3:\n        return 0.0\n    diagonal = np.array([image[i, i] for i in range(diag_len)])\n    second_deriv = np.abs(np.diff(diagonal, n=2))\n    return float(np.mean(second_deriv))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Coefficient of variation of local neighborhood standard deviations\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_stds = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            local_stds.append(np.std(neighborhood))\n    local_stds = np.array(local_stds)\n    mean_std = np.mean(local_stds)\n    if mean_std == 0:\n        return 0.0\n    return float(np.std(local_stds) / mean_std)\n",
    "def feature(image: np.ndarray) -> float:\n    \"Energy measure from sum of squared pixel values normalized by image size\"\n    if image.size == 0:\n        return 0.0\n    energy = np.sum(image ** 2)\n    return float(energy / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    pixels = image.flatten()\n    mean_val = np.mean(pixels)\n    std_val = np.std(pixels)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((pixels - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile to pixels below 10th percentile\"\n    if image.size == 0:\n        return 1.0\n    p10 = np.percentile(image, 10)\n    p90 = np.percentile(image, 90)\n    low_count = np.sum(image <= p10)\n    high_count = np.sum(image >= p90)\n    if low_count == 0:\n        return float(high_count)\n    return float(high_count / low_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average magnitude of second-order gradients\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    grad_yy, grad_yx = np.gradient(grad_y)\n    grad_xy, grad_xx = np.gradient(grad_x)\n    laplacian = grad_xx + grad_yy\n    return float(np.mean(np.abs(laplacian)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum row-wise intensity ranges\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 1.0\n    row_ranges = np.max(image, axis=1) - np.min(image, axis=1)\n    max_range = np.max(row_ranges)\n    min_range = np.min(row_ranges)\n    if min_range == 0:\n        return float(max_range)\n    return float(max_range / min_range)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local homogeneity measured by inverse distance weighted variance\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    center = image[1:-1, 1:-1]\n    neighbors = np.array([\n        image[:-2, 1:-1], image[2:, 1:-1],\n        image[1:-1, :-2], image[1:-1, 2:]\n    ])\n    diffs = np.abs(neighbors - center)\n    homogeneity = 1.0 / (1.0 + np.mean(diffs))\n    return float(homogeneity)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy approximation using histogram of intensity bins\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=16, density=True)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    entropy = -np.sum(hist * np.log2(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between diagonally opposite quadrants\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return 0.0\n    top_left = np.mean(image[:h//2, :w//2])\n    bottom_right = np.mean(image[h//2:, w//2:])\n    top_right = np.mean(image[:h//2, w//2:])\n    bottom_left = np.mean(image[h//2:, :w//2])\n    diag_diff = abs(top_left - bottom_right) + abs(top_right - bottom_left)\n    return float(diag_diff / 2)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above mean in central cross to total above mean\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return 0.5\n    mean_val = np.mean(image)\n    cross_mask = np.zeros_like(image, dtype=bool)\n    cross_mask[h//2, :] = True\n    cross_mask[:, w//2] = True\n    above_mean = image > mean_val\n    cross_above = np.sum(above_mean & cross_mask)\n    total_above = np.sum(above_mean)\n    if total_above == 0:\n        return 0.0\n    return float(cross_above / total_above)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum difference between adjacent column means\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    col_diffs = np.abs(np.diff(col_means))\n    return float(np.max(col_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of range in brightest row to range in darkest row\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 1.0\n    row_means = np.mean(image, axis=1)\n    brightest_row_idx = np.argmax(row_means)\n    darkest_row_idx = np.argmin(row_means)\n    bright_range = np.ptp(image[brightest_row_idx, :])\n    dark_range = np.ptp(image[darkest_row_idx, :])\n    if dark_range == 0:\n        return float(bright_range)\n    return float(bright_range / dark_range)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Normalized sum of squared differences from median\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    squared_diffs = (image - median_val) ** 2\n    sum_squared_diffs = np.sum(squared_diffs)\n    return float(sum_squared_diffs / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum intensity in each quadrant, averaged\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return float(image.max() / max(image.min(), 1e-8))\n    h_mid, w_mid = h // 2, w // 2\n    quadrants = [\n        image[:h_mid, :w_mid], image[:h_mid, w_mid:],\n        image[h_mid:, :w_mid], image[h_mid:, w_mid:]\n    ]\n    ratios = []\n    for quad in quadrants:\n        if quad.size > 0:\n            max_val, min_val = quad.max(), quad.min()\n            ratios.append(max_val / max(min_val, 1e-8))\n    return float(np.mean(ratios)) if ratios else 1.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy of intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=32, density=True)\n    hist = hist + 1e-12\n    entropy = -np.sum(hist * np.log2(hist))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Circular symmetry score around image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_h, center_w = h // 2, w // 2\n    if h < 3 or w < 3:\n        return 1.0\n    radius = min(center_h, center_w, 10)\n    if radius < 2:\n        return 1.0\n    angles = np.linspace(0, 2*np.pi, 8, endpoint=False)\n    values = []\n    for angle in angles:\n        y = int(center_h + radius * np.sin(angle))\n        x = int(center_w + radius * np.cos(angle))\n        if 0 <= y < h and 0 <= x < w:\n            values.append(image[y, x])\n    if len(values) < 2:\n        return 1.0\n    symmetry = 1.0 / (1.0 + np.std(values))\n    return float(symmetry)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of bright cluster compactness to total bright area\"\n    if image.size == 0:\n        return 0.0\n    threshold = np.percentile(image, 85)\n    bright_mask = image > threshold\n    bright_count = np.sum(bright_mask)\n    if bright_count == 0:\n        return 0.0\n    bright_coords = np.where(bright_mask)\n    if len(bright_coords[0]) < 2:\n        return 1.0\n    center_y, center_x = np.mean(bright_coords[0]), np.mean(bright_coords[1])\n    distances = np.sqrt((bright_coords[0] - center_y)**2 + (bright_coords[1] - center_x)**2)\n    compactness = 1.0 / (1.0 + np.mean(distances))\n    return float(compactness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance of high-intensity pixels from image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h / 2, w / 2\n    threshold = np.percentile(image, 75)\n    high_pixels = np.where(image > threshold)\n    if len(high_pixels[0]) == 0:\n        return 0.0\n    distances = np.sqrt((high_pixels[0] - center_y)**2 + (high_pixels[1] - center_x)**2)\n    return float(np.mean(distances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of diagonal variance to anti-diagonal variance\"\n    if image.size == 0 or image.shape[0] != image.shape[1]:\n        return 1.0\n    n = min(image.shape)\n    if n < 2:\n        return 1.0\n    diagonal = np.diag(image[:n, :n])\n    anti_diagonal = np.diag(np.fliplr(image[:n, :n]))\n    diag_var = np.var(diagonal)\n    anti_diag_var = np.var(anti_diagonal)\n    if anti_diag_var == 0:\n        return float(diag_var + 1)\n    return float(diag_var / anti_diag_var)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of distances between consecutive local maxima\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_maxima = []\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            if image[i, j] == np.max(neighborhood):\n                local_maxima.append((i, j))\n    if len(local_maxima) < 2:\n        return 0.0\n    distances = []\n    for k in range(len(local_maxima)-1):\n        y1, x1 = local_maxima[k]\n        y2, x2 = local_maxima[k+1]\n        distances.append(np.sqrt((y2-y1)**2 + (x2-x1)**2))\n    return float(np.std(distances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of mean intensity in corners to center square\"\n    if image.size == 0 or image.shape[0] < 4 or image.shape[1] < 4:\n        return 1.0\n    h, w = image.shape\n    corner_size = min(h//4, w//4)\n    if corner_size < 1:\n        return 1.0\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center_start_h, center_start_w = h//4, w//4\n    center_end_h, center_end_w = 3*h//4, 3*w//4\n    center = image[center_start_h:center_end_h, center_start_w:center_end_w]\n    corner_mean = np.mean(corners)\n    center_mean = np.mean(center)\n    if center_mean == 0:\n        return float(corner_mean + 1)\n    return float(corner_mean / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of pixels along the main diagonal\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    diagonal_values = image[np.arange(min_dim), np.arange(min_dim)]\n    return float(np.mean(diagonal_values))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum pixel values in each quadrant averaged\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 2 or w < 2:\n        return float(image.max() / max(image.min(), 1))\n    mid_h, mid_w = h // 2, w // 2\n    quadrants = [\n        image[:mid_h, :mid_w],\n        image[:mid_h, mid_w:],\n        image[mid_h:, :mid_w],\n        image[mid_h:, mid_w:]\n    ]\n    ratios = []\n    for quad in quadrants:\n        if quad.size > 0:\n            min_val = max(quad.min(), 1)\n            ratios.append(quad.max() / min_val)\n    return float(np.mean(ratios)) if ratios else 1.0\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on pixel value histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=16, density=True)\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    return float(-np.sum(hist * np.log(hist + 1e-10)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance from center for pixels above mean intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_r, center_c = h / 2, w / 2\n    mean_val = np.mean(image)\n    above_mean = image > mean_val\n    if not np.any(above_mean):\n        return 0.0\n    r_coords, c_coords = np.where(above_mean)\n    distances = np.sqrt((r_coords - center_r) ** 2 + (c_coords - center_c) ** 2)\n    return float(np.mean(distances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skew = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skew)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner pixels average to center pixel intensity\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.mean(image))\n    corners = [image[0, 0], image[0, w-1], image[h-1, 0], image[h-1, w-1]]\n    corner_avg = np.mean(corners)\n    center_val = max(image[h//2, w//2], 1)\n    return float(corner_avg / center_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise maximum values\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_maxes = np.max(image, axis=0)\n    return float(np.std(col_maxes))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above mean in diagonal corners versus anti-diagonal corners\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    threshold = np.mean(image)\n    corner_size = min(h//4, w//4)\n    tl = np.sum(image[:corner_size, :corner_size] > threshold)\n    br = np.sum(image[-corner_size:, -corner_size:] > threshold)\n    tr = np.sum(image[:corner_size, -corner_size:] > threshold)\n    bl = np.sum(image[-corner_size:, :corner_size] > threshold)\n    diag_corners = tl + br\n    anti_diag_corners = tr + bl\n    if anti_diag_corners == 0:\n        return float(diag_corners)\n    return float(diag_corners / anti_diag_corners)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Range of pixel intensities normalized by mean intensity\"\n    if image.size == 0:\n        return 0.0\n    pixel_range = np.max(image) - np.min(image)\n    mean_val = np.mean(image)\n    if mean_val == 0:\n        return float(pixel_range)\n    return float(pixel_range / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Concentration index: pixels within one std of mean divided by total pixels\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    std_val = np.std(image)\n    within_one_std = np.sum(np.abs(image - mean_val) <= std_val)\n    return float(within_one_std / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average distance from center weighted by pixel intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_h, center_w = h / 2, w / 2\n    total_weight = 0.0\n    weighted_distance = 0.0\n    for i in range(h):\n        for j in range(w):\n            weight = image[i, j]\n            distance = np.sqrt((i - center_h)**2 + (j - center_w)**2)\n            weighted_distance += weight * distance\n            total_weight += weight\n    if total_weight == 0:\n        return 0.0\n    return float(weighted_distance / total_weight)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of 75th percentile to 25th percentile pixel values\"\n    if image.size == 0:\n        return 1.0\n    p25 = np.percentile(image, 25)\n    p75 = np.percentile(image, 75)\n    if p25 == 0:\n        return float(p75)\n    return float(p75 / p25)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy approximation using histogram of 10 intensity bins\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=10)\n    hist = hist + 1e-10\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log2(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum intensity in center versus corners\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    corner_size = min(h//8, w//8, 5)\n    if corner_size < 1:\n        corner_size = 1\n    corners = [image[:corner_size, :corner_size], \n               image[:corner_size, -corner_size:],\n               image[-corner_size:, :corner_size], \n               image[-corner_size:, -corner_size:]]\n    center_max = np.max(center_region) if center_region.size > 0 else 0\n    corner_max = max(np.max(corner) for corner in corners)\n    if corner_max == 0:\n        return float(center_max)\n    return float(center_max / corner_max)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy approximation of intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=32, range=(image.min(), image.max() + 1e-8))\n    hist = hist + 1e-10\n    prob = hist / np.sum(hist)\n    entropy = -np.sum(prob * np.log(prob))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Mean distance of pixel intensities from image center point\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    center_intensity = image[center_y, center_x]\n    distances = np.abs(image - center_intensity)\n    return float(np.mean(distances))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry between diagonal quadrants\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.0\n    mid_h, mid_w = h // 2, w // 2\n    top_left = np.mean(image[:mid_h, :mid_w])\n    bottom_right = np.mean(image[mid_h:, mid_w:])\n    top_right = np.mean(image[:mid_h, mid_w:])\n    bottom_left = np.mean(image[mid_h:, :mid_w])\n    diag1 = abs(top_left - bottom_right)\n    diag2 = abs(top_right - bottom_left)\n    return float(diag1 - diag2)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above mean in checkerboard pattern\"\n    if image.size == 0:\n        return 0.5\n    h, w = image.shape\n    mean_val = np.mean(image)\n    checker1 = 0\n    checker2 = 0\n    total1 = 0\n    total2 = 0\n    for i in range(h):\n        for j in range(w):\n            if (i + j) % 2 == 0:\n                total1 += 1\n                if image[i, j] > mean_val:\n                    checker1 += 1\n            else:\n                total2 += 1\n                if image[i, j] > mean_val:\n                    checker2 += 1\n    if total1 == 0 or total2 == 0:\n        return 0.5\n    ratio1 = checker1 / total1\n    ratio2 = checker2 / total2\n    return float(abs(ratio1 - ratio2))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Asymmetry measure between left and right halves of the image\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    h, w = image.shape\n    left_half = image[:, :w//2]\n    right_half = np.fliplr(image[:, w//2:])\n    min_width = min(left_half.shape[1], right_half.shape[1])\n    left_crop = left_half[:, :min_width]\n    right_crop = right_half[:, :min_width]\n    asymmetry = np.mean(np.abs(left_crop - right_crop))\n    return float(asymmetry)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile in corners versus center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    threshold = np.percentile(image, 75)\n    corner_size = min(h//4, w//4)\n    if corner_size == 0:\n        return 0.0\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    corner_bright = np.sum(corners > threshold)\n    center_bright = np.sum(center_region > threshold) if center_region.size > 0 else 1\n    return float(corner_bright / max(center_bright, 1))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Local contrast measure using standard deviation of local means\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    window_size = max(1, min(h//8, w//8))\n    local_means = []\n    for i in range(0, h-window_size+1, window_size):\n        for j in range(0, w-window_size+1, window_size):\n            window = image[i:i+window_size, j:j+window_size]\n            local_means.append(np.mean(window))\n    if len(local_means) == 0:\n        return 0.0\n    return float(np.std(local_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of second moment to first moment of intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    first_moment = np.mean(image)\n    if first_moment == 0:\n        return 0.0\n    second_moment = np.mean(image ** 2)\n    return float(second_moment / (first_moment ** 2))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Edge density measured by high gradient magnitude pixels\"\n    if image.size == 0:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n    edge_threshold = np.percentile(gradient_magnitude, 90)\n    edge_pixels = np.sum(gradient_magnitude > edge_threshold)\n    return float(edge_pixels / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat_image = image.flatten()\n    mean_val = np.mean(flat_image)\n    std_val = np.std(flat_image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((flat_image - mean_val) / std_val) ** 3)\n    return float(skewness)\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum intensity difference between adjacent pixels\"\n    if image.size == 0:\n        return 0.0\n    if image.shape[0] < 2 and image.shape[1] < 2:\n        return 0.0\n    h_diff = np.abs(np.diff(image, axis=0)) if image.shape[0] > 1 else np.array([0])\n    v_diff = np.abs(np.diff(image, axis=1)) if image.shape[1] > 1 else np.array([0])\n    max_h = np.max(h_diff) if h_diff.size > 0 else 0\n    max_v = np.max(v_diff) if v_diff.size > 0 else 0\n    return float(max(max_h, max_v))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile to pixels below 25th percentile\"\n    if image.size == 0:\n        return 1.0\n    p75 = np.percentile(image, 75)\n    p25 = np.percentile(image, 25)\n    high_count = np.sum(image > p75)\n    low_count = np.sum(image < p25)\n    if low_count == 0:\n        return float(high_count)\n    return float(high_count / low_count)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity weighted by distance from center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h // 2, w // 2\n    y_coords, x_coords = np.ogrid[:h, :w]\n    distances = np.sqrt((y_coords - center_y)**2 + (x_coords - center_x)**2)\n    max_dist = np.max(distances)\n    if max_dist == 0:\n        return float(np.mean(image))\n    weights = distances / max_dist\n    weighted_sum = np.sum(image * weights)\n    total_weights = np.sum(weights)\n    return float(weighted_sum / total_weights)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure based on intensity histogram\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=min(32, image.size))\n    hist = hist + 1e-10\n    prob = hist / np.sum(hist)\n    entropy = -np.sum(prob * np.log2(prob))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of second moment to first moment of intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    first_moment = np.mean(flat)\n    second_moment = np.mean(flat**2)\n    if first_moment == 0:\n        return float(second_moment)\n    return float(second_moment / first_moment)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity of local maxima pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 3 or w < 3:\n        return float(np.mean(image))\n    local_max_mask = np.zeros_like(image, dtype=bool)\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            if image[i, j] == np.max(neighborhood):\n                local_max_mask[i, j] = True\n    if not np.any(local_max_mask):\n        return float(np.max(image))\n    return float(np.mean(image[local_max_mask]))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of column-wise mean intensities\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    return float(np.std(col_means))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum to minimum pixel intensity\"\n    if image.size == 0:\n        return 1.0\n    max_val = np.max(image)\n    min_val = np.min(image)\n    if min_val == 0:\n        return float(max_val)\n    return float(max_val / min_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent columns\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_diffs = np.abs(np.diff(image, axis=1))\n    return float(np.mean(col_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of pixels above the median intensity\"\n    if image.size == 0:\n        return 0.5\n    median_val = np.median(image)\n    above_median = np.sum(image > median_val)\n    return float(above_median / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Intensity range normalized by mean intensity\"\n    if image.size == 0:\n        return 0.0\n    intensity_range = np.max(image) - np.min(image)\n    mean_intensity = np.mean(image)\n    if mean_intensity == 0:\n        return float(intensity_range)\n    return float(intensity_range / mean_intensity)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average absolute deviation from median intensity\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    deviations = np.abs(image - median_val)\n    return float(np.mean(deviations))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half average intensity\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    if right_half == 0:\n        return float(left_half)\n    return float(left_half / right_half)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Sum of squared differences from mean intensity\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    squared_diffs = (image - mean_val) ** 2\n    return float(np.sum(squared_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Interquartile range of pixel intensities\"\n    if image.size == 0:\n        return 0.0\n    q75 = np.percentile(image, 75)\n    q25 = np.percentile(image, 25)\n    return float(q75 - q25)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between edge rows and center rows\"\n    if image.size == 0 or image.shape[0] < 4:\n        return 0.0\n    h = image.shape[0]\n    edge_thickness = max(1, h//8)\n    edge_rows = np.concatenate([image[:edge_thickness, :], image[-edge_thickness:, :]])\n    center_rows = image[edge_thickness:-edge_thickness, :]\n    edge_mean = np.mean(edge_rows)\n    center_mean = np.mean(center_rows)\n    return float(abs(edge_mean - center_mean))\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 90th percentile in center quadrant to total high pixels\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    threshold = np.percentile(image, 90)\n    high_pixels = image > threshold\n    center_h_start, center_h_end = h//4, 3*h//4\n    center_w_start, center_w_end = w//4, 3*w//4\n    center_high = np.sum(high_pixels[center_h_start:center_h_end, center_w_start:center_w_end])\n    total_high = np.sum(high_pixels)\n    if total_high == 0:\n        return 0.0\n    return float(center_high / total_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average of absolute differences between corner regions\"\n    if image.size == 0 or image.shape[0] < 4 or image.shape[1] < 4:\n        return 0.0\n    h, w = image.shape\n    corner_size = min(h//4, w//4, 5)\n    tl = np.mean(image[:corner_size, :corner_size])\n    tr = np.mean(image[:corner_size, -corner_size:])\n    bl = np.mean(image[-corner_size:, :corner_size])\n    br = np.mean(image[-corner_size:, -corner_size:])\n    corners = [tl, tr, bl, br]\n    diffs = []\n    for i in range(len(corners)):\n        for j in range(i+1, len(corners)):\n            diffs.append(abs(corners[i] - corners[j]))\n    return float(np.mean(diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of local maxima to total pixels\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_maxima_count = 0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            center = image[i, j]\n            neighbors = image[i-1:i+2, j-1:j+2]\n            if center == np.max(neighbors):\n                local_maxima_count += 1\n    return float(local_maxima_count / image.size)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Weighted sum of pixels by distance from image center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_h, center_w = h / 2, w / 2\n    weighted_sum = 0.0\n    total_weight = 0.0\n    for i in range(h):\n        for j in range(w):\n            distance = np.sqrt((i - center_h)**2 + (j - center_w)**2)\n            weight = 1.0 / (distance + 1.0)\n            weighted_sum += image[i, j] * weight\n            total_weight += weight\n    if total_weight == 0:\n        return 0.0\n    return float(weighted_sum / total_weight)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum difference between adjacent column means\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    col_means = np.mean(image, axis=0)\n    consecutive_diffs = np.abs(np.diff(col_means))\n    return float(np.max(consecutive_diffs))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Standard deviation of pixel values along the main diagonal\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    min_dim = min(h, w)\n    if min_dim == 0:\n        return 0.0\n    diagonal_values = np.array([image[i, i] for i in range(min_dim)])\n    return float(np.std(diagonal_values))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of maximum pixel value to mean pixel value\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    max_val = np.max(image)\n    if mean_val == 0:\n        return float(max_val)\n    return float(max_val / mean_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Concentration of high-intensity pixels in corners versus center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.5\n    corner_size = min(h//4, w//4)\n    threshold = np.percentile(image, 80)\n    corners = (image[:corner_size, :corner_size].sum() + \n               image[:corner_size, -corner_size:].sum() + \n               image[-corner_size:, :corner_size].sum() + \n               image[-corner_size:, -corner_size:].sum())\n    center = image[h//4:3*h//4, w//4:3*w//4]\n    corner_high = np.sum((image[:corner_size, :corner_size] > threshold)) + np.sum((image[:corner_size, -corner_size:] > threshold)) + np.sum((image[-corner_size:, :corner_size] > threshold)) + np.sum((image[-corner_size:, -corner_size:] > threshold))\n    center_high = np.sum(center > threshold)\n    total_high = corner_high + center_high\n    if total_high == 0:\n        return 0.0\n    return float(corner_high / total_high)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average absolute deviation from median pixel value\"\n    if image.size == 0:\n        return 0.0\n    median_val = np.median(image)\n    return float(np.mean(np.abs(image - median_val)))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of left half to right half standard deviations\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 1.0\n    h, w = image.shape\n    left_std = np.std(image[:, :w//2])\n    right_std = np.std(image[:, w//2:])\n    if right_std == 0:\n        return float(left_std)\n    return float(left_std / right_std)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness measure based on mean, median, and standard deviation\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    median_val = np.median(image)\n    std_val = np.std(image)\n    if std_val == 0:\n        return 0.0\n    return float(3 * (mean_val - median_val) / std_val)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels below median in corners versus center region\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 0.0\n    median_val = np.median(image)\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    corner_below = np.sum(corners < median_val)\n    center_below = np.sum(center_region < median_val)\n    if center_below == 0:\n        return float(corner_below)\n    return float(corner_below / center_below)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Range of pixel intensities normalized by mean intensity\"\n    if image.size == 0:\n        return 0.0\n    pixel_range = np.max(image) - np.min(image)\n    mean_intensity = np.mean(image)\n    if mean_intensity == 0:\n        return float(pixel_range)\n    return float(pixel_range / mean_intensity)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Fraction of pixels that are local maxima in 3x3 neighborhoods\"\n    if image.size == 0 or image.shape[0] < 3 or image.shape[1] < 3:\n        return 0.0\n    h, w = image.shape\n    local_max_count = 0\n    total_interior = (h-2) * (w-2)\n    if total_interior == 0:\n        return 0.0\n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            neighborhood = image[i-1:i+2, j-1:j+2]\n            if image[i, j] == np.max(neighborhood):\n                local_max_count += 1\n    return float(local_max_count / total_interior)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Correlation coefficient between row indices and row mean intensities\"\n    if image.size == 0 or image.shape[0] < 2:\n        return 0.0\n    row_means = np.mean(image, axis=1)\n    row_indices = np.arange(len(row_means))\n    if np.std(row_means) == 0 or np.std(row_indices) == 0:\n        return 0.0\n    correlation = np.corrcoef(row_indices, row_means)[0, 1]\n    return float(correlation if not np.isnan(correlation) else 0.0)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Weighted average intensity where weights are distance from center\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    center_y, center_x = h / 2, w / 2\n    y_coords, x_coords = np.ogrid[:h, :w]\n    distances = np.sqrt((y_coords - center_y)**2 + (x_coords - center_x)**2)\n    weights = distances + 1\n    weighted_sum = np.sum(image * weights)\n    total_weight = np.sum(weights)\n    return float(weighted_sum / total_weight)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy-like measure of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image.flatten(), bins=16, range=(0, 255))\n    hist = hist + 1e-7  # Avoid log(0)\n    probs = hist / np.sum(hist)\n    entropy = -np.sum(probs * np.log(probs))\n    return float(entropy)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution\"\n    if image.size == 0:\n        return 0.0\n    flat = image.flatten()\n    mean_val = np.mean(flat)\n    std_val = np.std(flat)\n    if std_val == 0:\n        return 0.0\n    skew = np.mean(((flat - mean_val) / std_val) ** 3)\n    return float(skew)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of corner region intensity to center region intensity\"\n    if image.size == 0:\n        return 1.0\n    h, w = image.shape\n    if h < 6 or w < 6:\n        return 1.0\n    corner_size = min(h//4, w//4)\n    corners = np.concatenate([\n        image[:corner_size, :corner_size].flatten(),\n        image[:corner_size, -corner_size:].flatten(),\n        image[-corner_size:, :corner_size].flatten(),\n        image[-corner_size:, -corner_size:].flatten()\n    ])\n    center = image[h//3:2*h//3, w//3:2*w//3]\n    corner_mean = np.mean(corners)\n    center_mean = np.mean(center)\n    if center_mean == 0:\n        return float(corner_mean)\n    return float(corner_mean / center_mean)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Contrast between left and right halves of the image\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    w = image.shape[1]\n    left_half = np.mean(image[:, :w//2])\n    right_half = np.mean(image[:, w//2:])\n    return float(abs(left_half - right_half))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Ratio of pixels above 75th percentile to below 25th percentile\"\n    if image.size == 0:\n        return 1.0\n    p25 = np.percentile(image, 25)\n    p75 = np.percentile(image, 75)\n    high_pixels = np.sum(image >= p75)\n    low_pixels = np.sum(image <= p25)\n    if low_pixels == 0:\n        return float(high_pixels)\n    return float(high_pixels / low_pixels)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Average intensity difference between adjacent pixels horizontally\"\n    if image.size == 0 or image.shape[1] < 2:\n        return 0.0\n    horizontal_diff = np.abs(image[:, 1:] - image[:, :-1])\n    return float(np.mean(horizontal_diff))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Skewness of pixel intensity distribution using third moment\"\n    if image.size == 0:\n        return 0.0\n    mean_val = np.mean(image)\n    std_val = np.std(image)\n    if std_val == 0:\n        return 0.0\n    skewness = np.mean(((image - mean_val) / std_val) ** 3)\n    return float(skewness)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Concentration index: ratio of central pixels to total intensity\"\n    if image.size == 0:\n        return 0.0\n    h, w = image.shape\n    if h < 4 or w < 4:\n        return 1.0\n    center_region = image[h//4:3*h//4, w//4:3*w//4]\n    center_sum = np.sum(center_region)\n    total_sum = np.sum(image)\n    if total_sum == 0:\n        return 0.0\n    return float(center_sum / total_sum)\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Maximum local gradient magnitude in the image\"\n    if image.size == 0:\n        return 0.0\n    grad_y, grad_x = np.gradient(image)\n    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n    return float(np.max(gradient_magnitude))\n\n",
    "def feature(image: np.ndarray) -> float:\n    \"Entropy approximation using histogram of intensity bins\"\n    if image.size == 0:\n        return 0.0\n    hist, _ = np.histogram(image, bins=min(32, image.size))\n    hist = hist[hist > 0]\n    if len(hist) == 0:\n        return 0.0\n    prob = hist / np.sum(hist)\n    entropy = -np.sum(prob * np.log2(prob))\n    return float(entropy)\n\n"
  ]
}